---
conversation_id: "6897dc05-09c4-8324-a787-828f77bf4cff"
title: "ループ処理の改善案"
create_time: 1754782726.464258
update_time: 1754784090.084156
language_guess: "en"
num_messages: 25
part_index: 1
part_count: 1
---

### user — 2025-08-09T23:38:45.658000+00:00

while (!cancellationToken.IsCancellationRequested)
        {
            var result = consumer.Consume(cancellationToken);
            if (result == null)
                yield break;
            if (result.IsPartitionEOF)
                continue;

            var value = (TPOCO)mapping.CombineFromAvroKeyValue(result.Message.Key, result.Message.Value!, typeof(TPOCO));
            var headers = new Dictionary<string, string>();
            if (result.Message.Headers != null)
            {
                foreach (var h in result.Message.Headers)
                    headers[h.Key] = System.Text.Encoding.UTF8.GetString(h.GetValueBytes());
            }

            yield return (value, headers);
            await Task.Yield();
        }
この部分で１件で処理が終了する
書き方が悪い？

### system — 2025-08-09T23:38:46.464258+00:00

_(empty)_

### user — 2025-08-09T23:38:46.464258+00:00

_(empty)_

### system — 2025-08-09T23:38:47.391994+00:00

_(empty)_

### tool — 2025-08-09T23:38:47.405752+00:00

_(empty)_

### tool — 2025-08-09T23:38:47.425478+00:00

fileciteturn0file0

using Confluent.Kafka;
using Confluent.Kafka.SyncOverAsync;
using Confluent.SchemaRegistry.Serdes;
using Kafka.Ksql.Linq.Configuration;
using Kafka.Ksql.Linq.Configuration.Abstractions;
using Kafka.Ksql.Linq.Core.Abstractions;
using Kafka.Ksql.Linq.Core.Extensions;
using Kafka.Ksql.Linq.Mapping;
using Kafka.Ksql.Linq.Messaging.Configuration;
using Microsoft.Extensions.Logging;
using Microsoft.Extensions.Options;
using System;
using System.Collections.Generic;
using System.Runtime.CompilerServices;
using System.Threading;
using System.Threading.Tasks;
using ConfluentSchemaRegistry = Confluent.SchemaRegistry;

namespace Kafka.Ksql.Linq.Messaging.Consumers;

internal sealed class KafkaConsumerManager : IDisposable
{
    private readonly KsqlDslOptions _options;
    private readonly ILogger? _logger;
    private readonly Lazy<ConfluentSchemaRegistry.ISchemaRegistryClient> _schemaRegistryClient;
    private readonly Dictionary<Type, EntityModel> _entityModels;
    private readonly MappingRegistry _mappingRegistry;
    private bool _disposed;

#pragma warning disable CS0067 // Event is never used
    public event Func<byte[]?, Exception, string, int, long, DateTime, Headers?, string, string, Task>? DeserializationError;
#pragma warning restore CS0067

    public KafkaConsumerManager(
        MappingRegistry mapping,
        IOptions<KsqlDslOptions> options,
        Dictionary<Type, EntityModel> entityModels,
        ILoggerFactory? loggerFactory = null)
    {
        _mappingRegistry = mapping;
        _options = options?.Value ?? throw new ArgumentNullException(nameof(options));
        _entityModels = entityModels ?? new();
        _logger = loggerFactory?.CreateLogger<KafkaConsumerManager>();
        _schemaRegistryClient = new Lazy<ConfluentSchemaRegistry.ISchemaRegistryClient>(CreateSchemaRegistryClient);
    }

    public async IAsyncEnumerable<(TPOCO, Dictionary<string, string>)> ConsumeAsync<TPOCO>(
        [EnumeratorCancellation] CancellationToken cancellationToken = default) where TPOCO : class
    {
        var model = GetEntityModel<TPOCO>();
        var topic = model.GetTopicName();
        var mapping = _mappingRegistry.GetMapping(typeof(TPOCO));
        var config = BuildConsumerConfig(topic, null);

        var method = typeof(KafkaConsumerManager)
            .GetMethod(nameof(ConsumeInternal), System.Reflection.BindingFlags.NonPublic | System.Reflection.BindingFlags.Instance)!
            .MakeGenericMethod(mapping.AvroKeyType!, mapping.AvroValueType!, typeof(TPOCO));

        var enumerable = (IAsyncEnumerable<(TPOCO, Dictionary<string, string>)>)method
            .Invoke(this, new object?[] { topic, config, mapping, cancellationToken })!;

        await foreach (var item in enumerable.WithCancellation(cancellationToken))
            yield return item;
    }

    private async IAsyncEnumerable<(TPOCO, Dictionary<string, string>)> ConsumeInternal<TKey, TValue, TPOCO>(
        string topicName,
        ConsumerConfig config,
        KeyValueTypeMapping mapping,
        [EnumeratorCancellation] CancellationToken cancellationToken)
        where TKey : class where TValue : class where TPOCO : class
    {
        using var consumer = CreateConsumer<TKey, TValue>(config);
        consumer.Subscribe(topicName);

        while (!cancellationToken.IsCancellationRequested)
        {
            var result = consumer.Consume(cancellationToken);
            if (result == null)
                yield break;
            if (result.IsPartitionEOF)
                continue;

            var value = (TPOCO)mapping.CombineFromAvroKeyValue(result.Message.Key, result.Message.Value!, typeof(TPOCO));
            var headers = new Dictionary<string, string>();
            if (result.Message.Headers != null)
            {
                foreach (var h in result.Message.Headers)
                    headers[h.Key] = System.Text.Encoding.UTF8.GetString(h.GetValueBytes());
            }

            yield return (value, headers);
            await Task.Yield();
        }
    }

    private IConsumer<TKey, TValue> CreateConsumer<TKey, TValue>(ConsumerConfig config)
        where TKey : class where TValue : class
    {
        return new ConsumerBuilder<TKey, TValue>(config)
            .SetKeyDeserializer(new AvroDeserializer<TKey>(_schemaRegistryClient.Value).AsSyncOverAsync())
            .SetValueDeserializer(new AvroDeserializer<TValue>(_schemaRegistryClient.Value).AsSyncOverAsync())
            .Build();
    }

    private ConfluentSchemaRegistry.ISchemaRegistryClient CreateSchemaRegistryClient()
    {
        var cfg = new ConfluentSchemaRegistry.SchemaRegistryConfig { Url = _options.SchemaRegistry.Url };
        return new ConfluentSchemaRegistry.CachedSchemaRegistryClient(cfg);
    }

    private EntityModel GetEntityModel<T>() where T : class
    {
        if (_entityModels.TryGetValue(typeof(T), out var model))
            return model;
        throw new InvalidOperationException($"Entity model not found for {typeof(T).Name}");
    }

    private ConsumerConfig BuildConsumerConfig(string topicName, KafkaSubscriptionOptions? subscriptionOptions)
    {
        var topicConfig = _options.Topics.TryGetValue(topicName, out var cfg) ? cfg : new TopicSection();
        var groupId = subscriptionOptions?.GroupId ?? topicConfig.Consumer.GroupId;
        if (string.IsNullOrWhiteSpace(groupId))
            groupId = "default-group";

        var consumerConfig = new ConsumerConfig
        {
            BootstrapServers = _options.Common.BootstrapServers,
            ClientId = _options.Common.ClientId,
            GroupId = groupId,
            AutoOffsetReset = Enum.Parse<AutoOffsetReset>(topicConfig.Consumer.AutoOffsetReset),
            EnableAutoCommit = topicConfig.Consumer.EnableAutoCommit,
            AutoCommitIntervalMs = topicConfig.Consumer.AutoCommitIntervalMs,
            SessionTimeoutMs = topicConfig.Consumer.SessionTimeoutMs,
            HeartbeatIntervalMs = topicConfig.Consumer.HeartbeatIntervalMs,
            MaxPollIntervalMs = topicConfig.Consumer.MaxPollIntervalMs,
            FetchMinBytes = topicConfig.Consumer.FetchMinBytes,
            FetchMaxBytes = topicConfig.Consumer.FetchMaxBytes,
            IsolationLevel = Enum.Parse<IsolationLevel>(topicConfig.Consumer.IsolationLevel)
        };

        if (subscriptionOptions != null)
        {
            if (subscriptionOptions.AutoCommit.HasValue)
                consumerConfig.EnableAutoCommit = subscriptionOptions.AutoCommit.Value;
            if (subscriptionOptions.SessionTimeout.HasValue)
                consumerConfig.SessionTimeoutMs = (int)subscriptionOptions.SessionTimeout.Value.TotalMilliseconds;
            if (subscriptionOptions.HeartbeatInterval.HasValue)
                consumerConfig.HeartbeatIntervalMs = (int)subscriptionOptions.HeartbeatInterval.Value.TotalMilliseconds;
            if (subscriptionOptions.MaxPollInterval.HasValue)
                consumerConfig.MaxPollIntervalMs = (int)subscriptionOptions.MaxPollInterval.Value.TotalMilliseconds;
        }

        if (_options.Common.SecurityProtocol != SecurityProtocol.Plaintext)
        {
            consumerConfig.SecurityProtocol = _options.Common.SecurityProtocol;
            if (_options.Common.SaslMechanism.HasValue)
            {
                consumerConfig.SaslMechanism = _options.Common.SaslMechanism.Value;
                consumerConfig.SaslUsername = _options.Common.SaslUsername;
                consumerConfig.SaslPassword = _options.Common.SaslPassword;
            }

            if (!string.IsNullOrEmpty(_options.Common.SslCaLocation))
            {
                consumerConfig.SslCaLocation = _options.Common.SslCaLocation;
                consumerConfig.SslCertificateLocation = _options.Common.SslCertificateLocation;
                consumerConfig.SslKeyLocation = _options.Common.SslKeyLocation;
                consumerConfig.SslKeyPassword = _options.Common.SslKeyPassword;
            }
        }

        foreach (var kvp in topicConfig.Consumer.AdditionalProperties)
            consumerConfig.Set(kvp.Key, kvp.Value);

        return consumerConfig;
    }

    public void Dispose()
    {
        if (_disposed) return;
        if (_schemaRegistryClient.IsValueCreated)
            _schemaRegistryClient.Value.Dispose();
        _disposed = true;
    }
}

### tool — 2025-08-09T23:38:47.455510+00:00

All the files uploaded by the user have been fully loaded. Searching won't provide additional information.

### assistant — 2025-08-09T23:38:47.492458+00:00

_(empty)_

### assistant — 2025-08-09T23:38:48.352671+00:00

_(empty)_

### assistant — 2025-08-09T23:39:02.345423+00:00

原因はこのループ自体というより「呼び出し側が1件だけ受け取って列挙を終了している」か「`Consume` の使い方で想定外の `null`/キャンセルに当たっている」可能性が高いです。チェックポイントと修正案はこれ👇

**まず疑うポイント（超重要）**
- 呼び出し側で `Take(1)` / `FirstAsync()` / 途中 `break` をしていない？  
  → `await foreach` が1回で抜けるとイテレータが破棄され、`using var consumer` もそこで `Dispose` されます。
- `CancellationTokenSource.Cancel()` や `CancelAfter(...)` をどこかで早期に呼んでいない？
- `Consume(cancellationToken)` は通常 `null` を返さず、キャンセル時は **例外** を投げます（`OperationCanceledException`）。`result == null` が起きるのはタイムアウト版 `Consume(TimeSpan)` を使ったときなので、ここに来ているなら別経路で `null` を作っているかも。

**安全なループ実装（例）**
タイムアウト版で回しつつ例外を明示処理する方がデバッグしやすいです。

```csharp
while (!cancellationToken.IsCancellationRequested)
{
    try
    {
        var result = consumer.Consume(TimeSpan.FromMilliseconds(250)); // タイムアウト式
        if (result == null) 
            continue; // タイムアウトは普通に継続

        if (result.IsPartitionEOF)
            continue;

        var value = (TPOCO)mapping.CombineFromAvroKeyValue(result.Message.Key, result.Message.Value!, typeof(TPOCO));

        var headers = new Dictionary<string, string>();
        if (result.Message.Headers is { Count: > 0 })
        {
            foreach (var h in result.Message.Headers)
                headers[h.Key] = System.Text.Encoding.UTF8.GetString(h.GetValueBytes());
        }

        yield return (value, headers);
        // await Task.Yield(); ← 基本不要。呼び出し側が続けて列挙しないとここで終わったように見えることがある
    }
    catch (OperationCanceledException)
    {
        break; // キャンセル時は終了
    }
    catch (Exception ex)
    {
        _logger?.LogError(ex, "Consume loop error");
        // 必要なら break/continue を判断
    }
}
```

**呼び出し側の最低限の形**
```csharp
await foreach (var (val, hdrs) in consumerManager.ConsumeAsync<MyPoco>(cts.Token))
{
    // ここでbreakしない。処理が重いならキュー渡し等を検討
}
```

**追加の見直しポイント**
- `EnablePartitionEof` を `false` に（不要なら）。EOF が多いと混乱します。
- ループ頭でログを仕込む（例：`_logger.LogDebug("Loop alive, ct={CT}", cancellationToken.IsCancellationRequested);`）。  
  1件後に **本当に** ループが回っていないのか、呼び出し側が抜けているのかを切り分け。
- `using var consumer` の外側に `try/finally` を置き、終了時に `consumer.Close()` を呼ぶとコミット・クリーンアップが確実。

上記を入れても1件で止まるなら、呼び出し側の `await foreach` 全体を見せてくれれば、どこで列挙が終わっているか一緒に詰めます。  

（送信: [[REDACTED_PHONE]]:39 JST）

### assistant — 2025-08-09T23:39:09.621262+00:00

_(empty)_

### user — 2025-08-09T23:43:24.734000+00:00

try catch内で  yield return (value, headers);は使えない

### assistant — 2025-08-09T23:43:25.428355+00:00

そう、それがC#の制約です。`yield return / yield break` は  
- `try` の **中** ではOKだけど、  
- **`catch` と `finally` の中では使えない**（`try-catch` 構造の「try」でもNG扱いになるケースがある）  

なので、例外処理の粒度を分けて「`yield` は例外ハンドリングの外」に出す形にしましょう。定番パターンはこれ。

```csharp
while (!cancellationToken.IsCancellationRequested)
{
    ConsumeResult<byte[], byte[]>? result = null;

    try
    {
        result = consumer.Consume(TimeSpan.FromMilliseconds(250));
    }
    catch (OperationCanceledException)
    {
        break;
    }
    catch (Exception ex)
    {
        _logger?.LogError(ex, "Consume failed");
        continue; // 1レコードだけ落として継続
    }

    if (result == null || result.IsPartitionEOF)
        continue;

    TPOCO value;
    Dictionary<string, string> headers;

    // レコード変換の例外は個別に握りつぶす
    try
    {
        value = (TPOCO)mapping.CombineFromAvroKeyValue(
            result.Message.Key, result.Message.Value!, typeof(TPOCO));

        headers = new();
        if (result.Message.Headers is { Count: > 0 })
        {
            foreach (var h in result.Message.Headers)
                headers[h.Key] = System.Text.Encoding.UTF8.GetString(h.GetValueBytes());
        }
    }
    catch (Exception ex)
    {
        _logger?.LogError(ex, "Record transform failed, skip one");
        continue;
    }

    // ← try/catch の外で yield
    yield return (value, headers);
    // await Task.Yield(); // 基本不要
}
```

ポイント  
- `Consume` 用の `try` と、**変換処理** 用の `try` を分離。  
- どちらの `try` にも `yield` を置かない。  
- 例外時は `continue`/`break` にして、正常系だけ最後に `yield return`。

これで「1件で終わっちゃう」誤作動も切り分けやすくなります。必要なら `EnablePartitionEof=false` も検討してね。

— 送信: [[REDACTED_PHONE]]:44 JST

### system — 2025-08-09T23:43:25.701583+00:00

_(empty)_

### assistant — 2025-08-09T23:43:26.101521+00:00

_(empty)_

### assistant — 2025-08-09T23:43:30.713373+00:00

_(empty)_

### user — 2025-08-09T23:49:44.936000+00:00

if (result == null || result.IsPartitionEOF)
        continue;
これだとOperationCanceledExceptionのbreakがなくなる

### system — 2025-08-09T23:49:45.427944+00:00

_(empty)_

### assistant — 2025-08-09T23:49:46.128068+00:00

_(empty)_

### assistant — 2025-08-09T23:49:47.948754+00:00

なるほど、その指摘は正しいです。**タイムアウト版 `Consume(TimeSpan)` を使う場合**は `OperationCanceledException` は投げられないので、`catch (OperationCanceledException)` での `break` は「役に立たない」＝なくなります。その代わりに**ループ先頭の `IsCancellationRequested` で抜ける**のが正解です。

使い分けはこの2択でOK：

### パターンA（タイムアウトでポーリング）
`Consume(TimeSpan)`＋`IsCancellationRequested` で終了判定。`OperationCanceledException` は発生しない前提。
```csharp
while (!cancellationToken.IsCancellationRequested)
{
    ConsumeResult<byte[], byte[]>? result = null;
    try
    {
        result = consumer.Consume(TimeSpan.FromMilliseconds(250)); // ← ここは例外出ない
    }
    catch (Exception ex)
    {
        _logger?.LogError(ex, "Consume failed");
        continue;
    }

    if (result == null || result.IsPartitionEOF)
        continue;

    TPOCO value;
    Dictionary<string,string> headers;
    try
    {
        value = (TPOCO)mapping.CombineFromAvroKeyValue(result.Message.Key, result.Message.Value!, typeof(TPOCO));
        headers = new();
        if (result.Message.Headers is { Count: > 0 })
            foreach (var h in result.Message.Headers)
                headers[h.Key] = System.Text.Encoding.UTF8.GetString(h.GetValueBytes());
    }
    catch (Exception ex)
    {
        _logger?.LogError(ex, "Transform failed, skip");
        continue;
    }

    yield return (value, headers); // try/catch の外
}
```

### パターンB（ブロッキングで待つ）
`Consume(cancellationToken)` を使って **キャンセル時は例外で抜ける**。こちらは `catch (OperationCanceledException)` が生きます。
```csharp
while (true)
{
    ConsumeResult<byte[], byte[]> result;
    try
    {
        result = consumer.Consume(cancellationToken); // ← キャンセル時は OCE
    }
    catch (OperationCanceledException)
    {
        break; // 明示的に終了
    }
    catch (Exception ex)
    {
        _logger?.LogError(ex, "Consume failed");
        continue;
    }

    if (result.IsPartitionEOF)
        continue;

    TPOCO value;
    Dictionary<string,string> headers;
    try
    {
        value = (TPOCO)mapping.CombineFromAvroKeyValue(result.Message.Key, result.Message.Value!, typeof(TPOCO));
        headers = new();
        if (result.Message.Headers is { Count: > 0 })
            foreach (var h in result.Message.Headers)
                headers[h.Key] = System.Text.Encoding.UTF8.GetString(h.GetValueBytes());
    }
    catch (Exception ex)
    {
        _logger?.LogError(ex, "Transform failed, skip");
        continue;
    }

    yield return (value, headers);
}
```

結論：
- **Aを使うなら** `result == null` で単にスルーし、終了は `IsCancellationRequested` で判定（`catch OCE` は不要）。
- **Bを使うなら** `Consume(cancellationToken)`＋`catch (OperationCanceledException) { break; }` にする。

好みと要件（スレッド占有を避けたい／レイテンシ重視など）で選んでください。どっちでも `yield` は **try/catch の外** に置くのが鉄則です。

（送信: [[REDACTED_PHONE]]:50 JST）

### assistant — 2025-08-09T23:49:52.108288+00:00

_(empty)_

### system — 2025-08-10T00:01:24.628712+00:00

_(empty)_

### assistant — 2025-08-10T00:01:24.676322+00:00

よかった！🎉  
これで1件で終わらずにちゃんとループ回るはずですし、`yield` の制約もクリアですね。  
あとは必要に応じて `EnablePartitionEof=false` と短めのタイムアウトを組み合わせれば、余計なEOFや無駄待機も減らせます。  

もし呼び出し側が「すぐに抜けちゃう」ケースがまだ出たら、`await foreach` 側のコードも見て一緒にデバッグできますよ。  

（送信: [[REDACTED_PHONE]]:53 JST）

### user — 2025-08-10T00:01:25.004000+00:00

OKとおった
