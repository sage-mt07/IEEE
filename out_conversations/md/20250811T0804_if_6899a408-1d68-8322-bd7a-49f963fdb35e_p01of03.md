---
conversation_id: "6899a408-1d68-8322-bd7a-49f963fdb35e"
title: "ifæ¡ä»¶æ”¹å–„æ¡ˆ"
create_time: 1754899494.597029
update_time: 1754914148.442342
language_guess: "en"
num_messages: 365
part_index: 1
part_count: 3
---

### assistant â€” 2025-08-11T08:04:54.086962+00:00

_(empty)_
### assistant â€” 2025-08-11T08:04:54.100221+00:00

æ‰¿çŸ¥ã—ã¾ã—ãŸã€‚  
ã“ã®ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ã® `if (msg.Value.Id == 3)` éƒ¨åˆ†ã¯ã€  
**ã€Œã©ã“ã§ commit ã™ã‚‹ã‹ã€ã‚’æ˜ç¢ºåŒ–ã™ã‚‹ãŸã‚ã®æ¡ä»¶å¼**ã§ã™ãŒã€  
ä»Šã®ã¾ã¾ã ã¨æ•°å­—ãƒ™ã‚¿æ›¸ããªã®ã§ã€ãƒ†ã‚¹ãƒˆæ„å›³ãŒã‚³ãƒ¼ãƒ‰ã‹ã‚‰ã¯èª­ã¿å–ã‚Šã¥ã‚‰ã„ã§ã™ã€‚  

æ”¹å–„æ¡ˆã¨ã—ã¦ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªæ–¹é‡ãŒè€ƒãˆã‚‰ã‚Œã¾ã™ã€‚

---

## 1. **æ„å‘³ã®ã‚ã‚‹å®šæ•°ï¼å¤‰æ•°ã«ç½®ãæ›ãˆã‚‹**
```csharp
const int CommitTriggerId = 3;

...

if (msg.Value.Id == CommitTriggerId)
{
    await msg.CommitAsync();
    break;
}
```
- **æ„å›³ãŒã‚ã‹ã‚Šã‚„ã™ã„**  
  ã€ŒId ãŒ 3 ã®ã¨ãã« commitã€ã¨ã„ã†æ„å‘³ã‚’ã€åå‰ä»˜ãã®å€¤ã§èª¬æ˜ã§ãã¾ã™ã€‚
- å¾Œã‹ã‚‰ commit æ¡ä»¶ã‚’å¤‰ãˆãŸã„ã¨ãã«æ•°å­—ã‚’æ¢ã—ã¦ç½®ãæ›ãˆã‚‹å¿…è¦ãŒãªããªã‚‹ã€‚

---

## 2. **`ShouldCommit` ãƒ¡ã‚½ãƒƒãƒ‰åŒ–**
```csharp
private static bool ShouldCommit(ManualCommitContext.Sample sample) => sample.Id == 3;

...

if (ShouldCommit(msg.Value))
{
    await msg.CommitAsync();
    break;
}
```
- æ¡ä»¶ãƒ­ã‚¸ãƒƒã‚¯ã‚’å¤–ã«å‡ºã™ã“ã¨ã§ã€ãƒ†ã‚¹ãƒˆæœ¬ä½“ã®å¯èª­æ€§ã‚’é«˜ã‚ã‚‰ã‚Œã¾ã™ã€‚
- ä»Šå¾Œ commit æ¡ä»¶ãŒè¤‡é›‘åŒ–ã—ãŸå ´åˆã‚‚ãƒ¡ã‚½ãƒƒãƒ‰å†…ã§å¯¾å¿œå¯èƒ½ã€‚

---

## 3. **LINQ/ã‚«ã‚¦ãƒ³ã‚¿åˆ©ç”¨ã§æ˜ç¤ºçš„ã«ã€Œ3ä»¶ç›®ã§commitã€**
ã‚‚ã— `Id` ã§ã¯ãªãã€Œä½•ä»¶ç›®ã« commitã€ã¨ã„ã†æ„å‘³ã‚’ãƒ†ã‚¹ãƒˆã—ãŸã„ãªã‚‰ï¼š
```csharp
var count = 0;
await foreach (var obj in ctx.Samples.ForEachAsync(consumeCts.Token))
{
    count++;
    var msg = (IManualCommitMessage<ManualCommitContext.Sample>)obj;
    if (count == 3)
    {
        await msg.CommitAsync();
        break;
    }
}
```
- ã“ã‚Œã«ã‚ˆã‚Šã€ã€Œ3ä»¶ç›®ã§ commitã€ã¨ã„ã†å‹•ä½œãŒæ„å›³ã¨ã—ã¦æ˜ç¢ºã«ãªã‚Šã¾ã™ã€‚
- `Id` é †åºã¨ç‰©ç†é †åºãŒä¸€è‡´ã—ãªã„ã‚±ãƒ¼ã‚¹ã§ã‚‚å‹•ãã€‚

---

## 4. **Arrangeã§æ¡ä»¶å€¤ã‚’ã‚»ãƒƒãƒˆã™ã‚‹**
ãƒ†ã‚¹ãƒˆã‚·ãƒŠãƒªã‚ªã”ã¨ã« commit ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’å¤‰ãˆã‚‹ãªã‚‰ã€  
ãƒ†ã‚¹ãƒˆãƒ¡ã‚½ãƒƒãƒ‰ã® Arrange éƒ¨åˆ†ã§ commit ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’è¨­å®šï¼š
```csharp
var commitAfterId = 3;

...

if (msg.Value.Id == commitAfterId)
{
    await msg.CommitAsync();
    break;
}
```
- è¤‡æ•°ã‚·ãƒŠãƒªã‚ªã‚’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ãƒ†ã‚¹ãƒˆã«ã—ã‚„ã™ã„ã€‚

---

ğŸ’¡ å€‹äººçš„ã«ã¯ã€ã“ã®ã‚±ãƒ¼ã‚¹ã¯ **ã€Œcommit ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã®æ„å›³ã‚’åå‰ã§è¡¨ã™ã€**ã®ãŒä¸€ç•ªåˆ†ã‹ã‚Šã‚„ã™ã„ã¨æ€ã„ã¾ã™ã€‚  
ã¤ã¾ã‚Š **1 + 2 ã®çµ„ã¿åˆã‚ã›**ï¼ˆå®šæ•°åŒ– + ãƒ¡ã‚½ãƒƒãƒ‰åŒ–ï¼‰ãŒãŠã™ã™ã‚ã§ã™ã€‚

---

ã‚‚ã—å¸Œæœ›ã‚ã‚Œã°ã€ã“ã®ãƒ†ã‚¹ãƒˆå…¨ä½“ã‚’ã€Œcommit æ¡ä»¶ã‚’å¼•æ•°åŒ–ã—ã¦å…±é€šãƒ¡ã‚½ãƒƒãƒ‰ã«ã¾ã¨ã‚ã‚‹ã€å½¢ã«ãƒªãƒ•ã‚¡ã‚¯ã‚¿ã—ãŸã‚µãƒ³ãƒ—ãƒ«ã‚‚ä½œã‚Œã¾ã™ã€‚  
ãã†ã™ã‚‹ã¨å°†æ¥çš„ã«ã€Œ2ä»¶ç›® commitã€ã€Œæœ€å¾Œã®1ä»¶ commitã€ãªã©ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ†ã‚¹ãƒˆãŒç°¡å˜ã«ãªã‚Šã¾ã™ã€‚
### system â€” 2025-08-11T08:04:54.597029+00:00

_(empty)_
### user â€” 2025-08-11T08:04:54.597029+00:00

_(empty)_
### user â€” 2025-08-11T08:04:55.462000+00:00

manual commitã«é–¢ã—ã¦
public class ManualCommitIntegrationTests
{
    [Fact]
    [Trait("Category", "Integration")]
    public async Task ManualCommit_PersistsOffset()
    {
        var groupId = Guid.NewGuid().ToString();

        var options = new KsqlDslOptions
        {
            Common = new CommonSection { BootstrapServers = EnvManualCommitIntegrationTests.KafkaBootstrapServers },
            SchemaRegistry = new SchemaRegistrySection { Url = EnvManualCommitIntegrationTests.SchemaRegistryUrl }
        };
        options.Topics.Add("manual_commit", new Kafka.Ksql.Linq.Messaging.Configuration.TopicSection
        {
            Consumer = new Kafka.Ksql.Linq.Messaging.Configuration.ConsumerSection
            {
                AutoOffsetReset = "Earliest",
                GroupId = groupId
            }
        });

        // produce five messages and commit at the third
        await using (var ctx = new ManualCommitContext(options))
        {
            using var sendCts = new CancellationTokenSource(TimeSpan.FromSeconds(10));
            for (var i = 1; i <= 5; i++)
            {
                await ctx.Samples.AddAsync(new ManualCommitContext.Sample { Id = i }, cancellationToken: sendCts.Token);
            }

            using var consumeCts = new CancellationTokenSource(TimeSpan.FromSeconds(10));
            await foreach (var obj in ctx.Samples.ForEachAsync(consumeCts.Token))
            {
                var msg = (IManualCommitMessage<ManualCommitContext.Sample>)obj;
                if (msg.Value.Id == 3)
                {
                    await msg.CommitAsync();
                    break;
                }
            }
        }

        // verify resuming from the committed offset
        await using (var ctx = new ManualCommitContext(options))
        {
            using var consumeCts = new CancellationTokenSource(TimeSpan.FromSeconds(10));
            ManualCommitContext.Sample? received = null;
            await foreach (var obj in ctx.Samples.ForEachAsync(consumeCts.Token))
            {
                var msg = (IManualCommitMessage<ManualCommitContext.Sample>)obj;
                received = msg.Value;
                await msg.CommitAsync();
                break;
            }

            Assert.Equal(4, received!.Id);
        }
    }
}
ã“ã‚ŒãŒãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰
IFãŒã„ã¾ã„ã¡ã€æ”¹å–„æ¡ˆãã ã•ã„
### assistant â€” 2025-08-11T08:05:30.011415+00:00

ã‚ã‚ã€ãªã‚‹ã»ã©ã€‚  
æ°—ã«ã•ã‚Œã¦ã„ã‚‹ã®ã¯ `if` æ¡ä»¶ã‚ˆã‚Šã‚‚ã€ã“ã® `(IManualCommitMessage<ManualCommitContext.Sample>)obj;` ã¨ã„ã†ã‚­ãƒ£ã‚¹ãƒˆã®ã»ã†ã§ã™ã­ã€‚  

ã“ã®éƒ¨åˆ†ã¯ç¢ºã‹ã« **æ¯å›ç”Ÿã‚­ãƒ£ã‚¹ãƒˆã‚’æ›¸ãã®ãŒå†—é•·** ã§ã€å‹å®‰å…¨æ€§ã‚„å¯èª­æ€§ã®é¢ã§ã‚‚ã‚¹ãƒƒã‚­ãƒªã—ã¾ã›ã‚“ã€‚  
æ”¹å–„ã™ã‚‹ã«ã¯ä¸»ã«ä»¥ä¸‹ã®æ–¹å‘ãŒã‚ã‚Šã¾ã™ã€‚  

---

## 1. **`ForEachAsync` ã®æˆ»ã‚Šå€¤å‹ã‚’ã‚¸ã‚§ãƒãƒªãƒƒã‚¯åŒ–**
ä»Šã® `ForEachAsync` ãŒ `IAsyncEnumerable<object>` ã‚’è¿”ã—ã¦ã„ã‚‹ãªã‚‰ã€  
**å‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å°å…¥**ã—ã¦ `IAsyncEnumerable<IManualCommitMessage<T>>` ã«ã™ã‚Œã°ã‚­ãƒ£ã‚¹ãƒˆä¸è¦ã«ãªã‚Šã¾ã™ã€‚

```csharp
// ç¾çŠ¶
IAsyncEnumerable<object> ForEachAsync(...)

// æ”¹å–„ä¾‹
IAsyncEnumerable<IManualCommitMessage<T>> ForEachAsync<T>(...)
```

å‘¼ã³å‡ºã—å´ï¼š
```csharp
await foreach (var msg in ctx.Samples.ForEachAsync<ManualCommitContext.Sample>(consumeCts.Token))
{
    if (msg.Value.Id == 3)
    {
        await msg.CommitAsync();
        break;
    }
}
```
âœ… **ã‚­ãƒ£ã‚¹ãƒˆãŒæ¶ˆãˆã¦ã‚¹ãƒƒã‚­ãƒª**  
âœ… ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚ã«å‹ãƒã‚§ãƒƒã‚¯ãŒåŠ¹ã  

---

## 2. **æ‹¡å¼µãƒ¡ã‚½ãƒƒãƒ‰ã§å‹ä»˜ãç‰ˆã‚’æä¾›**
`ForEachAsync` ã®æ—¢å­˜ã‚·ã‚°ãƒãƒãƒ£ã‚’å¤‰ãˆã‚‰ã‚Œãªã„å ´åˆã§ã‚‚ã€  
**å‹ä»˜ããƒ©ãƒƒãƒ‘ãƒ¼æ‹¡å¼µãƒ¡ã‚½ãƒƒãƒ‰**ã‚’ä½œã£ã¦ã‚­ãƒ£ã‚¹ãƒˆã‚’éš ã›ã¾ã™ã€‚

```csharp
public static async IAsyncEnumerable<IManualCommitMessage<T>> ForEachAsync<T>(
    this IKsqlEntity<T> entity,
    CancellationToken token)
{
    await foreach (var obj in entity.ForEachAsync(token))
        yield return (IManualCommitMessage<T>)obj;
}
```

å‘¼ã³å‡ºã—å´ï¼š
```csharp
await foreach (var msg in ctx.Samples.ForEachAsync(consumeCts.Token))
{
    if (msg.Value.Id == 3)
    {
        await msg.CommitAsync();
        break;
    }
}
```
âœ… å‘¼ã³å‡ºã—ãŒã‚·ãƒ³ãƒ—ãƒ«ã«ãªã‚Šã€ã‚­ãƒ£ã‚¹ãƒˆãŒ1ã‹æ‰€ã«é›†ç´„ã•ã‚Œã‚‹

---

## 3. **`IManualCommitMessage<T>`ã‚’`Sample`ã«ç›´æ¥çµ„ã¿è¾¼ã‚€**
ã‚‚ã— `ManualCommitContext.Sample` ãŒå¸¸ã« manual commit ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ã—ã¦ä½¿ã‚ã‚Œã‚‹ãªã‚‰ã€  
`IManualCommitMessage<T>` ã‚’å®Ÿè£…ã•ã›ã¦ã‚­ãƒ£ã‚¹ãƒˆè‡ªä½“ã‚’ä¸è¦ã«ã§ãã¾ã™ã€‚

```csharp
public class Sample : IManualCommitMessage<Sample>
{
    public int Id { get; set; }
    public Task CommitAsync() { ... }
}
```

å‘¼ã³å‡ºã—å´ï¼š
```csharp
await foreach (var msg in ctx.Samples.ForEachAsync(consumeCts.Token))
{
    if (msg.Id == 3)
    {
        await msg.CommitAsync();
        break;
    }
}
```
âš  ãŸã ã— **è²¬å‹™åˆ†é›¢ã®è¦³ç‚¹ã§ POCO ã« commit ãƒ­ã‚¸ãƒƒã‚¯ã‚’æ··ãœã‚‹**ã®ã¯è³›å¦ã‚ã‚Šã€‚

---

## 4. **`var (value, commit)` ã‚¿ãƒ—ãƒ«ã§è¿”ã™**
`ForEachAsync` ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’å¤‰ãˆã‚‰ã‚Œã‚‹å ´åˆã€  
`(T Value, Func<Task> Commit)` ã®å½¢ã«ã—ã¦ã—ã¾ã†ã®ã‚‚æ‰‹ã§ã™ã€‚

```csharp
await foreach (var (sample, commit) in ctx.Samples.ForEachAsync(consumeCts.Token))
{
    if (sample.Id == 3)
    {
        await commit();
        break;
    }
}
```
âœ… å‘¼ã³å‡ºã—ãŒéå¸¸ã«ç›´æ„Ÿçš„  
âœ… å‹ã‚­ãƒ£ã‚¹ãƒˆä¸è¦  
âš  API å¤‰æ›´ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆãŒå¤§ãã„

---

ç§ãªã‚‰ã€**ä»Šå¾Œã®APIè¨­è¨ˆã‚’è€ƒãˆã‚‹ã¨ â‘ ã€Œæˆ»ã‚Šå€¤å‹ã‚’ã‚¸ã‚§ãƒãƒªãƒƒã‚¯åŒ–ã€** ãŒä¸€ç•ªå®‰å…¨ã§æ‹¡å¼µæ€§ã‚‚é«˜ã„ã¨æ€ã„ã¾ã™ã€‚  
æ—¢å­˜APIäº’æ›ã‚’ä¿ã¡ãŸã„ãªã‚‰ â‘¡ã€Œæ‹¡å¼µãƒ¡ã‚½ãƒƒãƒ‰ã§å‹ä»˜ãç‰ˆã‚’æä¾›ã€ ãŒç¾å®Ÿçš„ã§ã™ã€‚  

---

ã“ã‚Œã€ã‚‚ã—ã‚ˆã‘ã‚Œã° `ForEachAsync` ã®ä»Šã®ã‚·ã‚°ãƒãƒãƒ£ã‚’è¦‹ã›ã¦ã‚‚ã‚‰ãˆã‚Œã°ã€  
äº’æ›æ€§ã‚’å£Šã•ãšã«ã‚­ãƒ£ã‚¹ãƒˆã‚’æ¶ˆã™æ”¹ä¿®æ¡ˆã‚’å…·ä½“ã‚³ãƒ¼ãƒ‰ã§ä½œã‚Œã¾ã™ã€‚
### user â€” 2025-08-11T08:05:31.398000+00:00

ã„ã¾ã„ã¡ãªã®ã¯
var msg = (IManualCommitMessage<ManualCommitContext.Sample>)obj;
ã“ã®ã‚­ãƒ£ã‚¹ãƒˆ
### system â€” 2025-08-11T08:07:45.032676+00:00

_(empty)_
### user â€” 2025-08-11T08:07:45.579000+00:00

await foreach (var msg in ctx.Samples.ForEachAsync<ManualCommitContext.Sample>(consumeCts.Token))
ã“ã‚Œã‚‚ã„ã¾ã„ã¡ã€€ãã‚Œã§ã‚ã‚Œã°IFã‚’å¤‰æ›´ã—ãŸã»ã†ãŒè‰¯ã„
ãŒ
internal class ManualCommitContext : KsqlContext
{
    public ManualCommitContext(KsqlDslOptions options) : base(options) { }

    protected override bool SkipSchemaRegistration => true;

    public EventSet<Sample> Samples { get; private set; } = null!;

    protected override void OnModelCreating(IModelBuilder modelBuilder)
        => modelBuilder.Entity<Sample>().WithManualCommit();

    [KsqlTopic("manual_commit")]
    internal class Sample
    {
        public int Id { get; set; }
    }
}ã“ã®å®£è¨€ã‚‚è€ƒãˆã©ã“ã‚
### assistant â€” 2025-08-11T08:07:45.828959+00:00

_(empty)_
### assistant â€” 2025-08-11T08:08:07.791332+00:00

ãªã‚‹ã»ã©ã€ã€Œæ¯å› T ã‚’æ˜ç¤ºã—ã¦ `ForEachAsync<T>` ã‚’å‘¼ã¶ãã‚‰ã„ãªã‚‰ã€IFï¼ˆAPIï¼‰ã‚’å¤‰ãˆã¦ã‚­ãƒ£ã‚¹ãƒˆè‡ªä½“ã‚’æ¶ˆã—ãŸã„ã€ã¨ã„ã†æ„å›³ã§ã™ã­ã€‚ã‚ã‹ã‚Šã¾ã™ã€‚  
â€œmanual commit ã‚’ä½¿ã†ã¨ãã ã‘è‡ªç„¶ã«å‹ãŒæ±ºã¾ã‚‹â€ å½¢ã«åˆ‡ã‚‹ã®ãŒæ°—æŒã¡ã„ã„ã®ã§ã€ä¸‹ã®ã©ã‚Œã‹ãŒã‚ªã‚¹ã‚¹ãƒ¡ã§ã™ï¼ˆä¸Šã»ã©æ¨ã—ï¼‰ã€‚

# æ¡ˆAï¼š`Manual` ã‚µãƒ–ãƒ“ãƒ¥ãƒ¼ã‚’ç”Ÿã‚„ã™ï¼ˆæœ€å°ä¾µè¥²ãƒ»æ„å›³ãŒæ˜å¿«ï¼‰
```csharp
public sealed class EventSet<T>
{
    // æ—¢å­˜ï¼šå€¤ã ã‘æ¶ˆè²»ï¼ˆè‡ªå‹•ã‚³ãƒŸãƒƒãƒˆã‚„èª­ã¿å–ã‚Šå°‚ç”¨ã«ä½¿ã†ï¼‰
    public IAsyncEnumerable<T> ForEachAsync(CancellationToken token = default);

    // è¿½åŠ ï¼šæ‰‹å‹•ã‚³ãƒŸãƒƒãƒˆå‰æã®ãƒ“ãƒ¥ãƒ¼
    public ManualView<T> Manual { get; } = new();
}

public sealed class ManualView<T>
{
    public IAsyncEnumerable<ManualMessage<T>> ForEachAsync(CancellationToken token = default);
}

public sealed record ManualMessage<T>(T Value)
{
    public Task CommitAsync() => _commit();
    private readonly Func<Task> _commit;
    public ManualMessage(T value, Func<Task> commit) : this(value) => _commit = commit;

    // ãŠå¥½ã¿ã§åˆ†è§£ã‚µãƒãƒ¼ãƒˆ
    public void Deconstruct(out T value, out Func<Task> commit)
        => (value, commit) = (Value, CommitAsync);
}
```
### ãƒ†ã‚¹ãƒˆå´ï¼ˆã¨ã¦ã‚‚ç´ ç›´ï¼‰
```csharp
await foreach (var msg in ctx.Samples.Manual.ForEachAsync(consumeCts.Token))
{
    if (msg.Value.Id == 3)
    {
        await msg.CommitAsync();
        break;
    }
}
```
ã¾ãŸã¯åˆ†è§£ã§ã•ã‚‰ã«èª­ã¿ã‚„ã™ãï¼š
```csharp
await foreach (var (sample, commit) in ctx.Samples.Manual.ForEachAsync(consumeCts.Token))
{
    if (sample.Id == 3)
    {
        await commit();
        break;
    }
}
```
- æ˜ç¤ºçš„ãªå‹å¼•æ•°ã‚‚ç”Ÿã‚­ãƒ£ã‚¹ãƒˆã‚‚æ¶ˆãˆã¾ã™ã€‚
- ã€Œæ‰‹å‹•ã‚³ãƒŸãƒƒãƒˆã§èª­ã‚€ã€ã¨ã„ã†æ„å›³ãŒ `.Manual` ã§ä¸€ç›®ç­ç„¶ã€‚
- æ—¢å­˜ã® `EventSet<T>` ã¯å£Šã•ãšæ‹¡å¼µã§ãã¾ã™ã€‚

# æ¡ˆBï¼š`ManualEventSet<T>` ã‚’å‹ã¨ã—ã¦åˆ†é›¢ï¼ˆå¼·ã„å‹ã§è¡¨ç¾ï¼‰
`WithManualCommit()` ã‚’é©ç”¨ã—ãŸã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã¯ **å‹ãã®ã‚‚ã®** ã‚’ `ManualEventSet<T>` ã«ã™ã‚‹ã€‚
```csharp
public sealed class ManualEventSet<T>
{
    public IAsyncEnumerable<ManualMessage<T>> ForEachAsync(CancellationToken token = default);
}

protected override void OnModelCreating(IModelBuilder modelBuilder)
    => modelBuilder.Entity<Sample>().WithManualCommit(); // ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ç”Ÿæˆæ™‚ã« ManualEventSet<Sample> ã‚’å‰²ã‚Šå½“ã¦
```### ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå´
```csharp
public ManualEventSet<Sample> Samples { get; private set; } = null!;
```### ãƒ†ã‚¹ãƒˆå´
```csharp
await foreach (var msg in ctx.Samples.ForEachAsync(consumeCts.Token))
{
    if (msg.Value.Id == 3) { await msg.CommitAsync(); break; }
}
```
- å‘¼ã³å‡ºã—ã¯ã•ã‚‰ã«çŸ­ããªã‚Šã¾ã™ãŒã€ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£å‹å¤‰æ›´ã®å½±éŸ¿ãŒå‡ºã¾ã™ï¼ˆäº’æ›æ€§ã«æ³¨æ„ï¼‰ã€‚

# æ¡ˆCï¼šãƒ¡ã‚½ãƒƒãƒ‰äºŒæœ¬ç«‹ã¦ã§è¿”ã‚Šå€¤ã‚’åˆ†ã‘ã‚‹ï¼ˆäº’æ›å„ªå…ˆï¼‰
æ—¢å­˜ `ForEachAsync` ã¯ãã®ã¾ã¾ã€æ‰‹å‹•ã‚³ãƒŸãƒƒãƒˆç”¨ã ã‘åˆ¥åã«ã€‚
```csharp
public IAsyncEnumerable<T> ForEachAsync(CancellationToken token = default);
public IAsyncEnumerable<ManualMessage<T>> ForEachMessagesAsync(CancellationToken token = default);
```### ãƒ†ã‚¹ãƒˆå´
```csharp
await foreach (var msg in ctx.Samples.ForEachMessagesAsync(consumeCts.Token))
{
    if (msg.Value.Id == 3) { await msg.CommitAsync(); break; }
}
```
- API è¡çªãŒãªãã€å®‰å…¨ã«æ®µéšå°å…¥ã§ãã¾ã™ã€‚
- `.Manual` ã»ã©æ„å›³ã¯å¼·èª¿ã•ã‚Œã¾ã›ã‚“ãŒã€ã‚­ãƒ£ã‚¹ãƒˆå•é¡Œã¯è§£æ¶ˆã€‚

---

## å‚è€ƒï¼š`ManualMessage<T>` ã®å®Ÿè£…ãƒ¡ãƒ¢
- `CommitAsync()` ã¯å†…éƒ¨ã§ `IConsumer` ã® `Commit`/`StoreOffset` ã«å§”è­²ã€‚  
- 1ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«ç´ã¥ãã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’ä¿æŒï¼ˆ`TopicPartitionOffset`ï¼‰ã—ã¦ãŠãã€Idempotent ã«ã‚³ãƒŸãƒƒãƒˆã€‚  
- æœ›ã‚€ãªã‚‰ `Headers` ç­‰ã®ãƒ¡ã‚¿ã‚‚è¼‰ã›ã‚‹ï¼š
  ```csharp
  public sealed record ManualMessage<T>(
      T Value,
      IReadOnlyDictionary<string,string> Headers,
      Func<Task> CommitAsync);
  ```

---

## ã‚ãªãŸã®ç¾çŠ¶ã‚³ãƒ¼ãƒ‰ã«ä¸€ç•ªé¦´æŸ“ã‚€ã®ã¯ï¼Ÿ
- æ—¢å­˜å‘¼ã³å‡ºã—ã‚’å´©ã—ãŸããªã„ â†’ **æ¡ˆA**ï¼ˆ`.Manual`ï¼‰  
- ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£å‹ã‚’å¤‰ãˆã¦ã§ã‚‚æœ€çŸ­ã«ã—ãŸã„ â†’ **æ¡ˆB**  
- ã¾ãšã¯å®‰å…¨ã«å°å…¥ã—ã¦æ®µéšç§»è¡Œ â†’ **æ¡ˆC**

ã”å¸Œæœ›ã‚ã‚Œã°ã€ä»Šã® `EventSet<T>` / `WithManualCommit()` å®Ÿè£…ã‚’å‰æã«ã€**æ¡ˆAã®æœ€å°å·®åˆ†ãƒ‘ãƒƒãƒ**ï¼ˆå†…éƒ¨ã®ã‚ªãƒ•ã‚»ãƒƒãƒˆä¿æŒã¨ `ManualMessage<T>` ã®ç”Ÿæˆä½ç½®ã¾ã§ï¼‰ã‚’å…·ä½“ã‚³ãƒ¼ãƒ‰ã§å‡ºã—ã¾ã™ã€‚ã©ã‚Œã§ã„ãã¾ã—ã‚‡ã†ï¼Ÿ

â€” é€ä¿¡æ—¥æ™‚: [[REDACTED_PHONE]]:08 (JST)
### assistant â€” 2025-08-11T08:08:08.347553+00:00

_(empty)_
### system â€” 2025-08-11T08:08:53.003993+00:00

_(empty)_
### assistant â€” 2025-08-11T08:08:53.046950+00:00

ã‚ã‹ã‚‹ã€ãã®æ°—æŒã¡ã€‚**ã€Œautocommit â‡„ manual commitã‚’åˆ‡ã‚Šæ›¿ãˆã¦ã‚‚ã€å‘¼ã³å‡ºã—å´ã®å‹ã‚„æ›¸ãæ–¹ã¯ãã®ã¾ã¾ã€**ã«ã—ãŸã„ã‚“ã§ã™ã‚ˆã­ã€‚  
ãƒã‚¤ãƒ³ãƒˆã¯ã€Œ**å€¤ã¯å¸¸ã« T ã‚’è¿”ã™**ã€ã€Œ**commit ã¯â€œåˆ¥çµŒè·¯â€ã§å–ã‚Œã‚‹**ã€ã«åˆ†é›¢ã™ã‚‹ã“ã¨ã€‚ã‚­ãƒ£ã‚¹ãƒˆã‚‚ã‚¸ã‚§ãƒãƒªãƒƒã‚¯å‹å¼•æ•°æŒ‡å®šã‚‚ä¸è¦ã«ã—ã¾ã™ã€‚

# ææ¡ˆï¼šå€¤ã¯ T ã®ã¾ã¾ã€commit ã¯ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆçµŒç”±ã§
- `ForEachAsync` ã¯å¸¸ã« `IAsyncEnumerable<T>` ã‚’è¿”ã™ï¼ˆï¼æ—¢å­˜ã‚³ãƒ¼ãƒ‰ãã®ã¾ã¾ï¼‰ã€‚
- å„ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ä¸­ã®ã€Œç¾åœ¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã‚ªãƒ•ã‚»ãƒƒãƒˆã€ã‚’ **å†…éƒ¨ã§è¿½è·¡**ã€‚
- æ˜ç¤ºçš„ã« commit ã—ãŸã„æ™‚ã ã‘ `ctx.Samples.CommitCurrentAsync()` ã‚’å‘¼ã¶ã€‚
- autocommit ãƒ¢ãƒ¼ãƒ‰ã§ã¯ `CommitCurrentAsync()` ã¯ **no-op**ï¼ˆäº’æ›ä¿æŒï¼‰ã€‚
### å‘¼ã³å‡ºã—å´ï¼ˆå¤‰æ›´ã»ã¼ã‚¼ãƒ­ï¼‰
```csharp
await foreach (var sample in ctx.Samples.ForEachAsync(consumeCts.Token))
{
    if (sample.Id == 3)
    {
        await ctx.Samples.CommitCurrentAsync(); // manualæ™‚ã®ã¿åŠ¹ãã€‚autocommitãªã‚‰no-op
        break;
    }
}
```
### IF ä¾‹
```csharp
public sealed class EventSet<T>
{
    // æ—¢å­˜ï¼šå¸¸ã« T ã‚’è¿”ã™
    public async IAsyncEnumerable<T> ForEachAsync(
        [EnumeratorCancellation] CancellationToken token = default)
    {
        await foreach (var (value, offset) in InternalStream(token))
        {
            _lastOffset.Value = offset;      // â† ã‚¹ãƒ¬ãƒƒãƒ‰ãƒ­ãƒ¼ã‚«ãƒ«/enumå˜ä½ã§ä¿æŒ
            yield return value;              // å‘¼ã³å‡ºã—å´ã¯ T ã ã‘ã‚’æ‰±ã†
        }
    }

    // manualæ™‚ã®ã¿å®Ÿå‡¦ç†ã€autocommitæ™‚ã¯ no-op
    public Task CommitCurrentAsync()
        => _commitStrategy.CommitAsync(_lastOffset.Value);

    // å®Ÿè£…ãƒ¡ãƒ¢ï¼š
    // - _lastOffset ã¯ AsyncLocal<TopicPartitionOffset?> ç­‰ã§åˆ—æŒ™ã”ã¨ã«ã‚¹ã‚³ãƒ¼ãƒ—åˆ†é›¢
    // - _commitStrategy ã¯ autocommit â†’ NoOpCommitStrategyã€manual â†’ KafkaCommitStrategy
}
```
### å®Ÿè£…ã®ã‚³ã‚¢
- `InternalStream(token)` ã¯ `(T value, TopicPartitionOffset tpo)` ã‚’è¿”ã™å†…éƒ¨åˆ—æŒ™ã€‚
- åˆ—æŒ™ã®ãŸã³ã« `AsyncLocal<TPO?>` ã« â€œä»Šã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã® TPOâ€ ã‚’æ ¼ç´ã€‚
- `CommitCurrentAsync()` ã¯ `AsyncLocal` ã®å€¤ã‚’è¦‹ã¦ã€manualæ™‚ã®ã¿ `consumer.Commit(tpo)`ã€‚

---

## ãƒ¡ãƒªãƒƒãƒˆ
- **ã‚­ãƒ£ã‚¹ãƒˆå®Œå…¨æ’¤å»ƒ**ï¼š`(IManualCommitMessage<T>)obj` ã‚‚ä¸è¦ã€‚
- **å‹å¼•æ•°æŒ‡å®šã‚‚ä¸è¦**ï¼š`ForEachAsync<Sample>` ã¿ãŸã„ãªæ˜ç¤ºã‚‚ä¸è¦ã€‚
- **åˆ‡æ›¿ã‚³ã‚¹ãƒˆæœ€å°**ï¼šautocommit â†’ manual ã«ã—ã¦ã‚‚ã€æ—¢å­˜ã®èª­ã¿å–ã‚Šã‚³ãƒ¼ãƒ‰ã¯ç„¡å¤‰æ›´ã€‚  
  ãŸã ã—â€œæ˜ç¤ºçš„ã«ã‚³ãƒŸãƒƒãƒˆã—ãŸã„ãƒ†ã‚¹ãƒˆâ€ã§ã¯ `CommitCurrentAsync()` ã‚’1è¡Œè¶³ã™ã ã‘ã€‚

---

## ä»£æ›¿æ¡ˆï¼ˆå¥½ã¿ãƒ»è¨­è¨ˆæ–¹é‡ã«å¿œã˜ã¦ï¼‰
1) `.Manual` ãƒ“ãƒ¥ãƒ¼ï¼ˆ`ctx.Samples.Manual.ForEachAsync`ï¼‰  
2) `ForEachMessagesAsync()` ã‚’åˆ¥ãƒ¡ã‚½ãƒƒãƒ‰ã§è¿½åŠ ï¼ˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼‹Commit handleè¿”å´ï¼‰  
â†’ ã„ãšã‚Œã‚‚æ˜å¿«ã§ã™ãŒã€ã€ŒIFå¤‰æ›´ã‚¼ãƒ­ã€ã«æœ€ã‚‚è¿‘ã„ã®ã¯ä¸Šè¨˜ **ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆçµŒç”± commit** æ–¹å¼ã§ã™ã€‚

å¿…è¦ãªã‚‰ã€ã“ã®æ–¹é‡ã§ **æœ€å°å·®åˆ†ãƒ‘ãƒƒãƒ**ï¼ˆ`AsyncLocal` ç®¡ç†ãƒ»commitæˆ¦ç•¥ãƒ»ãƒ†ã‚¹ãƒˆé€šã—è¾¼ã¿ï¼‰ã‚’æ›¸ãã¾ã™ã€‚å£°ã‹ã‘ã¦ãã ã•ã„ã€‚

â€” é€ä¿¡æ—¥æ™‚: [[REDACTED_PHONE]]:15 (JST)
### assistant â€” 2025-08-11T08:08:53.474366+00:00

_(empty)_
### user â€” 2025-08-11T08:08:53.933000+00:00

autocommitã‹ã‚‰manual commitã«å¤‰ãˆãŸã¨ãã«ã‚³ãƒ¼ãƒ‰å¤‰æ›´ãŒç™ºç”Ÿã™ã‚‹ã®ãŒã„ã¾ã„ã¡
### assistant â€” 2025-08-11T08:09:25.846694+00:00

_(empty)_
### system â€” 2025-08-11T08:11:15.589772+00:00

_(empty)_
### assistant â€” 2025-08-11T08:11:15.618082+00:00

ã„ã„ã­ã€ãã‚Œã‚¢ãƒªã§ã™ã€‚`ctx.Samples.Commit(poco)`ï¼ˆæ­£ç¢ºã«ã¯ `CommitAsync(poco)`ï¼‰ãªã‚‰ã€**å‘¼ã³å‡ºã—å´ã¯å¸¸ã« `T` ã ã‘æ‰±ãˆã¦ã€autocommitâ‡„manualã®åˆ‡æ›¿æ™‚ã«ã‚‚ã»ã¼å¤‰æ›´ã‚¼ãƒ­**ã«ã§ãã¾ã™ã€‚

# ã­ã‚‰ã„
- `ForEachAsync` ã¯å¾“æ¥ã©ãŠã‚Š `IAsyncEnumerable<T>` ã‚’è¿”ã™ï¼ˆï¼æ—¢å­˜èª­å–ã‚³ãƒ¼ãƒ‰ã¯ä¸å¤‰ï¼‰ã€‚
- manualæ™‚ã®ã¿ã€**ã€Œã„ã¾è¿”ã—ãŸ `poco` â†’ ãã®ã‚ªãƒ•ã‚»ãƒƒãƒˆã€**ã®å¯¾å¿œã‚’å†…éƒ¨ã§ä¿æŒã€‚
- `CommitAsync(poco)` ã§ã€ãã® `poco` ã«ç´ã¥ãã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’ã‚³ãƒŸãƒƒãƒˆã€‚
- autocommitæ™‚ã¯ `CommitAsync(poco)` ã‚’ **no-op** ã«ã™ã‚Œã°äº’æ›æ€§OKã€‚

# å®Ÿè£…ãƒã‚¤ãƒ³ãƒˆï¼ˆå®‰å…¨ãƒ»çœãƒ¡ãƒ¢ãƒªï¼‰
- è¿½è·¡ã¯ **å‚ç…§åŒä¸€æ€§** ã§è¡Œã†ï¼ˆå€¤ãŒåŒã˜åˆ¥ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’èª¤ã£ã¦ã‚³ãƒŸãƒƒãƒˆã—ãªã„ãŸã‚ï¼‰ã€‚
- C# ãªã‚‰ `ConditionalWeakTable<T, TopicPartitionOffset>` ãŒæœ€é©ï¼ˆ`T : class` å‰æï¼‰ã€‚
  - `ForEachAsync` ã§å€¤ã‚’ `yield` ã™ã‚‹ç›´å‰ã« `cwt.Add(poco, tpo)`ã€‚
  - `CommitAsync(poco)` ã§ `cwt.TryGetValue(poco, out tpo)`â†’ `consumer.Commit(tpo)`ã€‚
  - ã‚³ãƒŸãƒƒãƒˆå¾Œã‚„æ¬¡ãƒãƒ¼ãƒªãƒ³ã‚°æ™‚ã« `cwt.Remove(poco)` ã—ã¦ã‚¯ãƒªã‚¢ï¼ˆãƒªãƒ¼ã‚¯é˜²æ­¢ï¼‰ã€‚
- `T` ãŒ struct ã®å¯èƒ½æ€§ãŒã‚ã‚‹ãªã‚‰ã€manual å¯¾å¿œã¯ `T : class` ã«é™å®šã™ã‚‹ã‹ã€ãƒ©ãƒƒãƒ—å‹ã‚’è¿”ã™è¨­è¨ˆã«åˆ‡ã‚Šæ›¿ãˆã‚’æ¤œè¨ã€‚

## IFä¾‹
```csharp
public sealed class EventSet<T> where T : class // manualå¯¾å¿œã®ç¯„å›²ã‚’æ˜ç¢ºåŒ–
{
    private readonly ConditionalWeakTable<T, TopicPartitionOffset> _offsets = new();

    public async IAsyncEnumerable<T> ForEachAsync(
        [EnumeratorCancellation] CancellationToken token = default)
    {
        await foreach (var (value, tpo) in InternalStream(token))
        {
            _offsets.Add(value, tpo);
            try { yield return value; }
            finally
            {
                // ã“ã“ã§æ¶ˆã•ãšã€Commitå´ã§æ¶ˆã™é‹ç”¨ã‚‚OK
                // ã€Œå¾Œã§ã¾ã¨ã‚ã¦ã‚³ãƒŸãƒƒãƒˆã€æ´¾ãªã‚‰ä¿æŒã—ã¦ãŠã
            }
        }
    }

    public Task CommitAsync(T value)
    {
        if (!IsManualMode) return Task.CompletedTask; // autocommitã¯no-op
        if (!_offsets.TryGetValue(value, out var tpo))
            throw new InvalidOperationException("The value is not tracked for commit.");
        _offsets.Remove(value);
        return _consumer.CommitAsync(tpo);
    }
}
```

## å‘¼ã³å‡ºã—å´ï¼ˆã™ã£ãã‚Šï¼‰
```csharp
await foreach (var sample in ctx.Samples.ForEachAsync(consumeCts.Token))
{
    if (sample.Id == 3)
    {
        await ctx.Samples.CommitAsync(sample);
        break;
    }
}
```

# é•·æ‰€
- **ã‚­ãƒ£ã‚¹ãƒˆä¸è¦ï¼å‹å¼•æ•°æŒ‡å®šä¸è¦ï¼`ForEachAsync`ä¸å¤‰**ã€‚
- åˆ‡æ›¿ã‚³ã‚¹ãƒˆã¯ã€Œå¿…è¦ç®‡æ‰€ã§ `CommitAsync(poco)` ã‚’å‘¼ã¶ã€ã ã‘ã€‚
- åŒä¸€å€¤ã‚’åˆ¥ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã§ä½œã£ã¦ã—ã¾ã†äº‹æ•…ã‚’å›é¿ï¼ˆå‚ç…§åŒä¸€æ€§ãƒ™ãƒ¼ã‚¹ï¼‰ã€‚

# æ³¨æ„ç‚¹ãƒ»æ‹¡å¼µ
- **ä¸¦åˆ—æ¶ˆè²»**ã™ã‚‹ãªã‚‰ã€`ConditionalWeakTable` å…±æœ‰ã§OKï¼ˆå‚ç…§ã‚­ãƒ¼ãªã®ã§è¡çªä½ãƒªã‚¹ã‚¯ï¼‰ã€‚ãŸã ã—åŒä¸€ `poco` ã‚’è¤‡æ•°ã‚¹ãƒ¬ãƒƒãƒ‰ã§ã‚³ãƒŸãƒƒãƒˆã—ãªã„ã‚ˆã†ã« remove/commit ã‚’ã‚¢ãƒˆãƒŸãƒƒã‚¯ã«ã€‚
- ä½¿ã„å‹æ‰‹å‘ä¸Šã¨ã—ã¦ã€**æœ€å¾Œã«èª­ã‚“ã ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã‚³ãƒŸãƒƒãƒˆ**ã™ã‚‹ `CommitCurrentAsync()` ã‚‚ä½µè¨­å¯ï¼ˆ`AsyncLocal` ã§è¿½è·¡ï¼‰ã€‚
- ãƒ¡ã‚¿æƒ…å ±ãŒæ¬²ã—ã‘ã‚Œã°ã€`CommitAsync(poco, headers?)` ã®ã‚ˆã†ã« overload ã‚’ç”¨æ„ã€‚

ã“ã®æ–¹å‘ã§æœ€å°å·®åˆ†ãƒ‘ãƒƒãƒä½œã‚Šã¾ã™ï¼Ÿä»Šã® `EventSet<T>` é››å½¢ãŒã‚ã‹ã‚Œã°ã€ãã®ã¾ã¾å½“ã¦ã‚‰ã‚Œã‚‹å®Ÿè£…ã«è½ã¨ã—è¾¼ã¿ã¾ã™ã€‚

â€” é€ä¿¡æ—¥æ™‚: [[REDACTED_PHONE]]:22 (JST)
### assistant â€” 2025-08-11T08:11:16.079255+00:00

_(empty)_
### user â€” 2025-08-11T08:11:16.370000+00:00

ctx.Samples.Commit( poco )ã¯ã©ã†ã‹ï¼Ÿ
### assistant â€” 2025-08-11T08:11:33.299410+00:00

_(empty)_
### system â€” 2025-08-11T08:12:24.902848+00:00

_(empty)_
### assistant â€” 2025-08-11T08:12:25.437866+00:00

_(empty)_
### user â€” 2025-08-11T08:12:25.699000+00:00

codexã«ä¾é ¼ã—ã¾ã™
### assistant â€” 2025-08-11T08:12:30.241800+00:00

äº†è§£ã€‚Codex ã«ãã®ã¾ã¾æŠ•ã’ã‚‰ã‚Œã‚‹ã€Œä¾é ¼æ–‡ã€ã‚’ç”¨æ„ã—ã¾ã—ãŸã€‚å¿…è¦äº‹é …ã‚’å…¨éƒ¨å…¥ã‚Šã«ã—ã¦ã‚ã‚Šã¾ã™ã€‚ã‚³ãƒ”ãƒšã§ä½¿ã£ã¦ãã ã•ã„ã€‚

---

# Codexä¾é ¼æ–‡ï¼šautocommitâ‡„manualåˆ‡æ›¿æ™‚ã®å‘¼ã³å‡ºã—äº’æ›ã‚’ä¿ã£ãŸã¾ã¾ã€`CommitAsync(poco)` ã‚’å°å…¥

## ç›®çš„
- **å‘¼ã³å‡ºã—å´ã®IFã‚’å¤‰ãˆãšã«**ï¼ˆ= `ForEachAsync` ã¯å¸¸ã« `IAsyncEnumerable<T>` ã§å€¤ `T` ã‚’è¿”ã™ã¾ã¾ï¼‰ã€manual commit æ™‚ã ã‘ **`ctx.Samples.CommitAsync(poco)`** ã‚’å‘¼ã¹ã°è©²å½“ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’ã‚³ãƒŸãƒƒãƒˆã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚
- autocommit ã®ã¨ãã« `CommitAsync(poco)` ã‚’å‘¼ã‚“ã§ã‚‚ **no-op** ã¨ã™ã‚‹ï¼ˆäº’æ›ç¶­æŒï¼‰ã€‚

## ç¾çŠ¶ï¼ˆæŠœç²‹ï¼‰
- `ManualCommitContext.Sample` ã‚’å¯¾è±¡ã« `ForEachAsync` ã§ `object` ã¾ãŸã¯ `T` ã‚’åˆ—æŒ™ã—ã€manual ã§ã¯ã‚­ãƒ£ã‚¹ãƒˆã—ã¦ `CommitAsync()` ã‚’å‘¼ã¶å¿…è¦ãŒã‚ã‚‹è¨­è¨ˆã«ãªã£ã¦ãŠã‚Šã€**å‘¼ã³å‡ºã—å´ã®å¤‰æ›´ãŒç™ºç”Ÿ**ã—ã¦ã—ã¾ã†ã®ãŒèª²é¡Œã€‚

## è¦æ±‚ä»•æ§˜
1. `EventSet<T>`ï¼ˆã¾ãŸã¯ç›¸å½“ã‚¯ãƒ©ã‚¹ï¼‰ã¯ **å¸¸ã« `IAsyncEnumerable<T>` ã‚’è¿”ã™**ã€‚
2. manual commit ãƒ¢ãƒ¼ãƒ‰ã§ã¯ã€å„ `T` ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã¨ãã® **`TopicPartitionOffset`(TPO)** ã‚’ **å†…éƒ¨ã§è¿½è·¡**ã—ã€`CommitAsync(T poco)` ã§å¯¾å¿œã™ã‚‹ TPO ã‚’ã‚³ãƒŸãƒƒãƒˆã§ãã‚‹ã€‚
3. autocommit ãƒ¢ãƒ¼ãƒ‰ã§ã¯ `CommitAsync(T poco)` ã¯ **no-op**ã€‚
4. è¿½è·¡ã¯ **å‚ç…§åŒä¸€æ€§** ã§è¡Œã†ï¼ˆå€¤ãŒåŒã˜åˆ¥ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’èª¤ã‚³ãƒŸãƒƒãƒˆã—ãªã„ãŸã‚ï¼‰ã€‚
5. `T` ã¯ **class åˆ¶ç´„**ï¼ˆ`where T : class`ï¼‰ã§ã‚ˆã„ã€‚struct ã‚µãƒãƒ¼ãƒˆã¯ä¸è¦ã€‚
6. ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ã«ã—ã€ãƒªãƒ¼ã‚¯ã—ãªã„ã‚ˆã†ã«ã™ã‚‹ï¼ˆã‚³ãƒŸãƒƒãƒˆå¾Œã¯è¿½è·¡ã‚¨ãƒ³ãƒˆãƒªã‚’å‰Šé™¤ï¼‰ã€‚

## å®Ÿè£…è©³ç´°ï¼ˆæŒ‡ç¤ºï¼‰
- `EventSet<T>` ã« `where T : class` ã‚’ä»˜ä¸ã€‚
- ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã« `ConditionalWeakTable<T, TopicPartitionOffset>` ã‚’è¿½åŠ ï¼ˆä¾‹ï¼š`_offsets`ï¼‰ã€‚
- å†…éƒ¨ã®ãƒãƒ¼ãƒªãƒ³ã‚°ï¼åˆ—æŒ™ãƒ‘ã‚¹ã§ã€`T value` ã¨ `TopicPartitionOffset tpo` ã‚’å–å¾—ã—ãŸã‚‰ã€**`yield return value` ã®ç›´å‰**ã« `_offsets.Add(value, tpo)` ã‚’å‘¼ã¶ã€‚
- `CommitAsync(T value)` ã‚’è¿½åŠ ï¼š
  - autocommit ãªã‚‰ `return Task.CompletedTask`ã€‚
  - manual ã®ã¨ãã€`_offsets.TryGetValue(value, out var tpo)` ã«æˆåŠŸã—ãŸã‚‰ `_offsets.Remove(value)` â†’ å®Ÿã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒã«å¯¾ã—ã¦ **åŒæœŸ/éåŒæœŸã„ãšã‚Œã‹æ—¢å­˜ã®è¦ç´„ã«åˆã‚ã›ã¦**ã‚³ãƒŸãƒƒãƒˆï¼ˆ`consumer.Commit(tpo)` ã¾ãŸã¯ `CommitAsync`ï¼‰ã€‚
  - å¤±æ•—ã—ãŸã‚‰ `InvalidOperationException("The value is not tracked for commit.")` ã‚’æŠ•ã’ã‚‹ï¼ˆæ—¢å®šå‹•ä½œï¼‰ã€‚  
- **ä¸¦åˆ—æ¶ˆè²»**ã‚’æƒ³å®šã—ã€`_offsets` ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã¯å¸¸è­˜çš„ãªåˆ©ç”¨ã§è¡çªã—ãªã„ãŒã€ã‚³ãƒŸãƒƒãƒˆã¨å‰Šé™¤ã¯ã‚¢ãƒˆãƒŸãƒƒã‚¯ã«æ‰±ã†ï¼ˆäºŒé‡ã‚³ãƒŸãƒƒãƒˆé˜²æ­¢ï¼‰ã€‚
- å¾Œç¶šè¦ä»¶ã¨ã—ã¦ã€`CommitCurrentAsync()`ï¼ˆæœ€å¾Œã«è¿”ã—ãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã‚³ãƒŸãƒƒãƒˆï¼‰ã‚’å®Ÿè£…ã—ã¦ã‚‚ã‚ˆã„ãŒã€ä»Šå›ã¯å¿…é ˆã§ã¯ãªã„ã€‚
### å‚è€ƒã‚³ãƒ¼ãƒ‰ã‚¹ã‚±ãƒƒãƒï¼ˆé››å½¢ï¼‰
```csharp
public sealed class EventSet<T> where T : class
{
    private readonly ConditionalWeakTable<T, TopicPartitionOffset> _offsets = new();
    private readonly IConsumer<byte[], byte[]> _consumer; // æ—¢å­˜ã®DI/å‚ç…§ã«åˆã‚ã›ã‚‹
    private readonly bool _manual; // WithManualCommit() é©ç”¨æ™‚ true
    // ... ctor ç­‰ã¯æ—¢å­˜ã«åˆã‚ã›ã‚‹

    public async IAsyncEnumerable<T> ForEachAsync(
        [System.Runtime.CompilerServices.EnumeratorCancellation] CancellationToken token = default)
    {
        await foreach (var (value, tpo) in InternalStream(token)) // å†…éƒ¨ã§ value ã¨ tpo ã‚’å–å¾—ã™ã‚‹åˆ—æŒ™
        {
            if (_manual)
            {
                // å‚ç…§åŒä¸€æ€§ã§ç´ã¥ã‘
                _offsets.Add(value, tpo);
            }
            yield return value;
        }
    }

    public Task CommitAsync(T value)
    {
        if (!_manual) return Task.CompletedTask; // autocommit â†’ no-op

        if (!_offsets.TryGetValue(value, out var tpo))
            throw new InvalidOperationException("The value is not tracked for commit.");

        // äºŒé‡ã‚³ãƒŸãƒƒãƒˆé˜²æ­¢
        _offsets.Remove(value);

        // æ—¢å­˜ã®ã‚³ãƒŸãƒƒãƒˆè¦ç´„ã«åˆã‚ã›ã‚‹ï¼ˆä¾‹ï¼šåŒæœŸCommitï¼‰
        _consumer.Commit(new[] { new TopicPartitionOffset(tpo.TopicPartition, tpo.Offset) });

        return Task.CompletedTask;
    }

    // å†…éƒ¨ç”¨ï¼švalue ã¨ tpo ã‚’çµ„ã§æµã™
    private async IAsyncEnumerable<(T Value, TopicPartitionOffset Tpo)> InternalStream(
        [System.Runtime.CompilerServices.EnumeratorCancellation] CancellationToken token)
    {
        // æ—¢å­˜ã®ãƒãƒ¼ãƒªãƒ³ã‚°ãƒ»ãƒ‡ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºãƒ»ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’æ´»ç”¨ã—ã¦
        // (value, tpo) ã‚’æ§‹ç¯‰ã—ã¦ yield return ã™ã‚‹
        throw new NotImplementedException();
    }
}
```

## å—ã‘å…¥ã‚ŒåŸºæº–ï¼ˆå¿…é ˆãƒ†ã‚¹ãƒˆï¼‰
- æ—¢å­˜ãƒ†ã‚¹ãƒˆ `ManualCommit_PersistsOffset` ã‚’ä»¥ä¸‹ã®**æ–°IF**ã§ãƒ‘ã‚¹ã™ã‚‹ã“ã¨ï¼š
  - 1å›ç›®ã®æ¶ˆè²»ã§ 1..5 ã‚’æµã—ã€**3 ã®ã¨ãã« `await ctx.Samples.CommitAsync(sample);`** ã‚’å‘¼ã‚“ã§ breakã€‚
  - 2å›ç›®ã®æ¶ˆè²»é–‹å§‹ã§ **4 ã‹ã‚‰å†é–‹**ã™ã‚‹ã“ã¨ã‚’æ¤œè¨¼ã€‚
- autocommit ãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆã¦åŒã˜å‘¼ã³å‡ºã—ã‚’æ›¸ã„ã¦ã‚‚ã€`CommitAsync(sample)` ã¯ no-op ã§å‹•ä½œã«å½±éŸ¿ã—ãªã„ã“ã¨ï¼ˆä»»æ„ã®ã‚¹ãƒ¢ãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆã§å¯ï¼‰ã€‚
### ãƒ†ã‚¹ãƒˆå´ã®æ›¸ãæ–¹ï¼ˆæœŸå¾…å½¢ï¼‰
```csharp
await foreach (var sample in ctx.Samples.ForEachAsync(consumeCts.Token))
{
    if (sample.Id == 3)
    {
        await ctx.Samples.CommitAsync(sample); // â† ã“ã“ã ã‘è¿½åŠ 
        break;
    }
}
```

## éæ©Ÿèƒ½è¦ä»¶
- è¿½åŠ ã®å‰²ã‚Šå½“ã¦ãƒ»ä¿æŒã¯æœ€å°é™ï¼ˆ`ConditionalWeakTable` ã‚’ä½¿ã†ã“ã¨ã§ã€GCã¨ç›¸æ€§è‰¯ãã€å‚ç…§ãŒåˆ‡ã‚Œã‚Œã°è‡ªå‹•çš„ã«æƒé™¤ï¼‰ã€‚
- å…¬é–‹APIã®ç ´å£Šçš„å¤‰æ›´ãªã—ï¼ˆ`ForEachAsync` ã®ã‚·ã‚°ãƒãƒãƒ£ã¯ä¸å¤‰ï¼‰ã€‚
- ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ/ã‚³ãƒ¡ãƒ³ãƒˆã§ `T : class` åˆ¶ç´„ç†ç”±ï¼ˆå‚ç…§åŒä¸€æ€§ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ï¼‰ã‚’æ˜è¨˜ã€‚

## å¤‰æ›´ç¯„å›²
- `EventSet<T>`ï¼ˆã¾ãŸã¯ç›¸å½“ï¼‰ã¨ã€ãã®å†…éƒ¨åˆ—æŒ™ â†’ `(T, TPO)` ã‚’å¾—ã‚‹ç®‡æ‰€ã€‚
- manual/autocommit ã®ãƒ¢ãƒ¼ãƒ‰åˆ¤å®šã®æ³¨å…¥/åˆ¤å®šã€‚
- ã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒã¸ã® commit å‘¼ã³å‡ºã—ä½ç½®ï¼ˆæ–°è¦ãƒ¡ã‚½ãƒƒãƒ‰ï¼‰ã€‚

## æ³¨æ„ç‚¹
- **åŒä¸€POCOã®äºŒé‡ã‚³ãƒŸãƒƒãƒˆ**ã¯ `_offsets.Remove` ã‚’å…ˆã«è¡Œã†ã“ã¨ã§é˜²æ­¢ã€‚
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚³ãƒ¼ãƒ‰ãŒ **ã‚³ãƒ”ãƒ¼ï¼ˆåˆ¥ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼‰**ã‚’ä½œã£ã¦ `CommitAsync` ã«æ¸¡ã—ãŸå ´åˆã¯ä¾‹å¤–ã«ãªã‚‹ï¼ˆä»•æ§˜ï¼‰ã€‚  
- è¿½è·¡æœŸé–“ã¯ã€Œåˆ—æŒ™ã§å€¤ã‚’è¿”ã—ã¦ã‹ã‚‰ã‚³ãƒŸãƒƒãƒˆã•ã‚Œã‚‹ã¾ã§ã€ã€‚é•·æœŸä¿æŒã¯ã‚¢ãƒ³ãƒãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆå¿…è¦ãªã‚‰æ˜ç¤ºçš„ã«å†å–å¾—ï¼‰ã€‚

---

å¿…è¦ãªã‚‰ã€Œæœ€å°å·®åˆ†ã®å®Ÿè£…ãƒ‘ãƒƒãƒï¼ˆdiff å½¢å¼ï¼‰ã€ã‚‚å‡ºã—ã¾ã™ã€‚å£°ã‹ã‘ã¦ãã ã•ã„ã€‚

â€” é€ä¿¡æ—¥æ™‚: [[REDACTED_PHONE]]:12 (JST)
### assistant â€” 2025-08-11T08:12:31.690852+00:00

_(empty)_
### user â€” 2025-08-11T08:14:00.258000+00:00

é–¢ä¿‚ã—ãã†ãªã‚³ãƒ¼ãƒ‰ã‚’æ·»ä»˜
### system â€” 2025-08-11T08:14:00.267462+00:00

_(empty)_
### tool â€” 2025-08-11T08:14:00.288520+00:00

_(empty)_
### tool â€” 2025-08-11T08:14:00.306795+00:00

îˆ€fileciteîˆ‚turn0file0îˆ

using Kafka.Ksql.Linq.Core.Abstractions;
using Kafka.Ksql.Linq.Core.Extensions;
using Kafka.Ksql.Linq.Messaging.Internal;
using Kafka.Ksql.Linq.Messaging;
using Kafka.Ksql.Linq.Core.Dlq;
using Kafka.Ksql.Linq.Query.Abstractions;
using System;
using System.Collections.Generic;
using System.Runtime.CompilerServices;
using System.Threading;
using System.Threading.Tasks;

namespace Kafka.Ksql.Linq;

/// <summary>
/// Base class for EventSet implementing IEntitySet<T>
/// Reason for modification: unified with KsqlContext and added IEntitySet<T> implementation
/// </summary>
public abstract class EventSet<T> : IEntitySet<T> where T : class
{
    protected readonly IKsqlContext _context;
    protected readonly EntityModel _entityModel;
    private readonly ErrorHandlingContext _errorHandlingContext;
    private IErrorSink? _dlqErrorSink;
    private readonly Messaging.Producers.IDlqProducer? _dlqProducer;
    private readonly Messaging.Consumers.ICommitManager? _commitManager;

    protected EventSet(IKsqlContext context, EntityModel? entityModel = null, IErrorSink? dlqErrorSink = null,
        Messaging.Producers.IDlqProducer? dlqProducer = null, Messaging.Consumers.ICommitManager? commitManager = null)
    {
        _context = context ?? throw new ArgumentNullException(nameof(context));
        _errorHandlingContext = new ErrorHandlingContext();
        _dlqErrorSink = dlqErrorSink;
        _dlqProducer = dlqProducer;
        _commitManager = commitManager;

        if (context is KsqlContext kctx)
        {
            _entityModel = kctx.EnsureEntityModel(typeof(T), entityModel);
        }
        else
        {
            _entityModel = entityModel ?? throw new ArgumentNullException(nameof(entityModel));
        }

        if (_dlqErrorSink != null)
        {
            _errorHandlingContext.ErrorOccurred += (ctx, msg) => _dlqErrorSink.HandleErrorAsync(ctx, msg);
        }
    }

    private EventSet(IKsqlContext context, EntityModel entityModel, ErrorHandlingContext errorHandlingContext, IErrorSink? dlqErrorSink,
        Messaging.Producers.IDlqProducer? dlqProducer, Messaging.Consumers.ICommitManager? commitManager)
    {
        _context = context;
        _entityModel = entityModel;
        _errorHandlingContext = errorHandlingContext;
        _dlqErrorSink = dlqErrorSink;
        _dlqProducer = dlqProducer;
        _commitManager = commitManager;

        if (_dlqErrorSink != null)
        {
            _errorHandlingContext.ErrorOccurred += (ctx, msg) => _dlqErrorSink.HandleErrorAsync(ctx, msg);
        }
    }

    /// <summary>
    /// NEW: made abstract - must be implemented by concrete classes
    /// Unifies continuous Kafka consumption and returning a fixed list
    /// </summary>
    public abstract IAsyncEnumerator<T> GetAsyncEnumerator(CancellationToken cancellationToken = default);

    private async IAsyncEnumerable<T> GetAsyncEnumeratorWrapper([EnumeratorCancellation] CancellationToken cancellationToken = default)
    {
        await using var enumerator = GetAsyncEnumerator(cancellationToken);

        while (true)
        {
            bool hasNext;
            try
            {
                hasNext = await enumerator.MoveNextAsync();
            }
            catch (Exception ex)
            {
                var ctx = new KafkaMessageContext
                {
                    MessageId = Guid.NewGuid().ToString(),
                    Tags = new Dictionary<string, object>
                    {
                        ["processing_phase"] = "ForEachAsync"
                    }
                };

                var shouldContinue = await _errorHandlingContext.HandleErrorAsync(default(T)!, ex, ctx);

                if (!shouldContinue)
                {
                    continue;
                }

                throw;
            }

            if (!hasNext)
                yield break;

            yield return enumerator.Current;
        }
    }


    public virtual async Task<List<T>> ToListAsync(CancellationToken cancellationToken = default)
    {
        if (_entityModel.EntityType == typeof(Messaging.DlqEnvelope))
            throw new InvalidOperationException("DLQã¯ç„¡é™åˆ—æŒ™/å±¥æ­´åˆ—ã§ã‚ã‚Šã€ãƒãƒƒãƒå–å¾—ãƒ»ä»¶æ•°æŒ‡å®šå–å¾—ã¯ç¾çŠ¶æœªå¯¾å¿œã§ã™");

        if (_entityModel.GetExplicitStreamTableType() == StreamTableType.Stream)
            throw new InvalidOperationException("ToListAsync() is not supported on a Stream source. Use ForEachAsync or subscribe for event consumption.");

        var results = new List<T>();

        await foreach (var item in GetAsyncEnumeratorWrapper(cancellationToken))
        {
            results.Add(item);
        }

        return results;
    }
    /// <summary>
    /// ABSTRACT: Producer functionality - implemented in derived classes
    /// </summary>
    protected abstract Task SendEntityAsync(T entity, Dictionary<string, string>? headers, CancellationToken cancellationToken);

    /// <summary>
    /// IEntitySet<T> implementation: producer operations
    /// </summary>
    public virtual async Task AddAsync(T entity, Dictionary<string, string>? headers = null, CancellationToken cancellationToken = default)
    {
        if (entity == null)
            throw new ArgumentNullException(nameof(entity));

        await SendEntityAsync(entity, headers, cancellationToken);
    }

    public virtual Task RemoveAsync(T entity, CancellationToken cancellationToken = default)
    {
        throw new NotSupportedException($"RemoveAsync is not supported for {GetType().Name}.");
    }

    /// <summary>
    /// Retrieves messages from the underlying consumer.
    /// Separated for ease of testing.
    /// </summary>
    /// <param name="context">Active KsqlContext</param>
    /// <param name="cancellationToken">Cancellation token</param>
    /// <returns>Message stream with headers</returns>
    protected virtual IAsyncEnumerable<(T Entity, Dictionary<string, string> Headers, MessageMeta Meta)> ConsumeAsync(
        KsqlContext context,
        CancellationToken cancellationToken)
    {
        return context.GetConsumerManager().ConsumeAsync<T>(cancellationToken);
    }
    /// <summary>
    /// REDESIGNED: ForEachAsync supporting continuous Kafka consumption
    /// Design change: ToListAsync() is disallowed; now based on GetAsyncEnumerator
    /// </summary>
    public virtual Task ForEachAsync(Func<T, Task> action, TimeSpan timeout = default, CancellationToken cancellationToken = default)
    {
        if (action == null)
            throw new ArgumentNullException(nameof(action));

        return ForEachAsync((item, headers, _) => action(item), timeout, cancellationToken);
    }

    [Obsolete("Use ForEachAsync(Func<T, Dictionary<string,string>, MessageMeta, Task>)")]
    public virtual Task ForEachAsync(Func<T, Dictionary<string,string>, Task> action, TimeSpan timeout = default, CancellationToken cancellationToken = default)
        => ForEachAsync((e, h, _) => action(e, h), timeout, cancellationToken);

    public virtual async Task ForEachAsync(Func<T, Dictionary<string,string>, MessageMeta, Task> action, TimeSpan timeout = default, CancellationToken cancellationToken = default)
    {
        if (action == null)
            throw new ArgumentNullException(nameof(action));

        var context = GetContext() as KsqlContext
            ?? throw new InvalidOperationException("KsqlContext is required");

        using var linkedCts = CancellationTokenSource.CreateLinkedTokenSource(cancellationToken);

        if (timeout != default && timeout != TimeSpan.Zero)
        {
            linkedCts.CancelAfter(timeout);
        }
        await foreach (var (entity, headers, meta) in ConsumeAsync(context, linkedCts.Token))
        {
            if (headers.TryGetValue("is_dummy", out var dummyHeader) && bool.TryParse(dummyHeader, out var isDummy) && isDummy)
            {
                continue;
            }

            var maxAttempts = _errorHandlingContext.ErrorAction == ErrorAction.Retry
                ? _errorHandlingContext.RetryCount + 1
                : 1;

            for (var attempt = 1; attempt <= maxAttempts; attempt++)
            {
                try
                {
                    await action(entity, headers, meta);
                    break;
                }
                catch (Exception ex)
                {
                    _errorHandlingContext.CurrentAttempt = attempt;

                    if (attempt < maxAttempts && _errorHandlingContext.ErrorAction == ErrorAction.Retry)
                    {
                        await Task.Delay(_errorHandlingContext.RetryInterval, linkedCts.Token);
                        continue;
                    }

                    var dlq = context.DlqOptions;
                    if (_dlqProducer != null && dlq.EnableForHandlerError && DlqGuard.ShouldSend(dlq, context.DlqLimiter, ex.GetType()))
                    {
                        var env = DlqEnvelopeFactory.From(
                            meta, ex,
                            dlq.ApplicationId, dlq.ConsumerGroup, dlq.Host,
                            dlq.ErrorMessageMaxLength, dlq.StackTraceMaxLength, dlq.NormalizeStackTraceWhitespace);
                        await _dlqProducer.ProduceAsync(env, linkedCts.Token).ConfigureAwait(false);
                    }

                    _commitManager?.Commit(entity);
                    break;
                }
            }
        }
    }

    /// <summary>
    /// IEntitySet<T> implementation: retrieve metadata
    /// </summary>
    public string GetTopicName() => (_entityModel.TopicName ?? _entityModel.EntityType.Name).ToLowerInvariant();

    public EntityModel GetEntityModel() => _entityModel;

    public IKsqlContext GetContext() => _context;

    /// <summary>
    /// Create message context for error handling
    /// </summary>
    private KafkaMessageContext CreateMessageContext(T item)
    {
        return new KafkaMessageContext
        {
            MessageId = Guid.NewGuid().ToString(),
            Tags = new Dictionary<string, object>
            {
                ["entity_type"] = typeof(T).Name,
                ["topic_name"] = GetTopicName(),
                ["processing_phase"] = "ForEachAsync",
                ["timestamp"] = DateTime.UtcNow
            }
        };
    }

    /// <summary>
    /// Creates a ManualCommitMessage instance
    /// </summary>
    protected virtual IManualCommitMessage<T> CreateManualCommitMessage(T item)
    {
        return new ManualCommitMessage<T>(item, () => Task.CompletedTask, () => Task.CompletedTask);
    }

    /// <summary>
    /// Yields messages as different types depending on UseManualCommit
    /// </summary>
    public virtual async IAsyncEnumerable<object> ForEachAsync([EnumeratorCancellation] CancellationToken cancellationToken = default)
    {
        await foreach (var item in GetAsyncEnumeratorWrapper(cancellationToken))
        {
            if (_entityModel.UseManualCommit)
            {
                yield return CreateManualCommitMessage(item);
            }
            else
            {
                yield return item;
            }
        }
    }

    /// <summary>
    /// Configure the error handling policy
    /// </summary>
    internal virtual EventSet<T> WithErrorPolicy(ErrorHandlingPolicy policy)
    {
        if (policy == null)
            throw new ArgumentNullException(nameof(policy));

        _errorHandlingContext.ErrorAction = policy.Action;
        _errorHandlingContext.RetryCount = policy.RetryCount;
        _errorHandlingContext.RetryInterval = policy.RetryInterval;
        _errorHandlingContext.CustomHandler = policy.CustomHandler;

        return this;
    }

    public override string ToString()
    {
        return $"EventSet<{typeof(T).Name}> - Topic: {GetTopicName()}";
    }



    /// <summary>
    /// Specifies the number of retries.
    /// Used when ErrorAction.Retry is selected.
    /// </summary>
    /// <param name="maxRetries">Maximum retry count</param>
    /// <param name="retryInterval">Retry interval (optional)</param>
    /// <returns>EventSet with retry configuration applied</returns>
    public EventSet<T> WithRetry(int maxRetries, TimeSpan? retryInterval = null)
    {
        if (maxRetries < 0)
            throw new ArgumentException("Retry count must be zero or greater", nameof(maxRetries));

        var newContext = new ErrorHandlingContext
        {
            ErrorAction = _errorHandlingContext.ErrorAction,
            RetryCount = maxRetries,
            RetryInterval = retryInterval ?? TimeSpan.FromSeconds(1)
        };

        return CreateNewInstance(_context, _entityModel, newContext, _dlqErrorSink);
    }

    /// <summary>
    /// Passes the POCO to the business logic.
    /// After receiving from Kafka, each element is transformed using the supplied function.
    /// Exceptions and retries are handled based on the OnError and WithRetry settings.
    /// </summary>
    /// <typeparam name="TResult">Result type</typeparam>
    /// <param name="mapper">Mapping function</param>
    /// <returns>The mapped EventSet</returns>
    public async Task<EventSet<TResult>> Map<TResult>(Func<T, Task<TResult>> mapper) where TResult : class
    {
        if (mapper == null)
            throw new ArgumentNullException(nameof(mapper));

        var results = new List<TResult>();
        var sourceData = await ToListAsync();

        foreach (var item in sourceData)
        {
            var itemErrorContext = new ErrorHandlingContext
            {
                ErrorAction = _errorHandlingContext.ErrorAction,
                RetryCount = _errorHandlingContext.RetryCount,
                RetryInterval = _errorHandlingContext.RetryInterval
            };

            await ProcessItemWithErrorHandling(
                item,
                mapper,
                results,
                itemErrorContext);
        }

        var resultEntityModel = CreateEntityModelForType<TResult>();
        return new MappedEventSet<TResult>(results, _context, resultEntityModel, _dlqErrorSink);
    }

    /// <summary>
    /// Synchronous version of the Map function
    /// </summary>
    public EventSet<TResult> Map<TResult>(Func<T, TResult> mapper) where TResult : class
    {
        if (mapper == null)
            throw new ArgumentNullException(nameof(mapper));

        var results = new List<TResult>();
        var sourceData = ToListAsync().GetAwaiter().GetResult();

        foreach (var item in sourceData)
        {
            var itemErrorContext = new ErrorHandlingContext
            {
                ErrorAction = _errorHandlingContext.ErrorAction,
                RetryCount = _errorHandlingContext.RetryCount,
                RetryInterval = _errorHandlingContext.RetryInterval
            };

            ProcessItemWithErrorHandlingSync(
                item,
                mapper,
                results,
                itemErrorContext);
        }
        var resultEntityModel = CreateEntityModelForType<TResult>();
        return new MappedEventSet<TResult>(results, _context, resultEntityModel, _dlqErrorSink);
    }

    // Abstract method: create a new instance in derived classes
    protected virtual EventSet<T> CreateNewInstance(IKsqlContext context, EntityModel entityModel, ErrorHandlingContext errorContext, IErrorSink? dlqErrorSink)
    {
        // Default implementation: concrete classes must override
        throw new NotImplementedException("Derived classes must implement CreateNewInstance");
    }

    private EntityModel CreateEntityModelForType<TResult>() where TResult : class
    {
        return new EntityModel
        {
            EntityType = typeof(TResult),
            TopicName = $"{typeof(TResult).Name.ToLowerInvariant()}_mapped",
            AllProperties = typeof(TResult).GetProperties(),
            KeyProperties = Array.Empty<System.Reflection.PropertyInfo>(),
            ValidationResult = new ValidationResult { IsValid = true }
        };
    }

    /// <summary>
    /// Item-level processing with error handling (async version)
    /// </summary>
    private async Task ProcessItemWithErrorHandling<TResult>(
        T item,
        Func<T, Task<TResult>> mapper,
        List<TResult> results,
        ErrorHandlingContext errorContext) where TResult : class
    {
        var maxAttempts = errorContext.ErrorAction == ErrorAction.Retry
            ? errorContext.RetryCount + 1
            : 1;

        for (int attempt = 1; attempt <= maxAttempts; attempt++)
        {
            try
            {
                var result = await mapper(item);
                results.Add(result);
                return; // Processing completed successfully
            }
            catch (Exception ex)
            {
                errorContext.CurrentAttempt = attempt;

                // Retry regardless of ErrorAction if this is not the final attempt
                if (attempt < maxAttempts && errorContext.ErrorAction == ErrorAction.Retry)
                {
                    Console.WriteLine($"[{DateTime.UtcNow:HH:mm:ss}] Retry {attempt}/{errorContext.RetryCount}: {ex.Message}");
                    await Task.Delay(errorContext.RetryInterval);
                    continue;
                }

                // Perform error handling on the last attempt or when not retrying
                var shouldContinue = await errorContext.HandleErrorAsync(item, ex, CreateContext(item, errorContext));

                if (!shouldContinue)
                {
                    return; // Skip this item and move to the next
                }
            }
        }
    }

    /// <summary>
    /// Item-level processing with error handling (sync version)
    /// </summary>
    private void ProcessItemWithErrorHandlingSync<TResult>(
        T item,
        Func<T, TResult> mapper,
        List<TResult> results,
        ErrorHandlingContext errorContext) where TResult : class
    {
        var maxAttempts = errorContext.ErrorAction == ErrorAction.Retry
            ? errorContext.RetryCount + 1
            : 1;

        for (int attempt = 1; attempt <= maxAttempts; attempt++)
        {
            try
            {
                var result = mapper(item);
                results.Add(result);
                return; // Processing completed successfully
            }
            catch (Exception ex)
            {
                errorContext.CurrentAttempt = attempt;

                // Retry regardless of ErrorAction if this is not the final attempt
                if (attempt < maxAttempts && errorContext.ErrorAction == ErrorAction.Retry)
                {
                    Console.WriteLine($"[{DateTime.UtcNow:HH:mm:ss}] Retry {attempt}/{errorContext.RetryCount}: {ex.Message}");
                    Thread.Sleep(errorContext.RetryInterval);
                    continue;
                }

                // Perform error handling on the last attempt or when not retrying
                var shouldContinue = errorContext.HandleErrorAsync(item, ex, CreateContext(item, errorContext)).GetAwaiter().GetResult();

                if (!shouldContinue)
                {
                    return; // Skip this item and proceed to the next
                }
            }
        }
    }

    /// <summary>
    /// Create a message context
    /// </summary>
    private KafkaMessageContext CreateContext(T item, ErrorHandlingContext errorContext)
    {
        return new KafkaMessageContext
        {
            MessageId = Guid.NewGuid().ToString(),
            Tags = new Dictionary<string, object>
            {
                ["original_topic"] = GetTopicName(),
                ["original_partition"] = 0, // Replace with actual value
                ["original_offset"] = 0, // Replace with actual value
                ["retry_count"] = errorContext.CurrentAttempt,
                ["error_phase"] = "Processing"
            }
        };
    }

}
internal class MappedEventSet<T> : EventSet<T> where T : class
{
    private readonly List<T> _mapped;
    private readonly EntityModel _originalEntityModel;

    public MappedEventSet(List<T> mappedItems, IKsqlContext context, EntityModel originalEntityModel, IErrorSink? errorSink = null)
        : base(context, CreateMappedEntityModel<T>(originalEntityModel), errorSink)
    {
        _mapped = mappedItems ?? throw new ArgumentNullException(nameof(mappedItems));
        _originalEntityModel = originalEntityModel;
    }

    /// <summary>
    /// NEW: GetAsyncEnumerator implementation for fixed lists
    /// Returns each _mapped[i] sequentially via yield return
    /// </summary>
    public override async IAsyncEnumerator<T> GetAsyncEnumerator(CancellationToken cancellationToken = default)
    {
        foreach (var item in _mapped)
        {
            if (cancellationToken.IsCancellationRequested)
                yield break;

            yield return item;

            // Inserted to treat the loop asynchronously (avoid CPU intensive work)
            await Task.Yield();
        }
    }

    /// <summary>
    /// OPTIMIZATION: ToListAsync - already a fixed list so return immediately
    /// </summary>
    public override async Task<List<T>> ToListAsync(CancellationToken cancellationToken = default)
    {
        if (_entityModel.GetExplicitStreamTableType() == StreamTableType.Stream)
            throw new InvalidOperationException("ToListAsync() is not supported on a Stream source. Use ForEachAsync or subscribe for event consumption.");

        // Already a fixed list; return a copy
        await Task.CompletedTask;
        return new List<T>(_mapped);
    }

    /// <summary>
    /// Data after Map cannot be sent via Producer
    /// </summary>
    protected override Task SendEntityAsync(T entity, Dictionary<string, string>? headers, CancellationToken cancellationToken)
    {
        throw new NotSupportedException(
            $"MappedEventSet<{typeof(T).Name}> does not support AddAsync operations. " +
            "Mapped data is read-only and derived from transformation operations.");
    }

    public override Task RemoveAsync(T entity, CancellationToken cancellationToken = default)
    {
        throw new NotSupportedException($"MappedEventSet<{typeof(T).Name}> does not support RemoveAsync operations.");
    }

    /// <summary>
    /// Helper method to create a MappedEventSet
    /// </summary>
    public static MappedEventSet<T> Create(List<T> mappedItems, IKsqlContext context, EntityModel originalEntityModel, IErrorSink? errorSink = null)
    {
        return new MappedEventSet<T>(mappedItems, context, originalEntityModel, errorSink);
    }

    /// <summary>
    /// Create a MappedEventSet with DLQ support
    /// </summary>
    public static MappedEventSet<T> CreateWithDlq(List<T> mappedItems, IKsqlContext context, EntityModel originalEntityModel, IErrorSink dlqErrorSink)
    {
        return new MappedEventSet<T>(mappedItems, context, originalEntityModel, dlqErrorSink);
    }

    /// <summary>
    /// Create an EntityModel for mapped data
    /// </summary>
    private static EntityModel CreateMappedEntityModel<TMapped>(EntityModel originalModel) where TMapped : class
    {
        return new EntityModel
        {
            EntityType = typeof(TMapped),
            TopicName = $"{originalModel.GetTopicName()}_mapped",
            AllProperties = typeof(TMapped).GetProperties(),
            KeyProperties = Array.Empty<System.Reflection.PropertyInfo>(), // No key after mapping
            ValidationResult = new ValidationResult { IsValid = true }
        };
    }

    public override string ToString()
    {
        return $"MappedEventSet<{typeof(T).Name}> - Items: {_mapped.Count}";
    }
}
### tool â€” 2025-08-11T08:14:00.331102+00:00

îˆ€fileciteîˆ‚turn0file1îˆ

using Confluent.Kafka;
using Confluent.Kafka.SyncOverAsync;
using Confluent.SchemaRegistry.Serdes;
using Kafka.Ksql.Linq.Configuration;
using Kafka.Ksql.Linq.Configuration.Abstractions;
using Kafka.Ksql.Linq.Core.Abstractions;
using Kafka.Ksql.Linq.Core.Extensions;
using Kafka.Ksql.Linq.Mapping;
using Kafka.Ksql.Linq.Messaging.Configuration;
using Kafka.Ksql.Linq.Core.Dlq;
using Kafka.Ksql.Linq.Messaging.Producers;
using Microsoft.Extensions.Logging;
using Microsoft.Extensions.Options;
using System;
using System.Collections.Generic;
using System.Runtime.CompilerServices;
using System.Threading;
using System.Threading.Tasks;
using ConfluentSchemaRegistry = Confluent.SchemaRegistry;

namespace Kafka.Ksql.Linq.Messaging.Consumers;

internal sealed class KafkaConsumerManager : IDisposable
{
    private readonly KsqlDslOptions _options;
    private readonly ILogger? _logger;
    private readonly Lazy<ConfluentSchemaRegistry.ISchemaRegistryClient> _schemaRegistryClient;
    private readonly Dictionary<Type, EntityModel> _entityModels;
    private readonly MappingRegistry _mappingRegistry;
    private readonly DlqOptions _dlq;
    private readonly IRateLimiter _limiter;
    private readonly IDlqProducer _dlqProducer;
    private bool _disposed;

#pragma warning disable CS0067 // Event is never used
    public event Func<byte[]?, Exception, string, int, long, DateTime, Headers?, string, string, Task>? DeserializationError;
#pragma warning restore CS0067

    public KafkaConsumerManager(
        MappingRegistry mapping,
        IOptions<KsqlDslOptions> options,
        Dictionary<Type, EntityModel> entityModels,
        IDlqProducer dlqProducer,
        ILoggerFactory? loggerFactory = null,
        IRateLimiter? limiter = null)
    {
        _mappingRegistry = mapping;
        _options = options?.Value ?? throw new ArgumentNullException(nameof(options));
        _entityModels = entityModels ?? new();
        _dlqProducer = dlqProducer;
        _logger = loggerFactory?.CreateLogger<KafkaConsumerManager>();
        _schemaRegistryClient = new Lazy<ConfluentSchemaRegistry.ISchemaRegistryClient>(CreateSchemaRegistryClient);
        _dlq = _options.DlqOptions;
        _limiter = limiter ?? new SimpleRateLimiter(_dlq.MaxPerSecond);
    }



    public async IAsyncEnumerable<(TPOCO, Dictionary<string, string>, MessageMeta)> ConsumeAsync<TPOCO>(
        [EnumeratorCancellation] CancellationToken cancellationToken = default) where TPOCO : class
    {
        var model = GetEntityModel<TPOCO>();
        var topic = model.GetTopicName();
        var mapping = _mappingRegistry.GetMapping(typeof(TPOCO));
        var config = BuildConsumerConfig(topic, null);

        var method = typeof(KafkaConsumerManager)
            .GetMethod(nameof(ConsumeInternal), System.Reflection.BindingFlags.NonPublic | System.Reflection.BindingFlags.Instance)!
            .MakeGenericMethod(mapping.AvroKeyType!, mapping.AvroValueType!, typeof(TPOCO));

        var enumerable = (IAsyncEnumerable<(TPOCO, Dictionary<string, string>, MessageMeta)>)method
            .Invoke(this, new object?[] { topic, config, mapping, cancellationToken })!;

        await foreach (var item in enumerable.WithCancellation(cancellationToken))
            yield return item;
    }

    private async IAsyncEnumerable<(TPOCO, Dictionary<string, string>, MessageMeta)> ConsumeInternal<TKey, TValue, TPOCO>(
        string topicName,
        ConsumerConfig config,
        KeyValueTypeMapping mapping,
        [EnumeratorCancellation] CancellationToken cancellationToken)
        where TKey : class where TValue : class where TPOCO : class
    {
        using var consumer = CreateConsumer<TKey, TValue>(config);
        consumer.Subscribe(topicName);

        while (!cancellationToken.IsCancellationRequested)
        {
            ConsumeResult<TKey, TValue>? result;
            try
            {
                result = consumer.Consume(cancellationToken);
            }
            catch (OperationCanceledException)
            {
                break;
            }
            if (result == null || result.IsPartitionEOF)
                continue;

            TPOCO entity;
            Dictionary<string, string> headers;
            MessageMeta meta;
            try
            {
                entity = (TPOCO)mapping.CombineFromAvroKeyValue(result.Message.Key, result.Message.Value!, typeof(TPOCO));
                headers = new Dictionary<string, string>();
                if (result.Message.Headers != null)
                {
                    foreach (var h in result.Message.Headers)
                        headers[h.Key] = System.Text.Encoding.UTF8.GetString(h.GetValueBytes());
                }

                meta = new MessageMeta(
                    Topic: result.Topic,
                    Partition: result.Partition,
                    Offset: result.Offset,
                    TimestampUtc: result.Message.Timestamp.UtcDateTime,
                    SchemaIdKey: TryGetSchemaId(result.Message.Key as byte[]),
                    SchemaIdValue: TryGetSchemaId(result.Message.Value as byte[]),
                    KeyIsNull: result.Message.Key is null,
                    HeaderAllowList: ExtractAllowedHeaders(result.Message.Headers, _dlq.HeaderAllowList, _dlq.HeaderValueMaxLength)
                );
            }
            catch (Exception ex)
            {
                await HandleMappingException(result, ex, _dlqProducer, consumer, _dlq, _limiter, cancellationToken).ConfigureAwait(false);
                continue;
            }

            yield return (entity, headers, meta);
            await Task.CompletedTask;
        }
    }

    internal static async Task HandleMappingException<TKey, TValue>(
        ConsumeResult<TKey, TValue> result,
        Exception ex,
        IDlqProducer dlqProducer,
        IConsumer<TKey, TValue> consumer,
        DlqOptions options,
        IRateLimiter limiter,
        CancellationToken cancellationToken)
        where TKey : class where TValue : class
    {
        if (options.EnableForDeserializationError && DlqGuard.ShouldSend(options, limiter, ex.GetType()))
        {
            var allowHeaders = ExtractAllowedHeaders(result.Message.Headers, options.HeaderAllowList, options.HeaderValueMaxLength);
            var env = DlqEnvelopeFactory.From(result, ex,
                options.ApplicationId, options.ConsumerGroup, options.Host, allowHeaders,
                options.ErrorMessageMaxLength, options.StackTraceMaxLength, options.NormalizeStackTraceWhitespace);
            await dlqProducer.ProduceAsync(env, cancellationToken).ConfigureAwait(false);
        }
        consumer.Commit(result);
    }

    private IConsumer<TKey, TValue> CreateConsumer<TKey, TValue>(ConsumerConfig config)
        where TKey : class where TValue : class
    {
        return new ConsumerBuilder<TKey, TValue>(config)
            .SetKeyDeserializer(new AvroDeserializer<TKey>(_schemaRegistryClient.Value).AsSyncOverAsync())
            .SetValueDeserializer(new AvroDeserializer<TValue>(_schemaRegistryClient.Value).AsSyncOverAsync())
            .Build();
    }

    private ConfluentSchemaRegistry.ISchemaRegistryClient CreateSchemaRegistryClient()
    {
        var cfg = new ConfluentSchemaRegistry.SchemaRegistryConfig { Url = _options.SchemaRegistry.Url };
        return new ConfluentSchemaRegistry.CachedSchemaRegistryClient(cfg);
    }

    private EntityModel GetEntityModel<T>() where T : class
    {
        if (_entityModels.TryGetValue(typeof(T), out var model))
            return model;
        throw new InvalidOperationException($"Entity model not found for {typeof(T).Name}");
    }

    private ConsumerConfig BuildConsumerConfig(string topicName, KafkaSubscriptionOptions? subscriptionOptions)
    {
        var topicConfig = _options.Topics.TryGetValue(topicName, out var cfg) ? cfg : new TopicSection();
        var groupId = subscriptionOptions?.GroupId ?? topicConfig.Consumer.GroupId;
        if (string.IsNullOrWhiteSpace(groupId))
            groupId = "default-group";

        var consumerConfig = new ConsumerConfig
        {
            BootstrapServers = _options.Common.BootstrapServers,
            ClientId = _options.Common.ClientId,
            GroupId = groupId,
            AutoOffsetReset = Enum.Parse<AutoOffsetReset>(topicConfig.Consumer.AutoOffsetReset),
            EnableAutoCommit = topicConfig.Consumer.EnableAutoCommit,
            AutoCommitIntervalMs = topicConfig.Consumer.AutoCommitIntervalMs,
            SessionTimeoutMs = topicConfig.Consumer.SessionTimeoutMs,
            HeartbeatIntervalMs = topicConfig.Consumer.HeartbeatIntervalMs,
            MaxPollIntervalMs = topicConfig.Consumer.MaxPollIntervalMs,
            FetchMinBytes = topicConfig.Consumer.FetchMinBytes,
            FetchMaxBytes = topicConfig.Consumer.FetchMaxBytes,
            IsolationLevel = Enum.Parse<IsolationLevel>(topicConfig.Consumer.IsolationLevel)
        };

        if (subscriptionOptions != null)
        {
            if (subscriptionOptions.AutoCommit.HasValue)
                consumerConfig.EnableAutoCommit = subscriptionOptions.AutoCommit.Value;
            if (subscriptionOptions.SessionTimeout.HasValue)
                consumerConfig.SessionTimeoutMs = (int)subscriptionOptions.SessionTimeout.Value.TotalMilliseconds;
            if (subscriptionOptions.HeartbeatInterval.HasValue)
                consumerConfig.HeartbeatIntervalMs = (int)subscriptionOptions.HeartbeatInterval.Value.TotalMilliseconds;
            if (subscriptionOptions.MaxPollInterval.HasValue)
                consumerConfig.MaxPollIntervalMs = (int)subscriptionOptions.MaxPollInterval.Value.TotalMilliseconds;
        }

        if (_options.Common.SecurityProtocol != SecurityProtocol.Plaintext)
        {
            consumerConfig.SecurityProtocol = _options.Common.SecurityProtocol;
            if (_options.Common.SaslMechanism.HasValue)
            {
                consumerConfig.SaslMechanism = _options.Common.SaslMechanism.Value;
                consumerConfig.SaslUsername = _options.Common.SaslUsername;
                consumerConfig.SaslPassword = _options.Common.SaslPassword;
            }

            if (!string.IsNullOrEmpty(_options.Common.SslCaLocation))
            {
                consumerConfig.SslCaLocation = _options.Common.SslCaLocation;
                consumerConfig.SslCertificateLocation = _options.Common.SslCertificateLocation;
                consumerConfig.SslKeyLocation = _options.Common.SslKeyLocation;
                consumerConfig.SslKeyPassword = _options.Common.SslKeyPassword;
            }
        }

        foreach (var kvp in topicConfig.Consumer.AdditionalProperties)
            consumerConfig.Set(kvp.Key, kvp.Value);

        return consumerConfig;
    }

    public void ResetOffsetsToBeginning<TPOCO>() where TPOCO : class
    {
        var model = GetEntityModel<TPOCO>();
        var topic = model.GetTopicName();
        var mapping = _mappingRegistry.GetMapping(typeof(TPOCO));
        var config = BuildConsumerConfig(topic, null);
        config.EnableAutoCommit = false;
        var method = typeof(KafkaConsumerManager)
            .GetMethod(nameof(ResetOffsetsToBeginningInternal), System.Reflection.BindingFlags.NonPublic | System.Reflection.BindingFlags.Instance)!
            .MakeGenericMethod(mapping.AvroKeyType!, mapping.AvroValueType!);
        method.Invoke(this, new object?[] { topic, config, model.Partitions });
    }

    private void ResetOffsetsToBeginningInternal<TKey, TValue>(string topic, ConsumerConfig config, int partitions)
        where TKey : class where TValue : class
    {
        using var consumer = CreateConsumer<TKey, TValue>(config);
        var tps = new List<TopicPartitionOffset>(partitions);
        for (var i = 0; i < partitions; i++)
            tps.Add(new TopicPartitionOffset(topic, new Partition(i), new Offset(0)));
        consumer.Assign(tps);
        consumer.Commit(tps);
    }

    public void Dispose()
    {
        if (_disposed) return;
        if (_schemaRegistryClient.IsValueCreated)
            _schemaRegistryClient.Value.Dispose();
        _disposed = true;
    }

    private static int? TryGetSchemaId(byte[]? payload)
    {
        if (payload is { Length: >= 5 } && payload[0] == 0)
            return System.Buffers.Binary.BinaryPrimitives.ReadInt32BigEndian(payload.AsSpan(1, 4));
        return null;
    }

    private static System.Collections.Generic.IReadOnlyDictionary<string, string> ExtractAllowedHeaders(
        Headers? headers, System.Collections.Generic.IEnumerable<string> allowList, int maxLen = 1024)
    {
        var dict = new System.Collections.Generic.Dictionary<string, string>(System.StringComparer.OrdinalIgnoreCase);
        if (headers is null) return dict;

        var set = allowList is System.Collections.Generic.HashSet<string> hs ? hs :
                  new System.Collections.Generic.HashSet<string>(allowList ?? System.Array.Empty<string>(), System.StringComparer.OrdinalIgnoreCase);

        foreach (var h in headers)
        {
            if (!set.Contains(h.Key)) continue;
            var bytes = h.GetValueBytes() ?? System.Array.Empty<byte>();
            string val;
            try
            {
                val = System.Text.Encoding.UTF8.GetString(bytes);
                if (!System.Text.Encoding.UTF8.GetBytes(val).AsSpan().SequenceEqual(bytes))
                    val = "base64:" + System.Convert.ToBase64String(bytes);
            }
            catch
            {
                val = "base64:" + System.Convert.ToBase64String(bytes);
            }
            if (val.Length > maxLen) val = val[..maxLen];
            dict[h.Key] = val;
        }
        return dict;
    }
}
### tool â€” 2025-08-11T08:14:00.372561+00:00

îˆ€fileciteîˆ‚turn0file2îˆ

namespace Kafka.Ksql.Linq.Messaging.Consumers;

public interface ICommitManager
{
    void Commit(object entity);
}
### tool â€” 2025-08-11T08:14:00.415571+00:00

îˆ€fileciteîˆ‚turn0file3îˆ

namespace Kafka.Ksql.Linq.Messaging.Consumers;

internal class NoopCommitManager : ICommitManager
{
    public void Commit(object entity) { }
}
### tool â€” 2025-08-11T08:14:00.428421+00:00

All the files uploaded by the user have been fully loaded. Searching won't provide additional information.
### assistant â€” 2025-08-11T08:14:00.450367+00:00

_(empty)_
### assistant â€” 2025-08-11T08:29:17.376851+00:00

# Let's read the uploaded files to see content
import os, textwrap, json, sys, pathlib, re, itertools, math, random
### user â€” 2025-08-11T08:29:17.985000+00:00

å›ç­”ãŠé¡˜ã„ã—ã¾ã™
### system â€” 2025-08-11T08:29:18.225523+00:00

_(empty)_
### assistant â€” 2025-08-11T08:29:18.382018+00:00

_(empty)_
### assistant â€” 2025-08-11T08:29:23.272131+00:00

from pathlib import Path
base = Path('/mnt/data')
files = list(base.glob('*.cs'))
files
### tool â€” 2025-08-11T08:29:24.862062+00:00

[PosixPath('/mnt/data/EventSet.cs'),
 PosixPath('/mnt/data/KafkaConsumerManager.cs'),
 PosixPath('/mnt/data/ICommitManager.cs'),
 PosixPath('/mnt/data/NoopCommitManager.cs')]
### assistant â€” 2025-08-11T08:29:25.835580+00:00

for p in files:
    print("====", p.name, "====")
    print(p.read_text()[:2000])
### tool â€” 2025-08-11T08:29:26.878279+00:00

==== EventSet.cs ====
using Kafka.Ksql.Linq.Core.Abstractions;
using Kafka.Ksql.Linq.Core.Extensions;
using Kafka.Ksql.Linq.Messaging.Internal;
using Kafka.Ksql.Linq.Messaging;
using Kafka.Ksql.Linq.Core.Dlq;
using Kafka.Ksql.Linq.Query.Abstractions;
using System;
using System.Collections.Generic;
using System.Runtime.CompilerServices;
using System.Threading;
using System.Threading.Tasks;

namespace Kafka.Ksql.Linq;

/// <summary>
/// Base class for EventSet implementing IEntitySet<T>
/// Reason for modification: unified with KsqlContext and added IEntitySet<T> implementation
/// </summary>
public abstract class EventSet<T> : IEntitySet<T> where T : class
{
    protected readonly IKsqlContext _context;
    protected readonly EntityModel _entityModel;
    private readonly ErrorHandlingContext _errorHandlingContext;
    private IErrorSink? _dlqErrorSink;
    private readonly Messaging.Producers.IDlqProducer? _dlqProducer;
    private readonly Messaging.Consumers.ICommitManager? _commitManager;

    protected EventSet(IKsqlContext context, EntityModel? entityModel = null, IErrorSink? dlqErrorSink = null,
        Messaging.Producers.IDlqProducer? dlqProducer = null, Messaging.Consumers.ICommitManager? commitManager = null)
    {
        _context = context ?? throw new ArgumentNullException(nameof(context));
        _errorHandlingContext = new ErrorHandlingContext();
        _dlqErrorSink = dlqErrorSink;
        _dlqProducer = dlqProducer;
        _commitManager = commitManager;

        if (context is KsqlContext kctx)
        {
            _entityModel = kctx.EnsureEntityModel(typeof(T), entityModel);
        }
        else
        {
            _entityModel = entityModel ?? throw new ArgumentNullException(nameof(entityModel));
        }

        if (_dlqErrorSink != null)
        {
            _errorHandlingContext.ErrorOccurred += (ctx, msg) => _dlqErrorSink.HandleErrorAsync(ctx, msg);
        }
    }

    private EventSet(IKsqlContext context, EntityModel entityModel, ErrorHandlingContex
==== KafkaConsumerManager.cs ====
using Confluent.Kafka;
using Confluent.Kafka.SyncOverAsync;
using Confluent.SchemaRegistry.Serdes;
using Kafka.Ksql.Linq.Configuration;
using Kafka.Ksql.Linq.Configuration.Abstractions;
using Kafka.Ksql.Linq.Core.Abstractions;
using Kafka.Ksql.Linq.Core.Extensions;
using Kafka.Ksql.Linq.Mapping;
using Kafka.Ksql.Linq.Messaging.Configuration;
using Kafka.Ksql.Linq.Core.Dlq;
using Kafka.Ksql.Linq.Messaging.Producers;
using Microsoft.Extensions.Logging;
using Microsoft.Extensions.Options;
using System;
using System.Collections.Generic;
using System.Runtime.CompilerServices;
using System.Threading;
using System.Threading.Tasks;
using ConfluentSchemaRegistry = Confluent.SchemaRegistry;

namespace Kafka.Ksql.Linq.Messaging.Consumers;

internal sealed class KafkaConsumerManager : IDisposable
{
    private readonly KsqlDslOptions _options;
    private readonly ILogger? _logger;
    private readonly Lazy<ConfluentSchemaRegistry.ISchemaRegistryClient> _schemaRegistryClient;
    private readonly Dictionary<Type, EntityModel> _entityModels;
    private readonly MappingRegistry _mappingRegistry;
    private readonly DlqOptions _dlq;
    private readonly IRateLimiter _limiter;
    private readonly IDlqProducer _dlqProducer;
    private bool _disposed;

#pragma warning disable CS0067 // Event is never used
    public event Func<byte[]?, Exception, string, int, long, DateTime, Headers?, string, string, Task>? DeserializationError;
#pragma warning restore CS0067

    public KafkaConsumerManager(
        MappingRegistry mapping,
        IOptions<KsqlDslOptions> options,
        Dictionary<Type, EntityModel> entityModels,
        IDlqProducer dlqProducer,
        ILoggerFactory? loggerFactory = null,
        IRateLimiter? limiter = null)
    {
        _mappingRegistry = mapping;
        _options = options?.Value ?? throw new ArgumentNullException(nameof(options));
        _entityModels = entityModels ?? new();
        _dlqProducer = dlqProducer;
        _logger = loggerFactory?.Create
==== ICommitManager.cs ====
namespace Kafka.Ksql.Linq.Messaging.Consumers;

public interface ICommitManager
{
    void Commit(object entity);
}

==== NoopCommitManager.cs ====
namespace Kafka.Ksql.Linq.Messaging.Consumers;

internal class NoopCommitManager : ICommitManager
{
    public void Commit(object entity) { }
}
### assistant â€” 2025-08-11T08:29:27.775114+00:00

print(Path('/mnt/data/EventSet.cs').read_text())
### tool â€” 2025-08-11T08:29:28.879645+00:00

if (!shouldContinue)
                {
                    continue;
                }

                throw;
            }

            if (!hasNext)
                yield break;

            yield return enumerator.Current;
        }
    }


    public virtual async Task<List<T>> ToListAsync(CancellationToken cancellationToken = default)
    {
        if (_entityModel.EntityType == typeof(Messaging.DlqEnvelope))
            throw new InvalidOperationException("DLQã¯ç„¡é™åˆ—æŒ™/å±¥æ­´åˆ—ã§ã‚ã‚Šã€ãƒãƒƒãƒå–å¾—ãƒ»ä»¶æ•°æŒ‡å®šå–å¾—ã¯ç¾çŠ¶æœªå¯¾å¿œã§ã™");

        if (_entityModel.GetExplicitStreamTableType() == StreamTableType.Stream)
            throw new InvalidOperationException("ToListAsync() is not supported on a Stream source. Use ForEachAsync or subscribe for event consumption.");

        var results = new List<T>();

        await foreach (var item in GetAsyncEnumeratorWrapper(cancellationToken))
        {
            results.Add(item);
        }

        return results;
    }
    /// <summary>
    /// ABSTRACT: Producer functionality - implemented in derived classes
    /// </summary>
    protected abstract Task SendEntityAsync(T entity, Dictionary<string, string>? headers, CancellationToken cancellationToken);

    /// <summary>
    /// IEntitySet<T> implementation: producer operations
    /// </summary>
    public virtual async Task AddAsync(T entity, Dictionary<string, string>? headers = null, CancellationToken cancellationToken = default)
    {
        if (entity == null)
            throw new ArgumentNullException(nameof(entity));

        await SendEntityAsync(entity, headers, cancellationToken);
    }

    public virtual Task RemoveAsync(T entity, CancellationToken cancellationToken = default)
    {
        throw new NotSupportedException($"RemoveAsync is not supported for {GetType().Name}.");
    }

    /// <summary>
    /// Retrieves messages from the underlying consumer.
    /// Separated for ease of testing.
    /// </summary>
    /// <param name="context">Active KsqlContext</param>
    /// <param name="cancellationToken">Cancellation token</param>
    /// <returns>Message stream with headers</returns>
    protected virtual IAsyncEnumerable<(T Entity, Dictionary<string, string> Headers, MessageMeta Meta)> ConsumeAsync(
        KsqlContext context,
        CancellationToken cancellationToken)
    {
        return context.GetConsumerManager().ConsumeAsync<T>(cancellationToken);
    }
    /// <summary>
    /// REDESIGNED: ForEachAsync supporting continuous Kafka consumption
    /// Design change: ToListAsync() is disallowed; now based on GetAsyncEnumerator
    /// </summary>
    public virtual Task ForEachAsync(Func<T, Task> action, TimeSpan timeout = default, CancellationToken cancellationToken = default)
    {
        if (action == null)
            throw new ArgumentNullException(nameof(action));

        return ForEachAsync((item, headers, _) => action(item), timeout, cancellationToken);
    }

    [Obsolete("Use ForEachAsync(Func<T, Dictionary<string,string>, MessageMeta, Task>)")]
    public virtual Task ForEachAsync(Func<T, Dictionary<string,string>, Task> action, TimeSpan timeout = default, CancellationToken cancellationToken = default)
        => ForEachAsync((e, h, _) => action(e, h), timeout, cancellationToken);

    public virtual async Task ForEachAsync(Func<T, Dictionary<string,string>, MessageMeta, Task> action, TimeSpan timeout = default, CancellationToken cancellationToken = default)
    {
        if (action == null)
            throw new ArgumentNullException(nameof(action));

        var context = GetContext() as KsqlContext
            ?? throw new InvalidOperationException("KsqlContext is required");

        using var linkedCts = CancellationTokenSource.CreateLinkedTokenSource(cancellationToken);

        if (timeout != default && timeout != TimeSpan.Zero)
        {
            linkedCts.CancelAfter(timeout);
        }
        await foreach (var (entity, headers, meta) in ConsumeAsync(context, linkedCts.Token))
        {
            if (headers.TryGetValue("is_dummy", out var dummyHeader) && bool.TryParse(dummyHeader, out var isDummy) && isDummy)
            {
                continue;
            }

            var maxAttempts = _errorHandlingContext.ErrorAction == ErrorAction.Retry
                ? _errorHandlingContext.RetryCount + 1
                : 1;

            for (var attempt = 1; attempt <= maxAttempts; attempt++)
            {
                try
                {
                    await action(entity, headers, meta);
                    break;
                }
                catch (Exception ex)
                {
                    _errorHandlingContext.CurrentAttempt = attempt;

                    if (attempt < maxAttempts && _errorHandlingContext.ErrorAction == ErrorAction.Retry)
                    {
                        await Task.Delay(_errorHandlingContext.RetryInterval, linkedCts.Token);
                        continue;
                    }

                    var dlq = context.DlqOptions;
                    if (_dlqProducer != null && dlq.EnableForHandlerError && DlqGuard.ShouldSend(dlq, context.DlqLimiter, ex.GetType()))
                    {
                        var env = DlqEnvelopeFactory.From(
                            meta, ex,
                            dlq.ApplicationId, dlq.ConsumerGroup, dlq.Host,
                            dlq.ErrorMessageMaxLength, dlq.StackTraceMaxLength, dlq.NormalizeStackTraceWhitespace);
                        await _dlqProducer.ProduceAsync(env, linkedCts.Token).ConfigureAwait(false);
                    }

                    _commitManager?.Commit(entity);
                    break;
                }
            }
        }
    }

    /// <summary>
    /// IEntitySet<T> implementation: retrieve metadata
    /// </summary>
    public string GetTopicName() => (_entityModel.TopicName ?? _entityModel.EntityType.Name).ToLowerInvariant();

    public EntityModel GetEntityModel() => _entityModel;

    public IKsqlContext GetContext() => _context;

    /// <summary>
    /// Create message context for error handling
    /// </summary>
    private KafkaMessageContext CreateMessageContext(T item)
    {
        return new KafkaMessageContext
        {
            MessageId = Guid.NewGuid().ToString(),
            Tags = new Dictionary<string, object>
            {
                ["entity_type"] = typeof(T).Name,
                ["topic_name"] = GetTopicName(),
                ["processing_phase"] = "ForEachAsync",
                ["timestamp"] = DateTime.UtcNow
            }
        };
    }

    /// <summary>
    /// Creates a ManualCommitMessage instance
    /// </summary>
    protected virtual IManualCommitMessage<T> CreateManualCommitMessage(T item)
    {
        return new ManualCommitMessage<T>(item, () => Task.CompletedTask, () => Task.CompletedTask);
    }

    /// <summary>
    /// Yields messages as different types depending on UseManualCommit
    /// </summary>
    public virtual async IAsyncEnumerable<object> ForEachAsync([EnumeratorCancellation] CancellationToken cancellationToken = default)
    {
        await foreach (var item in GetAsyncEnumeratorWrapper(cancellationToken))
        {
            if (_entityModel.UseManualCommit)
            {
                yield return CreateManualCommitMessage(item);
            }
            else
            {
                yield return item;
            }
        }
    }

    /// <summary>
    /// Configure the error handling policy
    /// </summary>
    internal virtual EventSet<T> WithErrorPolicy(ErrorHandlingPolicy policy)
    {
        if (policy == null)
            throw new ArgumentNullException(nameof(policy));

        _errorHandlingContext.ErrorAction = policy.Action;
        _errorHandlingContext.RetryCount = policy.RetryCount;
        _errorHandlingContext.RetryInterval = policy.RetryInterval;
        _errorHandlingContext.CustomHandler = policy.CustomHandler;

        return this;
    }

    public override string ToString()
    {
        return $"EventSet<{typeof(T).Name}> - Topic: {GetTopicName()}";
    }



    /// <summary>
    /// Specifies the number of retries.
    /// Used when ErrorAction.Retry is selected.
    /// </summary>
    /// <param name="maxRetries">Maximum retry count</param>
    /// <param name="retryInterval">Retry interval (optional)</param>
    /// <returns>EventSet with retry configuration applied</returns>
    public EventSet<T> WithRetry(int maxRetries, TimeSpan? retryInterval = null)
    {
        if (maxRetries < 0)
            throw new ArgumentException("Retry count must be zero or greater", nameof(maxRetries));

        var newContext = new ErrorHandlingContext
        {
            ErrorAction = _errorHandlingContext.ErrorAction,
            RetryCount = maxRetries,
            RetryInterval = retryInterval ?? TimeSpan.FromSeconds(1)
        };

        return CreateNewInstance(_context, _entityModel, newContext, _dlqErrorSink);
    }

    /// <summary>
    /// Passes the POCO to the business logic.
    /// After receiving from Kafka, each element is transformed using the supplied function.
    /// Exceptions and retries are handled based on the OnError and WithRetry settings.
    /// </summary>
    /// <typeparam name="TResult">Result type</typeparam>
    /// <param name="mapper">Mapping function</param>
    /// <returns>The mapped EventSet</returns>
    public async Task<EventSet<TResult>> Map<TResult>(Func<T, Task<TResult>> mapper) where TResult : class
    {
        if (mapper == null)
            throw new ArgumentNullException(nameof(mapper));

        var results = new List<TResult>();
        var sourceData = await ToListAsync();

        foreach (var item in sourceData)
        {
            var itemErrorContext = new ErrorHandlingContext
            {
                ErrorAction = _errorHandlingContext.ErrorAction,
                RetryCount = _errorHandlingContext.RetryCount,
                RetryInterval = _errorHandlingContext.RetryInterval
            };

            await ProcessItemWithErrorHandling(
                item,
                mapper,
                results,
                itemErrorContext);
        }

        var resultEntityModel = CreateEntityModelForType<TResult>();
        return new MappedEventSet<TResult>(results, _context, resultEntityModel, _dlqErrorSink);
    }

    /// <summary>
    /// Synchronous version of the Map function
    /// </summary>
    public EventSet<TResult> Map<TResult>(Func<T, TResult> mapper) where TResult : class
    {
        if (mapper == null)
            throw new ArgumentNullException(nameof(mapper));

        var results = new List<TResult>();
        var sourceData = ToListAsync().GetAwaiter().GetResult();

        foreach (var item in sourceData)
        {
            var itemErrorContext = new ErrorHandlingContext
            {
                ErrorAction = _errorHandlingContext.ErrorAction,
                RetryCount = _errorHandlingContext.RetryCount,
                RetryInterval = _errorHandlingContext.RetryInterval
            };

            ProcessItemWithErrorHandlingSync(
                item,
                mapper,
                results,
                itemErrorContext);
        }
        var resultEntityModel = CreateEntityModelForType<TResult>();
        return new MappedEventSet<TResult>(results, _context, resultEntityModel, _dlqErrorSink);
    }

    // Abstract method: create a new instance in derived classes
    protected virtual EventSet<T> CreateNewInstance(IKsqlContext context, EntityModel entityModel, ErrorHandlingContext errorContext, IErrorSink? dlqErrorSink)
    {
        // Default implementation: concrete classes must override
        throw new NotImplementedException("Derived classes must implement CreateNewInstance");
    }

    private EntityModel CreateEntityModelForType<TResult>() where TResult : class
    {
        return new EntityModel
        {
            EntityType = typeof(TResult),
            TopicName = $"{typeof(TResult).Name.ToLowerInvariant()}_mapped",
            AllProperties = typeof(TResult).GetProperties(),
            KeyProperties = Array.Empty<System.Reflection.PropertyInfo>(),
            ValidationResult = new ValidationResult { IsValid = true }
        };
    }

    /// <summary>
    /// Item-level processing with error handling (async version)
    /// </summary>
    private async Task ProcessItemWithErrorHandling<TResult>(
        T item,
        Func<T, Task<TResult>> mapper,
        List<TResult> results,
        ErrorHandlingContext errorContext) where TResult : class
    {
        var maxAttempts = errorContext.ErrorAction == ErrorAction.Retry
            ? errorContext.RetryCount + 1
            : 1;

        for (int attempt = 1; attempt <= maxAttempts; attempt++)
        {
            try
            {
                var result = await mapper(item);
                results.Add(result);
                return; // Processing completed successfully
            }
            catch (Exception ex)
            {
                errorContext.CurrentAttempt = attempt;

                // Retry regardless of ErrorAction if this is not the final attempt
                if (attempt < maxAttempts && errorContext.ErrorAction == ErrorAction.Retry)
                {
                    Console.WriteLine($"[{DateTime.UtcNow:HH:mm:ss}] Retry {attempt}/{errorContext.RetryCount}: {ex.Message}");
                    await Task.Delay(errorContext.RetryInterval);
                    continue;
                }

                // Perform error handling on the last attempt or when not retrying
                var shouldContinue = await errorContext.HandleErrorAsync(item, ex, CreateContext(item, errorContext));

                if (!shouldContinue)
                {
                    return; // Skip this item and move to the next
                }
            }
        }
    }

    /// <summary>
    /// Item-level processing with error handling (sync version)
    /// </summary>
    private void ProcessItemWithErrorHandlingSync<TResult>(
        T item,
        Func<T, TResult> mapper,
        List<TResult> results,
        ErrorHandlingContext errorContext) where TResult : class
    {
        var maxAttempts = errorContext.ErrorAction == ErrorAction.Retry
            ? errorContext.RetryCount + 1
            : 1;

        for (int attempt = 1; attempt <= maxAttempts; attempt++)
        {
            try
            {
                var result = mapper(item);
                results.Add(result);
                return; // Processing completed successfully
            }
            catch (Exception ex)
            {
                errorContext.CurrentAttempt = attempt;

                // Retry regardless of ErrorAction if this is not the final attempt
                if (attempt < maxAttempts && errorContext.ErrorAction == ErrorAction.Retry)
                {
                    Console.WriteLine($"[{DateTime.UtcNow:HH:mm:ss}] Retry {attempt}/{errorContext.RetryCount}: {ex.Message}");
                    Thread.Sleep(errorContext.RetryInterval);
                    continue;
                }

                // Perform error handling on the last attempt or when not retrying
                var shouldContinue = errorContext.HandleErrorAsync(item, ex, CreateContext(item, errorContext)).GetAwaiter().GetResult();

                if (!shouldContinue)
                {
                    return; // Skip this item and proceed to the next
                }
            }
        }
    }

    /// <summary>
    /// Create a message context
    /// </summary>
    private KafkaMessageContext CreateContext(T item, ErrorHandlingContext errorContext)
    {
        return new KafkaMessageContext
        {
            MessageId = Guid.NewGuid().ToString(),
            Tags = new Dictionary<string, object>
            {
                ["original_topic"] = GetTopicName(),
                ["original_partition"] = 0, // Replace with actual value
                ["original_offset"] = 0, // Replace with actual value
                ["retry_count"] = errorContext.CurrentAttempt,
                ["error_phase"] = "Processing"
            }
        };
    }

}
internal class MappedEventSet<T> : EventSet<T> where T : class
{
    private readonly List<T> _mapped;
    private readonly EntityModel _originalEntityModel;

    public MappedEventSet(List<T> mappedItems, IKsqlContext context, EntityModel originalEntityModel, IErrorSink? errorSink = null)
        : base(context, CreateMappedEntityModel<T>(originalEntityModel), errorSink)
    {
        _mapped = mappedItems ?? throw new ArgumentNullException(nameof(mappedItems));
        _originalEntityModel = originalEntityModel;
    }

    /// <summary>
    /// NEW: GetAsyncEnumerator implementation for fixed lists
    /// Returns each _mapped[i] sequentially via yield return
    /// </summary>
    public override async IAsyncEnumerator<T> GetAsyncEnumerator(CancellationToken cancellationToken = default)
    {
        foreach (var item in _mapped)
        {
            if (cancellationToken.IsCancellationRequested)
                yield break;

            yield return item;

            // Inserted to treat the loop asynchronously (avoid CPU intensive work)
            await Task.Yield();
        }
    }

    /// <summary>
    /// OPTIMIZATION: ToListAsync - already a fixed list so return immediately
    /// </summary>
    public override async Task<List<T>> ToListAsync(CancellationToken cancellationToken = default)
    {
        if (_entityModel.GetExplicitStreamTableType() == StreamTableType.Stream)
            throw new InvalidOperationException("ToListAsync() is not supported on a Stream source. Use ForEachAsync or subscribe for event consumption.");

        // Already a fixed list; return a copy
        await Task.CompletedTask;
        return new List<T>(_mapped);
    }

    /// <summary>
    /// Data after Map cannot be sent via Producer
    /// </summary>
    protected override Task SendEntityAsync(T entity, Dictionary<string, string>? headers, CancellationToken cancellationToken)
    {
        throw new NotSupportedException(
            $"MappedEventSet<{typeof(T).Name}> does not support AddAsync operations. " +
            "Mapped data is read-only and derived from transformation operations.");
    }

    public override Task RemoveAsync(T entity, CancellationToken cancellationToken = default)
    {
        throw new NotSupportedException($"MappedEventSet<{typeof(T).Name}> does not support RemoveAsync operations.");
    }

    /// <summary>
    /// Helper method to create a MappedEventSet
    /// </summary>
    public static MappedEventSet<T> Create(List<T> mappedItems, IKsqlContext context, EntityModel originalEntityModel, IErrorSink? errorSink = null)
    {
        return new MappedEventSet<T>(mappedItems, context, originalEntityModel, errorSink);
    }

    /// <summary>
    /// Create a MappedEventSet with DLQ support
    /// </summary>
    public static MappedEventSet<T> CreateWithDlq(List<T> mappedItems, IKsqlContext context, EntityModel originalEntityModel, IErrorSink dlqErrorSink)
    {
        return new MappedEventSet<T>(mappedItems, context, originalEntityModel, dlqErrorSink);
    }

    /// <summary>
    /// Create an EntityModel for mapped data
    /// </summary>
    private static EntityModel CreateMappedEntityModel<TMapped>(EntityModel originalModel) where TMapped : class
    {
        return new EntityModel
        {
            EntityType = typeof(TMapped),
            TopicName = $"{originalModel.GetTopicName()}_mapped",
            AllProperties = typeof(TMapped).GetProperties(),
            KeyProperties = Array.Empty<System.Reflection.PropertyInfo>(), // No key after mapping
            ValidationResult = new ValidationResult { IsValid = true }
        };
    }

    public override string ToString()
    {
        return $"MappedEventSet<{typeof(T).Name}> - Items: {_mapped.Count}";
    }
}
### assistant â€” 2025-08-11T08:29:29.835182+00:00

print(Path('/mnt/data/KafkaConsumerManager.cs').read_text()[:8000])
### tool â€” 2025-08-11T08:29:31.066949+00:00

using Confluent.Kafka;
using Confluent.Kafka.SyncOverAsync;
using Confluent.SchemaRegistry.Serdes;
using Kafka.Ksql.Linq.Configuration;
using Kafka.Ksql.Linq.Configuration.Abstractions;
using Kafka.Ksql.Linq.Core.Abstractions;
using Kafka.Ksql.Linq.Core.Extensions;
using Kafka.Ksql.Linq.Mapping;
using Kafka.Ksql.Linq.Messaging.Configuration;
using Kafka.Ksql.Linq.Core.Dlq;
using Kafka.Ksql.Linq.Messaging.Producers;
using Microsoft.Extensions.Logging;
using Microsoft.Extensions.Options;
using System;
using System.Collections.Generic;
using System.Runtime.CompilerServices;
using System.Threading;
using System.Threading.Tasks;
using ConfluentSchemaRegistry = Confluent.SchemaRegistry;

namespace Kafka.Ksql.Linq.Messaging.Consumers;

internal sealed class KafkaConsumerManager : IDisposable
{
    private readonly KsqlDslOptions _options;
    private readonly ILogger? _logger;
    private readonly Lazy<ConfluentSchemaRegistry.ISchemaRegistryClient> _schemaRegistryClient;
    private readonly Dictionary<Type, EntityModel> _entityModels;
    private readonly MappingRegistry _mappingRegistry;
    private readonly DlqOptions _dlq;
    private readonly IRateLimiter _limiter;
    private readonly IDlqProducer _dlqProducer;
    private bool _disposed;

#pragma warning disable CS0067 // Event is never used
    public event Func<byte[]?, Exception, string, int, long, DateTime, Headers?, string, string, Task>? DeserializationError;
#pragma warning restore CS0067

    public KafkaConsumerManager(
        MappingRegistry mapping,
        IOptions<KsqlDslOptions> options,
        Dictionary<Type, EntityModel> entityModels,
        IDlqProducer dlqProducer,
        ILoggerFactory? loggerFactory = null,
        IRateLimiter? limiter = null)
    {
        _mappingRegistry = mapping;
        _options = options?.Value ?? throw new ArgumentNullException(nameof(options));
        _entityModels = entityModels ?? new();
        _dlqProducer = dlqProducer;
        _logger = loggerFactory?.CreateLogger<KafkaConsumerManager>();
        _schemaRegistryClient = new Lazy<ConfluentSchemaRegistry.ISchemaRegistryClient>(CreateSchemaRegistryClient);
        _dlq = _options.DlqOptions;
        _limiter = limiter ?? new SimpleRateLimiter(_dlq.MaxPerSecond);
    }



    public async IAsyncEnumerable<(TPOCO, Dictionary<string, string>, MessageMeta)> ConsumeAsync<TPOCO>(
        [EnumeratorCancellation] CancellationToken cancellationToken = default) where TPOCO : class
    {
        var model = GetEntityModel<TPOCO>();
        var topic = model.GetTopicName();
        var mapping = _mappingRegistry.GetMapping(typeof(TPOCO));
        var config = BuildConsumerConfig(topic, null);

        var method = typeof(KafkaConsumerManager)
            .GetMethod(nameof(ConsumeInternal), System.Reflection.BindingFlags.NonPublic | System.Reflection.BindingFlags.Instance)!
            .MakeGenericMethod(mapping.AvroKeyType!, mapping.AvroValueType!, typeof(TPOCO));

        var enumerable = (IAsyncEnumerable<(TPOCO, Dictionary<string, string>, MessageMeta)>)method
            .Invoke(this, new object?[] { topic, config, mapping, cancellationToken })!;

        await foreach (var item in enumerable.WithCancellation(cancellationToken))
            yield return item;
    }

    private async IAsyncEnumerable<(TPOCO, Dictionary<string, string>, MessageMeta)> ConsumeInternal<TKey, TValue, TPOCO>(
        string topicName,
        ConsumerConfig config,
        KeyValueTypeMapping mapping,
        [EnumeratorCancellation] CancellationToken cancellationToken)
        where TKey : class where TValue : class where TPOCO : class
    {
        using var consumer = CreateConsumer<TKey, TValue>(config);
        consumer.Subscribe(topicName);

        while (!cancellationToken.IsCancellationRequested)
        {
            ConsumeResult<TKey, TValue>? result;
            try
            {
                result = consumer.Consume(cancellationToken);
            }
            catch (OperationCanceledException)
            {
                break;
            }
            if (result == null || result.IsPartitionEOF)
                continue;

            TPOCO entity;
            Dictionary<string, string> headers;
            MessageMeta meta;
            try
            {
                entity = (TPOCO)mapping.CombineFromAvroKeyValue(result.Message.Key, result.Message.Value!, typeof(TPOCO));
                headers = new Dictionary<string, string>();
                if (result.Message.Headers != null)
                {
                    foreach (var h in result.Message.Headers)
                        headers[h.Key] = System.Text.Encoding.UTF8.GetString(h.GetValueBytes());
                }

                meta = new MessageMeta(
                    Topic: result.Topic,
                    Partition: result.Partition,
                    Offset: result.Offset,
                    TimestampUtc: result.Message.Timestamp.UtcDateTime,
                    SchemaIdKey: TryGetSchemaId(result.Message.Key as byte[]),
                    SchemaIdValue: TryGetSchemaId(result.Message.Value as byte[]),
                    KeyIsNull: result.Message.Key is null,
                    HeaderAllowList: ExtractAllowedHeaders(result.Message.Headers, _dlq.HeaderAllowList, _dlq.HeaderValueMaxLength)
                );
            }
            catch (Exception ex)
            {
                await HandleMappingException(result, ex, _dlqProducer, consumer, _dlq, _limiter, cancellationToken).ConfigureAwait(false);
                continue;
            }

            yield return (entity, headers, meta);
            await Task.CompletedTask;
        }
    }

    internal static async Task HandleMappingException<TKey, TValue>(
        ConsumeResult<TKey, TValue> result,
        Exception ex,
        IDlqProducer dlqProducer,
        IConsumer<TKey, TValue> consumer,
        DlqOptions options,
        IRateLimiter limiter,
        CancellationToken cancellationToken)
        where TKey : class where TValue : class
    {
        if (options.EnableForDeserializationError && DlqGuard.ShouldSend(options, limiter, ex.GetType()))
        {
            var allowHeaders = ExtractAllowedHeaders(result.Message.Headers, options.HeaderAllowList, options.HeaderValueMaxLength);
            var env = DlqEnvelopeFactory.From(result, ex,
                options.ApplicationId, options.ConsumerGroup, options.Host, allowHeaders,
                options.ErrorMessageMaxLength, options.StackTraceMaxLength, options.NormalizeStackTraceWhitespace);
            await dlqProducer.ProduceAsync(env, cancellationToken).ConfigureAwait(false);
        }
        consumer.Commit(result);
    }

    private IConsumer<TKey, TValue> CreateConsumer<TKey, TValue>(ConsumerConfig config)
        where TKey : class where TValue : class
    {
        return new ConsumerBuilder<TKey, TValue>(config)
            .SetKeyDeserializer(new AvroDeserializer<TKey>(_schemaRegistryClient.Value).AsSyncOverAsync())
            .SetValueDeserializer(new AvroDeserializer<TValue>(_schemaRegistryClient.Value).AsSyncOverAsync())
            .Build();
    }

    private ConfluentSchemaRegistry.ISchemaRegistryClient CreateSchemaRegistryClient()
    {
        var cfg = new ConfluentSchemaRegistry.SchemaRegistryConfig { Url = _options.SchemaRegistry.Url };
        return new ConfluentSchemaRegistry.CachedSchemaRegistryClient(cfg);
    }

    private EntityModel GetEntityModel<T>() where T : class
    {
        if (_entityModels.TryGetValue(typeof(T), out var model))
            return model;
        throw new InvalidOperationException($"Entity model not found for {typeof(T).Name}");
    }

    private ConsumerConfig BuildConsumerConfig(string topicName, KafkaSubscriptionOptions? subscriptionOptions)
    {
        var topicConfig = _options.Topics.TryGetValue(topicName, out var cfg) ? cfg : new TopicSection();
        var groupId = subscriptionOptions?.GroupId ?? topicConfig.Consumer.GroupId;
        if
### assistant â€” 2025-08-11T08:29:32.006432+00:00

import re, pathlib, itertools, sys, os, json, textwrap
text = Path('/mnt/data/EventSet.cs').read_text()
# find occurrences of ICommitManager and commit
for m in re.finditer(r'ICommitManager|Commit\(|CommitAsync|Manual', text):
    start = max(0, m.start()-300)
    end = min(len(text), m.end()+300)
    print(text[start:end])
    print('---')
### tool â€” 2025-08-11T08:29:37.621896+00:00

cted readonly IKsqlContext _context;
    protected readonly EntityModel _entityModel;
    private readonly ErrorHandlingContext _errorHandlingContext;
    private IErrorSink? _dlqErrorSink;
    private readonly Messaging.Producers.IDlqProducer? _dlqProducer;
    private readonly Messaging.Consumers.ICommitManager? _commitManager;

    protected EventSet(IKsqlContext context, EntityModel? entityModel = null, IErrorSink? dlqErrorSink = null,
        Messaging.Producers.IDlqProducer? dlqProducer = null, Messaging.Consumers.ICommitManager? commitManager = null)
    {
        _context = context ?? throw new Argu
---
cers.IDlqProducer? _dlqProducer;
    private readonly Messaging.Consumers.ICommitManager? _commitManager;

    protected EventSet(IKsqlContext context, EntityModel? entityModel = null, IErrorSink? dlqErrorSink = null,
        Messaging.Producers.IDlqProducer? dlqProducer = null, Messaging.Consumers.ICommitManager? commitManager = null)
    {
        _context = context ?? throw new ArgumentNullException(nameof(context));
        _errorHandlingContext = new ErrorHandlingContext();
        _dlqErrorSink = dlqErrorSink;
        _dlqProducer = dlqProducer;
        _commitManager = commitManager;

        if (con
---
rorOccurred += (ctx, msg) => _dlqErrorSink.HandleErrorAsync(ctx, msg);
        }
    }

    private EventSet(IKsqlContext context, EntityModel entityModel, ErrorHandlingContext errorHandlingContext, IErrorSink? dlqErrorSink,
        Messaging.Producers.IDlqProducer? dlqProducer, Messaging.Consumers.ICommitManager? commitManager)
    {
        _context = context;
        _entityModel = entityModel;
        _errorHandlingContext = errorHandlingContext;
        _dlqErrorSink = dlqErrorSink;
        _dlqProducer = dlqProducer;
        _commitManager = commitManager;

        if (_dlqErrorSink != null)
        {
---
onsumerGroup, dlq.Host,
                            dlq.ErrorMessageMaxLength, dlq.StackTraceMaxLength, dlq.NormalizeStackTraceWhitespace);
                        await _dlqProducer.ProduceAsync(env, linkedCts.Token).ConfigureAwait(false);
                    }

                    _commitManager?.Commit(entity);
                    break;
                }
            }
        }
    }

    /// <summary>
    /// IEntitySet<T> implementation: retrieve metadata
    /// </summary>
    public string GetTopicName() => (_entityModel.TopicName ?? _entityModel.EntityType.Name).ToLowerInvariant();

    publ
---
string, object>
            {
                ["entity_type"] = typeof(T).Name,
                ["topic_name"] = GetTopicName(),
                ["processing_phase"] = "ForEachAsync",
                ["timestamp"] = DateTime.UtcNow
            }
        };
    }

    /// <summary>
    /// Creates a ManualCommitMessage instance
    /// </summary>
    protected virtual IManualCommitMessage<T> CreateManualCommitMessage(T item)
    {
        return new ManualCommitMessage<T>(item, () => Task.CompletedTask, () => Task.CompletedTask);
    }

    /// <summary>
    /// Yields messages as different types dep
---
T).Name,
                ["topic_name"] = GetTopicName(),
                ["processing_phase"] = "ForEachAsync",
                ["timestamp"] = DateTime.UtcNow
            }
        };
    }

    /// <summary>
    /// Creates a ManualCommitMessage instance
    /// </summary>
    protected virtual IManualCommitMessage<T> CreateManualCommitMessage(T item)
    {
        return new ManualCommitMessage<T>(item, () => Task.CompletedTask, () => Task.CompletedTask);
    }

    /// <summary>
    /// Yields messages as different types depending on UseManualCommit
    /// </summary>
    public virtual async I
---
pic_name"] = GetTopicName(),
                ["processing_phase"] = "ForEachAsync",
                ["timestamp"] = DateTime.UtcNow
            }
        };
    }

    /// <summary>
    /// Creates a ManualCommitMessage instance
    /// </summary>
    protected virtual IManualCommitMessage<T> CreateManualCommitMessage(T item)
    {
        return new ManualCommitMessage<T>(item, () => Task.CompletedTask, () => Task.CompletedTask);
    }

    /// <summary>
    /// Yields messages as different types depending on UseManualCommit
    /// </summary>
    public virtual async IAsyncEnumerable<object> ForEa
---
sing_phase"] = "ForEachAsync",
                ["timestamp"] = DateTime.UtcNow
            }
        };
    }

    /// <summary>
    /// Creates a ManualCommitMessage instance
    /// </summary>
    protected virtual IManualCommitMessage<T> CreateManualCommitMessage(T item)
    {
        return new ManualCommitMessage<T>(item, () => Task.CompletedTask, () => Task.CompletedTask);
    }

    /// <summary>
    /// Yields messages as different types depending on UseManualCommit
    /// </summary>
    public virtual async IAsyncEnumerable<object> ForEachAsync([EnumeratorCancellation] CancellationToken ca
---
 instance
    /// </summary>
    protected virtual IManualCommitMessage<T> CreateManualCommitMessage(T item)
    {
        return new ManualCommitMessage<T>(item, () => Task.CompletedTask, () => Task.CompletedTask);
    }

    /// <summary>
    /// Yields messages as different types depending on UseManualCommit
    /// </summary>
    public virtual async IAsyncEnumerable<object> ForEachAsync([EnumeratorCancellation] CancellationToken cancellationToken = default)
    {
        await foreach (var item in GetAsyncEnumeratorWrapper(cancellationToken))
        {
            if (_entityModel.UseManualComm
---
 UseManualCommit
    /// </summary>
    public virtual async IAsyncEnumerable<object> ForEachAsync([EnumeratorCancellation] CancellationToken cancellationToken = default)
    {
        await foreach (var item in GetAsyncEnumeratorWrapper(cancellationToken))
        {
            if (_entityModel.UseManualCommit)
            {
                yield return CreateManualCommitMessage(item);
            }
            else
            {
                yield return item;
            }
        }
    }

    /// <summary>
    /// Configure the error handling policy
    /// </summary>
    internal virtual Eve
---
syncEnumerable<object> ForEachAsync([EnumeratorCancellation] CancellationToken cancellationToken = default)
    {
        await foreach (var item in GetAsyncEnumeratorWrapper(cancellationToken))
        {
            if (_entityModel.UseManualCommit)
            {
                yield return CreateManualCommitMessage(item);
            }
            else
            {
                yield return item;
            }
        }
    }

    /// <summary>
    /// Configure the error handling policy
    /// </summary>
    internal virtual EventSet<T> WithErrorPolicy(ErrorHandlingPolicy policy)
    {
    
---
### assistant â€” 2025-08-11T08:29:39.349064+00:00

idx = text.find("protected EventSet")
print(text[idx:idx+1000])
### tool â€” 2025-08-11T08:29:40.455066+00:00

protected EventSet(IKsqlContext context, EntityModel? entityModel = null, IErrorSink? dlqErrorSink = null,
        Messaging.Producers.IDlqProducer? dlqProducer = null, Messaging.Consumers.ICommitManager? commitManager = null)
    {
        _context = context ?? throw new ArgumentNullException(nameof(context));
        _errorHandlingContext = new ErrorHandlingContext();
        _dlqErrorSink = dlqErrorSink;
        _dlqProducer = dlqProducer;
        _commitManager = commitManager;

        if (context is KsqlContext kctx)
        {
            _entityModel = kctx.EnsureEntityModel(typeof(T), entityModel);
        }
        else
        {
            _entityModel = entityModel ?? throw new ArgumentNullException(nameof(entityModel));
        }

        if (_dlqErrorSink != null)
        {
            _errorHandlingContext.ErrorOccurred += (ctx, msg) => _dlqErrorSink.HandleErrorAsync(ctx, msg);
        }
    }

    private EventSet(IKsqlContext context, EntityModel entityModel, ErrorHand
### assistant â€” 2025-08-11T08:29:41.305417+00:00

for m in re.finditer(r'ForEachAsync', text):
    print(m.start())
### tool â€” 2025-08-11T08:29:42.238052+00:00

[[REDACTED_PHONE]]
[[REDACTED_PHONE]]
[[REDACTED_PHONE]]
### assistant â€” 2025-08-11T08:29:43.165083+00:00

print(text[3400:4600])
### tool â€” 2025-08-11T08:29:44.924055+00:00

(),
                    Tags = new Dictionary<string, object>
                    {
                        ["processing_phase"] = "ForEachAsync"
                    }
                };

                var shouldContinue = await _errorHandlingContext.HandleErrorAsync(default(T)!, ex, ctx);

                if (!shouldContinue)
                {
                    continue;
                }

                throw;
            }

            if (!hasNext)
                yield break;

            yield return enumerator.Current;
        }
    }


    public virtual async Task<List<T>> ToListAsync(CancellationToken cancellationToken = default)
    {
        if (_entityModel.EntityType == typeof(Messaging.DlqEnvelope))
            throw new InvalidOperationException("DLQã¯ç„¡é™åˆ—æŒ™/å±¥æ­´åˆ—ã§ã‚ã‚Šã€ãƒãƒƒãƒå–å¾—ãƒ»ä»¶æ•°æŒ‡å®šå–å¾—ã¯ç¾çŠ¶æœªå¯¾å¿œã§ã™");

        if (_entityModel.GetExplicitStreamTableType() == StreamTableType.Stream)
            throw new InvalidOperationException("ToListAsync() is not supported on a Stream source. Use ForEachAsync or subscribe for event consumption.");

        var results = new List<T>();

        await foreach (var item in GetAsyncEnumeratorWrapper(cancellationToken))
        {
            re
### assistant â€” 2025-08-11T08:29:45.882376+00:00

print(Path('/mnt/data/ICommitManager.cs').read_text())
### tool â€” 2025-08-11T08:29:51.153616+00:00

namespace Kafka.Ksql.Linq.Messaging.Consumers;

public interface ICommitManager
{
    void Commit(object entity);
}
### assistant â€” 2025-08-11T08:29:52.069383+00:00

kc = Path('/mnt/data/KafkaConsumerManager.cs').read_text()
print("length", len(kc))
for m in re.finditer(r'CommitManager|ICommitManager|NoopCommitManager|manual', kc, re.IGNORECASE):
    start=max(0,m.start()-300); end=min(len(kc), m.end()+300)
    print(kc[start:end], "\n---")
### tool â€” 2025-08-11T08:29:53.686632+00:00

length 13775
### assistant â€” 2025-08-11T08:29:54.541176+00:00

print(kc[-2000:])
### tool â€” 2025-08-11T08:29:55.451788+00:00

rtitionOffset>(partitions);
        for (var i = 0; i < partitions; i++)
            tps.Add(new TopicPartitionOffset(topic, new Partition(i), new Offset(0)));
        consumer.Assign(tps);
        consumer.Commit(tps);
    }

    public void Dispose()
    {
        if (_disposed) return;
        if (_schemaRegistryClient.IsValueCreated)
            _schemaRegistryClient.Value.Dispose();
        _disposed = true;
    }

    private static int? TryGetSchemaId(byte[]? payload)
    {
        if (payload is { Length: >= 5 } && payload[0] == 0)
            return System.Buffers.Binary.BinaryPrimitives.ReadInt32BigEndian(payload.AsSpan(1, 4));
        return null;
    }

    private static System.Collections.Generic.IReadOnlyDictionary<string, string> ExtractAllowedHeaders(
        Headers? headers, System.Collections.Generic.IEnumerable<string> allowList, int maxLen = 1024)
    {
        var dict = new System.Collections.Generic.Dictionary<string, string>(System.StringComparer.OrdinalIgnoreCase);
        if (headers is null) return dict;

        var set = allowList is System.Collections.Generic.HashSet<string> hs ? hs :
                  new System.Collections.Generic.HashSet<string>(allowList ?? System.Array.Empty<string>(), System.StringComparer.OrdinalIgnoreCase);

        foreach (var h in headers)
        {
            if (!set.Contains(h.Key)) continue;
            var bytes = h.GetValueBytes() ?? System.Array.Empty<byte>();
            string val;
            try
            {
                val = System.Text.Encoding.UTF8.GetString(bytes);
                if (!System.Text.Encoding.UTF8.GetBytes(val).AsSpan().SequenceEqual(bytes))
                    val = "base64:" + System.Convert.ToBase64String(bytes);
            }
            catch
            {
                val = "base64:" + System.Convert.ToBase64String(bytes);
            }
            if (val.Length > maxLen) val = val[..maxLen];
            dict[h.Key] = val;
        }
        return dict;
    }
}
### assistant â€” 2025-08-11T08:29:56.497626+00:00

for m in re.finditer(r'Commit\(', text):
    print(m.start(), text[m.start()-60:m.start()+120])
### tool â€” 2025-08-11T08:29:57.823150+00:00

9322 
                    }

                    _commitManager?.Commit(entity);
                    break;
                }
            }
        }
    }

    /// <summary>
    /// IE
### assistant â€” 2025-08-11T08:29:58.796105+00:00

print(text[9000:9600])
### tool â€” 2025-08-11T08:30:02.397457+00:00

q.ApplicationId, dlq.ConsumerGroup, dlq.Host,
                            dlq.ErrorMessageMaxLength, dlq.StackTraceMaxLength, dlq.NormalizeStackTraceWhitespace);
                        await _dlqProducer.ProduceAsync(env, linkedCts.Token).ConfigureAwait(false);
                    }

                    _commitManager?.Commit(entity);
                    break;
                }
            }
        }
    }

    /// <summary>
    /// IEntitySet<T> implementation: retrieve metadata
    /// </summary>
    public string GetTopicName() => (_entityModel.TopicName ?? _entityModel.EntityType.Name).
### assistant â€” 2025-08-11T08:30:03.332763+00:00

for m in re.finditer(r'public .*Commit', text):
    print(m.start(), text[m.start()-100:m.start()+200])
### assistant â€” 2025-08-11T08:30:06.290894+00:00

if 'ConditionalWeakTable' in kc:
    print("Has CWT")
else:
    print("No CWT found")
### tool â€” 2025-08-11T08:30:10.455806+00:00

No CWT found
### assistant â€” 2025-08-11T08:30:11.394342+00:00

# Try to find where EventSet enumerates consumer
for kw in ['Consume', 'enumerator', 'GetAsyncEnumeratorWrapper', 'InternalStream']:
    pos = text.find(kw)
    print(kw, pos)
### tool â€” 2025-08-11T08:30:16.899188+00:00

Consume 943
enumerator 3016
GetAsyncEnumeratorWrapper 2888
InternalStream -1
### assistant â€” 2025-08-11T08:30:17.794195+00:00

print(text[2800:3600])
### tool â€” 2025-08-11T08:30:18.645108+00:00

(CancellationToken cancellationToken = default);

    private async IAsyncEnumerable<T> GetAsyncEnumeratorWrapper([EnumeratorCancellation] CancellationToken cancellationToken = default)
    {
        await using var enumerator = GetAsyncEnumerator(cancellationToken);

        while (true)
        {
            bool hasNext;
            try
            {
                hasNext = await enumerator.MoveNextAsync();
            }
            catch (Exception ex)
            {
                var ctx = new KafkaMessageContext
                {
                    MessageId = Guid.NewGuid().ToString(),
                    Tags = new Dictionary<string, object>
                    {
                        ["processing_phase"] = "ForEachAsync"
                    }
                };
### assistant â€” 2025-08-11T08:30:19.726729+00:00

ã„ã„ã­ã€`ctx.Samples.Commit(poco)` ã§ã„ãã¾ã—ã‚‡ã†ã€‚**å‘¼ã³å‡ºã—å´ã®åˆ—æŒ™ã¯å¸¸ã« `T` ã®ã¾ã¾**ã€manual/auto ã‚’å†…éƒ¨ã§å¸åã—ã¾ã™ã€‚æ·»ä»˜ã‚³ãƒ¼ãƒ‰ã®æ§‹æˆï¼ˆ`EventSet<T>` ã« `_commitManager`ã€`ICommitManager` ã¨ `NoopCommitManager` ã‚ã‚Šï¼‰ã«ãƒ”ãƒƒã‚¿ãƒªã¯ã¾ã‚Šã¾ã™ã€‚

# å¤‰æ›´ãƒã‚¤ãƒ³ãƒˆï¼ˆæœ€å°å·®åˆ†ï¼‰

## 1) `EventSet<T>` ã«å…¬é–‹ `Commit` ã‚’è¿½åŠ 
`_commitManager?.Commit(entity)` ã¯å†…éƒ¨ï¼ˆDLQå¾Œï¼‰ã§ã—ã‹å‘¼ã°ã‚Œã¦ã„ãªã„ã®ã§ã€**å‘¼ã³å‡ºã—å´ã‹ã‚‰å©ã‘ã‚‹è–„ã„å§”è­²**ã‚’1æœ¬ç”Ÿã‚„ã—ã¾ã™ã€‚

```diff
*** a/EventSet.cs
--- b/EventSet.cs
@@
     private readonly Messaging.Consumers.ICommitManager? _commitManager;
@@
     }
 
+    /// <summary>
+    /// å‘¼ã³å‡ºã—å´ã‹ã‚‰æ‰‹å‹•ã‚³ãƒŸãƒƒãƒˆã‚’è¡Œã†ã€‚autocommit æ™‚ã¯ Noop å®Ÿè£…ã«ã‚ˆã‚Šç„¡åŠ¹å‹•ä½œã€‚
+    /// </summary>
+    public void Commit(T entity)
+    {
+        // entity ã¯ ForEachAsync ã§è¿”ã—ãŸã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’æ¸¡ã™å‰æ
+        _commitManager?.Commit(entity!);
+    }
```

> è£œè¶³  
> - æ—¢å­˜ã® `ICommitManager` ã¯ `void Commit(object entity)` ãªã®ã§ **éåŒæœŸã«ã—ãªã„**ï¼ˆç¾åœ¨ã®IFã«åˆã‚ã›ã‚‹ï¼‰ã€‚  
> - autocommit ã®ã¨ãã¯ `NoopCommitManager` ãŒå·®ã•ã£ã¦ã„ã‚‹ã¯ãšãªã®ã§ **no-op** ã§äº’æ›ç¶­æŒã€‚

## 2) å‘¼ã³å‡ºã—å´ï¼ˆãƒ†ã‚¹ãƒˆï¼‰ã‚’æ›¸ãæ›ãˆ
ã‚­ãƒ£ã‚¹ãƒˆã‚’å»ƒã—ã€`T` ã®ã¾ã¾ã‚³ãƒŸãƒƒãƒˆã§ãã¾ã™ã€‚

```diff
- await foreach (var obj in ctx.Samples.ForEachAsync(consumeCts.Token))
- {
-     var msg = (IManualCommitMessage<ManualCommitContext.Sample>)obj;
-     if (msg.Value.Id == 3)
-     {
-         await msg.CommitAsync();
-         break;
-     }
- }
+ await foreach (var sample in ctx.Samples.ForEachAsync(consumeCts.Token))
+ {
+     if (sample.Id == 3)
+     {
+         ctx.Samples.Commit(sample); // autocommitã§ã‚‚no-op
+         break;
+     }
+ }
```

2å›ç›®ã®æ¤œè¨¼å´ã‚‚åŒæ§˜ã« `Commit(sample)` ã§OKï¼ˆã¾ãŸã¯ãã®å ´ã¯ä¸è¦ãªã‚‰çœç•¥å¯ï¼‰ã€‚

---

# ä»•çµ„ã¿ã®å‰æï¼ˆã“ã®è¨­è¨ˆãŒæˆç«‹ã™ã‚‹ç†ç”±ï¼‰
- `EventSet<T>` ã«ã¯ã™ã§ã« `_commitManager` ãŒæ³¨å…¥ã•ã‚Œã¦ãŠã‚Šã€å†…éƒ¨ã§ã‚‚ `Commit(entity)` å‘¼ã³å‡ºã—ãŒã‚ã‚Šã¾ã™ï¼ˆDLQå‡¦ç†éƒ¨ã®ç›´å¾Œï¼‰ã€‚  
- **manualæ™‚**ï¼šå®Ÿä½“ã® `CommitManager` å´ã§ã€Œåˆ—æŒ™ä¸­ã«è¿”ã—ãŸ `entity` ã¨ãã® `TopicPartitionOffset` ã®å¯¾å¿œã€ã‚’ä¿æŒã—ã¦ã„ã‚‹å‰æï¼ˆä¸€èˆ¬çš„ã«ã¯ `ConditionalWeakTable<object, TPO>` ãªã©ï¼‰ã€‚`Commit(entity)` ã§å¯¾å¿œã™ã‚‹ã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’åŒæœŸã‚³ãƒŸãƒƒãƒˆã€‚  
- **autocommitæ™‚**ï¼š`NoopCommitManager` å®Ÿè£…ã§ç„¡è¦–ã€‚

> ã‚‚ã—å®Ÿè£…ãŒæœªã ãªã‚‰ï¼š  
> `CommitManager` å®Ÿè£…ã§ã€**ForEachAsync ã® yield ç›´å‰**ã« `entityâ†’TPO` ã‚’ç™»éŒ²ã—ã€`Commit(entity)` ã§å–ã‚Šå‡ºã—ã¦ `consumer.Commit(tpo)` â†’ ç™»éŒ²è§£é™¤ã€ã¨ã„ã†æµã‚Œã«ã—ã¦ãã ã•ã„ã€‚å‚ç…§åŒä¸€æ€§ã§è¿½è·¡ã™ã‚‹ãŸã‚ `T : class` å‰æãŒå …ã„ã§ã™ã€‚

---

# è¿½åŠ ã®å°ãƒã‚¿ï¼ˆå¿…è¦ãªã‚‰ï¼‰
- ãƒãƒƒãƒç”¨ `Commit(IEnumerable<T> entities)` ã‚’è¶³ã™ã®ã‚‚å®¹æ˜“ï¼ˆå†…éƒ¨ã§é †ã« `_commitManager.Commit`ï¼‰ã€‚  
- åˆ¥åã§ `CommitCurrent()`ï¼ˆæœ€å¾Œã«è¿”ã—ãŸ1ä»¶ã‚’ã‚³ãƒŸãƒƒãƒˆï¼‰ã‚’ç”¨æ„ã™ã‚‹ã¨ã€å‘¼ã³å‡ºã—å´ãŒ `poco` ã‚’æŒã¡å›ã‚‰ãªãã¦æ¸ˆã‚€ï¼ˆ`AsyncLocal` ã§è¿½è·¡ï¼‰ã€‚

---

ã“ã®å¤‰æ›´ã§ã€**autocommit â‡„ manual commit ã®åˆ‡æ›¿æ™‚ã«ã‚‚å‘¼ã³å‡ºã—å´ã®æ§‹é€ ã¯ä¸å¤‰**ã€ã‹ã¤**ã‚­ãƒ£ã‚¹ãƒˆä¸è¦**ã«ãªã‚Šã¾ã™ã€‚å·®åˆ†ãŒã‚‚ã£ã¨æ¬²ã—ã‘ã‚Œã° `diff` å®Œå…¨ç‰ˆã‚‚å‡ºã—ã¾ã™ã€‚  

â€” é€ä¿¡æ—¥æ™‚: [[REDACTED_PHONE]]:35 (JST)
### assistant â€” 2025-08-11T08:30:31.331281+00:00

_(empty)_
### assistant â€” 2025-08-11T08:31:47.656066+00:00

äº†è§£ã€**æ—¢å­˜IFã‚’å´©ã•ãš**ã«ã€Œ`ctx.Samples.Commit(poco)`ã€ã§æ‰‹å‹•ã‚³ãƒŸãƒƒãƒˆã§ãã‚‹ã‚ˆã†ã€**`EventSet<T>` ã ã‘æœ€å°å·®åˆ†**ã§æ‹¡å¼µã—ã¾ã™ã€‚  
ï¼ˆ`ICommitManager` ã¯æ—¢å­˜ã®ã¾ã¾ `Commit(object)` ã‚’å‘¼ã³å‡ºã—ã¾ã™ã€‚autocommit æ™‚ã¯ `NoopCommitManager` ã®ã¾ã¾ no-op ã§ã™ã€‚ï¼‰  
â€»ä¸‹è¨˜ã¯ãã®ã¾ã¾é©ç”¨ã§ãã‚‹å·®åˆ†ã§ã™ã€‚

---

# å¤‰æ›´ç‚¹ï¼ˆæœ€å°å·®åˆ†ï¼‰

## 1) `EventSet<T>` ã«å…¬é–‹ `Commit(T entity)` ã‚’è¿½åŠ 
- å‘¼ã³å‡ºã—å´ã¯ **å¸¸ã« `T` ã‚’æ‰±ã†**ã¾ã¾ã§ OKï¼ˆã‚­ãƒ£ã‚¹ãƒˆä¸è¦ãƒ»ã‚¸ã‚§ãƒãƒªãƒƒã‚¯æŒ‡å®šä¸è¦ï¼‰ã€‚
- manual æ™‚ã®ã¿å®Ÿã‚³ãƒŸãƒƒãƒˆã€autocommit æ™‚ã¯ `NoopCommitManager` ã§ no-opã€‚

```diff
*** a/EventSet.cs
--- b/EventSet.cs
@@
     private readonly Messaging.Consumers.ICommitManager? _commitManager;
@@
     }
 
+    /// <summary>
+    /// å‘¼ã³å‡ºã—å´ã‹ã‚‰æ‰‹å‹•ã‚³ãƒŸãƒƒãƒˆã‚’è¡Œã†ï¼ˆautocommitæ™‚ã¯no-opï¼‰ã€‚
+    /// ForEachAsync ã§å—ã‘å–ã£ãŸ entity ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’æ¸¡ã™ã“ã¨ã€‚
+    /// </summary>
+    public void Commit(T entity)
+    {
+        if (entity is null) throw new ArgumentNullException(nameof(entity));
+        _commitManager?.Commit(entity);
+    }
```

## 2) ï¼ˆä»»æ„ãƒ»æ¨å¥¨ï¼‰ã‚³ãƒŸãƒƒãƒˆå¯¾è±¡ã®è¿½è·¡ãƒ•ãƒƒã‚¯ã‚’è¿½åŠ   
**æ—¢å­˜IFã¯å¤‰æ›´ã›ãš**ã€æ‰‹å‹•ã‚³ãƒŸãƒƒãƒˆå®Ÿè£…å´ï¼ˆ`ICommitManager` ã®å…·ä½“å‹ï¼‰ãŒ **â€œä»Šè¿”ã—ãŸ `entity` â†’ ã‚ªãƒ•ã‚»ãƒƒãƒˆæƒ…å ±â€** ã‚’å—ã‘å–ã‚Œã‚‹ã‚ˆã†ã«ã€**ã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«ãªå†…éƒ¨ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹**ã‚’æŒ¿å…¥ã—ã¾ã™ã€‚  
ã“ã‚Œã«ã‚ˆã‚Šã€Œautocommitâ‡„manual ã®åˆ‡æ›¿ã§å‘¼ã³å‡ºã—å´ã¯ç„¡å¤‰æ›´ã€ã®ã¾ã¾ã€æ‰‹å‹•ã‚³ãƒŸãƒƒãƒˆå´ãŒã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ã«ç´ã¥ã‘å¯èƒ½ã§ã™ã€‚
### 2-1) è¿½è·¡ç”¨ã®å†…éƒ¨IFã‚’ `EventSet.cs` å†…ã«å®£è¨€
```diff
*** a/EventSet.cs
--- b/EventSet.cs
@@
 namespace Kafka.Ksql.Linq;
 
 /// <summary>
 /// Base class for EventSet implementing IEntitySet<T>
 /// Reason for modification: unified with KsqlContext and added IEntitySet<T> implementation
 /// </summary>
 public abstract class EventSet<T> : IEntitySet<T> where T : class
 {
+    // ä»»æ„å®Ÿè£…ï¼šCommitManager ãŒ entity ã¨ meta ã‚’ç´ã¥ã‘ãŸã„å ´åˆã«å®Ÿè£…ã™ã‚‹
+    internal interface ICommitRegistrar
+    {
+        void Track(object entity, MessageMeta meta);
+    }
@@
     protected virtual IAsyncEnumerable<(T Entity, Dictionary<string, string> Headers, MessageMeta Meta)> ConsumeAsync(
         KsqlContext context,
         CancellationToken cancellationToken)
     {
-        return context.GetConsumerManager().ConsumeAsync<T>(cancellationToken);
+        // å…ƒã®åˆ—æŒ™ã«ã€å¿…è¦ãªã‚‰ â€œã‚³ãƒŸãƒƒãƒˆè¿½è·¡â€ ã‚’å·®ã—è¾¼ã‚€
+        var source = context.GetConsumerManager().ConsumeAsync<T>(cancellationToken);
+        return TrackCommitIfSupported(source);
     }
+
+    // _commitManager ãŒ ICommitRegistrar ã‚’å®Ÿè£…ã—ã¦ã„ã‚‹å ´åˆã ã‘ entityâ†’meta ã‚’ç´ã¥ã‘ã‚‹
+    private async IAsyncEnumerable<(T Entity, Dictionary<string, string> Headers, MessageMeta Meta)> TrackCommitIfSupported(
+        IAsyncEnumerable<(T Entity, Dictionary<string, string> Headers, MessageMeta Meta)> source,
+        [EnumeratorCancellation] CancellationToken cancellationToken = default)
+    {
+        var registrar = _commitManager as ICommitRegistrar;
+        await foreach (var (entity, headers, meta) in source.WithCancellation(cancellationToken))
+        {
+            registrar?.Track(entity!, meta);
+            yield return (entity, headers, meta);
+        }
+    }
```

> ãƒ¡ãƒ¢  
> - **æ—¢å­˜ã® `ICommitManager` ã¯ä¸€åˆ‡å¤‰æ›´ä¸è¦**ã€‚  
> - manual ç”¨ã®å®Ÿè£…å´ï¼ˆã‚ãªãŸã®å®Ÿãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã® CommitManagerï¼‰ãŒ `ICommitManager` ã« **åŠ ãˆã¦** `EventSet<T>.ICommitRegistrar` ã‚’ **å®Ÿè£…ã™ã‚‹ã¨**ã€`Track(entity, meta)` çµŒç”±ã§ **ã‚ªãƒ•ã‚»ãƒƒãƒˆæƒ…å ±ï¼ˆ`MessageMeta`ï¼‰ã®å—ã‘å–ã‚Š**ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚  
> - autocommit ã§ã¯ `NoopCommitManager`ï¼ˆæ—¢å­˜ï¼‰ãªã®ã§ä½•ã‚‚èµ·ãã¾ã›ã‚“ï¼ˆno-opï¼‰ã€‚

---

# å‘¼ã³å‡ºã—å´ï¼ˆãƒ†ã‚¹ãƒˆï¼‰ã®æ›¸ãæ›ãˆï¼ˆã‚­ãƒ£ã‚¹ãƒˆæ’é™¤ï¼‰
```diff
- await foreach (var obj in ctx.Samples.ForEachAsync(consumeCts.Token))
- {
-     var msg = (IManualCommitMessage<ManualCommitContext.Sample>)obj;
-     if (msg.Value.Id == 3)
-     {
-         await msg.CommitAsync();
-         break;
-     }
- }
+ await foreach (var sample in ctx.Samples.ForEachAsync(consumeCts.Token))
+ {
+     if (sample.Id == 3)
+     {
+         ctx.Samples.Commit(sample); // manual: å®Ÿã‚³ãƒŸãƒƒãƒˆ / autocommit: no-op
+         break;
+     }
+ }
```

2å›ç›®ã®æ¤œè¨¼å´ã‚‚åŒæ§˜ã« `Commit(sample)` ã§OKï¼ˆå¿…è¦ãªã‚‰ï¼‰ã€‚

---

# å®Ÿè£…å´ãƒ¡ãƒ¢ï¼ˆæ—¢å­˜æ§‹æˆã«ãã®ã¾ã¾ä¹—ã›ã‚‹ï¼‰
- `KafkaConsumerManager.ConsumeAsync<TPOCO>()` ã¯ **`(TPOCO, Headers, MessageMeta)`** ã‚’è¿”ã—ã¦ãã‚Œã¦ã„ã¾ã™ï¼ˆæ—¢å­˜ï¼‰ã€‚  
  `EventSet<T>.ConsumeAsync` ã®å·®ã—è¾¼ã¿ã§ **`entity â†’ meta` ã®ç´ã¥ã‘**ãŒå¯èƒ½ã«ãªã‚Šã¾ã—ãŸã€‚ îˆ€fileciteîˆ‚turn1file1îˆ
- autocommit æ™‚ã® no-op ã¯æ—¢å­˜ã® `NoopCommitManager` ãŒæ‹…ä¿ï¼ˆ`Commit(object){}`ï¼‰ã€‚ îˆ€fileciteîˆ‚turn1file2îˆ
- `ICommitManager` ã¯ **ç¾çŠ¶ã®ã¾ã¾**ï¼ˆ`void Commit(object entity)`ï¼‰ã€‚ îˆ€fileciteîˆ‚turn1file0îˆ

> manual ç”¨ `CommitManager` å®Ÿè£…ã®ãƒ’ãƒ³ãƒˆ  
> - `Track(entity, meta)` ã§ **å‚ç…§åŒä¸€æ€§**ãƒ™ãƒ¼ã‚¹ã« `entity â†’ meta` ã‚’ä¿æŒï¼ˆ`ConditionalWeakTable<object, MessageMeta>` ãŒå®‰å…¨ï¼‰ã€‚  
> - `Commit(entity)` ã§å–ã‚Šå‡ºã—ãŸ `meta` ã® `Topic/Partition/Offset` ã‚’ä½¿ã£ã¦ **åŒæœŸã‚³ãƒŸãƒƒãƒˆ**ï¼ˆã‚ãªãŸã®å®Ÿè£…å†…ã® Kafka Consumer ã§ `Commit(TopicPartitionOffset)`ï¼‰ã€‚  
> - ã‚³ãƒŸãƒƒãƒˆå¾Œã¯ç™»éŒ²è§£é™¤ï¼ˆãƒªãƒ¼ã‚¯é˜²æ­¢ã€äºŒé‡ã‚³ãƒŸãƒƒãƒˆé˜²æ­¢ï¼‰ã€‚

---

ã“ã®å·®åˆ†ãªã‚‰ã€**æ—¢å­˜ã®å‹ã‚„IFã¯ãã®ã¾ã¾**ã€å‘¼ã³å‡ºã—å´ã¯ **`T` ã‚’æ‰±ã£ãŸã¾ã¾** `Commit(sample)` ã‚’å‘¼ã¶ã ã‘ã§ã™ã€‚  
ä»–ãƒ•ã‚¡ã‚¤ãƒ«ã®å¤‰æ›´ã¯ **ä¸è¦** ã§ã™ï¼ˆmanual ç”¨ã® CommitManager å®Ÿè£…ã ã‘ã€ä»»æ„ã§ `ICommitRegistrar` ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ï¼‰ã€‚

â€” é€ä¿¡æ—¥æ™‚: [[REDACTED_PHONE]]:46 (JST)
### system â€” 2025-08-11T08:31:47.935317+00:00

_(empty)_
### tool â€” 2025-08-11T08:31:47.940805+00:00

_(empty)_
### tool â€” 2025-08-11T08:31:47.951618+00:00

îˆ€fileciteîˆ‚turn1file0îˆ

namespace Kafka.Ksql.Linq.Messaging.Consumers;

public interface ICommitManager
{
    void Commit(object entity);
}
### tool â€” 2025-08-11T08:31:47.963176+00:00

îˆ€fileciteîˆ‚turn1file1îˆ

using Confluent.Kafka;
using Confluent.Kafka.SyncOverAsync;
using Confluent.SchemaRegistry.Serdes;
using Kafka.Ksql.Linq.Configuration;
using Kafka.Ksql.Linq.Configuration.Abstractions;
using Kafka.Ksql.Linq.Core.Abstractions;
using Kafka.Ksql.Linq.Core.Extensions;
using Kafka.Ksql.Linq.Mapping;
using Kafka.Ksql.Linq.Messaging.Configuration;
using Kafka.Ksql.Linq.Core.Dlq;
using Kafka.Ksql.Linq.Messaging.Producers;
using Microsoft.Extensions.Logging;
using Microsoft.Extensions.Options;
using System;
using System.Collections.Generic;
using System.Runtime.CompilerServices;
using System.Threading;
using System.Threading.Tasks;
using ConfluentSchemaRegistry = Confluent.SchemaRegistry;

namespace Kafka.Ksql.Linq.Messaging.Consumers;

internal sealed class KafkaConsumerManager : IDisposable
{
    private readonly KsqlDslOptions _options;
    private readonly ILogger? _logger;
    private readonly Lazy<ConfluentSchemaRegistry.ISchemaRegistryClient> _schemaRegistryClient;
    private readonly Dictionary<Type, EntityModel> _entityModels;
    private readonly MappingRegistry _mappingRegistry;
    private readonly DlqOptions _dlq;
    private readonly IRateLimiter _limiter;
    private readonly IDlqProducer _dlqProducer;
    private bool _disposed;

#pragma warning disable CS0067 // Event is never used
    public event Func<byte[]?, Exception, string, int, long, DateTime, Headers?, string, string, Task>? DeserializationError;
#pragma warning restore CS0067

    public KafkaConsumerManager(
        MappingRegistry mapping,
        IOptions<KsqlDslOptions> options,
        Dictionary<Type, EntityModel> entityModels,
        IDlqProducer dlqProducer,
        ILoggerFactory? loggerFactory = null,
        IRateLimiter? limiter = null)
    {
        _mappingRegistry = mapping;
        _options = options?.Value ?? throw new ArgumentNullException(nameof(options));
        _entityModels = entityModels ?? new();
        _dlqProducer = dlqProducer;
        _logger = loggerFactory?.CreateLogger<KafkaConsumerManager>();
        _schemaRegistryClient = new Lazy<ConfluentSchemaRegistry.ISchemaRegistryClient>(CreateSchemaRegistryClient);
        _dlq = _options.DlqOptions;
        _limiter = limiter ?? new SimpleRateLimiter(_dlq.MaxPerSecond);
    }



    public async IAsyncEnumerable<(TPOCO, Dictionary<string, string>, MessageMeta)> ConsumeAsync<TPOCO>(
        [EnumeratorCancellation] CancellationToken cancellationToken = default) where TPOCO : class
    {
        var model = GetEntityModel<TPOCO>();
        var topic = model.GetTopicName();
        var mapping = _mappingRegistry.GetMapping(typeof(TPOCO));
        var config = BuildConsumerConfig(topic, null);

        var method = typeof(KafkaConsumerManager)
            .GetMethod(nameof(ConsumeInternal), System.Reflection.BindingFlags.NonPublic | System.Reflection.BindingFlags.Instance)!
            .MakeGenericMethod(mapping.AvroKeyType!, mapping.AvroValueType!, typeof(TPOCO));

        var enumerable = (IAsyncEnumerable<(TPOCO, Dictionary<string, string>, MessageMeta)>)method
            .Invoke(this, new object?[] { topic, config, mapping, cancellationToken })!;

        await foreach (var item in enumerable.WithCancellation(cancellationToken))
            yield return item;
    }

    private async IAsyncEnumerable<(TPOCO, Dictionary<string, string>, MessageMeta)> ConsumeInternal<TKey, TValue, TPOCO>(
        string topicName,
        ConsumerConfig config,
        KeyValueTypeMapping mapping,
        [EnumeratorCancellation] CancellationToken cancellationToken)
        where TKey : class where TValue : class where TPOCO : class
    {
        using var consumer = CreateConsumer<TKey, TValue>(config);
        consumer.Subscribe(topicName);

        while (!cancellationToken.IsCancellationRequested)
        {
            ConsumeResult<TKey, TValue>? result;
            try
            {
                result = consumer.Consume(cancellationToken);
            }
            catch (OperationCanceledException)
            {
                break;
            }
            if (result == null || result.IsPartitionEOF)
                continue;

            TPOCO entity;
            Dictionary<string, string> headers;
            MessageMeta meta;
            try
            {
                entity = (TPOCO)mapping.CombineFromAvroKeyValue(result.Message.Key, result.Message.Value!, typeof(TPOCO));
                headers = new Dictionary<string, string>();
                if (result.Message.Headers != null)
                {
                    foreach (var h in result.Message.Headers)
                        headers[h.Key] = System.Text.Encoding.UTF8.GetString(h.GetValueBytes());
                }

                meta = new MessageMeta(
                    Topic: result.Topic,
                    Partition: result.Partition,
                    Offset: result.Offset,
                    TimestampUtc: result.Message.Timestamp.UtcDateTime,
                    SchemaIdKey: TryGetSchemaId(result.Message.Key as byte[]),
                    SchemaIdValue: TryGetSchemaId(result.Message.Value as byte[]),
                    KeyIsNull: result.Message.Key is null,
                    HeaderAllowList: ExtractAllowedHeaders(result.Message.Headers, _dlq.HeaderAllowList, _dlq.HeaderValueMaxLength)
                );
            }
            catch (Exception ex)
            {
                await HandleMappingException(result, ex, _dlqProducer, consumer, _dlq, _limiter, cancellationToken).ConfigureAwait(false);
                continue;
            }

            yield return (entity, headers, meta);
            await Task.CompletedTask;
        }
    }

    internal static async Task HandleMappingException<TKey, TValue>(
        ConsumeResult<TKey, TValue> result,
        Exception ex,
        IDlqProducer dlqProducer,
        IConsumer<TKey, TValue> consumer,
        DlqOptions options,
        IRateLimiter limiter,
        CancellationToken cancellationToken)
        where TKey : class where TValue : class
    {
        if (options.EnableForDeserializationError && DlqGuard.ShouldSend(options, limiter, ex.GetType()))
        {
            var allowHeaders = ExtractAllowedHeaders(result.Message.Headers, options.HeaderAllowList, options.HeaderValueMaxLength);
            var env = DlqEnvelopeFactory.From(result, ex,
                options.ApplicationId, options.ConsumerGroup, options.Host, allowHeaders,
                options.ErrorMessageMaxLength, options.StackTraceMaxLength, options.NormalizeStackTraceWhitespace);
            await dlqProducer.ProduceAsync(env, cancellationToken).ConfigureAwait(false);
        }
        consumer.Commit(result);
    }

    private IConsumer<TKey, TValue> CreateConsumer<TKey, TValue>(ConsumerConfig config)
        where TKey : class where TValue : class
    {
        return new ConsumerBuilder<TKey, TValue>(config)
            .SetKeyDeserializer(new AvroDeserializer<TKey>(_schemaRegistryClient.Value).AsSyncOverAsync())
            .SetValueDeserializer(new AvroDeserializer<TValue>(_schemaRegistryClient.Value).AsSyncOverAsync())
            .Build();
    }

    private ConfluentSchemaRegistry.ISchemaRegistryClient CreateSchemaRegistryClient()
    {
        var cfg = new ConfluentSchemaRegistry.SchemaRegistryConfig { Url = _options.SchemaRegistry.Url };
        return new ConfluentSchemaRegistry.CachedSchemaRegistryClient(cfg);
    }

    private EntityModel GetEntityModel<T>() where T : class
    {
        if (_entityModels.TryGetValue(typeof(T), out var model))
            return model;
        throw new InvalidOperationException($"Entity model not found for {typeof(T).Name}");
    }

    private ConsumerConfig BuildConsumerConfig(string topicName, KafkaSubscriptionOptions? subscriptionOptions)
    {
        var topicConfig = _options.Topics.TryGetValue(topicName, out var cfg) ? cfg : new TopicSection();
        var groupId = subscriptionOptions?.GroupId ?? topicConfig.Consumer.GroupId;
        if (string.IsNullOrWhiteSpace(groupId))
            groupId = "default-group";

        var consumerConfig = new ConsumerConfig
        {
            BootstrapServers = _options.Common.BootstrapServers,
            ClientId = _options.Common.ClientId,
            GroupId = groupId,
            AutoOffsetReset = Enum.Parse<AutoOffsetReset>(topicConfig.Consumer.AutoOffsetReset),
            EnableAutoCommit = topicConfig.Consumer.EnableAutoCommit,
            AutoCommitIntervalMs = topicConfig.Consumer.AutoCommitIntervalMs,
            SessionTimeoutMs = topicConfig.Consumer.SessionTimeoutMs,
            HeartbeatIntervalMs = topicConfig.Consumer.HeartbeatIntervalMs,
            MaxPollIntervalMs = topicConfig.Consumer.MaxPollIntervalMs,
            FetchMinBytes = topicConfig.Consumer.FetchMinBytes,
            FetchMaxBytes = topicConfig.Consumer.FetchMaxBytes,
            IsolationLevel = Enum.Parse<IsolationLevel>(topicConfig.Consumer.IsolationLevel)
        };

        if (subscriptionOptions != null)
        {
            if (subscriptionOptions.AutoCommit.HasValue)
                consumerConfig.EnableAutoCommit = subscriptionOptions.AutoCommit.Value;
            if (subscriptionOptions.SessionTimeout.HasValue)
                consumerConfig.SessionTimeoutMs = (int)subscriptionOptions.SessionTimeout.Value.TotalMilliseconds;
            if (subscriptionOptions.HeartbeatInterval.HasValue)
                consumerConfig.HeartbeatIntervalMs = (int)subscriptionOptions.HeartbeatInterval.Value.TotalMilliseconds;
            if (subscriptionOptions.MaxPollInterval.HasValue)
                consumerConfig.MaxPollIntervalMs = (int)subscriptionOptions.MaxPollInterval.Value.TotalMilliseconds;
        }

        if (_options.Common.SecurityProtocol != SecurityProtocol.Plaintext)
        {
            consumerConfig.SecurityProtocol = _options.Common.SecurityProtocol;
            if (_options.Common.SaslMechanism.HasValue)
            {
                consumerConfig.SaslMechanism = _options.Common.SaslMechanism.Value;
                consumerConfig.SaslUsername = _options.Common.SaslUsername;
                consumerConfig.SaslPassword = _options.Common.SaslPassword;
            }

            if (!string.IsNullOrEmpty(_options.Common.SslCaLocation))
            {
                consumerConfig.SslCaLocation = _options.Common.SslCaLocation;
                consumerConfig.SslCertificateLocation = _options.Common.SslCertificateLocation;
                consumerConfig.SslKeyLocation = _options.Common.SslKeyLocation;
                consumerConfig.SslKeyPassword = _options.Common.SslKeyPassword;
            }
        }

        foreach (var kvp in topicConfig.Consumer.AdditionalProperties)
            consumerConfig.Set(kvp.Key, kvp.Value);

        return consumerConfig;
    }

    public void ResetOffsetsToBeginning<TPOCO>() where TPOCO : class
    {
        var model = GetEntityModel<TPOCO>();
        var topic = model.GetTopicName();
        var mapping = _mappingRegistry.GetMapping(typeof(TPOCO));
        var config = BuildConsumerConfig(topic, null);
        config.EnableAutoCommit = false;
        var method = typeof(KafkaConsumerManager)
            .GetMethod(nameof(ResetOffsetsToBeginningInternal), System.Reflection.BindingFlags.NonPublic | System.Reflection.BindingFlags.Instance)!
            .MakeGenericMethod(mapping.AvroKeyType!, mapping.AvroValueType!);
        method.Invoke(this, new object?[] { topic, config, model.Partitions });
    }

    private void ResetOffsetsToBeginningInternal<TKey, TValue>(string topic, ConsumerConfig config, int partitions)
        where TKey : class where TValue : class
    {
        using var consumer = CreateConsumer<TKey, TValue>(config);
        var tps = new List<TopicPartitionOffset>(partitions);
        for (var i = 0; i < partitions; i++)
            tps.Add(new TopicPartitionOffset(topic, new Partition(i), new Offset(0)));
        consumer.Assign(tps);
        consumer.Commit(tps);
    }

    public void Dispose()
    {
        if (_disposed) return;
        if (_schemaRegistryClient.IsValueCreated)
            _schemaRegistryClient.Value.Dispose();
        _disposed = true;
    }

    private static int? TryGetSchemaId(byte[]? payload)
    {
        if (payload is { Length: >= 5 } && payload[0] == 0)
            return System.Buffers.Binary.BinaryPrimitives.ReadInt32BigEndian(payload.AsSpan(1, 4));
        return null;
    }

    private static System.Collections.Generic.IReadOnlyDictionary<string, string> ExtractAllowedHeaders(
        Headers? headers, System.Collections.Generic.IEnumerable<string> allowList, int maxLen = 1024)
    {
        var dict = new System.Collections.Generic.Dictionary<string, string>(System.StringComparer.OrdinalIgnoreCase);
        if (headers is null) return dict;

        var set = allowList is System.Collections.Generic.HashSet<string> hs ? hs :
                  new System.Collections.Generic.HashSet<string>(allowList ?? System.Array.Empty<string>(), System.StringComparer.OrdinalIgnoreCase);

        foreach (var h in headers)
        {
            if (!set.Contains(h.Key)) continue;
            var bytes = h.GetValueBytes() ?? System.Array.Empty<byte>();
            string val;
            try
            {
                val = System.Text.Encoding.UTF8.GetString(bytes);
                if (!System.Text.Encoding.UTF8.GetBytes(val).AsSpan().SequenceEqual(bytes))
                    val = "base64:" + System.Convert.ToBase64String(bytes);
            }
            catch
            {
                val = "base64:" + System.Convert.ToBase64String(bytes);
            }
            if (val.Length > maxLen) val = val[..maxLen];
            dict[h.Key] = val;
        }
        return dict;
    }
}
### tool â€” 2025-08-11T08:31:47.978117+00:00

îˆ€fileciteîˆ‚turn1file2îˆ

namespace Kafka.Ksql.Linq.Messaging.Consumers;

internal class NoopCommitManager : ICommitManager
{
    public void Commit(object entity) { }
}
### user â€” 2025-08-11T08:31:47.982000+00:00

æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰ã‚’åˆ©ç”¨ã™ã‚‹å½¢ã§ãŠé¡˜ã„ã—ã¾ã™
### tool â€” 2025-08-11T08:31:47.991503+00:00

îˆ€fileciteîˆ‚turn1file3îˆ

using Kafka.Ksql.Linq.Core.Abstractions;
using Kafka.Ksql.Linq.Core.Extensions;
using Kafka.Ksql.Linq.Messaging.Internal;
using Kafka.Ksql.Linq.Messaging;
using Kafka.Ksql.Linq.Core.Dlq;
using Kafka.Ksql.Linq.Query.Abstractions;
using System;
using System.Collections.Generic;
using System.Runtime.CompilerServices;
using System.Threading;
using System.Threading.Tasks;

namespace Kafka.Ksql.Linq;

/// <summary>
/// Base class for EventSet implementing IEntitySet<T>
/// Reason for modification: unified with KsqlContext and added IEntitySet<T> implementation
/// </summary>
public abstract class EventSet<T> : IEntitySet<T> where T : class
{
    protected readonly IKsqlContext _context;
    protected readonly EntityModel _entityModel;
    private readonly ErrorHandlingContext _errorHandlingContext;
    private IErrorSink? _dlqErrorSink;
    private readonly Messaging.Producers.IDlqProducer? _dlqProducer;
    private readonly Messaging.Consumers.ICommitManager? _commitManager;

    protected EventSet(IKsqlContext context, EntityModel? entityModel = null, IErrorSink? dlqErrorSink = null,
        Messaging.Producers.IDlqProducer? dlqProducer = null, Messaging.Consumers.ICommitManager? commitManager = null)
    {
        _context = context ?? throw new ArgumentNullException(nameof(context));
        _errorHandlingContext = new ErrorHandlingContext();
        _dlqErrorSink = dlqErrorSink;
        _dlqProducer = dlqProducer;
        _commitManager = commitManager;

        if (context is KsqlContext kctx)
        {
            _entityModel = kctx.EnsureEntityModel(typeof(T), entityModel);
        }
        else
        {
            _entityModel = entityModel ?? throw new ArgumentNullException(nameof(entityModel));
        }

        if (_dlqErrorSink != null)
        {
            _errorHandlingContext.ErrorOccurred += (ctx, msg) => _dlqErrorSink.HandleErrorAsync(ctx, msg);
        }
    }

    private EventSet(IKsqlContext context, EntityModel entityModel, ErrorHandlingContext errorHandlingContext, IErrorSink? dlqErrorSink,
        Messaging.Producers.IDlqProducer? dlqProducer, Messaging.Consumers.ICommitManager? commitManager)
    {
        _context = context;
        _entityModel = entityModel;
        _errorHandlingContext = errorHandlingContext;
        _dlqErrorSink = dlqErrorSink;
        _dlqProducer = dlqProducer;
        _commitManager = commitManager;

        if (_dlqErrorSink != null)
        {
            _errorHandlingContext.ErrorOccurred += (ctx, msg) => _dlqErrorSink.HandleErrorAsync(ctx, msg);
        }
    }

    /// <summary>
    /// NEW: made abstract - must be implemented by concrete classes
    /// Unifies continuous Kafka consumption and returning a fixed list
    /// </summary>
    public abstract IAsyncEnumerator<T> GetAsyncEnumerator(CancellationToken cancellationToken = default);

    private async IAsyncEnumerable<T> GetAsyncEnumeratorWrapper([EnumeratorCancellation] CancellationToken cancellationToken = default)
    {
        await using var enumerator = GetAsyncEnumerator(cancellationToken);

        while (true)
        {
            bool hasNext;
            try
            {
                hasNext = await enumerator.MoveNextAsync();
            }
            catch (Exception ex)
            {
                var ctx = new KafkaMessageContext
                {
                    MessageId = Guid.NewGuid().ToString(),
                    Tags = new Dictionary<string, object>
                    {
                        ["processing_phase"] = "ForEachAsync"
                    }
                };

                var shouldContinue = await _errorHandlingContext.HandleErrorAsync(default(T)!, ex, ctx);

                if (!shouldContinue)
                {
                    continue;
                }

                throw;
            }

            if (!hasNext)
                yield break;

            yield return enumerator.Current;
        }
    }


    public virtual async Task<List<T>> ToListAsync(CancellationToken cancellationToken = default)
    {
        if (_entityModel.EntityType == typeof(Messaging.DlqEnvelope))
            throw new InvalidOperationException("DLQã¯ç„¡é™åˆ—æŒ™/å±¥æ­´åˆ—ã§ã‚ã‚Šã€ãƒãƒƒãƒå–å¾—ãƒ»ä»¶æ•°æŒ‡å®šå–å¾—ã¯ç¾çŠ¶æœªå¯¾å¿œã§ã™");

        if (_entityModel.GetExplicitStreamTableType() == StreamTableType.Stream)
            throw new InvalidOperationException("ToListAsync() is not supported on a Stream source. Use ForEachAsync or subscribe for event consumption.");

        var results = new List<T>();

        await foreach (var item in GetAsyncEnumeratorWrapper(cancellationToken))
        {
            results.Add(item);
        }

        return results;
    }
    /// <summary>
    /// ABSTRACT: Producer functionality - implemented in derived classes
    /// </summary>
    protected abstract Task SendEntityAsync(T entity, Dictionary<string, string>? headers, CancellationToken cancellationToken);

    /// <summary>
    /// IEntitySet<T> implementation: producer operations
    /// </summary>
    public virtual async Task AddAsync(T entity, Dictionary<string, string>? headers = null, CancellationToken cancellationToken = default)
    {
        if (entity == null)
            throw new ArgumentNullException(nameof(entity));

        await SendEntityAsync(entity, headers, cancellationToken);
    }

    public virtual Task RemoveAsync(T entity, CancellationToken cancellationToken = default)
    {
        throw new NotSupportedException($"RemoveAsync is not supported for {GetType().Name}.");
    }

    /// <summary>
    /// Retrieves messages from the underlying consumer.
    /// Separated for ease of testing.
    /// </summary>
    /// <param name="context">Active KsqlContext</param>
    /// <param name="cancellationToken">Cancellation token</param>
    /// <returns>Message stream with headers</returns>
    protected virtual IAsyncEnumerable<(T Entity, Dictionary<string, string> Headers, MessageMeta Meta)> ConsumeAsync(
        KsqlContext context,
        CancellationToken cancellationToken)
    {
        return context.GetConsumerManager().ConsumeAsync<T>(cancellationToken);
    }
    /// <summary>
    /// REDESIGNED: ForEachAsync supporting continuous Kafka consumption
    /// Design change: ToListAsync() is disallowed; now based on GetAsyncEnumerator
    /// </summary>
    public virtual Task ForEachAsync(Func<T, Task> action, TimeSpan timeout = default, CancellationToken cancellationToken = default)
    {
        if (action == null)
            throw new ArgumentNullException(nameof(action));

        return ForEachAsync((item, headers, _) => action(item), timeout, cancellationToken);
    }

    [Obsolete("Use ForEachAsync(Func<T, Dictionary<string,string>, MessageMeta, Task>)")]
    public virtual Task ForEachAsync(Func<T, Dictionary<string,string>, Task> action, TimeSpan timeout = default, CancellationToken cancellationToken = default)
        => ForEachAsync((e, h, _) => action(e, h), timeout, cancellationToken);

    public virtual async Task ForEachAsync(Func<T, Dictionary<string,string>, MessageMeta, Task> action, TimeSpan timeout = default, CancellationToken cancellationToken = default)
    {
        if (action == null)
            throw new ArgumentNullException(nameof(action));

        var context = GetContext() as KsqlContext
            ?? throw new InvalidOperationException("KsqlContext is required");

        using var linkedCts = CancellationTokenSource.CreateLinkedTokenSource(cancellationToken);

        if (timeout != default && timeout != TimeSpan.Zero)
        {
            linkedCts.CancelAfter(timeout);
        }
        await foreach (var (entity, headers, meta) in ConsumeAsync(context, linkedCts.Token))
        {
            if (headers.TryGetValue("is_dummy", out var dummyHeader) && bool.TryParse(dummyHeader, out var isDummy) && isDummy)
            {
                continue;
            }

            var maxAttempts = _errorHandlingContext.ErrorAction == ErrorAction.Retry
                ? _errorHandlingContext.RetryCount + 1
                : 1;

            for (var attempt = 1; attempt <= maxAttempts; attempt++)
            {
                try
                {
                    await action(entity, headers, meta);
                    break;
                }
                catch (Exception ex)
                {
                    _errorHandlingContext.CurrentAttempt = attempt;

                    if (attempt < maxAttempts && _errorHandlingContext.ErrorAction == ErrorAction.Retry)
                    {
                        await Task.Delay(_errorHandlingContext.RetryInterval, linkedCts.Token);
                        continue;
                    }

                    var dlq = context.DlqOptions;
                    if (_dlqProducer != null && dlq.EnableForHandlerError && DlqGuard.ShouldSend(dlq, context.DlqLimiter, ex.GetType()))
                    {
                        var env = DlqEnvelopeFactory.From(
                            meta, ex,
                            dlq.ApplicationId, dlq.ConsumerGroup, dlq.Host,
                            dlq.ErrorMessageMaxLength, dlq.StackTraceMaxLength, dlq.NormalizeStackTraceWhitespace);
                        await _dlqProducer.ProduceAsync(env, linkedCts.Token).ConfigureAwait(false);
                    }

                    _commitManager?.Commit(entity);
                    break;
                }
            }
        }
    }

    /// <summary>
    /// IEntitySet<T> implementation: retrieve metadata
    /// </summary>
    public string GetTopicName() => (_entityModel.TopicName ?? _entityModel.EntityType.Name).ToLowerInvariant();

    public EntityModel GetEntityModel() => _entityModel;

    public IKsqlContext GetContext() => _context;

    /// <summary>
    /// Create message context for error handling
    /// </summary>
    private KafkaMessageContext CreateMessageContext(T item)
    {
        return new KafkaMessageContext
        {
            MessageId = Guid.NewGuid().ToString(),
            Tags = new Dictionary<string, object>
            {
                ["entity_type"] = typeof(T).Name,
                ["topic_name"] = GetTopicName(),
                ["processing_phase"] = "ForEachAsync",
                ["timestamp"] = DateTime.UtcNow
            }
        };
    }

    /// <summary>
    /// Creates a ManualCommitMessage instance
    /// </summary>
    protected virtual IManualCommitMessage<T> CreateManualCommitMessage(T item)
    {
        return new ManualCommitMessage<T>(item, () => Task.CompletedTask, () => Task.CompletedTask);
    }

    /// <summary>
    /// Yields messages as different types depending on UseManualCommit
    /// </summary>
    public virtual async IAsyncEnumerable<object> ForEachAsync([EnumeratorCancellation] CancellationToken cancellationToken = default)
    {
        await foreach (var item in GetAsyncEnumeratorWrapper(cancellationToken))
        {
            if (_entityModel.UseManualCommit)
            {
                yield return CreateManualCommitMessage(item);
            }
            else
            {
                yield return item;
            }
        }
    }

    /// <summary>
    /// Configure the error handling policy
    /// </summary>
    internal virtual EventSet<T> WithErrorPolicy(ErrorHandlingPolicy policy)
    {
        if (policy == null)
            throw new ArgumentNullException(nameof(policy));

        _errorHandlingContext.ErrorAction = policy.Action;
        _errorHandlingContext.RetryCount = policy.RetryCount;
        _errorHandlingContext.RetryInterval = policy.RetryInterval;
        _errorHandlingContext.CustomHandler = policy.CustomHandler;

        return this;
    }

    public override string ToString()
    {
        return $"EventSet<{typeof(T).Name}> - Topic: {GetTopicName()}";
    }



    /// <summary>
    /// Specifies the number of retries.
    /// Used when ErrorAction.Retry is selected.
    /// </summary>
    /// <param name="maxRetries">Maximum retry count</param>
    /// <param name="retryInterval">Retry interval (optional)</param>
    /// <returns>EventSet with retry configuration applied</returns>
    public EventSet<T> WithRetry(int maxRetries, TimeSpan? retryInterval = null)
    {
        if (maxRetries < 0)
            throw new ArgumentException("Retry count must be zero or greater", nameof(maxRetries));

        var newContext = new ErrorHandlingContext
        {
            ErrorAction = _errorHandlingContext.ErrorAction,
            RetryCount = maxRetries,
            RetryInterval = retryInterval ?? TimeSpan.FromSeconds(1)
        };

        return CreateNewInstance(_context, _entityModel, newContext, _dlqErrorSink);
    }

    /// <summary>
    /// Passes the POCO to the business logic.
    /// After receiving from Kafka, each element is transformed using the supplied function.
    /// Exceptions and retries are handled based on the OnError and WithRetry settings.
    /// </summary>
    /// <typeparam name="TResult">Result type</typeparam>
    /// <param name="mapper">Mapping function</param>
    /// <returns>The mapped EventSet</returns>
    public async Task<EventSet<TResult>> Map<TResult>(Func<T, Task<TResult>> mapper) where TResult : class
    {
        if (mapper == null)
            throw new ArgumentNullException(nameof(mapper));

        var results = new List<TResult>();
        var sourceData = await ToListAsync();

        foreach (var item in sourceData)
        {
            var itemErrorContext = new ErrorHandlingContext
            {
                ErrorAction = _errorHandlingContext.ErrorAction,
                RetryCount = _errorHandlingContext.RetryCount,
                RetryInterval = _errorHandlingContext.RetryInterval
            };

            await ProcessItemWithErrorHandling(
                item,
                mapper,
                results,
                itemErrorContext);
        }

        var resultEntityModel = CreateEntityModelForType<TResult>();
        return new MappedEventSet<TResult>(results, _context, resultEntityModel, _dlqErrorSink);
    }

    /// <summary>
    /// Synchronous version of the Map function
    /// </summary>
    public EventSet<TResult> Map<TResult>(Func<T, TResult> mapper) where TResult : class
    {
        if (mapper == null)
            throw new ArgumentNullException(nameof(mapper));

        var results = new List<TResult>();
        var sourceData = ToListAsync().GetAwaiter().GetResult();

        foreach (var item in sourceData)
        {
            var itemErrorContext = new ErrorHandlingContext
            {
                ErrorAction = _errorHandlingContext.ErrorAction,
                RetryCount = _errorHandlingContext.RetryCount,
                RetryInterval = _errorHandlingContext.RetryInterval
            };

            ProcessItemWithErrorHandlingSync(
                item,
                mapper,
                results,
                itemErrorContext);
        }
        var resultEntityModel = CreateEntityModelForType<TResult>();
        return new MappedEventSet<TResult>(results, _context, resultEntityModel, _dlqErrorSink);
    }

    // Abstract method: create a new instance in derived classes
    protected virtual EventSet<T> CreateNewInstance(IKsqlContext context, EntityModel entityModel, ErrorHandlingContext errorContext, IErrorSink? dlqErrorSink)
    {
        // Default implementation: concrete classes must override
        throw new NotImplementedException("Derived classes must implement CreateNewInstance");
    }

    private EntityModel CreateEntityModelForType<TResult>() where TResult : class
    {
        return new EntityModel
        {
            EntityType = typeof(TResult),
            TopicName = $"{typeof(TResult).Name.ToLowerInvariant()}_mapped",
            AllProperties = typeof(TResult).GetProperties(),
            KeyProperties = Array.Empty<System.Reflection.PropertyInfo>(),
            ValidationResult = new ValidationResult { IsValid = true }
        };
    }

    /// <summary>
    /// Item-level processing with error handling (async version)
    /// </summary>
    private async Task ProcessItemWithErrorHandling<TResult>(
        T item,
        Func<T, Task<TResult>> mapper,
        List<TResult> results,
        ErrorHandlingContext errorContext) where TResult : class
    {
        var maxAttempts = errorContext.ErrorAction == ErrorAction.Retry
            ? errorContext.RetryCount + 1
            : 1;

        for (int attempt = 1; attempt <= maxAttempts; attempt++)
        {
            try
            {
                var result = await mapper(item);
                results.Add(result);
                return; // Processing completed successfully
            }
            catch (Exception ex)
            {
                errorContext.CurrentAttempt = attempt;

                // Retry regardless of ErrorAction if this is not the final attempt
                if (attempt < maxAttempts && errorContext.ErrorAction == ErrorAction.Retry)
                {
                    Console.WriteLine($"[{DateTime.UtcNow:HH:mm:ss}] Retry {attempt}/{errorContext.RetryCount}: {ex.Message}");
                    await Task.Delay(errorContext.RetryInterval);
                    continue;
                }

                // Perform error handling on the last attempt or when not retrying
                var shouldContinue = await errorContext.HandleErrorAsync(item, ex, CreateContext(item, errorContext));

                if (!shouldContinue)
                {
                    return; // Skip this item and move to the next
                }
            }
        }
    }

    /// <summary>
    /// Item-level processing with error handling (sync version)
    /// </summary>
    private void ProcessItemWithErrorHandlingSync<TResult>(
        T item,
        Func<T, TResult> mapper,
        List<TResult> results,
        ErrorHandlingContext errorContext) where TResult : class
    {
        var maxAttempts = errorContext.ErrorAction == ErrorAction.Retry
            ? errorContext.RetryCount + 1
            : 1;

        for (int attempt = 1; attempt <= maxAttempts; attempt++)
        {
            try
            {
                var result = mapper(item);
                results.Add(result);
                return; // Processing completed successfully
            }
            catch (Exception ex)
            {
                errorContext.CurrentAttempt = attempt;

                // Retry regardless of ErrorAction if this is not the final attempt
                if (attempt < maxAttempts && errorContext.ErrorAction == ErrorAction.Retry)
                {
                    Console.WriteLine($"[{DateTime.UtcNow:HH:mm:ss}] Retry {attempt}/{errorContext.RetryCount}: {ex.Message}");
                    Thread.Sleep(errorContext.RetryInterval);
                    continue;
                }

                // Perform error handling on the last attempt or when not retrying
                var shouldContinue = errorContext.HandleErrorAsync(item, ex, CreateContext(item, errorContext)).GetAwaiter().GetResult();

                if (!shouldContinue)
                {
                    return; // Skip this item and proceed to the next
                }
            }
        }
    }

    /// <summary>
    /// Create a message context
    /// </summary>
    private KafkaMessageContext CreateContext(T item, ErrorHandlingContext errorContext)
    {
        return new KafkaMessageContext
        {
            MessageId = Guid.NewGuid().ToString(),
            Tags = new Dictionary<string, object>
            {
                ["original_topic"] = GetTopicName(),
                ["original_partition"] = 0, // Replace with actual value
                ["original_offset"] = 0, // Replace with actual value
                ["retry_count"] = errorContext.CurrentAttempt,
                ["error_phase"] = "Processing"
            }
        };
    }

}
internal class MappedEventSet<T> : EventSet<T> where T : class
{
    private readonly List<T> _mapped;
    private readonly EntityModel _originalEntityModel;

    public MappedEventSet(List<T> mappedItems, IKsqlContext context, EntityModel originalEntityModel, IErrorSink? errorSink = null)
        : base(context, CreateMappedEntityModel<T>(originalEntityModel), errorSink)
    {
        _mapped = mappedItems ?? throw new ArgumentNullException(nameof(mappedItems));
        _originalEntityModel = originalEntityModel;
    }

    /// <summary>
    /// NEW: GetAsyncEnumerator implementation for fixed lists
    /// Returns each _mapped[i] sequentially via yield return
    /// </summary>
    public override async IAsyncEnumerator<T> GetAsyncEnumerator(CancellationToken cancellationToken = default)
    {
        foreach (var item in _mapped)
        {
            if (cancellationToken.IsCancellationRequested)
                yield break;

            yield return item;

            // Inserted to treat the loop asynchronously (avoid CPU intensive work)
            await Task.Yield();
        }
    }

    /// <summary>
    /// OPTIMIZATION: ToListAsync - already a fixed list so return immediately
    /// </summary>
    public override async Task<List<T>> ToListAsync(CancellationToken cancellationToken = default)
    {
        if (_entityModel.GetExplicitStreamTableType() == StreamTableType.Stream)
            throw new InvalidOperationException("ToListAsync() is not supported on a Stream source. Use ForEachAsync or subscribe for event consumption.");

        // Already a fixed list; return a copy
        await Task.CompletedTask;
        return new List<T>(_mapped);
    }

    /// <summary>
    /// Data after Map cannot be sent via Producer
    /// </summary>
    protected override Task SendEntityAsync(T entity, Dictionary<string, string>? headers, CancellationToken cancellationToken)
    {
        throw new NotSupportedException(
            $"MappedEventSet<{typeof(T).Name}> does not support AddAsync operations. " +
            "Mapped data is read-only and derived from transformation operations.");
    }

    public override Task RemoveAsync(T entity, CancellationToken cancellationToken = default)
    {
        throw new NotSupportedException($"MappedEventSet<{typeof(T).Name}> does not support RemoveAsync operations.");
    }

    /// <summary>
    /// Helper method to create a MappedEventSet
    /// </summary>
    public static MappedEventSet<T> Create(List<T> mappedItems, IKsqlContext context, EntityModel originalEntityModel, IErrorSink? errorSink = null)
    {
        return new MappedEventSet<T>(mappedItems, context, originalEntityModel, errorSink);
    }

    /// <summary>
    /// Create a MappedEventSet with DLQ support
    /// </summary>
    public static MappedEventSet<T> CreateWithDlq(List<T> mappedItems, IKsqlContext context, EntityModel originalEntityModel, IErrorSink dlqErrorSink)
    {
        return new MappedEventSet<T>(mappedItems, context, originalEntityModel, dlqErrorSink);
    }

    /// <summary>
    /// Create an EntityModel for mapped data
    /// </summary>
    private static EntityModel CreateMappedEntityModel<TMapped>(EntityModel originalModel) where TMapped : class
    {
        return new EntityModel
        {
            EntityType = typeof(TMapped),
            TopicName = $"{originalModel.GetTopicName()}_mapped",
            AllProperties = typeof(TMapped).GetProperties(),
            KeyProperties = Array.Empty<System.Reflection.PropertyInfo>(), // No key after mapping
            ValidationResult = new ValidationResult { IsValid = true }
        };
    }

    public override string ToString()
    {
        return $"MappedEventSet<{typeof(T).Name}> - Items: {_mapped.Count}";
    }
}
### tool â€” 2025-08-11T08:31:48.004250+00:00

All the files uploaded by the user have been fully loaded. Searching won't provide additional information.
### assistant â€” 2025-08-11T08:31:49.606016+00:00

_(empty)_
### assistant â€” 2025-08-11T08:32:05.693919+00:00

_(empty)_
### user â€” 2025-08-11T09:35:01.742000+00:00

public virtual async IAsyncEnumerable<object> ForEachAsync([EnumeratorCancellation] CancellationToken cancellationToken = default)
    {
        await foreach (var item in GetAsyncEnumeratorWrapper(cancellationToken))
        {
            if (_entityModel.UseManualCommit)
            {
                yield return CreateManualCommitMessage(item);
            }
            else
            {
                yield return item;
            }
        }
    }
æˆ»ã‚Šå€¤ãŒobjectã€€ã“ã‚Œã‚’pocoã¨ã—ãŸã„
### assistant â€” 2025-08-11T09:35:14.570187+00:00

import os, textwrap, json, pathlib, sys, re, itertools, math
### system â€” 2025-08-11T09:35:14.988974+00:00

_(empty)_
### assistant â€” 2025-08-11T09:35:15.017523+00:00

_(empty)_
### assistant â€” 2025-08-11T09:35:15.595810+00:00

_(empty)_
### tool â€” 2025-08-11T09:35:27.578165+00:00

Code execution state reset.
### assistant â€” 2025-08-11T09:35:27.779911+00:00

from pathlib import Path, PurePosixPath
base=Path('/mnt/data')
list(base.iterdir())
### tool â€” 2025-08-11T09:35:29.492795+00:00

[PosixPath('/mnt/data/ICommitManager.cs'),
 PosixPath('/mnt/data/KafkaConsumerManager.cs'),
 PosixPath('/mnt/data/EventSet.cs'),
 PosixPath('/mnt/data/NoopCommitManager.cs')]
### assistant â€” 2025-08-11T09:35:30.593121+00:00

print(Path('/mnt/data/EventSet.cs').read_text()[:2000])
### tool â€” 2025-08-11T09:35:33.293034+00:00

using Kafka.Ksql.Linq.Core.Abstractions;
using Kafka.Ksql.Linq.Core.Extensions;
using Kafka.Ksql.Linq.Messaging.Internal;
using Kafka.Ksql.Linq.Messaging;
using Kafka.Ksql.Linq.Core.Dlq;
using Kafka.Ksql.Linq.Query.Abstractions;
using System;
using System.Collections.Generic;
using System.Runtime.CompilerServices;
using System.Threading;
using System.Threading.Tasks;

namespace Kafka.Ksql.Linq;

/// <summary>
/// Base class for EventSet implementing IEntitySet<T>
/// Reason for modification: unified with KsqlContext and added IEntitySet<T> implementation
/// </summary>
public abstract class EventSet<T> : IEntitySet<T> where T : class
{
    protected readonly IKsqlContext _context;
    protected readonly EntityModel _entityModel;
    private readonly ErrorHandlingContext _errorHandlingContext;
    private IErrorSink? _dlqErrorSink;
    private readonly Messaging.Producers.IDlqProducer? _dlqProducer;
    private readonly Messaging.Consumers.ICommitManager? _commitManager;

    protected EventSet(IKsqlContext context, EntityModel? entityModel = null, IErrorSink? dlqErrorSink = null,
        Messaging.Producers.IDlqProducer? dlqProducer = null, Messaging.Consumers.ICommitManager? commitManager = null)
    {
        _context = context ?? throw new ArgumentNullException(nameof(context));
        _errorHandlingContext = new ErrorHandlingContext();
        _dlqErrorSink = dlqErrorSink;
        _dlqProducer = dlqProducer;
        _commitManager = commitManager;

        if (context is KsqlContext kctx)
        {
            _entityModel = kctx.EnsureEntityModel(typeof(T), entityModel);
        }
        else
        {
            _entityModel = entityModel ?? throw new ArgumentNullException(nameof(entityModel));
        }

        if (_dlqErrorSink != null)
        {
            _errorHandlingContext.ErrorOccurred += (ctx, msg) => _dlqErrorSink.HandleErrorAsync(ctx, msg);
        }
    }

    private EventSet(IKsqlContext context, EntityModel entityModel, ErrorHandlingContex
### assistant â€” 2025-08-11T09:35:34.435172+00:00

print(Path('/mnt/data/EventSet.cs').read_text())
### tool â€” 2025-08-11T09:35:36.132866+00:00

if (!shouldContinue)
                {
                    continue;
                }

                throw;
            }

            if (!hasNext)
                yield break;

            yield return enumerator.Current;
        }
    }


    public virtual async Task<List<T>> ToListAsync(CancellationToken cancellationToken = default)
    {
        if (_entityModel.EntityType == typeof(Messaging.DlqEnvelope))
            throw new InvalidOperationException("DLQã¯ç„¡é™åˆ—æŒ™/å±¥æ­´åˆ—ã§ã‚ã‚Šã€ãƒãƒƒãƒå–å¾—ãƒ»ä»¶æ•°æŒ‡å®šå–å¾—ã¯ç¾çŠ¶æœªå¯¾å¿œã§ã™");

        if (_entityModel.GetExplicitStreamTableType() == StreamTableType.Stream)
            throw new InvalidOperationException("ToListAsync() is not supported on a Stream source. Use ForEachAsync or subscribe for event consumption.");

        var results = new List<T>();

        await foreach (var item in GetAsyncEnumeratorWrapper(cancellationToken))
        {
            results.Add(item);
        }

        return results;
    }
    /// <summary>
    /// ABSTRACT: Producer functionality - implemented in derived classes
    /// </summary>
    protected abstract Task SendEntityAsync(T entity, Dictionary<string, string>? headers, CancellationToken cancellationToken);

    /// <summary>
    /// IEntitySet<T> implementation: producer operations
    /// </summary>
    public virtual async Task AddAsync(T entity, Dictionary<string, string>? headers = null, CancellationToken cancellationToken = default)
    {
        if (entity == null)
            throw new ArgumentNullException(nameof(entity));

        await SendEntityAsync(entity, headers, cancellationToken);
    }

    public virtual Task RemoveAsync(T entity, CancellationToken cancellationToken = default)
    {
        throw new NotSupportedException($"RemoveAsync is not supported for {GetType().Name}.");
    }

    /// <summary>
    /// Retrieves messages from the underlying consumer.
    /// Separated for ease of testing.
    /// </summary>
    /// <param name="context">Active KsqlContext</param>
    /// <param name="cancellationToken">Cancellation token</param>
    /// <returns>Message stream with headers</returns>
    protected virtual IAsyncEnumerable<(T Entity, Dictionary<string, string> Headers, MessageMeta Meta)> ConsumeAsync(
        KsqlContext context,
        CancellationToken cancellationToken)
    {
        return context.GetConsumerManager().ConsumeAsync<T>(cancellationToken);
    }
    /// <summary>
    /// REDESIGNED: ForEachAsync supporting continuous Kafka consumption
    /// Design change: ToListAsync() is disallowed; now based on GetAsyncEnumerator
    /// </summary>
    public virtual Task ForEachAsync(Func<T, Task> action, TimeSpan timeout = default, CancellationToken cancellationToken = default)
    {
        if (action == null)
            throw new ArgumentNullException(nameof(action));

        return ForEachAsync((item, headers, _) => action(item), timeout, cancellationToken);
    }

    [Obsolete("Use ForEachAsync(Func<T, Dictionary<string,string>, MessageMeta, Task>)")]
    public virtual Task ForEachAsync(Func<T, Dictionary<string,string>, Task> action, TimeSpan timeout = default, CancellationToken cancellationToken = default)
        => ForEachAsync((e, h, _) => action(e, h), timeout, cancellationToken);

    public virtual async Task ForEachAsync(Func<T, Dictionary<string,string>, MessageMeta, Task> action, TimeSpan timeout = default, CancellationToken cancellationToken = default)
    {
        if (action == null)
            throw new ArgumentNullException(nameof(action));

        var context = GetContext() as KsqlContext
            ?? throw new InvalidOperationException("KsqlContext is required");

        using var linkedCts = CancellationTokenSource.CreateLinkedTokenSource(cancellationToken);

        if (timeout != default && timeout != TimeSpan.Zero)
        {
            linkedCts.CancelAfter(timeout);
        }
        await foreach (var (entity, headers, meta) in ConsumeAsync(context, linkedCts.Token))
        {
            if (headers.TryGetValue("is_dummy", out var dummyHeader) && bool.TryParse(dummyHeader, out var isDummy) && isDummy)
            {
                continue;
            }

            var maxAttempts = _errorHandlingContext.ErrorAction == ErrorAction.Retry
                ? _errorHandlingContext.RetryCount + 1
                : 1;

            for (var attempt = 1; attempt <= maxAttempts; attempt++)
            {
                try
                {
                    await action(entity, headers, meta);
                    break;
                }
                catch (Exception ex)
                {
                    _errorHandlingContext.CurrentAttempt = attempt;

                    if (attempt < maxAttempts && _errorHandlingContext.ErrorAction == ErrorAction.Retry)
                    {
                        await Task.Delay(_errorHandlingContext.RetryInterval, linkedCts.Token);
                        continue;
                    }

                    var dlq = context.DlqOptions;
                    if (_dlqProducer != null && dlq.EnableForHandlerError && DlqGuard.ShouldSend(dlq, context.DlqLimiter, ex.GetType()))
                    {
                        var env = DlqEnvelopeFactory.From(
                            meta, ex,
                            dlq.ApplicationId, dlq.ConsumerGroup, dlq.Host,
                            dlq.ErrorMessageMaxLength, dlq.StackTraceMaxLength, dlq.NormalizeStackTraceWhitespace);
                        await _dlqProducer.ProduceAsync(env, linkedCts.Token).ConfigureAwait(false);
                    }

                    _commitManager?.Commit(entity);
                    break;
                }
            }
        }
    }

    /// <summary>
    /// IEntitySet<T> implementation: retrieve metadata
    /// </summary>
    public string GetTopicName() => (_entityModel.TopicName ?? _entityModel.EntityType.Name).ToLowerInvariant();

    public EntityModel GetEntityModel() => _entityModel;

    public IKsqlContext GetContext() => _context;

    /// <summary>
    /// Create message context for error handling
    /// </summary>
    private KafkaMessageContext CreateMessageContext(T item)
    {
        return new KafkaMessageContext
        {
            MessageId = Guid.NewGuid().ToString(),
            Tags = new Dictionary<string, object>
            {
                ["entity_type"] = typeof(T).Name,
                ["topic_name"] = GetTopicName(),
                ["processing_phase"] = "ForEachAsync",
                ["timestamp"] = DateTime.UtcNow
            }
        };
    }

    /// <summary>
    /// Creates a ManualCommitMessage instance
    /// </summary>
    protected virtual IManualCommitMessage<T> CreateManualCommitMessage(T item)
    {
        return new ManualCommitMessage<T>(item, () => Task.CompletedTask, () => Task.CompletedTask);
    }

    /// <summary>
    /// Yields messages as different types depending on UseManualCommit
    /// </summary>
    public virtual async IAsyncEnumerable<object> ForEachAsync([EnumeratorCancellation] CancellationToken cancellationToken = default)
    {
        await foreach (var item in GetAsyncEnumeratorWrapper(cancellationToken))
        {
            if (_entityModel.UseManualCommit)
            {
                yield return CreateManualCommitMessage(item);
            }
            else
            {
                yield return item;
            }
        }
    }

    /// <summary>
    /// Configure the error handling policy
    /// </summary>
    internal virtual EventSet<T> WithErrorPolicy(ErrorHandlingPolicy policy)
    {
        if (policy == null)
            throw new ArgumentNullException(nameof(policy));

        _errorHandlingContext.ErrorAction = policy.Action;
        _errorHandlingContext.RetryCount = policy.RetryCount;
        _errorHandlingContext.RetryInterval = policy.RetryInterval;
        _errorHandlingContext.CustomHandler = policy.CustomHandler;

        return this;
    }

    public override string ToString()
    {
        return $"EventSet<{typeof(T).Name}> - Topic: {GetTopicName()}";
    }



    /// <summary>
    /// Specifies the number of retries.
    /// Used when ErrorAction.Retry is selected.
    /// </summary>
    /// <param name="maxRetries">Maximum retry count</param>
    /// <param name="retryInterval">Retry interval (optional)</param>
    /// <returns>EventSet with retry configuration applied</returns>
    public EventSet<T> WithRetry(int maxRetries, TimeSpan? retryInterval = null)
    {
        if (maxRetries < 0)
            throw new ArgumentException("Retry count must be zero or greater", nameof(maxRetries));

        var newContext = new ErrorHandlingContext
        {
            ErrorAction = _errorHandlingContext.ErrorAction,
            RetryCount = maxRetries,
            RetryInterval = retryInterval ?? TimeSpan.FromSeconds(1)
        };

        return CreateNewInstance(_context, _entityModel, newContext, _dlqErrorSink);
    }

    /// <summary>
    /// Passes the POCO to the business logic.
    /// After receiving from Kafka, each element is transformed using the supplied function.
    /// Exceptions and retries are handled based on the OnError and WithRetry settings.
    /// </summary>
    /// <typeparam name="TResult">Result type</typeparam>
    /// <param name="mapper">Mapping function</param>
    /// <returns>The mapped EventSet</returns>
    public async Task<EventSet<TResult>> Map<TResult>(Func<T, Task<TResult>> mapper) where TResult : class
    {
        if (mapper == null)
            throw new ArgumentNullException(nameof(mapper));

        var results = new List<TResult>();
        var sourceData = await ToListAsync();

        foreach (var item in sourceData)
        {
            var itemErrorContext = new ErrorHandlingContext
            {
                ErrorAction = _errorHandlingContext.ErrorAction,
                RetryCount = _errorHandlingContext.RetryCount,
                RetryInterval = _errorHandlingContext.RetryInterval
            };

            await ProcessItemWithErrorHandling(
                item,
                mapper,
                results,
                itemErrorContext);
        }

        var resultEntityModel = CreateEntityModelForType<TResult>();
        return new MappedEventSet<TResult>(results, _context, resultEntityModel, _dlqErrorSink);
    }

    /// <summary>
    /// Synchronous version of the Map function
    /// </summary>
    public EventSet<TResult> Map<TResult>(Func<T, TResult> mapper) where TResult : class
    {
        if (mapper == null)
            throw new ArgumentNullException(nameof(mapper));

        var results = new List<TResult>();
        var sourceData = ToListAsync().GetAwaiter().GetResult();

        foreach (var item in sourceData)
        {
            var itemErrorContext = new ErrorHandlingContext
            {
                ErrorAction = _errorHandlingContext.ErrorAction,
                RetryCount = _errorHandlingContext.RetryCount,
                RetryInterval = _errorHandlingContext.RetryInterval
            };

            ProcessItemWithErrorHandlingSync(
                item,
                mapper,
                results,
                itemErrorContext);
        }
        var resultEntityModel = CreateEntityModelForType<TResult>();
        return new MappedEventSet<TResult>(results, _context, resultEntityModel, _dlqErrorSink);
    }

    // Abstract method: create a new instance in derived classes
    protected virtual EventSet<T> CreateNewInstance(IKsqlContext context, EntityModel entityModel, ErrorHandlingContext errorContext, IErrorSink? dlqErrorSink)
    {
        // Default implementation: concrete classes must override
        throw new NotImplementedException("Derived classes must implement CreateNewInstance");
    }

    private EntityModel CreateEntityModelForType<TResult>() where TResult : class
    {
        return new EntityModel
        {
            EntityType = typeof(TResult),
            TopicName = $"{typeof(TResult).Name.ToLowerInvariant()}_mapped",
            AllProperties = typeof(TResult).GetProperties(),
            KeyProperties = Array.Empty<System.Reflection.PropertyInfo>(),
            ValidationResult = new ValidationResult { IsValid = true }
        };
    }

    /// <summary>
    /// Item-level processing with error handling (async version)
    /// </summary>
    private async Task ProcessItemWithErrorHandling<TResult>(
        T item,
        Func<T, Task<TResult>> mapper,
        List<TResult> results,
        ErrorHandlingContext errorContext) where TResult : class
    {
        var maxAttempts = errorContext.ErrorAction == ErrorAction.Retry
            ? errorContext.RetryCount + 1
            : 1;

        for (int attempt = 1; attempt <= maxAttempts; attempt++)
        {
            try
            {
                var result = await mapper(item);
                results.Add(result);
                return; // Processing completed successfully
            }
            catch (Exception ex)
            {
                errorContext.CurrentAttempt = attempt;

                // Retry regardless of ErrorAction if this is not the final attempt
                if (attempt < maxAttempts && errorContext.ErrorAction == ErrorAction.Retry)
                {
                    Console.WriteLine($"[{DateTime.UtcNow:HH:mm:ss}] Retry {attempt}/{errorContext.RetryCount}: {ex.Message}");
                    await Task.Delay(errorContext.RetryInterval);
                    continue;
                }

                // Perform error handling on the last attempt or when not retrying
                var shouldContinue = await errorContext.HandleErrorAsync(item, ex, CreateContext(item, errorContext));

                if (!shouldContinue)
                {
                    return; // Skip this item and move to the next
                }
            }
        }
    }

    /// <summary>
    /// Item-level processing with error handling (sync version)
    /// </summary>
    private void ProcessItemWithErrorHandlingSync<TResult>(
        T item,
        Func<T, TResult> mapper,
        List<TResult> results,
        ErrorHandlingContext errorContext) where TResult : class
    {
        var maxAttempts = errorContext.ErrorAction == ErrorAction.Retry
            ? errorContext.RetryCount + 1
            : 1;

        for (int attempt = 1; attempt <= maxAttempts; attempt++)
        {
            try
            {
                var result = mapper(item);
                results.Add(result);
                return; // Processing completed successfully
            }
            catch (Exception ex)
            {
                errorContext.CurrentAttempt = attempt;

                // Retry regardless of ErrorAction if this is not the final attempt
                if (attempt < maxAttempts && errorContext.ErrorAction == ErrorAction.Retry)
                {
                    Console.WriteLine($"[{DateTime.UtcNow:HH:mm:ss}] Retry {attempt}/{errorContext.RetryCount}: {ex.Message}");
                    Thread.Sleep(errorContext.RetryInterval);
                    continue;
                }

                // Perform error handling on the last attempt or when not retrying
                var shouldContinue = errorContext.HandleErrorAsync(item, ex, CreateContext(item, errorContext)).GetAwaiter().GetResult();

                if (!shouldContinue)
                {
                    return; // Skip this item and proceed to the next
                }
            }
        }
    }

    /// <summary>
    /// Create a message context
    /// </summary>
    private KafkaMessageContext CreateContext(T item, ErrorHandlingContext errorContext)
    {
        return new KafkaMessageContext
        {
            MessageId = Guid.NewGuid().ToString(),
            Tags = new Dictionary<string, object>
            {
                ["original_topic"] = GetTopicName(),
                ["original_partition"] = 0, // Replace with actual value
                ["original_offset"] = 0, // Replace with actual value
                ["retry_count"] = errorContext.CurrentAttempt,
                ["error_phase"] = "Processing"
            }
        };
    }

}
internal class MappedEventSet<T> : EventSet<T> where T : class
{
    private readonly List<T> _mapped;
    private readonly EntityModel _originalEntityModel;

    public MappedEventSet(List<T> mappedItems, IKsqlContext context, EntityModel originalEntityModel, IErrorSink? errorSink = null)
        : base(context, CreateMappedEntityModel<T>(originalEntityModel), errorSink)
    {
        _mapped = mappedItems ?? throw new ArgumentNullException(nameof(mappedItems));
        _originalEntityModel = originalEntityModel;
    }

    /// <summary>
    /// NEW: GetAsyncEnumerator implementation for fixed lists
    /// Returns each _mapped[i] sequentially via yield return
    /// </summary>
    public override async IAsyncEnumerator<T> GetAsyncEnumerator(CancellationToken cancellationToken = default)
    {
        foreach (var item in _mapped)
        {
            if (cancellationToken.IsCancellationRequested)
                yield break;

            yield return item;

            // Inserted to treat the loop asynchronously (avoid CPU intensive work)
            await Task.Yield();
        }
    }

    /// <summary>
    /// OPTIMIZATION: ToListAsync - already a fixed list so return immediately
    /// </summary>
    public override async Task<List<T>> ToListAsync(CancellationToken cancellationToken = default)
    {
        if (_entityModel.GetExplicitStreamTableType() == StreamTableType.Stream)
            throw new InvalidOperationException("ToListAsync() is not supported on a Stream source. Use ForEachAsync or subscribe for event consumption.");

        // Already a fixed list; return a copy
        await Task.CompletedTask;
        return new List<T>(_mapped);
    }

    /// <summary>
    /// Data after Map cannot be sent via Producer
    /// </summary>
    protected override Task SendEntityAsync(T entity, Dictionary<string, string>? headers, CancellationToken cancellationToken)
    {
        throw new NotSupportedException(
            $"MappedEventSet<{typeof(T).Name}> does not support AddAsync operations. " +
            "Mapped data is read-only and derived from transformation operations.");
    }

    public override Task RemoveAsync(T entity, CancellationToken cancellationToken = default)
    {
        throw new NotSupportedException($"MappedEventSet<{typeof(T).Name}> does not support RemoveAsync operations.");
    }

    /// <summary>
    /// Helper method to create a MappedEventSet
    /// </summary>
    public static MappedEventSet<T> Create(List<T> mappedItems, IKsqlContext context, EntityModel originalEntityModel, IErrorSink? errorSink = null)
    {
        return new MappedEventSet<T>(mappedItems, context, originalEntityModel, errorSink);
    }

    /// <summary>
    /// Create a MappedEventSet with DLQ support
    /// </summary>
    public static MappedEventSet<T> CreateWithDlq(List<T> mappedItems, IKsqlContext context, EntityModel originalEntityModel, IErrorSink dlqErrorSink)
    {
        return new MappedEventSet<T>(mappedItems, context, originalEntityModel, dlqErrorSink);
    }

    /// <summary>
    /// Create an EntityModel for mapped data
    /// </summary>
    private static EntityModel CreateMappedEntityModel<TMapped>(EntityModel originalModel) where TMapped : class
    {
        return new EntityModel
        {
            EntityType = typeof(TMapped),
            TopicName = $"{originalModel.GetTopicName()}_mapped",
            AllProperties = typeof(TMapped).GetProperties(),
            KeyProperties = Array.Empty<System.Reflection.PropertyInfo>(), // No key after mapping
            ValidationResult = new ValidationResult { IsValid = true }
        };
    }

    public override string ToString()
    {
        return $"MappedEventSet<{typeof(T).Name}> - Items: {_mapped.Count}";
    }
}
### assistant â€” 2025-08-11T09:35:37.401509+00:00

text=Path('/mnt/data/EventSet.cs').read_text()
lines=text.splitlines()
print(len(lines))
print('\n'.join(lines[:200]))
### tool â€” 2025-08-11T09:35:39.142158+00:00

624
using Kafka.Ksql.Linq.Core.Abstractions;
using Kafka.Ksql.Linq.Core.Extensions;
using Kafka.Ksql.Linq.Messaging.Internal;
using Kafka.Ksql.Linq.Messaging;
using Kafka.Ksql.Linq.Core.Dlq;
using Kafka.Ksql.Linq.Query.Abstractions;
using System;
using System.Collections.Generic;
using System.Runtime.CompilerServices;
using System.Threading;
using System.Threading.Tasks;

namespace Kafka.Ksql.Linq;

/// <summary>
/// Base class for EventSet implementing IEntitySet<T>
/// Reason for modification: unified with KsqlContext and added IEntitySet<T> implementation
/// </summary>
public abstract class EventSet<T> : IEntitySet<T> where T : class
{
    protected readonly IKsqlContext _context;
    protected readonly EntityModel _entityModel;
    private readonly ErrorHandlingContext _errorHandlingContext;
    private IErrorSink? _dlqErrorSink;
    private readonly Messaging.Producers.IDlqProducer? _dlqProducer;
    private readonly Messaging.Consumers.ICommitManager? _commitManager;

    protected EventSet(IKsqlContext context, EntityModel? entityModel = null, IErrorSink? dlqErrorSink = null,
        Messaging.Producers.IDlqProducer? dlqProducer = null, Messaging.Consumers.ICommitManager? commitManager = null)
    {
        _context = context ?? throw new ArgumentNullException(nameof(context));
        _errorHandlingContext = new ErrorHandlingContext();
        _dlqErrorSink = dlqErrorSink;
        _dlqProducer = dlqProducer;
        _commitManager = commitManager;

        if (context is KsqlContext kctx)
        {
            _entityModel = kctx.EnsureEntityModel(typeof(T), entityModel);
        }
        else
        {
            _entityModel = entityModel ?? throw new ArgumentNullException(nameof(entityModel));
        }

        if (_dlqErrorSink != null)
        {
            _errorHandlingContext.ErrorOccurred += (ctx, msg) => _dlqErrorSink.HandleErrorAsync(ctx, msg);
        }
    }

    private EventSet(IKsqlContext context, EntityModel entityModel, ErrorHandlingContext errorHandlingContext, IErrorSink? dlqErrorSink,
        Messaging.Producers.IDlqProducer? dlqProducer, Messaging.Consumers.ICommitManager? commitManager)
    {
        _context = context;
        _entityModel = entityModel;
        _errorHandlingContext = errorHandlingContext;
        _dlqErrorSink = dlqErrorSink;
        _dlqProducer = dlqProducer;
        _commitManager = commitManager;

        if (_dlqErrorSink != null)
        {
            _errorHandlingContext.ErrorOccurred += (ctx, msg) => _dlqErrorSink.HandleErrorAsync(ctx, msg);
        }
    }

    /// <summary>
    /// NEW: made abstract - must be implemented by concrete classes
    /// Unifies continuous Kafka consumption and returning a fixed list
    /// </summary>
    public abstract IAsyncEnumerator<T> GetAsyncEnumerator(CancellationToken cancellationToken = default);

    private async IAsyncEnumerable<T> GetAsyncEnumeratorWrapper([EnumeratorCancellation] CancellationToken cancellationToken = default)
    {
        await using var enumerator = GetAsyncEnumerator(cancellationToken);

        while (true)
        {
            bool hasNext;
            try
            {
                hasNext = await enumerator.MoveNextAsync();
            }
            catch (Exception ex)
            {
                var ctx = new KafkaMessageContext
                {
                    MessageId = Guid.NewGuid().ToString(),
                    Tags = new Dictionary<string, object>
                    {
                        ["processing_phase"] = "ForEachAsync"
                    }
                };

                var shouldContinue = await _errorHandlingContext.HandleErrorAsync(default(T)!, ex, ctx);

                if (!shouldContinue)
                {
                    continue;
                }

                throw;
            }

            if (!hasNext)
                yield break;

            yield return enumerator.Current;
        }
    }


    public virtual async Task<List<T>> ToListAsync(CancellationToken cancellationToken = default)
    {
        if (_entityModel.EntityType == typeof(Messaging.DlqEnvelope))
            throw new InvalidOperationException("DLQã¯ç„¡é™åˆ—æŒ™/å±¥æ­´åˆ—ã§ã‚ã‚Šã€ãƒãƒƒãƒå–å¾—ãƒ»ä»¶æ•°æŒ‡å®šå–å¾—ã¯ç¾çŠ¶æœªå¯¾å¿œã§ã™");

        if (_entityModel.GetExplicitStreamTableType() == StreamTableType.Stream)
            throw new InvalidOperationException("ToListAsync() is not supported on a Stream source. Use ForEachAsync or subscribe for event consumption.");

        var results = new List<T>();

        await foreach (var item in GetAsyncEnumeratorWrapper(cancellationToken))
        {
            results.Add(item);
        }

        return results;
    }
    /// <summary>
    /// ABSTRACT: Producer functionality - implemented in derived classes
    /// </summary>
    protected abstract Task SendEntityAsync(T entity, Dictionary<string, string>? headers, CancellationToken cancellationToken);

    /// <summary>
    /// IEntitySet<T> implementation: producer operations
    /// </summary>
    public virtual async Task AddAsync(T entity, Dictionary<string, string>? headers = null, CancellationToken cancellationToken = default)
    {
        if (entity == null)
            throw new ArgumentNullException(nameof(entity));

        await SendEntityAsync(entity, headers, cancellationToken);
    }

    public virtual Task RemoveAsync(T entity, CancellationToken cancellationToken = default)
    {
        throw new NotSupportedException($"RemoveAsync is not supported for {GetType().Name}.");
    }

    /// <summary>
    /// Retrieves messages from the underlying consumer.
    /// Separated for ease of testing.
    /// </summary>
    /// <param name="context">Active KsqlContext</param>
    /// <param name="cancellationToken">Cancellation token</param>
    /// <returns>Message stream with headers</returns>
    protected virtual IAsyncEnumerable<(T Entity, Dictionary<string, string> Headers, MessageMeta Meta)> ConsumeAsync(
        KsqlContext context,
        CancellationToken cancellationToken)
    {
        return context.GetConsumerManager().ConsumeAsync<T>(cancellationToken);
    }
    /// <summary>
    /// REDESIGNED: ForEachAsync supporting continuous Kafka consumption
    /// Design change: ToListAsync() is disallowed; now based on GetAsyncEnumerator
    /// </summary>
    public virtual Task ForEachAsync(Func<T, Task> action, TimeSpan timeout = default, CancellationToken cancellationToken = default)
    {
        if (action == null)
            throw new ArgumentNullException(nameof(action));

        return ForEachAsync((item, headers, _) => action(item), timeout, cancellationToken);
    }

    [Obsolete("Use ForEachAsync(Func<T, Dictionary<string,string>, MessageMeta, Task>)")]
    public virtual Task ForEachAsync(Func<T, Dictionary<string,string>, Task> action, TimeSpan timeout = default, CancellationToken cancellationToken = default)
        => ForEachAsync((e, h, _) => action(e, h), timeout, cancellationToken);

    public virtual async Task ForEachAsync(Func<T, Dictionary<string,string>, MessageMeta, Task> action, TimeSpan timeout = default, CancellationToken cancellationToken = default)
    {
        if (action == null)
            throw new ArgumentNullException(nameof(action));

        var context = GetContext() as KsqlContext
            ?? throw new InvalidOperationException("KsqlContext is required");

        using var linkedCts = CancellationTokenSource.CreateLinkedTokenSource(cancellationToken);

        if (timeout != default && timeout != TimeSpan.Zero)
        {
            linkedCts.CancelAfter(timeout);
        }
        await foreach (var (entity, headers, meta) in ConsumeAsync(context, linkedCts.Token))
        {
            if (headers.TryGetValue("is_dummy", out var dummyHeader) && bool.TryParse(dummyHeader, out var isDummy) && isDummy)
            {
                continue;
            }
### assistant â€” 2025-08-11T09:35:40.247548+00:00

# Show more lines around Real ForEachAsync definition
for i,l in enumerate(lines):
    if 'ForEachAsync' in l:
        print(i,l)
