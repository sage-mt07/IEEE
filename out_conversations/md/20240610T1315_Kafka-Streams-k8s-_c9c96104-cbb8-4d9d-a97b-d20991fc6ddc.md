---
conversation_id: "c9c96104-cbb8-4d9d-a97b-d20991fc6ddc"
title: "Kafka Streams k8s デプロイ"
create_time: 1718025350.223259
update_time: 1718025883.340373
language_guess: "en"
num_messages: 11
part_index: 1
part_count: 1
---

### system — 2024-06-10T13:15:50.223259+00:00

_(empty)_

### user — 2024-06-10T13:15:50.230343+00:00

Kafkaでtableを利用しpersistent volumeをしようするための設定

### assistant — 2024-06-10T13:16:00.284949+00:00

Kafka Streamsでテーブルを利用し、データを永続的に保存するための設定について説明します。具体的には、Kafka StreamsアプリケーションでKTableを使用し、データを永続的に保存する方法について説明します。

### 1. KafkaとKafka Streamsの設定

まず、KafkaとKafka Streamsをインストールし、設定ファイルを用意します。

#### Kafkaの設定
Kafkaの`server.properties`ファイルを編集して、データディレクトリやログディレクトリを設定します。

```properties
log.dirs=/path/to/kafka-logs
```

#### Kafka Streamsの依存関係を追加
Kafka Streamsを使用するために、MavenやGradleの依存関係をプロジェクトに追加します。

**Maven**
```xml
<dependency>
    <groupId>org.apache.kafka</groupId>
    <artifactId>kafka-streams</artifactId>
    <version>2.8.0</version>

### assistant — 2024-06-10T13:16:05.105873+00:00

_(empty)_

### user — 2024-06-10T13:17:39.768079+00:00

ｋ8ｓ前提とする

### assistant — 2024-06-10T13:18:22.443132+00:00

Kubernetes（k8s）上でKafka Streamsを利用し、永続ボリューム（Persistent Volume, PV）を設定する方法を説明します。このガイドでは、Kafkaクラスターをk8s上で動かし、Kafka Streamsアプリケーションをデプロイし、永続ボリュームを設定する手順をカバーします。

### 前提条件

1. Kubernetesクラスターがセットアップされていること。
2. `kubectl`コマンドラインツールがインストールされていること。
3. KafkaクラスターをデプロイするためのHelmがインストールされていること。

### ステップ 1: Kafka クラスターのデプロイ

Kafkaクラスターをデプロイするために、Helmチャートを使用します。

```sh
helm repo add bitnami https://charts.bitnami.com/bitnami
helm install my-kafka bitnami/kafka
```

デフォルトの設定でKafkaがデプロイされますが、永続ボリュームを設定するために`values.yaml`ファイルをカスタマイズします。

**values.yaml**
```yaml
persistence:
  enabled: true
  storageClass: "standard"
  size: 20Gi
```

カスタマイズした`values.yaml`ファイルを使用してデプロイします。

```sh
helm install my-kafka -f values.yaml bitnami/kafka
```

### ステップ 2: 永続ボリュームの設定

永続ボリュームを設定するために、以下のようなYAMLファイルを作成します。

**persistent-volume.yaml**
```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: kafka-pv
spec:
  capacity:
    storage: 20Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: standard
  hostPath:
    path: "/mnt/data/kafka"
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: kafka-pvc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 20Gi
  storageClassName: standard
```

このファイルを適用してPVとPVCを作成します。

```sh
kubectl apply -f persistent-volume.yaml
```

### ステップ 3: Kafka Streamsアプリケーションのデプロイ

Kafka StreamsアプリケーションをDockerコンテナとしてビルドし、k8s上にデプロイします。

**Dockerfile**
```Dockerfile
FROM openjdk:11-jre-slim
COPY target/my-kafka-streams-app.jar /app.jar
ENTRYPOINT ["java", "-jar", "/app.jar"]
```

Dockerイメージをビルドし、レジストリにプッシュします。

```sh
docker build -t my-kafka-streams-app .
docker tag my-kafka-streams-app my-docker-registry/my-kafka-streams-app:latest
docker push my-docker-registry/my-kafka-streams-app:latest
```

**kafka-streams-deployment.yaml**
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kafka-streams-app
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kafka-streams-app
  template:
    metadata:
      labels:
        app: kafka-streams-app
    spec:
      containers:
        - name: kafka-streams-app
          image: my-docker-registry/my-kafka-streams-app:latest
          ports:
            - containerPort: 8080
          volumeMounts:
            - mountPath: /mnt/data
              name: kafka-persistent-storage
      volumes:
        - name: kafka-persistent-storage
          persistentVolumeClaim:
            claimName: kafka-pvc
```

このYAMLファイルを適用してKafka Streamsアプリケーションをデプロイします。

```sh
kubectl apply -f kafka-streams-deployment.yaml
```

### ステップ 4: Kafka Streams アプリケーションの設定

Kafka Streamsアプリケーションの設定ファイルに、Kafkaブローカーとトピックの情報を記載します。

**application.properties**
```properties
bootstrap.servers=my-kafka:9092
application.id=my-kafka-streams-app
default.key.serde=org.apache.kafka.common.serialization.Serdes$StringSerde
default.value.serde=org.apache.kafka.common.serialization.Serdes$StringSerde
state.dir=/mnt/data/kafka-streams-state
```

### まとめ

これで、Kubernetes上にKafkaクラスターとKafka Streamsアプリケーションがデプロイされ、永続ボリュームを使用してデータを保存する設定が完了しました。Kafka Streamsアプリケーションは、指定した永続ボリュームにデータを保存し、再起動後もデータを保持します。

### user — 2024-06-10T13:21:40.959549+00:00

Pvとpvcのかくにｎコマンド

### assistant — 2024-06-10T13:21:55.465670+00:00

Persistent Volume (PV) と Persistent Volume Claim (PVC) の状態を確認するためのコマンドは以下の通りです。

### PVの確認

Persistent Volume（PV）のリストを表示するには、以下のコマンドを使用します。

```sh
kubectl get pv
```

特定のPVの詳細情報を確認するには、以下のコマンドを使用します。

```sh
kubectl describe pv <pv-name>
```

### PVCの確認

Persistent Volume Claim（PVC）のリストを表示するには、以下のコマンドを使用します。

```sh
kubectl get pvc
```

特定のPVCの詳細情報を確認するには、以下のコマンドを使用します。

```sh
kubectl describe pvc <pvc-name>
```

これらのコマンドを使用して、PVとPVCが正しく作成されているか、状態がどうなっているかを確認できます。例えば、以下のような出力が得られます。

```sh
kubectl get pv
```

```
NAME          CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM                  STORAGECLASS   REASON   AGE
kafka-pv      20Gi       RWO            Retain           Bound       default/kafka-pvc      standard                5m
```

```sh
kubectl get pvc
```

```
NAME        STATUS   VOLUME     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
kafka-pvc   Bound    kafka-pv   20Gi       RWO            standard       5m
```

```sh
kubectl describe pv kafka-pv
```

```sh
kubectl describe pvc kafka-pvc
```

これらのコマンドを使用して、永続ボリュームと永続ボリュームクレームの詳細情報を確認し、設定が正しいかどうかを確認できます。

### user — 2024-06-10T13:24:17.138128+00:00

Pvはあぷりと同じなまえくうかんにある必要があるのか

### assistant — 2024-06-10T13:24:43.093305+00:00

KubernetesでPersistent Volume（PV）は、特定の名前空間に関連付けられていないため、クラスター全体で共有されます。Persistent Volume Claim（PVC）は名前空間に関連付けられているため、PVCとPVをバインドするためには、PVCが作成された名前空間内でアプリケーションがPVCを使用する必要があります。

### 名前空間の確認と作成

まず、PVとPVCがどの名前空間に属しているか確認します。

### 名前空間の確認

現在の名前空間を確認するには以下のコマンドを使います。

```sh
kubectl config view --minify --output 'jsonpath={..namespace}'
```

すべての名前空間を表示するには以下のコマンドを使います。

```sh
kubectl get namespaces
```

### 名前空間の作成

新しい名前空間を作成するには以下のコマンドを使います。

```sh
kubectl create namespace my-namespace
```

### 名前空間の設定

PVは名前空間に属さないため、特に設定は不要です。ただし、PVCとアプリケーションは同じ名前空間に存在する必要があります。以下に、PVCとアプリケーションを特定の名前空間で設定する例を示します。

### PVCの設定

**persistent-volume.yaml**
```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: kafka-pv
spec:
  capacity:
    storage: 20Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: standard
  hostPath:
    path: "/mnt/data/kafka"
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: kafka-pvc
  namespace: my-namespace  # ここで名前空間を指定
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 20Gi
  storageClassName: standard
```

### アプリケーションの設定

**kafka-streams-deployment.yaml**
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kafka-streams-app
  namespace: my-namespace  # ここで名前空間を指定
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kafka-streams-app
  template:
    metadata:
      labels:
        app: kafka-streams-app
    spec:
      containers:
        - name: kafka-streams-app
          image: my-docker-registry/my-kafka-streams-app:latest
          ports:
            - containerPort: 8080
          volumeMounts:
            - mountPath: /mnt/data
              name: kafka-persistent-storage
      volumes:
        - name: kafka-persistent-storage
          persistentVolumeClaim:
            claimName: kafka-pvc
```

これらの設定により、PVCとアプリケーションが同じ名前空間内で正しくバインドされます。これで、PVCが指定したPVにバインドされ、アプリケーションがPVCを通じてストレージを利用できるようになります。
