---
conversation_id: "6869c179-15bc-8007-9627-0f534f0a1f0f"
title: "物理テストサポート"
create_time: 1751761273.214843
update_time: 1751888286.142466
language_guess: "en"
num_messages: 468
part_index: 4
part_count: 7
---

### tool — 2025-07-06T07:38:05.973234+00:00

All the files uploaded by the user have been fully loaded. Searching won't provide additional information.
### user — 2025-07-06T07:47:32.735000+00:00

{'content_type': 'image_asset_pointer', 'asset_pointer': 'file-service://file-1aF4ShcHUqpSW3hkssXb9V', 'size_bytes': [[REDACTED_PHONE]], 'width': 1446, 'height': 1482, 'fovea': None, 'metadata': {'dalle': None, 'gizmo': None, 'generation': None, 'container_pixel_height': None, 'container_pixel_width': None, 'emu_omit_glimpse_image': None, 'emu_patches_override': None, 'lpe_keep_patch_ijhw': None, 'sanitized': True, 'asset_pointer_link': None, 'watermarked_asset_pointer': None}}
ドキュメントのみ更新した
### assistant — 2025-07-06T07:47:33.330733+00:00

ドキュメントの更新、お疲れさまです！  
`getting-started.md` と `dummy_flag_test/viewpoints.md` の修正内容は、問題点の整理や補足が明確で良い感じですね。

このままテスト実装フェーズに進める旨、詩音さんに指示してよいと思います。

もし指示文が必要でしたら、例として以下のように送るとスムーズです：

---

詩音へ

ドキュメント更新ありがとう。  
今回追加した以下のポイントを踏まえて、dummy flagを使ったAVROメッセージ送信のテスト実装に進んでください。

- スキーマ名とフィールド名はSchema Registryに登録されている通り、大文字小文字まで完全一致が必要であること。  
- Pull QueryではGROUP BYを使えないため、必要に応じてEMIT CHANGESを付けてPush Queryとして実行すること。  
- dummyメッセージの送信・検証・除外動作の確認を含むこと。  

テスト環境は `physicalTests/docker_compose.yaml` のKafka＋ksqlDB環境を利用し、CI環境でも問題なく動作するようにしてください。  

よろしくお願いします。

---

ご希望あればこの文章の調整や他のフォーマットも作成しますので教えてくださいね。

---

[[REDACTED_PHONE]]:40:00 JST
### assistant — 2025-07-06T07:56:16.401937+00:00

エラーログとテスト結果から、以下の問題が見受けられます。

---
### 主な問題点

1. **Schema Registryのスキーマ名不一致（Name Mismatch）**  
   - エラー例: `Schema being registered is incompatible with an earlier schema for subject "orders-value"`  
   - `Order` と `OrderValue` の名前不一致でコンフリクトが発生している。  
   - 既存のスキーマと今回登録しようとしているスキーマの名前が違うためにSchema Registryが登録を拒否。

2. **KSQLのテーブル作成時にPRIMARY KEY指定がない**  
   - エラーメッセージ: `Tables require a PRIMARY KEY. Please define the PRIMARY KEY.`  
   - KSQLではテーブルを作成する際に必ずPRIMARY KEYを指定する必要がある。

3. **クエリ内のカラム（Region、Amount、Idなど）が「cannot be resolved」エラー**  
   - スキーマやテーブル定義が不完全か不一致である可能性大。  
   - `GROUP BY`、`WHERE`、`SELECT`で指定したカラム名が認識されていない。  
   - 多くのクエリで`REGION`カラムが未解決と出ている。大文字小文字の不一致やスキーマ側にカラムが存在しない可能性。

4. **Pull QueryとPush Queryの混同によるエラー**  
   - `Pull queries don't support GROUP BY clauses.`というエラーから、Pull QueryでGROUP BYを使っているが許可されていない。  
   - Push Queryとして実行するなら`EMIT CHANGES`をつける必要がある。

---
### 対応方針案

#### 1. スキーマ名不一致の修正

- コードの`AvroEntityConfiguration`やエンティティの`[AvroRecord(Name = "OrderValue")]`などの設定を確認し、既存のSchema Registryに登録されているスキーマ名（`OrderValue`）に合わせる。  
- 既にあるスキーマ名を変更すると後方互換性が壊れるため注意。

#### 2. テーブル作成時のPRIMARY KEY指定追加

- KSQLの`CREATE TABLE`文に`PRIMARY KEY`を必ず指定する。  
  例：  
  ```sql
  CREATE TABLE IF NOT EXISTS ORDERS (
    CUSTOMERID INTEGER PRIMARY KEY,
    REGION STRING,
    AMOUNT DECIMAL(38, 9),
    ...
  ) WITH (...);
  ```

- `physicalTests`内でテーブル作成を行っているスクリプトやコードのDDLを修正。

#### 3. スキーマとクエリのカラム名整合性確認

- スキーマに`REGION`や`AMOUNT`など必要なカラムが全て含まれているか確認。  
- 大文字小文字のミスマッチを避けるため、エンティティクラスのプロパティ名とAvroスキーマ名を統一する。  
- Kafkaトピックのスキーマ登録状況をSchema Registryでチェックし、問題あればスキーマ登録をクリア（削除）してやり直す。  
- KafkaとksqlDBのトピックが正しく同期されているか確認。

#### 4. Pull QueryとPush Queryの使い分け

- Pull QueryはGROUP BY非対応のため、GROUP BY使うクエリは`EMIT CHANGES`を付けてPush Queryにする。  
- テストコード内のクエリ文を見直して、Pull QueryでGROUP BYが使われていないか確認。

---
### まとめ

現状は

- スキーマ名不一致によるSchema Registry登録失敗  
- PRIMARY KEY未指定によるテーブル作成失敗  
- スキーマ不整合や大文字小文字の不一致によるカラム未認識  
- Pull Query/Pull Queryの誤用によるクエリエラー

これらが複合的に絡んでテストが多数失敗しています。

---

もし詳しいソースコードやDDL、Avroスキーマ定義の抜粋があれば、さらに具体的な修正案を提示できます。  
まずは上記4点を軸に見直しをお願いします。

---

[[REDACTED_PHONE]]:53:00 JST
### user — 2025-07-06T07:56:16.431000+00:00

C:\Users\seiji_yfc8940\final\final\physicalTests\DummyFlagMessageTests.cs(31,114): warning CS8632: '#nullable' 注釈コンテキスト内のコードでのみ、Null 許容参照型の注釈を使用する必要があります。
    C:\Users\seiji_yfc8940\final\final\physicalTests\DummyFlagMessageTests.cs(32,131): warning CS8632: '#nullable' 注釈コンテキスト内のコードでのみ、Null 許容参照型の注釈を使用する必要があります。
    C:\Users\seiji_yfc8940\final\final\physicalTests\DummyFlagMessageTests.cs(72,22): warning CS8632: '#nullable' 注釈コンテキスト内のコードでのみ、Null 許容参照型の注釈を使用する必要があります。
[xUnit.net 00:00:00.00] xUnit.net VSTest Adapter v2.4.5+1caef2f33e (64-bit .NET 8.0.17)
[xUnit.net 00:00:00.41]   Discovering: Kafka.Ksql.Linq.Tests.Integration
[KSQL-LINQ INFO] ORDER BY in KSQL is limited to Pull Queries and specific scenarios. Push Queries (streaming) do not guarantee order due to distributed processing.
[KSQL-LINQ WARNING] JOIN performance optimization: Ensure topics 'orders' and 'customers' have same partition count and key distribution.
[KSQL-LINQ INFO] ORDER BY in KSQL is limited to Pull Queries and specific scenarios. Push Queries (streaming) do not guarantee order due to distributed processing.
[KSQL-LINQ INFO] ORDER BY in KSQL is limited to Pull Queries and specific scenarios. Push Queries (streaming) do not guarantee order due to distributed processing.
[KSQL-LINQ INFO] ORDER BY in KSQL is limited to Pull Queries and specific scenarios. Push Queries (streaming) do not guarantee order due to distributed processing.
[xUnit.net 00:00:01.05]   Discovered:  Kafka.Ksql.Linq.Tests.Integration
[xUnit.net 00:00:01.05]   Starting:    Kafka.Ksql.Linq.Tests.Integration
[xUnit.net 00:00:01.11]     Kafka.Ksql.Linq.Tests.Integration.DummyFlagMessageTests.SendAsync_AddsDummyFlagHeader [FAIL]
[xUnit.net 00:00:01.11]       Assert.Equal() Failure
[xUnit.net 00:00:01.11]                 ↓ (pos 0)
[xUnit.net 00:00:01.11]       Expected: true
[xUnit.net 00:00:01.11]       Actual:   True
[xUnit.net 00:00:01.11]                 ↑ (pos 0)
[xUnit.net 00:00:01.11]       Stack Trace:
[xUnit.net 00:00:01.11]         C:\Users\seiji_yfc8940\final\final\physicalTests\DummyFlagMessageTests.cs(110,0): at Kafka.Ksql.Linq.Tests.Integration.DummyFlagMessageTests.SendAsync_AddsDummyFlagHeader()
[xUnit.net 00:00:01.11]         --- End of stack trace from previous location ---
[xUnit.net 00:00:01.12]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT CustomerId, Region, SUM(Amount) AS TotalAmo"...) [FAIL]
[xUnit.net 00:00:01.12]       SELECT CustomerId, Region, SUM(Amount) AS TotalAmount, COUNT(*) AS OrderCount, AVG(Amount) AS AverageAmount FROM orders GROUP BY CustomerId, Region HAVING (((SUM(Amount) > 1000) AND (COUNT(*) > 10)) OR (AVG(Amount) > 150)) EMIT CHANGES; failed: {"@type":"statement_error","error_code":40001,"message":"Line: 1, Col: 150: GROUP BY column 'REGION' cannot be resolved.","statementText":"EXPLAIN SELECT CustomerId, Region, SUM(Amount) AS TotalAmount, COUNT(*) AS OrderCount, AVG(Amount) AS AverageAmount FROM orders GROUP BY CustomerId, Region HAVING (((SUM(Amount) > 1000) AND (COUNT(*) > 10)) OR (AVG(Amount) > 150)) EMIT CHANGES;","entities":[]}
[xUnit.net 00:00:01.12]       Expected: True
[xUnit.net 00:00:01.12]       Actual:   False
[xUnit.net 00:00:01.12]       Stack Trace:
[xUnit.net 00:00:01.12]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql)
[xUnit.net 00:00:01.12]         --- End of stack trace from previous location ---
CREATE STREAM result: True, msg: [{"@type":"warning_entity","statementText":"CREATE STREAM IF NOT EXISTS source (id INT) WITH (KAFKA_TOPIC='source', VALUE_FORMAT='AVRO', PARTITIONS=1);","message":"Cannot add stream `SOURCE`: A stream with the same name already exists.","warnings":[]}]
DDL result: False, msg: {"@type":"statement_error","error_code":40001,"message":"Tables require a PRIMARY KEY. Please define the PRIMARY KEY.","statementText":"CREATE TABLE IF NOT EXISTS ORDERS (CUSTOMERID INTEGER, ID INTEGER, REGION STRING, AMOUNT DECIMAL(38, 9), ISHIGHPRIORITY BOOLEAN, COUNT INTEGER) WITH (CLEANUP_POLICY='compact', KAFKA_TOPIC='orders', KEY_FORMAT='KAFKA', PARTITIONS=1, VALUE_FORMAT='AVRO');","entities":[]}
DDL result: False, msg: {"@type":"statement_error","error_code":40001,"message":"Tables require a PRIMARY KEY. Please define the PRIMARY KEY.","statementText":"CREATE TABLE IF NOT EXISTS CUSTOMERS (ID INTEGER, NAME STRING) WITH (CLEANUP_POLICY='compact', KAFKA_TOPIC='customers', KEY_FORMAT='KAFKA', PARTITIONS=1, VALUE_FORMAT='AVRO');","entities":[]}
DDL result: False, msg: {"@type":"statement_error","error_code":40001,"message":"Tables require a PRIMARY KEY. Please define the PRIMARY KEY.","statementText":"CREATE TABLE IF NOT EXISTS EVENTS (LEVEL INTEGER, MESSAGE STRING) WITH (CLEANUP_POLICY='compact', KAFKA_TOPIC='events', KEY_FORMAT='KAFKA', PARTITIONS=1, VALUE_FORMAT='AVRO');","entities":[]}
DDL result: False, msg: {"@type":"statement_error","error_code":40001,"message":"Tables require a PRIMARY KEY. Please define the PRIMARY KEY.","statementText":"CREATE TABLE IF NOT EXISTS ORDERS_NULLABLE (CUSTOMERID INTEGER, REGION STRING, AMOUNT DECIMAL(38, 9)) WITH (CLEANUP_POLICY='compact', KAFKA_TOPIC='orders_nullable', KEY_FORMAT='KAFKA', PARTITIONS=1, VALUE_FORMAT='AVRO');","entities":[]}
[xUnit.net 00:00:01.23]     Kafka.Ksql.Linq.Tests.Integration.SchemaNameCaseSensitivityTests.MismatchedFieldCase_ShouldThrowException [FAIL]
[xUnit.net 00:00:01.23]       System.InvalidOperationException : FATAL: KsqlContext initialization failed. Application cannot continue without Kafka connectivity.
[xUnit.net 00:00:01.23]       ---- Kafka.Ksql.Linq.Serialization.Avro.Exceptions.AvroSchemaRegistrationException : Failed to register schema for OrderCorrectCase
[xUnit.net 00:00:01.23]       -------- Confluent.SchemaRegistry.SchemaRegistryException : Schema being registered is incompatible with an earlier schema for subject "orders-value", details: [{errorType:'NAME_MISMATCH', description:'The name of the schema has changed (path '/name')', additionalInfo:'expected: OrderValue'}, {oldSchemaVersion: 1}, {oldSchema: '{"type":"record","name":"OrderValue","fields":[{"name":"CustomerId","type":"int"},{"name":"dummy","type":"string"}]}'}, {compatibility: 'BACKWARD'}]; error code: 409
[xUnit.net 00:00:01.23]       Stack Trace:
[xUnit.net 00:00:01.23]         C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs(84,0): at Kafka.Ksql.Linq.Application.KsqlContext..ctor()
[xUnit.net 00:00:01.23]            at Kafka.Ksql.Linq.Tests.Integration.SchemaNameCaseSensitivityTests.OrderContext..ctor()
[xUnit.net 00:00:01.23]            at System.RuntimeMethodHandle.InvokeMethod(Object target, Void** arguments, Signature sig, Boolean isConstructor)
[xUnit.net 00:00:01.23]            at System.Reflection.MethodBaseInvoker.InvokeWithNoArgs(Object obj, BindingFlags invokeAttr)
[xUnit.net 00:00:01.23]         ----- Inner Stack Trace -----
[xUnit.net 00:00:01.23]         C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs(203,0): at Kafka.Ksql.Linq.Application.KsqlContext.RegisterSchemasSync(IReadOnlyDictionary`2 configurations)
[xUnit.net 00:00:01.23]         C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs(151,0): at Kafka.Ksql.Linq.Application.KsqlContext.InitializeWithSchemaRegistration()
[xUnit.net 00:00:01.23]         C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs(59,0): at Kafka.Ksql.Linq.Application.KsqlContext..ctor()
[xUnit.net 00:00:01.23]         ----- Inner Stack Trace -----
[xUnit.net 00:00:01.23]            at Confluent.SchemaRegistry.RestService.ExecuteOnOneInstanceAsync(Func`1 createRequest)
[xUnit.net 00:00:01.23]            at Confluent.SchemaRegistry.RestService.RequestAsync[T](String endPoint, HttpMethod method, Object[] jsonBody)
[xUnit.net 00:00:01.23]            at Confluent.SchemaRegistry.RestService.RegisterSchemaAsync(String subject, Schema schema, Boolean normalize)
[xUnit.net 00:00:01.23]            at Confluent.SchemaRegistry.CachedSchemaRegistryClient.RegisterSchemaAsync(String subject, Schema schema, Boolean normalize)
[xUnit.net 00:00:01.23]         C:\Users\seiji_yfc8940\final\final\src\Serialization\Avro\Management\AvroSchemaRegistrationService.cs(100,0): at Kafka.Ksql.Linq.Serialization.Avro.Management.AvroSchemaRegistrationService.RegisterSchemaAsync(String subject, String avroSchema)
[xUnit.net 00:00:01.23]         C:\Users\seiji_yfc8940\final\final\src\Serialization\Avro\Management\AvroSchemaRegistrationService.cs(69,0): at Kafka.Ksql.Linq.Serialization.Avro.Management.AvroSchemaRegistrationService.RegisterEntitySchemaAsync(Type entityType, AvroEntityConfiguration config)
[xUnit.net 00:00:01.23]     Kafka.Ksql.Linq.Tests.Integration.DummyFlagSchemaRecognitionTests.Consumer_SkipsDummyMessages [FAIL]
[xUnit.net 00:00:01.23]       System.InvalidOperationException : FATAL: KsqlContext initialization failed. Application cannot continue without Kafka connectivity.
[xUnit.net 00:00:01.23]       ---- Kafka.Ksql.Linq.Serialization.Avro.Exceptions.AvroSchemaRegistrationException : Failed to register schema for Order
[xUnit.net 00:00:01.23]       -------- Confluent.SchemaRegistry.SchemaRegistryException : Schema being registered is incompatible with an earlier schema for subject "orders-value", details: [{errorType:'NAME_MISMATCH', description:'The name of the schema has changed (path '/name')', additionalInfo:'expected: OrderValue'}, {oldSchemaVersion: 1}, {oldSchema: '{"type":"record","name":"OrderValue","fields":[{"name":"CustomerId","type":"int"},{"name":"dummy","type":"string"}]}'}, {compatibility: 'BACKWARD'}]; error code: 409
[xUnit.net 00:00:01.23]       Stack Trace:
[xUnit.net 00:00:01.23]         C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs(84,0): at Kafka.Ksql.Linq.Application.KsqlContext..ctor()
[xUnit.net 00:00:01.23]            at Kafka.Ksql.Linq.Tests.Integration.DummyFlagSchemaRecognitionTests.DummyContext..ctor()
[xUnit.net 00:00:01.23]            at System.RuntimeMethodHandle.InvokeMethod(Object target, Void** arguments, Signature sig, Boolean isConstructor)
[xUnit.net 00:00:01.23]            at System.Reflection.MethodBaseInvoker.InvokeWithNoArgs(Object obj, BindingFlags invokeAttr)
[xUnit.net 00:00:01.23]         ----- Inner Stack Trace -----
[xUnit.net 00:00:01.23]         C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs(203,0): at Kafka.Ksql.Linq.Application.KsqlContext.RegisterSchemasSync(IReadOnlyDictionary`2 configurations)
[xUnit.net 00:00:01.23]         C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs(151,0): at Kafka.Ksql.Linq.Application.KsqlContext.InitializeWithSchemaRegistration()
[xUnit.net 00:00:01.23]         C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs(59,0): at Kafka.Ksql.Linq.Application.KsqlContext..ctor()
[xUnit.net 00:00:01.23]         ----- Inner Stack Trace -----
[xUnit.net 00:00:01.23]            at Confluent.SchemaRegistry.RestService.ExecuteOnOneInstanceAsync(Func`1 createRequest)
[xUnit.net 00:00:01.23]            at Confluent.SchemaRegistry.RestService.RequestAsync[T](String endPoint, HttpMethod method, Object[] jsonBody)
[xUnit.net 00:00:01.23]            at Confluent.SchemaRegistry.RestService.RegisterSchemaAsync(String subject, Schema schema, Boolean normalize)
[xUnit.net 00:00:01.23]            at Confluent.SchemaRegistry.CachedSchemaRegistryClient.RegisterSchemaAsync(String subject, Schema schema, Boolean normalize)
[xUnit.net 00:00:01.23]         C:\Users\seiji_yfc8940\final\final\src\Serialization\Avro\Management\AvroSchemaRegistrationService.cs(100,0): at Kafka.Ksql.Linq.Serialization.Avro.Management.AvroSchemaRegistrationService.RegisterSchemaAsync(String subject, String avroSchema)
[xUnit.net 00:00:01.23]         C:\Users\seiji_yfc8940\final\final\src\Serialization\Avro\Management\AvroSchemaRegistrationService.cs(69,0): at Kafka.Ksql.Linq.Serialization.Avro.Management.AvroSchemaRegistrationService.RegisterEntitySchemaAsync(Type entityType, AvroEntityConfiguration config)
DDL result: False, msg: {"@type":"statement_error","error_code":40001,"message":"Tables require a PRIMARY KEY. Please define the PRIMARY KEY.","statementText":"CREATE TABLE IF NOT EXISTS ORDERS_NULLABLE_KEY (CUSTOMERID INTEGER, AMOUNT DECIMAL(38, 9)) WITH (CLEANUP_POLICY='compact', KAFKA_TOPIC='orders_nullable_key', KEY_FORMAT='KAFKA', PARTITIONS=1, VALUE_FORMAT='AVRO');","entities":[]}
CREATE STREAM result: True, msg: [{"@type":"warning_entity","statementText":"CREATE STREAM IF NOT EXISTS source (id INT) WITH (KAFKA_TOPIC='source', VALUE_FORMAT='AVRO', PARTITIONS=1);","message":"Cannot add stream `SOURCE`: A stream with the same name already exists.","warnings":[]}]
[xUnit.net 00:00:01.45]     Kafka.Ksql.Linq.Tests.Integration.DummyFlagSchemaRecognitionTests.DummyMessages_EnableQueries [FAIL]
[xUnit.net 00:00:01.45]       System.InvalidOperationException : FATAL: KsqlContext initialization failed. Application cannot continue without Kafka connectivity.
[xUnit.net 00:00:01.45]       ---- Kafka.Ksql.Linq.Serialization.Avro.Exceptions.AvroSchemaRegistrationException : Failed to register schema for Order
[xUnit.net 00:00:01.45]       -------- Confluent.SchemaRegistry.SchemaRegistryException : Schema being registered is incompatible with an earlier schema for subject "orders-value", details: [{errorType:'NAME_MISMATCH', description:'The name of the schema has changed (path '/name')', additionalInfo:'expected: OrderValue'}, {oldSchemaVersion: 1}, {oldSchema: '{"type":"record","name":"OrderValue","fields":[{"name":"CustomerId","type":"int"},{"name":"dummy","type":"string"}]}'}, {compatibility: 'BACKWARD'}]; error code: 409
[xUnit.net 00:00:01.45]       Stack Trace:
[xUnit.net 00:00:01.45]         C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs(84,0): at Kafka.Ksql.Linq.Application.KsqlContext..ctor()
[xUnit.net 00:00:01.45]            at Kafka.Ksql.Linq.Tests.Integration.DummyFlagSchemaRecognitionTests.DummyContext..ctor()
[xUnit.net 00:00:01.45]            at InvokeStub_DummyContext..ctor(Object, Object, IntPtr*)
[xUnit.net 00:00:01.45]            at System.Reflection.MethodBaseInvoker.InvokeWithNoArgs(Object obj, BindingFlags invokeAttr)
[xUnit.net 00:00:01.45]         ----- Inner Stack Trace -----
[xUnit.net 00:00:01.45]         C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs(203,0): at Kafka.Ksql.Linq.Application.KsqlContext.RegisterSchemasSync(IReadOnlyDictionary`2 configurations)
[xUnit.net 00:00:01.45]         C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs(151,0): at Kafka.Ksql.Linq.Application.KsqlContext.InitializeWithSchemaRegistration()
[xUnit.net 00:00:01.45]         C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs(59,0): at Kafka.Ksql.Linq.Application.KsqlContext..ctor()
[xUnit.net 00:00:01.45]         ----- Inner Stack Trace -----
[xUnit.net 00:00:01.45]            at Confluent.SchemaRegistry.RestService.ExecuteOnOneInstanceAsync(Func`1 createRequest)
[xUnit.net 00:00:01.45]            at Confluent.SchemaRegistry.RestService.RequestAsync[T](String endPoint, HttpMethod method, Object[] jsonBody)
[xUnit.net 00:00:01.45]            at Confluent.SchemaRegistry.RestService.RegisterSchemaAsync(String subject, Schema schema, Boolean normalize)
[xUnit.net 00:00:01.45]            at Confluent.SchemaRegistry.CachedSchemaRegistryClient.RegisterSchemaAsync(String subject, Schema schema, Boolean normalize)
[xUnit.net 00:00:01.45]         C:\Users\seiji_yfc8940\final\final\src\Serialization\Avro\Management\AvroSchemaRegistrationService.cs(100,0): at Kafka.Ksql.Linq.Serialization.Avro.Management.AvroSchemaRegistrationService.RegisterSchemaAsync(String subject, String avroSchema)
[xUnit.net 00:00:01.45]         C:\Users\seiji_yfc8940\final\final\src\Serialization\Avro\Management\AvroSchemaRegistrationService.cs(69,0): at Kafka.Ksql.Linq.Serialization.Avro.Management.AvroSchemaRegistrationService.RegisterEntitySchemaAsync(Type entityType, AvroEntityConfiguration config)
DDL result: False, msg: {"@type":"statement_error","error_code":40001,"message":"Tables require a PRIMARY KEY. Please define the PRIMARY KEY.","statementText":"CREATE TABLE IF NOT EXISTS ORDERS (CUSTOMERID INTEGER, ID INTEGER, REGION STRING, AMOUNT DECIMAL(38, 9), ISHIGHPRIORITY BOOLEAN, COUNT INTEGER) WITH (CLEANUP_POLICY='compact', KAFKA_TOPIC='orders', KEY_FORMAT='KAFKA', PARTITIONS=1, VALUE_FORMAT='AVRO');","entities":[]}
DDL result: False, msg: {"@type":"statement_error","error_code":40001,"message":"Tables require a PRIMARY KEY. Please define the PRIMARY KEY.","statementText":"CREATE TABLE IF NOT EXISTS CUSTOMERS (ID INTEGER, NAME STRING) WITH (CLEANUP_POLICY='compact', KAFKA_TOPIC='customers', KEY_FORMAT='KAFKA', PARTITIONS=1, VALUE_FORMAT='AVRO');","entities":[]}
DDL result: False, msg: {"@type":"statement_error","error_code":40001,"message":"Tables require a PRIMARY KEY. Please define the PRIMARY KEY.","statementText":"CREATE TABLE IF NOT EXISTS EVENTS (LEVEL INTEGER, MESSAGE STRING) WITH (CLEANUP_POLICY='compact', KAFKA_TOPIC='events', KEY_FORMAT='KAFKA', PARTITIONS=1, VALUE_FORMAT='AVRO');","entities":[]}
DDL result: False, msg: {"@type":"statement_error","error_code":40001,"message":"Tables require a PRIMARY KEY. Please define the PRIMARY KEY.","statementText":"CREATE TABLE IF NOT EXISTS ORDERS_NULLABLE (CUSTOMERID INTEGER, REGION STRING, AMOUNT DECIMAL(38, 9)) WITH (CLEANUP_POLICY='compact', KAFKA_TOPIC='orders_nullable', KEY_FORMAT='KAFKA', PARTITIONS=1, VALUE_FORMAT='AVRO');","entities":[]}
DDL result: False, msg: {"@type":"statement_error","error_code":40001,"message":"Tables require a PRIMARY KEY. Please define the PRIMARY KEY.","statementText":"CREATE TABLE IF NOT EXISTS ORDERS_NULLABLE_KEY (CUSTOMERID INTEGER, AMOUNT DECIMAL(38, 9)) WITH (CLEANUP_POLICY='compact', KAFKA_TOPIC='orders_nullable_key', KEY_FORMAT='KAFKA', PARTITIONS=1, VALUE_FORMAT='AVRO');","entities":[]}
[xUnit.net 00:00:01.61]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT CustomerId, Region, SUM(Amount) AS Total FR"...) [FAIL]
[xUnit.net 00:00:01.61]       SELECT CustomerId, Region, SUM(Amount) AS Total FROM orders GROUP BY CustomerId, Region HAVING (SUM(Amount) > 500) EMIT CHANGES; failed: {"@type":"statement_error","error_code":40001,"message":"Line: 1, Col: 90: GROUP BY column 'REGION' cannot be resolved.","statementText":"EXPLAIN SELECT CustomerId, Region, SUM(Amount) AS Total FROM orders GROUP BY CustomerId, Region HAVING (SUM(Amount) > 500) EMIT CHANGES;","entities":[]}
[xUnit.net 00:00:01.61]       Expected: True
[xUnit.net 00:00:01.61]       Actual:   False
[xUnit.net 00:00:01.61]       Stack Trace:
[xUnit.net 00:00:01.61]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql)
[xUnit.net 00:00:01.61]         --- End of stack trace from previous location ---
[xUnit.net 00:00:01.62]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT CustomerId, SUM(Amount) AS Total, COUNT(*) "...) [FAIL]
[xUnit.net 00:00:01.62]       SELECT CustomerId, SUM(Amount) AS Total, COUNT(*) AS Count, AVG(Amount) AS Avg FROM orders GROUP BY CustomerId HAVING (((SUM(Amount) > 1000) AND (COUNT(*) > 5)) OR (AVG(Amount) > 500)) EMIT CHANGES; failed: {"@type":"statement_error","error_code":40001,"message":"Line: 1, Col: 134: HAVING column 'AMOUNT' cannot be resolved.","statementText":"EXPLAIN SELECT CustomerId, SUM(Amount) AS Total, COUNT(*) AS Count, AVG(Amount) AS Avg FROM orders GROUP BY CustomerId HAVING (((SUM(Amount) > 1000) AND (COUNT(*) > 5)) OR (AVG(Amount) > 500)) EMIT CHANGES;","entities":[]}
[xUnit.net 00:00:01.62]       Expected: True
[xUnit.net 00:00:01.62]       Actual:   False
[xUnit.net 00:00:01.62]       Stack Trace:
[xUnit.net 00:00:01.62]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql)
[xUnit.net 00:00:01.62]         --- End of stack trace from previous location ---
[xUnit.net 00:00:01.63]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT COUNT(*) FROM orders;") [FAIL]
[xUnit.net 00:00:01.63]       SELECT COUNT(*) FROM orders; failed: {"@type":"statement_error","error_code":40001,"message":"Pull queries don't support GROUP BY clauses. See https://cnfl.io/queries for more info.\nAdd EMIT CHANGES if you intended to issue a push query.","statementText":"EXPLAIN SELECT COUNT(*) FROM orders;","entities":[]}
[xUnit.net 00:00:01.63]       Expected: True
[xUnit.net 00:00:01.63]       Actual:   False
[xUnit.net 00:00:01.63]       Stack Trace:
[xUnit.net 00:00:01.63]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql)
[xUnit.net 00:00:01.63]         --- End of stack trace from previous location ---
[xUnit.net 00:00:01.63]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT CustomerId, Region, Amount FROM orders WHER"...) [FAIL]
[xUnit.net 00:00:01.63]       SELECT CustomerId, Region, Amount FROM orders WHERE Region NOT IN ('CN', 'RU') EMIT CHANGES; failed: {"@type":"statement_error","error_code":40001,"message":"Line: 1, Col: 61: WHERE column 'REGION' cannot be resolved.","statementText":"EXPLAIN SELECT CustomerId, Region, Amount FROM orders WHERE Region NOT IN ('CN', 'RU') EMIT CHANGES;","entities":[]}
[xUnit.net 00:00:01.63]       Expected: True
[xUnit.net 00:00:01.63]       Actual:   False
[xUnit.net 00:00:01.63]       Stack Trace:
[xUnit.net 00:00:01.63]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql)
[xUnit.net 00:00:01.63]         --- End of stack trace from previous location ---
[xUnit.net 00:00:01.65]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT CustomerId, SUM(Amount) AS Total, CASE WHEN"...) [FAIL]
[xUnit.net 00:00:01.65]       SELECT CustomerId, SUM(Amount) AS Total, CASE WHEN (SUM(Amount) > 1000) THEN 'VIP' ELSE 'Regular' END AS Status FROM orders GROUP BY CustomerId EMIT CHANGES; failed: {"@type":"statement_error","error_code":40001,"message":"Line: 1, Col: 32: SELECT column 'AMOUNT' cannot be resolved.","statementText":"EXPLAIN SELECT CustomerId, SUM(Amount) AS Total, CASE WHEN (SUM(Amount) > 1000) THEN 'VIP' ELSE 'Regular' END AS Status FROM orders GROUP BY CustomerId EMIT CHANGES;","entities":[]}
[xUnit.net 00:00:01.65]       Expected: True
[xUnit.net 00:00:01.65]       Actual:   False
[xUnit.net 00:00:01.65]       Stack Trace:
[xUnit.net 00:00:01.65]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql)
[xUnit.net 00:00:01.65]         --- End of stack trace from previous location ---
[xUnit.net 00:00:01.66]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT LATEST_BY_OFFSET(Id) AS Last FROM orders;") [FAIL]
[xUnit.net 00:00:01.66]       SELECT LATEST_BY_OFFSET(Id) AS Last FROM orders; failed: {"@type":"statement_error","error_code":40001,"message":"Line: 1, Col: 33: SELECT column 'ID' cannot be resolved.","statementText":"EXPLAIN SELECT LATEST_BY_OFFSET(Id) AS Last FROM orders;","entities":[]}
[xUnit.net 00:00:01.66]       Expected: True
[xUnit.net 00:00:01.66]       Actual:   False
[xUnit.net 00:00:01.66]       Stack Trace:
[xUnit.net 00:00:01.66]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql)
[xUnit.net 00:00:01.66]         --- End of stack trace from previous location ---
[xUnit.net 00:00:01.66]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT CustomerId, SUM(Amount) AS TotalAmount, SUM"...) [FAIL]
[xUnit.net 00:00:01.66]       SELECT CustomerId, SUM(Amount) AS TotalAmount, SUM(Count) AS TotalCount FROM orders GROUP BY CustomerId HAVING ((SUM(Amount) > 1000) OR (SUM(Count) > 5)) EMIT CHANGES; failed: {"@type":"statement_error","error_code":40001,"message":"Line: 1, Col: 126: HAVING column 'AMOUNT' cannot be resolved.","statementText":"EXPLAIN SELECT CustomerId, SUM(Amount) AS TotalAmount, SUM(Count) AS TotalCount FROM orders GROUP BY CustomerId HAVING ((SUM(Amount) > 1000) OR (SUM(Count) > 5)) EMIT CHANGES;","entities":[]}
[xUnit.net 00:00:01.66]       Expected: True
[xUnit.net 00:00:01.66]       Actual:   False
[xUnit.net 00:00:01.66]       Stack Trace:
[xUnit.net 00:00:01.66]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql)
[xUnit.net 00:00:01.66]         --- End of stack trace from previous location ---
[xUnit.net 00:00:01.77]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT UPPER(Region), SUM(Amount) AS TotalAmount F"...) [FAIL]
[xUnit.net 00:00:01.77]       SELECT UPPER(Region), SUM(Amount) AS TotalAmount FROM orders GROUP BY UPPER(Region) HAVING (SUM(Amount) > 500) EMIT CHANGES; failed: {"@type":"statement_error","error_code":40001,"message":"Line: 1, Col: 85: GROUP BY column 'REGION' cannot be resolved.","statementText":"EXPLAIN SELECT UPPER(Region), SUM(Amount) AS TotalAmount FROM orders GROUP BY UPPER(Region) HAVING (SUM(Amount) > 500) EMIT CHANGES;","entities":[]}
[xUnit.net 00:00:01.77]       Expected: True
[xUnit.net 00:00:01.77]       Actual:   False
[xUnit.net 00:00:01.77]       Stack Trace:
[xUnit.net 00:00:01.77]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql)
[xUnit.net 00:00:01.77]         --- End of stack trace from previous location ---
[xUnit.net 00:00:01.87]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT CustomerId, Region, SUM(Amount) AS Total FR"...) [FAIL]
[xUnit.net 00:00:01.87]       SELECT CustomerId, Region, SUM(Amount) AS Total FROM orders GROUP BY CustomerId, Region ORDER BY Total DESC EMIT CHANGES; failed: {"@type":"statement_error","error_code":40001,"message":"line 1:97: Syntax Error\n","statementText":"EXPLAIN SELECT CustomerId, Region, SUM(Amount) AS Total FROM orders GROUP BY CustomerId, Region ORDER BY Total DESC EMIT CHANGES;","entities":[]}
[xUnit.net 00:00:01.87]       Expected: True
[xUnit.net 00:00:01.87]       Actual:   False
[xUnit.net 00:00:01.87]       Stack Trace:
[xUnit.net 00:00:01.87]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql)
[xUnit.net 00:00:01.87]         --- End of stack trace from previous location ---
[xUnit.net 00:00:01.96]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT CustomerId, AVG(Amount) AS AverageAmount, M"...) [FAIL]
[xUnit.net 00:00:01.96]       SELECT CustomerId, AVG(Amount) AS AverageAmount, MIN(Amount) AS MinAmount, MAX(Amount) AS MaxAmount FROM orders GROUP BY CustomerId EMIT CHANGES; failed: {"@type":"statement_error","error_code":40001,"message":"Line: 1, Col: 32: SELECT column 'AMOUNT' cannot be resolved.","statementText":"EXPLAIN SELECT CustomerId, AVG(Amount) AS AverageAmount, MIN(Amount) AS MinAmount, MAX(Amount) AS MaxAmount FROM orders GROUP BY CustomerId EMIT CHANGES;","entities":[]}
[xUnit.net 00:00:01.96]       Expected: True
[xUnit.net 00:00:01.96]       Actual:   False
[xUnit.net 00:00:01.96]       Stack Trace:
[xUnit.net 00:00:01.96]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql)
[xUnit.net 00:00:01.96]         --- End of stack trace from previous location ---
[xUnit.net 00:00:01.97]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT CustomerId, SUM(Amount) AS Total FROM order"...) [FAIL]
[xUnit.net 00:00:01.97]       SELECT CustomerId, SUM(Amount) AS Total FROM orders GROUP BY CustomerId ORDER BY Total DESC EMIT CHANGES; failed: {"@type":"statement_error","error_code":40001,"message":"line 1:81: Syntax Error\n","statementText":"EXPLAIN SELECT CustomerId, SUM(Amount) AS Total FROM orders GROUP BY CustomerId ORDER BY Total DESC EMIT CHANGES;","entities":[]}
[xUnit.net 00:00:01.97]       Expected: True
[xUnit.net 00:00:01.97]       Actual:   False
[xUnit.net 00:00:01.97]       Stack Trace:
[xUnit.net 00:00:01.97]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql)
[xUnit.net 00:00:01.97]         --- End of stack trace from previous location ---
[xUnit.net 00:00:01.97]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT CustomerId, SUM(Amount) AS Total FROM Order"...) [FAIL]
[xUnit.net 00:00:01.97]       Assert.Contains() Failure
[xUnit.net 00:00:01.97]       Not found: Order
[xUnit.net 00:00:01.97]       In value:  List<String> ["orders", "customers", "events", "orders_nullable", "orders_nullable_key"]
[xUnit.net 00:00:01.97]       Stack Trace:
[xUnit.net 00:00:01.97]         C:\Users\seiji_yfc8940\final\final\physicalTests\TestSchema.cs(63,0): at Kafka.Ksql.Linq.Tests.Integration.TestSchema.ValidateDmlQuery(String query)
[xUnit.net 00:00:01.97]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(282,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql)
[xUnit.net 00:00:01.97]         --- End of stack trace from previous location ---
[xUnit.net 00:00:02.07]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT SUM(Amount) AS Sum FROM orders;") [FAIL]
[xUnit.net 00:00:02.07]       SELECT SUM(Amount) AS Sum FROM orders; failed: {"@type":"statement_error","error_code":40001,"message":"Line: 1, Col: 20: SELECT column 'AMOUNT' cannot be resolved.","statementText":"EXPLAIN SELECT SUM(Amount) AS Sum FROM orders;","entities":[]}
[xUnit.net 00:00:02.07]       Expected: True
[xUnit.net 00:00:02.07]       Actual:   False
[xUnit.net 00:00:02.07]       Stack Trace:
[xUnit.net 00:00:02.07]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql)
[xUnit.net 00:00:02.07]         --- End of stack trace from previous location ---
[xUnit.net 00:00:02.07]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT COUNT(*) FROM customers;") [FAIL]
[xUnit.net 00:00:02.07]       SELECT COUNT(*) FROM customers; failed: {"@type":"statement_error","error_code":40001,"message":"Pull queries don't support GROUP BY clauses. See https://cnfl.io/queries for more info.\nAdd EMIT CHANGES if you intended to issue a push query.","statementText":"EXPLAIN SELECT COUNT(*) FROM customers;","entities":[]}
[xUnit.net 00:00:02.07]       Expected: True
[xUnit.net 00:00:02.07]       Actual:   False
[xUnit.net 00:00:02.07]       Stack Trace:
[xUnit.net 00:00:02.07]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql)
[xUnit.net 00:00:02.07]         --- End of stack trace from previous location ---
[xUnit.net 00:00:02.27]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT COUNT(*) FROM orders_nullable_key;") [FAIL]
[xUnit.net 00:00:02.27]       SELECT COUNT(*) FROM orders_nullable_key; failed: {"@type":"statement_error","error_code":40001,"message":"Pull queries don't support GROUP BY clauses. See https://cnfl.io/queries for more info.\nAdd EMIT CHANGES if you intended to issue a push query.","statementText":"EXPLAIN SELECT COUNT(*) FROM orders_nullable_key;","entities":[]}
[xUnit.net 00:00:02.27]       Expected: True
[xUnit.net 00:00:02.27]       Actual:   False
[xUnit.net 00:00:02.27]       Stack Trace:
[xUnit.net 00:00:02.27]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql)
[xUnit.net 00:00:02.27]         --- End of stack trace from previous location ---
[xUnit.net 00:00:02.28]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT EARLIEST_BY_OFFSET(Id) AS First FROM orders"...) [FAIL]
[xUnit.net 00:00:02.28]       SELECT EARLIEST_BY_OFFSET(Id) AS First FROM orders; failed: {"@type":"statement_error","error_code":40001,"message":"Line: 1, Col: 35: SELECT column 'ID' cannot be resolved.","statementText":"EXPLAIN SELECT EARLIEST_BY_OFFSET(Id) AS First FROM orders;","entities":[]}
[xUnit.net 00:00:02.28]       Expected: True
[xUnit.net 00:00:02.28]       Actual:   False
[xUnit.net 00:00:02.28]       Stack Trace:
[xUnit.net 00:00:02.28]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql)
[xUnit.net 00:00:02.28]         --- End of stack trace from previous location ---
[xUnit.net 00:00:02.38]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT CustomerId, SUM(Amount) AS Total, SUM(CASE "...) [FAIL]
[xUnit.net 00:00:02.38]       SELECT CustomerId, SUM(Amount) AS Total, SUM(CASE WHEN IsHighPriority THEN Amount ELSE 0 END) AS HighPriorityTotal FROM orders GROUP BY CustomerId EMIT CHANGES; failed: {"@type":"statement_error","error_code":40001,"message":"Line: 1, Col: 32: SELECT column 'AMOUNT' cannot be resolved.","statementText":"EXPLAIN SELECT CustomerId, SUM(Amount) AS Total, SUM(CASE WHEN IsHighPriority THEN Amount ELSE 0 END) AS HighPriorityTotal FROM orders GROUP BY CustomerId EMIT CHANGES;","entities":[]}
[xUnit.net 00:00:02.38]       Expected: True
[xUnit.net 00:00:02.38]       Actual:   False
[xUnit.net 00:00:02.38]       Stack Trace:
[xUnit.net 00:00:02.38]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql)
[xUnit.net 00:00:02.38]         --- End of stack trace from previous location ---
[xUnit.net 00:00:02.39]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT COUNT(*) FROM orders_nullable;") [FAIL]
[xUnit.net 00:00:02.39]       SELECT COUNT(*) FROM orders_nullable; failed: {"@type":"statement_error","error_code":40001,"message":"Pull queries don't support GROUP BY clauses. See https://cnfl.io/queries for more info.\nAdd EMIT CHANGES if you intended to issue a push query.","statementText":"EXPLAIN SELECT COUNT(*) FROM orders_nullable;","entities":[]}
[xUnit.net 00:00:02.39]       Expected: True
[xUnit.net 00:00:02.39]       Actual:   False
[xUnit.net 00:00:02.39]       Stack Trace:
[xUnit.net 00:00:02.39]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql)
[xUnit.net 00:00:02.39]         --- End of stack trace from previous location ---
[xUnit.net 00:00:02.50]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT CustomerId, COUNT(*) AS Count FROM orders W"...) [FAIL]
[xUnit.net 00:00:02.50]       SELECT CustomerId, COUNT(*) AS Count FROM orders WHERE (Amount > 100) WINDOW TUMBLING (SIZE 5 MINUTES) GROUP BY CustomerId HAVING (COUNT(*) > 1) ORDER BY Key ASC EMIT CHANGES; failed: {"@type":"statement_error","error_code":40001,"message":"line 1:79: Syntax Error\n","statementText":"EXPLAIN SELECT CustomerId, COUNT(*) AS Count FROM orders WHERE (Amount > 100) WINDOW TUMBLING (SIZE 5 MINUTES) GROUP BY CustomerId HAVING (COUNT(*) > 1) ORDER BY Key ASC EMIT CHANGES;","entities":[]}
[xUnit.net 00:00:02.50]       Expected: True
[xUnit.net 00:00:02.50]       Actual:   False
[xUnit.net 00:00:02.50]       Stack Trace:
[xUnit.net 00:00:02.50]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql)
[xUnit.net 00:00:02.50]         --- End of stack trace from previous location ---
[xUnit.net 00:00:02.72]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.CreateAllObjectsByOnModelCreating [FAIL]
[xUnit.net 00:00:02.72]       DDL failed: {"@type":"statement_error","error_code":40001,"message":"Could not determine output schema for query due to error: Line: 1, Col: 89: WHERE column 'AMOUNT' cannot be resolved.","statementText":"CREATE TABLE ORDERS_BY_REGION WITH (CLEANUP_POLICY='compact', KAFKA_TOPIC='ORDERS_BY_REGION', PARTITIONS=1, REPLICAS=1, RETENTION_MS=[[REDACTED_PHONE]]) AS SELECT\n  REGION REGION,\n  SUM(AMOUNT) TOTAL\nFROM ORDERS ORDERS\nWHERE (AMOUNT > 100)\nGROUP BY REGION\nEMIT CHANGES;","entities":[]}
[xUnit.net 00:00:02.72]       Expected: True
[xUnit.net 00:00:02.72]       Actual:   False
[xUnit.net 00:00:02.72]       Stack Trace:
[xUnit.net 00:00:02.72]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(252,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.CreateAllObjectsByOnModelCreating()
[xUnit.net 00:00:02.72]         --- End of stack trace from previous location ---
[xUnit.net 00:00:02.72]   Finished:    Kafka.Ksql.Linq.Tests.Integration
  Kafka.Ksql.Linq.Tests.Integration テスト 25 件のエラーで失敗しました (3.4 秒)
    C:\Users\seiji_yfc8940\final\final\physicalTests\DummyFlagMessageTests.cs(110): error TESTERROR:
      Kafka.Ksql.Linq.Tests.Integration.DummyFlagMessageTests.SendAsync_AddsDummyFlagHeader (10ms): エラー メッセージ: Assert.Equal()
       Failure
                ↓ (pos 0)
      Expected: true
      Actual:   True
                ↑ (pos 0)
      スタック トレース:
         at Kafka.Ksql.Linq.Tests.Integration.DummyFlagMessageTests.SendAsync_AddsDummyFlagHeader() in C:\Users\seiji_yfc8940
      \final\final\physicalTests\DummyFlagMessageTests.cs:line 110
      --- End of stack trace from previous location ---
    C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284): error TESTERROR:
      Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT Customer
      Id, Region, SUM(Amount) AS TotalAmo"...) (12ms): エラー メッセージ: SELECT CustomerId, Region, SUM(Amount) AS TotalAmount, COUN
      T(*) AS OrderCount, AVG(Amount) AS AverageAmount FROM orders GROUP BY CustomerId, Region HAVING (((SUM(Amount) > 1000)
      AND (COUNT(*) > 10)) OR (AVG(Amount) > 150)) EMIT CHANGES; failed: {"@type":"statement_error","error_code":40001,"messa
      ge":"Line: 1, Col: 150: GROUP BY column 'REGION' cannot be resolved.","statementText":"EXPLAIN SELECT CustomerId, Regio
      n, SUM(Amount) AS TotalAmount, COUNT(*) AS OrderCount, AVG(Amount) AS AverageAmount FROM orders GROUP BY CustomerId, Re
      gion HAVING (((SUM(Amount) > 1000) AND (COUNT(*) > 10)) OR (AVG(Amount) > 150)) EMIT CHANGES;","entities":[]}
      Expected: True
      Actual:   False
      スタック トレース:
         at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql) in
      C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs:line 284
      --- End of stack trace from previous location ---
    C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs(84): error TESTERROR:
      Kafka.Ksql.Linq.Tests.Integration.SchemaNameCaseSensitivityTests.MismatchedFieldCase_ShouldThrowException (131ms): エラー
      メッセージ: System.InvalidOperationException : FATAL: KsqlContext initialization failed. Application cannot continue without
       Kafka connectivity.
      ---- Kafka.Ksql.Linq.Serialization.Avro.Exceptions.AvroSchemaRegistrationException : Failed to register schema for Orde
      rCorrectCase
      -------- Confluent.SchemaRegistry.SchemaRegistryException : Schema being registered is incompatible with an earlier sch
      ema for subject "orders-value", details: [{errorType:'NAME_MISMATCH', description:'The name of the schema has changed (
      path '/name')', additionalInfo:'expected: OrderValue'}, {oldSchemaVersion: 1}, {oldSchema: '{"type":"record","name":"Or
      derValue","fields":[{"name":"CustomerId","type":"int"},{"name":"dummy","type":"string"}]}'}, {compatibility: 'BACKWARD'
      }]; error code: 409
      スタック トレース:
         at Kafka.Ksql.Linq.Application.KsqlContext..ctor() in C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs:line 84
         at Kafka.Ksql.Linq.Tests.Integration.SchemaNameCaseSensitivityTests.OrderContext..ctor()
         at System.RuntimeMethodHandle.InvokeMethod(Object target, Void** arguments, Signature sig, Boolean isConstructor)
         at System.Reflection.MethodBaseInvoker.InvokeWithNoArgs(Object obj, BindingFlags invokeAttr)
      ----- Inner Stack Trace -----
         at Kafka.Ksql.Linq.Application.KsqlContext.RegisterSchemasSync(IReadOnlyDictionary`2 configurations) in C:\Users\sei
      ji_yfc8940\final\final\src\KsqlContext.cs:line 203
         at Kafka.Ksql.Linq.Application.KsqlContext.InitializeWithSchemaRegistration() in C:\Users\seiji_yfc8940\final\final\
      src\KsqlContext.cs:line 151
         at Kafka.Ksql.Linq.Application.KsqlContext..ctor() in C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs:line 59
      ----- Inner Stack Trace -----
         at Confluent.SchemaRegistry.RestService.ExecuteOnOneInstanceAsync(Func`1 createRequest)
         at Confluent.SchemaRegistry.RestService.RequestAsync[T](String endPoint, HttpMethod method, Object[] jsonBody)
         at Confluent.SchemaRegistry.RestService.RegisterSchemaAsync(String subject, Schema schema, Boolean normalize)
         at Confluent.SchemaRegistry.CachedSchemaRegistryClient.RegisterSchemaAsync(String subject, Schema schema, Boolean no
      rmalize)
         at Kafka.Ksql.Linq.Serialization.Avro.Management.AvroSchemaRegistrationService.RegisterSchemaAsync(String subject, S
      tring avroSchema) in C:\Users\seiji_yfc8940\final\final\src\Serialization\Avro\Management\AvroSchemaRegistrationService
      .cs:line 100
         at Kafka.Ksql.Linq.Serialization.Avro.Management.AvroSchemaRegistrationService.RegisterEntitySchemaAsync(Type entity
      Type, AvroEntityConfiguration config) in C:\Users\seiji_yfc8940\final\final\src\Serialization\Avro\Management\AvroSchem
      aRegistrationService.cs:line 69
    C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs(84): error TESTERROR:
      Kafka.Ksql.Linq.Tests.Integration.DummyFlagSchemaRecognitionTests.Consumer_SkipsDummyMessages (136ms): エラー メッセージ: Syste
      m.InvalidOperationException : FATAL: KsqlContext initialization failed. Application cannot continue without Kafka conne
      ctivity.
      ---- Kafka.Ksql.Linq.Serialization.Avro.Exceptions.AvroSchemaRegistrationException : Failed to register schema for Orde
      r
      -------- Confluent.SchemaRegistry.SchemaRegistryException : Schema being registered is incompatible with an earlier sch
      ema for subject "orders-value", details: [{errorType:'NAME_MISMATCH', description:'The name of the schema has changed (
      path '/name')', additionalInfo:'expected: OrderValue'}, {oldSchemaVersion: 1}, {oldSchema: '{"type":"record","name":"Or
      derValue","fields":[{"name":"CustomerId","type":"int"},{"name":"dummy","type":"string"}]}'}, {compatibility: 'BACKWARD'
      }]; error code: 409
      スタック トレース:
         at Kafka.Ksql.Linq.Application.KsqlContext..ctor() in C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs:line 84
         at Kafka.Ksql.Linq.Tests.Integration.DummyFlagSchemaRecognitionTests.DummyContext..ctor()
         at System.RuntimeMethodHandle.InvokeMethod(Object target, Void** arguments, Signature sig, Boolean isConstructor)
         at System.Reflection.MethodBaseInvoker.InvokeWithNoArgs(Object obj, BindingFlags invokeAttr)
      ----- Inner Stack Trace -----
         at Kafka.Ksql.Linq.Application.KsqlContext.RegisterSchemasSync(IReadOnlyDictionary`2 configurations) in C:\Users\sei
      ji_yfc8940\final\final\src\KsqlContext.cs:line 203
         at Kafka.Ksql.Linq.Application.KsqlContext.InitializeWithSchemaRegistration() in C:\Users\seiji_yfc8940\final\final\
      src\KsqlContext.cs:line 151
         at Kafka.Ksql.Linq.Application.KsqlContext..ctor() in C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs:line 59
      ----- Inner Stack Trace -----
         at Confluent.SchemaRegistry.RestService.ExecuteOnOneInstanceAsync(Func`1 createRequest)
         at Confluent.SchemaRegistry.RestService.RequestAsync[T](String endPoint, HttpMethod method, Object[] jsonBody)
         at Confluent.SchemaRegistry.RestService.RegisterSchemaAsync(String subject, Schema schema, Boolean normalize)
         at Confluent.SchemaRegistry.CachedSchemaRegistryClient.RegisterSchemaAsync(String subject, Schema schema, Boolean no
      rmalize)
         at Kafka.Ksql.Linq.Serialization.Avro.Management.AvroSchemaRegistrationService.RegisterSchemaAsync(String subject, S
      tring avroSchema) in C:\Users\seiji_yfc8940\final\final\src\Serialization\Avro\Management\AvroSchemaRegistrationService
      .cs:line 100
         at Kafka.Ksql.Linq.Serialization.Avro.Management.AvroSchemaRegistrationService.RegisterEntitySchemaAsync(Type entity
      Type, AvroEntityConfiguration config) in C:\Users\seiji_yfc8940\final\final\src\Serialization\Avro\Management\AvroSchem
      aRegistrationService.cs:line 69
    C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs(84): error TESTERROR:
      Kafka.Ksql.Linq.Tests.Integration.DummyFlagSchemaRecognitionTests.DummyMessages_EnableQueries (224ms): エラー メッセージ: Syste
      m.InvalidOperationException : FATAL: KsqlContext initialization failed. Application cannot continue without Kafka conne
      ctivity.
      ---- Kafka.Ksql.Linq.Serialization.Avro.Exceptions.AvroSchemaRegistrationException : Failed to register schema for Orde
      r
      -------- Confluent.SchemaRegistry.SchemaRegistryException : Schema being registered is incompatible with an earlier sch
      ema for subject "orders-value", details: [{errorType:'NAME_MISMATCH', description:'The name of the schema has changed (
      path '/name')', additionalInfo:'expected: OrderValue'}, {oldSchemaVersion: 1}, {oldSchema: '{"type":"record","name":"Or
      derValue","fields":[{"name":"CustomerId","type":"int"},{"name":"dummy","type":"string"}]}'}, {compatibility: 'BACKWARD'
      }]; error code: 409
      スタック トレース:
         at Kafka.Ksql.Linq.Application.KsqlContext..ctor() in C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs:line 84
         at Kafka.Ksql.Linq.Tests.Integration.DummyFlagSchemaRecognitionTests.DummyContext..ctor()
         at InvokeStub_DummyContext..ctor(Object, Object, IntPtr*)
         at System.Reflection.MethodBaseInvoker.InvokeWithNoArgs(Object obj, BindingFlags invokeAttr)
      ----- Inner Stack Trace -----
         at Kafka.Ksql.Linq.Application.KsqlContext.RegisterSchemasSync(IReadOnlyDictionary`2 configurations) in C:\Users\sei
      ji_yfc8940\final\final\src\KsqlContext.cs:line 203
         at Kafka.Ksql.Linq.Application.KsqlContext.InitializeWithSchemaRegistration() in C:\Users\seiji_yfc8940\final\final\
      src\KsqlContext.cs:line 151
         at Kafka.Ksql.Linq.Application.KsqlContext..ctor() in C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs:line 59
      ----- Inner Stack Trace -----
         at Confluent.SchemaRegistry.RestService.ExecuteOnOneInstanceAsync(Func`1 createRequest)
         at Confluent.SchemaRegistry.RestService.RequestAsync[T](String endPoint, HttpMethod method, Object[] jsonBody)
         at Confluent.SchemaRegistry.RestService.RegisterSchemaAsync(String subject, Schema schema, Boolean normalize)
         at Confluent.SchemaRegistry.CachedSchemaRegistryClient.RegisterSchemaAsync(String subject, Schema schema, Boolean no
      rmalize)
         at Kafka.Ksql.Linq.Serialization.Avro.Management.AvroSchemaRegistrationService.RegisterSchemaAsync(String subject, S
      tring avroSchema) in C:\Users\seiji_yfc8940\final\final\src\Serialization\Avro\Management\AvroSchemaRegistrationService
      .cs:line 100
         at Kafka.Ksql.Linq.Serialization.Avro.Management.AvroSchemaRegistrationService.RegisterEntitySchemaAsync(Type entity
      Type, AvroEntityConfiguration config) in C:\Users\seiji_yfc8940\final\final\src\Serialization\Avro\Management\AvroSchem
      aRegistrationService.cs:line 69
    C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284): error TESTERROR:
      Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT Customer
      Id, Region, SUM(Amount) AS Total FR"...) (6ms): エラー メッセージ: SELECT CustomerId, Region, SUM(Amount) AS Total FROM orders
      GROUP BY CustomerId, Region HAVING (SUM(Amount) > 500) EMIT CHANGES; failed: {"@type":"statement_error","error_code":40
      001,"message":"Line: 1, Col: 90: GROUP BY column 'REGION' cannot be resolved.","statementText":"EXPLAIN SELECT Customer
      Id, Region, SUM(Amount) AS Total FROM orders GROUP BY CustomerId, Region HAVING (SUM(Amount) > 500) EMIT CHANGES;","ent
      ities":[]}
      Expected: True
      Actual:   False
      スタック トレース:
         at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql) in
      C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs:line 284
      --- End of stack trace from previous location ---
    C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284): error TESTERROR:
      Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT Customer
      Id, SUM(Amount) AS Total, COUNT(*) "...) (7ms): エラー メッセージ: SELECT CustomerId, SUM(Amount) AS Total, COUNT(*) AS Count,
      AVG(Amount) AS Avg FROM orders GROUP BY CustomerId HAVING (((SUM(Amount) > 1000) AND (COUNT(*) > 5)) OR (AVG(Amount) >
      500)) EMIT CHANGES; failed: {"@type":"statement_error","error_code":40001,"message":"Line: 1, Col: 134: HAVING column '
      AMOUNT' cannot be resolved.","statementText":"EXPLAIN SELECT CustomerId, SUM(Amount) AS Total, COUNT(*) AS Count, AVG(A
      mount) AS Avg FROM orders GROUP BY CustomerId HAVING (((SUM(Amount) > 1000) AND (COUNT(*) > 5)) OR (AVG(Amount) > 500))
       EMIT CHANGES;","entities":[]}
      Expected: True
      Actual:   False
      スタック トレース:
         at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql) in
      C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs:line 284
      --- End of stack trace from previous location ---
    C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284): error TESTERROR:
      Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT COUNT(*)
       FROM orders;") (6ms): エラー メッセージ: SELECT COUNT(*) FROM orders; failed: {"@type":"statement_error","error_code":40001,"m
      essage":"Pull queries don't support GROUP BY clauses. See https://cnfl.io/queries for more info.\nAdd EMIT CHANGES if y
      ou intended to issue a push query.","statementText":"EXPLAIN SELECT COUNT(*) FROM orders;","entities":[]}
      Expected: True
      Actual:   False
      スタック トレース:
         at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql) in
      C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs:line 284
      --- End of stack trace from previous location ---
    C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284): error TESTERROR:
      Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT Customer
      Id, Region, Amount FROM orders WHER"...) (7ms): エラー メッセージ: SELECT CustomerId, Region, Amount FROM orders WHERE Region N
      OT IN ('CN', 'RU') EMIT CHANGES; failed: {"@type":"statement_error","error_code":40001,"message":"Line: 1, Col: 61: WHE
      RE column 'REGION' cannot be resolved.","statementText":"EXPLAIN SELECT CustomerId, Region, Amount FROM orders WHERE Re
      gion NOT IN ('CN', 'RU') EMIT CHANGES;","entities":[]}
      Expected: True
      Actual:   False
      スタック トレース:
         at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql) in
      C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs:line 284
      --- End of stack trace from previous location ---
    C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284): error TESTERROR:
      Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT Customer
      Id, SUM(Amount) AS Total, CASE WHEN"...) (7ms): エラー メッセージ: SELECT CustomerId, SUM(Amount) AS Total, CASE WHEN (SUM(Amou
      nt) > 1000) THEN 'VIP' ELSE 'Regular' END AS Status FROM orders GROUP BY CustomerId EMIT CHANGES; failed: {"@type":"sta
      tement_error","error_code":40001,"message":"Line: 1, Col: 32: SELECT column 'AMOUNT' cannot be resolved.","statementTex
      t":"EXPLAIN SELECT CustomerId, SUM(Amount) AS Total, CASE WHEN (SUM(Amount) > 1000) THEN 'VIP' ELSE 'Regular' END AS St
      atus FROM orders GROUP BY CustomerId EMIT CHANGES;","entities":[]}
      Expected: True
      Actual:   False
      スタック トレース:
         at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql) in
      C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs:line 284
      --- End of stack trace from previous location ---
    C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284): error TESTERROR:
      Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT LATEST_B
      Y_OFFSET(Id) AS Last FROM orders;") (10ms): エラー メッセージ: SELECT LATEST_BY_OFFSET(Id) AS Last FROM orders; failed: {"@type
      ":"statement_error","error_code":40001,"message":"Line: 1, Col: 33: SELECT column 'ID' cannot be resolved.","statementT
      ext":"EXPLAIN SELECT LATEST_BY_OFFSET(Id) AS Last FROM orders;","entities":[]}
      Expected: True
      Actual:   False
      スタック トレース:
         at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql) in
      C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs:line 284
      --- End of stack trace from previous location ---
    C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284): error TESTERROR:
      Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT Customer
      Id, SUM(Amount) AS TotalAmount, SUM"...) (6ms): エラー メッセージ: SELECT CustomerId, SUM(Amount) AS TotalAmount, SUM(Count) AS
       TotalCount FROM orders GROUP BY CustomerId HAVING ((SUM(Amount) > 1000) OR (SUM(Count) > 5)) EMIT CHANGES; failed: {"@
      type":"statement_error","error_code":40001,"message":"Line: 1, Col: 126: HAVING column 'AMOUNT' cannot be resolved.","s
      tatementText":"EXPLAIN SELECT CustomerId, SUM(Amount) AS TotalAmount, SUM(Count) AS TotalCount FROM orders GROUP BY Cus
      tomerId HAVING ((SUM(Amount) > 1000) OR (SUM(Count) > 5)) EMIT CHANGES;","entities":[]}
      Expected: True
      Actual:   False
      スタック トレース:
         at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql) in
      C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs:line 284
      --- End of stack trace from previous location ---
    C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284): error TESTERROR:
      Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT UPPER(Re
      gion), SUM(Amount) AS TotalAmount F"...) (10ms): エラー メッセージ: SELECT UPPER(Region), SUM(Amount) AS TotalAmount FROM order
      s GROUP BY UPPER(Region) HAVING (SUM(Amount) > 500) EMIT CHANGES; failed: {"@type":"statement_error","error_code":40001
      ,"message":"Line: 1, Col: 85: GROUP BY column 'REGION' cannot be resolved.","statementText":"EXPLAIN SELECT UPPER(Regio
      n), SUM(Amount) AS TotalAmount FROM orders GROUP BY UPPER(Region) HAVING (SUM(Amount) > 500) EMIT CHANGES;","entities":
      []}
      Expected: True
      Actual:   False
      スタック トレース:
         at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql) in
      C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs:line 284
      --- End of stack trace from previous location ---
    C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284): error TESTERROR:
      Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT Customer
      Id, Region, SUM(Amount) AS Total FR"...) (5ms): エラー メッセージ: SELECT CustomerId, Region, SUM(Amount) AS Total FROM orders
      GROUP BY CustomerId, Region ORDER BY Total DESC EMIT CHANGES; failed: {"@type":"statement_error","error_code":40001,"me
      ssage":"line 1:97: Syntax Error\n","statementText":"EXPLAIN SELECT CustomerId, Region, SUM(Amount) AS Total FROM orders
       GROUP BY CustomerId, Region ORDER BY Total DESC EMIT CHANGES;","entities":[]}
      Expected: True
      Actual:   False
      スタック トレース:
         at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql) in
      C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs:line 284
      --- End of stack trace from previous location ---
    C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284): error TESTERROR:
      Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT Customer
      Id, AVG(Amount) AS AverageAmount, M"...) (6ms): エラー メッセージ: SELECT CustomerId, AVG(Amount) AS AverageAmount, MIN(Amount)
       AS MinAmount, MAX(Amount) AS MaxAmount FROM orders GROUP BY CustomerId EMIT CHANGES; failed: {"@type":"statement_error
      ","error_code":40001,"message":"Line: 1, Col: 32: SELECT column 'AMOUNT' cannot be resolved.","statementText":"EXPLAIN
      SELECT CustomerId, AVG(Amount) AS AverageAmount, MIN(Amount) AS MinAmount, MAX(Amount) AS MaxAmount FROM orders GROUP B
      Y CustomerId EMIT CHANGES;","entities":[]}
      Expected: True
      Actual:   False
      スタック トレース:
         at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql) in
      C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs:line 284
      --- End of stack trace from previous location ---
    C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284): error TESTERROR:
      Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT Customer
      Id, SUM(Amount) AS Total FROM order"...) (6ms): エラー メッセージ: SELECT CustomerId, SUM(Amount) AS Total FROM orders GROUP BY
       CustomerId ORDER BY Total DESC EMIT CHANGES; failed: {"@type":"statement_error","error_code":40001,"message":"line 1:8
      1: Syntax Error\n","statementText":"EXPLAIN SELECT CustomerId, SUM(Amount) AS Total FROM orders GROUP BY CustomerId ORD
      ER BY Total DESC EMIT CHANGES;","entities":[]}
      Expected: True
      Actual:   False
      スタック トレース:
         at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql) in
      C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs:line 284
      --- End of stack trace from previous location ---
    C:\Users\seiji_yfc8940\final\final\physicalTests\TestSchema.cs(63): error TESTERROR:
      Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT Customer
      Id, SUM(Amount) AS Total FROM Order"...) (2ms): エラー メッセージ: Assert.Contains() Failure
      Not found: Order
      In value:  List<String> ["orders", "customers", "events", "orders_nullable", "orders_nullable_key"]
      スタック トレース:
         at Kafka.Ksql.Linq.Tests.Integration.TestSchema.ValidateDmlQuery(String query) in C:\Users\seiji_yfc8940\final\final
      \physicalTests\TestSchema.cs:line 63
         at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql) in
      C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs:line 282
      --- End of stack trace from previous location ---
    C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284): error TESTERROR:
      Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT SUM(Amou
      nt) AS Sum FROM orders;") (6ms): エラー メッセージ: SELECT SUM(Amount) AS Sum FROM orders; failed: {"@type":"statement_error","
      error_code":40001,"message":"Line: 1, Col: 20: SELECT column 'AMOUNT' cannot be resolved.","statementText":"EXPLAIN SEL
      ECT SUM(Amount) AS Sum FROM orders;","entities":[]}
      Expected: True
      Actual:   False
      スタック トレース:
         at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql) in
      C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs:line 284
      --- End of stack trace from previous location ---
    C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284): error TESTERROR:
      Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT COUNT(*)
       FROM customers;") (6ms): エラー メッセージ: SELECT COUNT(*) FROM customers; failed: {"@type":"statement_error","error_code":40
      001,"message":"Pull queries don't support GROUP BY clauses. See https://cnfl.io/queries for more info.\nAdd EMIT CHANGE
      S if you intended to issue a push query.","statementText":"EXPLAIN SELECT COUNT(*) FROM customers;","entities":[]}
      Expected: True
      Actual:   False
      スタック トレース:
         at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql) in
      C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs:line 284
      --- End of stack trace from previous location ---
    C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284): error TESTERROR:
      Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT COUNT(*)
       FROM orders_nullable_key;") (6ms): エラー メッセージ: SELECT COUNT(*) FROM orders_nullable_key; failed: {"@type":"statement_er
      ror","error_code":40001,"message":"Pull queries don't support GROUP BY clauses. See https://cnfl.io/queries for more in
      fo.\nAdd EMIT CHANGES if you intended to issue a push query.","statementText":"EXPLAIN SELECT COUNT(*) FROM orders_null
      able_key;","entities":[]}
      Expected: True
      Actual:   False
      スタック トレース:
         at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql) in
      C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs:line 284
      --- End of stack trace from previous location ---
    C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284): error TESTERROR:
      Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT EARLIEST
      _BY_OFFSET(Id) AS First FROM orders"...) (5ms): エラー メッセージ: SELECT EARLIEST_BY_OFFSET(Id) AS First FROM orders; failed:
      {"@type":"statement_error","error_code":40001,"message":"Line: 1, Col: 35: SELECT column 'ID' cannot be resolved.","sta
      tementText":"EXPLAIN SELECT EARLIEST_BY_OFFSET(Id) AS First FROM orders;","entities":[]}
      Expected: True
      Actual:   False
      スタック トレース:
         at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql) in
      C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs:line 284
      --- End of stack trace from previous location ---
    C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284): error TESTERROR:
      Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT Customer
      Id, SUM(Amount) AS Total, SUM(CASE "...) (6ms): エラー メッセージ: SELECT CustomerId, SUM(Amount) AS Total, SUM(CASE WHEN IsHig
      hPriority THEN Amount ELSE 0 END) AS HighPriorityTotal FROM orders GROUP BY CustomerId EMIT CHANGES; failed: {"@type":"
      statement_error","error_code":40001,"message":"Line: 1, Col: 32: SELECT column 'AMOUNT' cannot be resolved.","statement
      Text":"EXPLAIN SELECT CustomerId, SUM(Amount) AS Total, SUM(CASE WHEN IsHighPriority THEN Amount ELSE 0 END) AS HighPri
      orityTotal FROM orders GROUP BY CustomerId EMIT CHANGES;","entities":[]}
      Expected: True
      Actual:   False
      スタック トレース:
         at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql) in
      C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs:line 284
      --- End of stack trace from previous location ---
    C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284): error TESTERROR:
      Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT COUNT(*)
       FROM orders_nullable;") (7ms): エラー メッセージ: SELECT COUNT(*) FROM orders_nullable; failed: {"@type":"statement_error","er
      ror_code":40001,"message":"Pull queries don't support GROUP BY clauses. See https://cnfl.io/queries for more info.\nAdd
       EMIT CHANGES if you intended to issue a push query.","statementText":"EXPLAIN SELECT COUNT(*) FROM orders_nullable;","
      entities":[]}
      Expected: True
      Actual:   False
      スタック トレース:
         at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql) in
      C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs:line 284
      --- End of stack trace from previous location ---
    C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284): error TESTERROR:
      Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT Customer
      Id, COUNT(*) AS Count FROM orders W"...) (5ms): エラー メッセージ: SELECT CustomerId, COUNT(*) AS Count FROM orders WHERE (Amou
      nt > 100) WINDOW TUMBLING (SIZE 5 MINUTES) GROUP BY CustomerId HAVING (COUNT(*) > 1) ORDER BY Key ASC EMIT CHANGES; fai
      led: {"@type":"statement_error","error_code":40001,"message":"line 1:79: Syntax Error\n","statementText":"EXPLAIN SELEC
      T CustomerId, COUNT(*) AS Count FROM orders WHERE (Amount > 100) WINDOW TUMBLING (SIZE 5 MINUTES) GROUP BY CustomerId H
      AVING (COUNT(*) > 1) ORDER BY Key ASC EMIT CHANGES;","entities":[]}
      Expected: True
      Actual:   False
      スタック トレース:
         at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql) in
      C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs:line 284
      --- End of stack trace from previous location ---
    C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(252): error TESTERROR:
      Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.CreateAllObjectsByOnModelCreating (130ms): エラー メッセージ: DDL
      failed: {"@type":"statement_error","error_code":40001,"message":"Could not determine output schema for query due to err
      or: Line: 1, Col: 89: WHERE column 'AMOUNT' cannot be resolved.","statementText":"CREATE TABLE ORDERS_BY_REGION WITH (C
      LEANUP_POLICY='compact', KAFKA_TOPIC='ORDERS_BY_REGION', PARTITIONS=1, REPLICAS=1, RETENTION_MS=[[REDACTED_PHONE]]) AS SELECT\n
       REGION REGION,\n  SUM(AMOUNT) TOTAL\nFROM ORDERS ORDERS\nWHERE (AMOUNT > 100)\nGROUP BY REGION\nEMIT CHANGES;","entiti
      es":[]}
      Expected: True
      Actual:   False
      スタック トレース:
         at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.CreateAllObjectsByOnModelCreating() in C:\Users\seij
      i_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs:line 252
### assistant — 2025-07-06T07:56:52.783014+00:00

司令さん、いただいたログの中には明示的にDROP文がある記述は見当たりませんが、スキーマやテーブルの再登録エラーが頻発しているため、以下の可能性が考えられます。

---
### DROPしているかどうかの可能性

- **テストや初期化コードで明示的にDROP TABLEやDROP STREAMを実行しているケース**  
  - もしテストのセットアップや初期化処理で、古いテーブルやストリームを削除してから再作成している場合、それがDROPに該当します。  
  - ログにDROPコマンドの出力があれば分かりますが、見当たらないのでコードを確認が必要です。

- **テーブルやスキーマを作り直すために、Schema Registryのスキーマ登録をクリア（削除）している**  
  - これもDROPの一種と捉えられますが、スキーマ名不一致エラーを見ると古いスキーマが残っているので削除はされていない可能性が高いです。

---
### 確認方法

1. **テストコードのセットアップ/初期化部分を確認**  
   - `CREATE TABLE`前に`DROP TABLE`や`DROP STREAM`が実行されていないか確認。  
   - 明示的なDROPがない場合、テストの前後で状態リセットはされていない可能性があります。

2. **Schema RegistryのUIまたはAPIでスキーマ一覧を確認**  
   - 既存のスキーマ名やバージョンを確認し、古いスキーマが残っているか確認。  
   - 競合しているスキーマは削除または互換性を保つ必要があります。

3. **Kafkaトピックの状態確認**  
   - もしテーブルやストリームのCREATEが成功しているなら、Kafka上に対応するトピックが存在します。  
   - トピックの中身とスキーマの整合性も重要です。

---
### 結論

- 今のところDROPしている明示的な証拠はログにありません。  
- スキーマの名前不一致エラーやPRIMARY KEYの不足など、スキーマ設計やDDLの問題がテスト失敗の本質的な原因です。  
- DROPに関してはテストコードやセットアップ手順を精査して判断する必要があります。

---

必要ならテストセットアップコードやDDL部分の抜粋を教えてください。確認して適切なアドバイスをします。

[[REDACTED_PHONE]]:54:50 JST
### user — 2025-07-06T07:56:52.853000+00:00

dropしてない？
### user — 2025-07-06T08:01:56.970000+00:00

dropがないので、指示を
### assistant — 2025-07-06T08:01:56.978125+00:00

司令さん、

DROP文が見当たらないことを踏まえ、テスト実行時の状態リセットや競合を避けるための指示案を以下にまとめます。

---

## テスト環境整備とDROPの検討指示案

1. **テスト開始前に既存のテーブル・ストリームを明示的にDROPする**  
   - `CREATE TABLE IF NOT EXISTS` や `CREATE STREAM IF NOT EXISTS` を使っても、スキーマやトピックの残存により問題が起きやすい。  
   - 明示的に `DROP TABLE <table_name> DELETE TOPIC;` や `DROP STREAM <stream_name> DELETE TOPIC;` を実行してリセットすることを推奨。

2. **DROPができない場合はスキーマやトピックの名前を変更して衝突を避ける**  
   - テストごとにユニークな名前を付けることでスキーマ競合を回避。

3. **Schema Registryのスキーマをリセットする**  
   - スキーマ競合が残っている場合は、Schema Registryの管理画面やAPIからスキーマ削除を検討。

4. **PRIMARY KEYが不足しているエラーの対応**  
   - CREATE TABLE文には必ずPRIMARY KEYを定義し、KSQLが正しくテーブルを認識できる状態にする。

5. **テストのセットアップとクリーンアップコードにDROPを組み込む**  
   - 可能であれば、テストの前後で状態をリセットするためのDROPコマンドを含める。

---

## まとめて司令さんへの指示

> 「テスト実行前に、すべての対象テーブルとストリームをDROPし、関連Kafkaトピックも削除してください。これによりスキーマやトピックの競合を防ぎます。特にCREATE TABLEにはPRIMARY KEY指定が必須なので不足を補ってください。Schema Registryの古いスキーマが競合している場合は管理画面から削除し、テスト環境をクリーンに保つようお願いします。」

---

もしテストコードやセットアップにDROP文の追加やスキーマ登録解除を含めたほうがよい場合、そのコード案も作成可能ですのでお知らせください。

[[REDACTED_PHONE]]:54:50 JST
### assistant — 2025-07-06T08:02:36.721154+00:00

司令さん、

了解です。テストコードやセットアップに以下のようにDROP文やスキーマ登録解除処理を組み込む例を示します。

---

## 1. KSQLのDROP文をテストセットアップに追加する例（C#コード内）

```csharp
public async Task ResetEnvironmentAsync()
{
    var ksqlStatements = new[]
    {
        "DROP STREAM IF EXISTS source DELETE TOPIC;",
        "DROP TABLE IF EXISTS orders DELETE TOPIC;",
        "DROP TABLE IF EXISTS customers DELETE TOPIC;",
        "DROP TABLE IF EXISTS events DELETE TOPIC;",
        "DROP TABLE IF EXISTS orders_nullable DELETE TOPIC;",
        "DROP TABLE IF EXISTS orders_nullable_key DELETE TOPIC;",
        // 必要なテーブル・ストリームを列挙
    };

    foreach(var stmt in ksqlStatements)
    {
        try
        {
            await ksqlContext.ExecuteAsync(stmt);
        }
        catch(Exception ex)
        {
            // ログに記録など適宜対応
            Console.WriteLine($"Failed to execute: {stmt} Exception: {ex.Message}");
        }
    }

    // Schema Registryのスキーマ登録解除を行う場合は下記で実装
    await ClearSchemaRegistryAsync();
}
```

---

## 2. Schema Registryのスキーマ登録解除例（Confluent.SchemaRegistry クライアント利用）

```csharp
private readonly CachedSchemaRegistryClient schemaRegistryClient;

public async Task ClearSchemaRegistryAsync()
{
    var subjects = await schemaRegistryClient.GetAllSubjectsAsync();
    foreach(var subject in subjects)
    {
        try
        {
            await schemaRegistryClient.DeleteSubjectAsync(subject);
            Console.WriteLine($"Deleted schema subject: {subject}");
        }
        catch(Exception ex)
        {
            Console.WriteLine($"Failed to delete schema subject: {subject} Exception: {ex.Message}");
        }
    }
}
```

---

## 3. テストのセットアップに組み込み

```csharp
[Fact]
public async Task Test_Example()
{
    await ResetEnvironmentAsync();

    // ここからテスト本体の処理
}
```

---

このように、テストの前段階で明示的にKafka側のテーブル・ストリーム、そしてSchema Registryのスキーマ登録をリセットし、クリーンな環境でテストを開始することが可能です。

必要があれば、セットアップメソッドの具体的な配置場所や呼び出しタイミングについても提案しますので教えてくださいね。

[[REDACTED_PHONE]]:54:50 JST
### user — 2025-07-06T08:02:37.012000+00:00

テストコードやセットアップにDROP文の追加やスキーマ登録解除を含めたほうがよい
### user — 2025-07-06T08:26:20.029000+00:00

添付のエラー
### assistant — 2025-07-06T08:26:20.288302+00:00

司令さん、以下のエラー内容とポイントから解説しますね（日本時間：[[REDACTED_PHONE]]:13）。

---
### 1. スキーマ登録エラー（SchemaRegistryException）

- エラー内容：「Schema being registered is incompatible with an earlier schema for subject 'orders-value'」
- 詳細：「name の不一致」（旧スキーマは `OrderValue` なのに、新スキーマは `Order` になっている）
- つまり、スキーマ名が変わってしまっていて、互換性エラーで登録拒否されている。

**対策案**  
- 既存のスキーマ名（`OrderValue`）に合わせてエンティティのAvroスキーマ名を固定する。  
- もしくはSchema Registry上で既存スキーマを削除し、リセットする（テスト環境ならこれもあり）。  
- スキーマの名前は安易に変えないこと。名前変更時は互換性ルールを十分に確認する。

---
### 2. テーブル作成のPRIMARY KEY不足エラー

- エラー内容：「Tables require a PRIMARY KEY. Please define the PRIMARY KEY.」
- KSQLのテーブルは必ずPRIMARY KEYが必要だが、CREATE TABLE文にPRIMARY KEY指定がないためエラー。

**対策案**  
- 各CREATE TABLE文にPRIMARY KEYを必ず含めること。  
- 例：
  ```sql
  CREATE TABLE IF NOT EXISTS ORDERS (
    CUSTOMERID INTEGER PRIMARY KEY,
    ID INTEGER,
    REGION STRING,
    AMOUNT DECIMAL(38, 9),
    ISHIGHPRIORITY BOOLEAN,
    COUNT INTEGER
  ) WITH (...)
  ```
- 既存コードのスキーマ定義部分を見直し、PRIMARY KEY属性を追加する。

---
### 3. SQLエラー「GROUP BY column 'REGION' cannot be resolved」など

- エラー内容：KSQLが列名（RegionやAmountなど）を認識できない。  
- これはストリーム／テーブルのスキーマが正しく反映されていないか、列名の大文字小文字や別名に問題がある場合が多い。  
- また、ストリームやテーブルの登録（CREATE STREAM/TABLE）が正しくできていないことも原因。

**対策案**  
- 1. スキーマ登録が正常に通ること（上記1、2の解決が前提）。  
- 2. スキーマの列名とクエリ中の列名の大文字小文字を合わせる。  
- 3. クエリを発行する前に対象のストリームやテーブルがKSQLサーバ上で正しく作成されているか確認。  
- 4. 可能ならば、先にDROP文で既存のストリームやテーブルを削除し、クリアな状態から作り直す。

---
### 4. Pull Query と Push Query の違い関連エラー

- 「Pull queries don't support GROUP BY clauses. Add EMIT CHANGES if push query intended.」というエラー  
- KSQLでは集計クエリに対しては`EMIT CHANGES`句が必須（プッシュクエリ）であり、これがないとエラーになる。  
- つまり、クエリの文法で`EMIT CHANGES`を忘れている可能性。

**対策案**  
- 集計・グルーピングを含むクエリは必ず`EMIT CHANGES`を付ける。  
- Pull Queryは単純取得系のクエリ限定と理解し、テストクエリで適切に使い分ける。

---
### 5. テストのセットアップ改善の提案

- テストの初期化処理に、**既存のストリーム・テーブルのDROP文を入れて完全リセットすることを強く推奨**します。  
- スキーマの再登録で名前衝突や互換性エラーを防止。  
- テスト環境なので、以下例のように事前にDROPしてからCREATEする流れが良いです。

```sql
DROP STREAM IF EXISTS orders;
DROP TABLE IF EXISTS orders;

CREATE STREAM orders (...) WITH (...);
CREATE TABLE orders (...) WITH (... PRIMARY KEY ...);
```

- さらにSchema Registryのスキーマを手動で削除してリセットも視野に。

---
### まとめ

- **スキーマ名を変えず互換性を守ること。**
- **テーブルには必ずPRIMARY KEYを指定すること。**
- **DROP文をテストセットアップに入れてクリアにすること。**
- **クエリに`EMIT CHANGES`を忘れず付けること。**
- **列名の大文字小文字も含めてスキーマとクエリを整合させること。**

これらの対応を順に行えば、テストの失敗はかなり減るはずです。

---

もし、具体的にテストコードやスキーマ定義ファイルの修正案が欲しい場合は、そのファイルや該当コードを教えてくださいね。

---

[[REDACTED_PHONE]]:13 JST
### tool — 2025-07-06T08:26:27.573144+00:00

_(empty)_
### tool — 2025-07-06T08:26:27.573237+00:00

[xUnit.net 00:00:00.00] xUnit.net VSTest Adapter v2.4.5+1caef2f33e (64-bit .NET 8.0.17)
[xUnit.net 00:00:00.41]   Discovering: Kafka.Ksql.Linq.Tests.Integration
[KSQL-LINQ INFO] ORDER BY in KSQL is limited to Pull Queries and specific scenarios. Push Queries (streaming) do not guarantee order due to distributed processing.
[KSQL-LINQ WARNING] JOIN performance optimization: Ensure topics 'orders' and 'customers' have same partition count and key distribution.
[KSQL-LINQ INFO] ORDER BY in KSQL is limited to Pull Queries and specific scenarios. Push Queries (streaming) do not guarantee order due to distributed processing.
[KSQL-LINQ INFO] ORDER BY in KSQL is limited to Pull Queries and specific scenarios. Push Queries (streaming) do not guarantee order due to distributed processing.
[KSQL-LINQ INFO] ORDER BY in KSQL is limited to Pull Queries and specific scenarios. Push Queries (streaming) do not guarantee order due to distributed processing.
[xUnit.net 00:00:01.05]   Discovered:  Kafka.Ksql.Linq.Tests.Integration
[xUnit.net 00:00:01.05]   Starting:    Kafka.Ksql.Linq.Tests.Integration
[xUnit.net 00:00:01.11]     Kafka.Ksql.Linq.Tests.Integration.DummyFlagMessageTests.SendAsync_AddsDummyFlagHeader [FAIL]
[xUnit.net 00:00:01.11]       Assert.Equal() Failure
[xUnit.net 00:00:01.11]                 ↓ (pos 0)
[xUnit.net 00:00:01.11]       Expected: true
[xUnit.net 00:00:01.11]       Actual:   True
[xUnit.net 00:00:01.11]                 ↑ (pos 0)
[xUnit.net 00:00:01.11]       Stack Trace:
[xUnit.net 00:00:01.11]         C:\Users\seiji_yfc8940\final\final\physicalTests\DummyFlagMessageTests.cs(110,0): at Kafka.Ksql.Linq.Tests.Integration.DummyFlagMessageTests.SendAsync_AddsDummyFlagHeader()
[xUnit.net 00:00:01.11]         --- End of stack trace from previous location ---
[xUnit.net 00:00:01.12]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT CustomerId, Region, SUM(Amount) AS TotalAmo"...) [FAIL]
[xUnit.net 00:00:01.12]       SELECT CustomerId, Region, SUM(Amount) AS TotalAmount, COUNT(*) AS OrderCount, AVG(Amount) AS AverageAmount FROM orders GROUP BY CustomerId, Region HAVING (((SUM(Amount) > 1000) AND (COUNT(*) > 10)) OR (AVG(Amount) > 150)) EMIT CHANGES; failed: {"@type":"statement_error","error_code":40001,"message":"Line: 1, Col: 150: GROUP BY column 'REGION' cannot be resolved.","statementText":"EXPLAIN SELECT CustomerId, Region, SUM(Amount) AS TotalAmount, COUNT(*) AS OrderCount, AVG(Amount) AS AverageAmount FROM orders GROUP BY CustomerId, Region HAVING (((SUM(Amount) > 1000) AND (COUNT(*) > 10)) OR (AVG(Amount) > 150)) EMIT CHANGES;","entities":[]}
[xUnit.net 00:00:01.12]       Expected: True
[xUnit.net 00:00:01.12]       Actual:   False
[xUnit.net 00:00:01.12]       Stack Trace:
[xUnit.net 00:00:01.12]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql)
[xUnit.net 00:00:01.12]         --- End of stack trace from previous location ---
CREATE STREAM result: True, msg: [{"@type":"warning_entity","statementText":"CREATE STREAM IF NOT EXISTS source (id INT) WITH (KAFKA_TOPIC='source', VALUE_FORMAT='AVRO', PARTITIONS=1);","message":"Cannot add stream `SOURCE`: A stream with the same name already exists.","warnings":[]}]
DDL result: False, msg: {"@type":"statement_error","error_code":40001,"message":"Tables require a PRIMARY KEY. Please define the PRIMARY KEY.","statementText":"CREATE TABLE IF NOT EXISTS ORDERS (CUSTOMERID INTEGER, ID INTEGER, REGION STRING, AMOUNT DECIMAL(38, 9), ISHIGHPRIORITY BOOLEAN, COUNT INTEGER) WITH (CLEANUP_POLICY='compact', KAFKA_TOPIC='orders', KEY_FORMAT='KAFKA', PARTITIONS=1, VALUE_FORMAT='AVRO');","entities":[]}
DDL result: False, msg: {"@type":"statement_error","error_code":40001,"message":"Tables require a PRIMARY KEY. Please define the PRIMARY KEY.","statementText":"CREATE TABLE IF NOT EXISTS CUSTOMERS (ID INTEGER, NAME STRING) WITH (CLEANUP_POLICY='compact', KAFKA_TOPIC='customers', KEY_FORMAT='KAFKA', PARTITIONS=1, VALUE_FORMAT='AVRO');","entities":[]}
DDL result: False, msg: {"@type":"statement_error","error_code":40001,"message":"Tables require a PRIMARY KEY. Please define the PRIMARY KEY.","statementText":"CREATE TABLE IF NOT EXISTS EVENTS (LEVEL INTEGER, MESSAGE STRING) WITH (CLEANUP_POLICY='compact', KAFKA_TOPIC='events', KEY_FORMAT='KAFKA', PARTITIONS=1, VALUE_FORMAT='AVRO');","entities":[]}
DDL result: False, msg: {"@type":"statement_error","error_code":40001,"message":"Tables require a PRIMARY KEY. Please define the PRIMARY KEY.","statementText":"CREATE TABLE IF NOT EXISTS ORDERS_NULLABLE (CUSTOMERID INTEGER, REGION STRING, AMOUNT DECIMAL(38, 9)) WITH (CLEANUP_POLICY='compact', KAFKA_TOPIC='orders_nullable', KEY_FORMAT='KAFKA', PARTITIONS=1, VALUE_FORMAT='AVRO');","entities":[]}
[xUnit.net 00:00:01.23]     Kafka.Ksql.Linq.Tests.Integration.SchemaNameCaseSensitivityTests.MismatchedFieldCase_ShouldThrowException [FAIL]
[xUnit.net 00:00:01.23]       System.InvalidOperationException : FATAL: KsqlContext initialization failed. Application cannot continue without Kafka connectivity.
[xUnit.net 00:00:01.23]       ---- Kafka.Ksql.Linq.Serialization.Avro.Exceptions.AvroSchemaRegistrationException : Failed to register schema for OrderCorrectCase
[xUnit.net 00:00:01.23]       -------- Confluent.SchemaRegistry.SchemaRegistryException : Schema being registered is incompatible with an earlier schema for subject "orders-value", details: [{errorType:'NAME_MISMATCH', description:'The name of the schema has changed (path '/name')', additionalInfo:'expected: OrderValue'}, {oldSchemaVersion: 1}, {oldSchema: '{"type":"record","name":"OrderValue","fields":[{"name":"CustomerId","type":"int"},{"name":"dummy","type":"string"}]}'}, {compatibility: 'BACKWARD'}]; error code: 409
[xUnit.net 00:00:01.23]       Stack Trace:
[xUnit.net 00:00:01.23]         C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs(84,0): at Kafka.Ksql.Linq.Application.KsqlContext..ctor()
[xUnit.net 00:00:01.23]            at Kafka.Ksql.Linq.Tests.Integration.SchemaNameCaseSensitivityTests.OrderContext..ctor()
[xUnit.net 00:00:01.23]            at System.RuntimeMethodHandle.InvokeMethod(Object target, Void** arguments, Signature sig, Boolean isConstructor)
[xUnit.net 00:00:01.23]            at System.Reflection.MethodBaseInvoker.InvokeWithNoArgs(Object obj, BindingFlags invokeAttr)
[xUnit.net 00:00:01.23]         ----- Inner Stack Trace -----
[xUnit.net 00:00:01.23]         C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs(203,0): at Kafka.Ksql.Linq.Application.KsqlContext.RegisterSchemasSync(IReadOnlyDictionary`2 configurations)
[xUnit.net 00:00:01.23]         C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs(151,0): at Kafka.Ksql.Linq.Application.KsqlContext.InitializeWithSchemaRegistration()
[xUnit.net 00:00:01.23]         C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs(59,0): at Kafka.Ksql.Linq.Application.KsqlContext..ctor()
[xUnit.net 00:00:01.23]         ----- Inner Stack Trace -----
[xUnit.net 00:00:01.23]            at Confluent.SchemaRegistry.RestService.ExecuteOnOneInstanceAsync(Func`1 createRequest)
[xUnit.net 00:00:01.23]            at Confluent.SchemaRegistry.RestService.RequestAsync[T](String endPoint, HttpMethod method, Object[] jsonBody)
[xUnit.net 00:00:01.23]            at Confluent.SchemaRegistry.RestService.RegisterSchemaAsync(String subject, Schema schema, Boolean normalize)
[xUnit.net 00:00:01.23]            at Confluent.SchemaRegistry.CachedSchemaRegistryClient.RegisterSchemaAsync(String subject, Schema schema, Boolean normalize)
[xUnit.net 00:00:01.23]         C:\Users\seiji_yfc8940\final\final\src\Serialization\Avro\Management\AvroSchemaRegistrationService.cs(100,0): at Kafka.Ksql.Linq.Serialization.Avro.Management.AvroSchemaRegistrationService.RegisterSchemaAsync(String subject, String avroSchema)
[xUnit.net 00:00:01.23]         C:\Users\seiji_yfc8940\final\final\src\Serialization\Avro\Management\AvroSchemaRegistrationService.cs(69,0): at Kafka.Ksql.Linq.Serialization.Avro.Management.AvroSchemaRegistrationService.RegisterEntitySchemaAsync(Type entityType, AvroEntityConfiguration config)
[xUnit.net 00:00:01.23]     Kafka.Ksql.Linq.Tests.Integration.DummyFlagSchemaRecognitionTests.Consumer_SkipsDummyMessages [FAIL]
[xUnit.net 00:00:01.23]       System.InvalidOperationException : FATAL: KsqlContext initialization failed. Application cannot continue without Kafka connectivity.
[xUnit.net 00:00:01.23]       ---- Kafka.Ksql.Linq.Serialization.Avro.Exceptions.AvroSchemaRegistrationException : Failed to register schema for Order
[xUnit.net 00:00:01.23]       -------- Confluent.SchemaRegistry.SchemaRegistryException : Schema being registered is incompatible with an earlier schema for subject "orders-value", details: [{errorType:'NAME_MISMATCH', description:'The name of the schema has changed (path '/name')', additionalInfo:'expected: OrderValue'}, {oldSchemaVersion: 1}, {oldSchema: '{"type":"record","name":"OrderValue","fields":[{"name":"CustomerId","type":"int"},{"name":"dummy","type":"string"}]}'}, {compatibility: 'BACKWARD'}]; error code: 409
[xUnit.net 00:00:01.23]       Stack Trace:
[xUnit.net 00:00:01.23]         C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs(84,0): at Kafka.Ksql.Linq.Application.KsqlContext..ctor()
[xUnit.net 00:00:01.23]            at Kafka.Ksql.Linq.Tests.Integration.DummyFlagSchemaRecognitionTests.DummyContext..ctor()
[xUnit.net 00:00:01.23]            at System.RuntimeMethodHandle.InvokeMethod(Object target, Void** arguments, Signature sig, Boolean isConstructor)
[xUnit.net 00:00:01.23]            at System.Reflection.MethodBaseInvoker.InvokeWithNoArgs(Object obj, BindingFlags invokeAttr)
[xUnit.net 00:00:01.23]         ----- Inner Stack Trace -----
[xUnit.net 00:00:01.23]         C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs(203,0): at Kafka.Ksql.Linq.Application.KsqlContext.RegisterSchemasSync(IReadOnlyDictionary`2 configurations)
[xUnit.net 00:00:01.23]         C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs(151,0): at Kafka.Ksql.Linq.Application.KsqlContext.InitializeWithSchemaRegistration()
[xUnit.net 00:00:01.23]         C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs(59,0): at Kafka.Ksql.Linq.Application.KsqlContext..ctor()
[xUnit.net 00:00:01.23]         ----- Inner Stack Trace -----
[xUnit.net 00:00:01.23]            at Confluent.SchemaRegistry.RestService.ExecuteOnOneInstanceAsync(Func`1 createRequest)
[xUnit.net 00:00:01.23]            at Confluent.SchemaRegistry.RestService.RequestAsync[T](String endPoint, HttpMethod method, Object[] jsonBody)
[xUnit.net 00:00:01.23]            at Confluent.SchemaRegistry.RestService.RegisterSchemaAsync(String subject, Schema schema, Boolean normalize)
[xUnit.net 00:00:01.23]            at Confluent.SchemaRegistry.CachedSchemaRegistryClient.RegisterSchemaAsync(String subject, Schema schema, Boolean normalize)
[xUnit.net 00:00:01.23]         C:\Users\seiji_yfc8940\final\final\src\Serialization\Avro\Management\AvroSchemaRegistrationService.cs(100,0): at Kafka.Ksql.Linq.Serialization.Avro.Management.AvroSchemaRegistrationService.RegisterSchemaAsync(String subject, String avroSchema)
[xUnit.net 00:00:01.23]         C:\Users\seiji_yfc8940\final\final\src\Serialization\Avro\Management\AvroSchemaRegistrationService.cs(69,0): at Kafka.Ksql.Linq.Serialization.Avro.Management.AvroSchemaRegistrationService.RegisterEntitySchemaAsync(Type entityType, AvroEntityConfiguration config)
DDL result: False, msg: {"@type":"statement_error","error_code":40001,"message":"Tables require a PRIMARY KEY. Please define the PRIMARY KEY.","statementText":"CREATE TABLE IF NOT EXISTS ORDERS_NULLABLE_KEY (CUSTOMERID INTEGER, AMOUNT DECIMAL(38, 9)) WITH (CLEANUP_POLICY='compact', KAFKA_TOPIC='orders_nullable_key', KEY_FORMAT='KAFKA', PARTITIONS=1, VALUE_FORMAT='AVRO');","entities":[]}
CREATE STREAM result: True, msg: [{"@type":"warning_entity","statementText":"CREATE STREAM IF NOT EXISTS source (id INT) WITH (KAFKA_TOPIC='source', VALUE_FORMAT='AVRO', PARTITIONS=1);","message":"Cannot add stream `SOURCE`: A stream with the same name already exists.","warnings":[]}]
[xUnit.net 00:00:01.45]     Kafka.Ksql.Linq.Tests.Integration.DummyFlagSchemaRecognitionTests.DummyMessages_EnableQueries [FAIL]
[xUnit.net 00:00:01.45]       System.InvalidOperationException : FATAL: KsqlContext initialization failed. Application cannot continue without Kafka connectivity.
[xUnit.net 00:00:01.45]       ---- Kafka.Ksql.Linq.Serialization.Avro.Exceptions.AvroSchemaRegistrationException : Failed to register schema for Order
[xUnit.net 00:00:01.45]       -------- Confluent.SchemaRegistry.SchemaRegistryException : Schema being registered is incompatible with an earlier schema for subject "orders-value", details: [{errorType:'NAME_MISMATCH', description:'The name of the schema has changed (path '/name')', additionalInfo:'expected: OrderValue'}, {oldSchemaVersion: 1}, {oldSchema: '{"type":"record","name":"OrderValue","fields":[{"name":"CustomerId","type":"int"},{"name":"dummy","type":"string"}]}'}, {compatibility: 'BACKWARD'}]; error code: 409
[xUnit.net 00:00:01.45]       Stack Trace:
[xUnit.net 00:00:01.45]         C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs(84,0): at Kafka.Ksql.Linq.Application.KsqlContext..ctor()
[xUnit.net 00:00:01.45]            at Kafka.Ksql.Linq.Tests.Integration.DummyFlagSchemaRecognitionTests.DummyContext..ctor()
[xUnit.net 00:00:01.45]            at InvokeStub_DummyContext..ctor(Object, Object, IntPtr*)
[xUnit.net 00:00:01.45]            at System.Reflection.MethodBaseInvoker.InvokeWithNoArgs(Object obj, BindingFlags invokeAttr)
[xUnit.net 00:00:01.45]         ----- Inner Stack Trace -----
[xUnit.net 00:00:01.45]         C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs(203,0): at Kafka.Ksql.Linq.Application.KsqlContext.RegisterSchemasSync(IReadOnlyDictionary`2 configurations)
[xUnit.net 00:00:01.45]         C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs(151,0): at Kafka.Ksql.Linq.Application.KsqlContext.InitializeWithSchemaRegistration()
[xUnit.net 00:00:01.45]         C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs(59,0): at Kafka.Ksql.Linq.Application.KsqlContext..ctor()
[xUnit.net 00:00:01.45]         ----- Inner Stack Trace -----
[xUnit.net 00:00:01.45]            at Confluent.SchemaRegistry.RestService.ExecuteOnOneInstanceAsync(Func`1 createRequest)
[xUnit.net 00:00:01.45]            at Confluent.SchemaRegistry.RestService.RequestAsync[T](String endPoint, HttpMethod method, Object[] jsonBody)
[xUnit.net 00:00:01.45]            at Confluent.SchemaRegistry.RestService.RegisterSchemaAsync(String subject, Schema schema, Boolean normalize)
[xUnit.net 00:00:01.45]            at Confluent.SchemaRegistry.CachedSchemaRegistryClient.RegisterSchemaAsync(String subject, Schema schema, Boolean normalize)
[xUnit.net 00:00:01.45]         C:\Users\seiji_yfc8940\final\final\src\Serialization\Avro\Management\AvroSchemaRegistrationService.cs(100,0): at Kafka.Ksql.Linq.Serialization.Avro.Management.AvroSchemaRegistrationService.RegisterSchemaAsync(String subject, String avroSchema)
[xUnit.net 00:00:01.45]         C:\Users\seiji_yfc8940\final\final\src\Serialization\Avro\Management\AvroSchemaRegistrationService.cs(69,0): at Kafka.Ksql.Linq.Serialization.Avro.Management.AvroSchemaRegistrationService.RegisterEntitySchemaAsync(Type entityType, AvroEntityConfiguration config)
DDL result: False, msg: {"@type":"statement_error","error_code":40001,"message":"Tables require a PRIMARY KEY. Please define the PRIMARY KEY.","statementText":"CREATE TABLE IF NOT EXISTS ORDERS (CUSTOMERID INTEGER, ID INTEGER, REGION STRING, AMOUNT DECIMAL(38, 9), ISHIGHPRIORITY BOOLEAN, COUNT INTEGER) WITH (CLEANUP_POLICY='compact', KAFKA_TOPIC='orders', KEY_FORMAT='KAFKA', PARTITIONS=1, VALUE_FORMAT='AVRO');","entities":[]}
DDL result: False, msg: {"@type":"statement_error","error_code":40001,"message":"Tables require a PRIMARY KEY. Please define the PRIMARY KEY.","statementText":"CREATE TABLE IF NOT EXISTS CUSTOMERS (ID INTEGER, NAME STRING) WITH (CLEANUP_POLICY='compact', KAFKA_TOPIC='customers', KEY_FORMAT='KAFKA', PARTITIONS=1, VALUE_FORMAT='AVRO');","entities":[]}
DDL result: False, msg: {"@type":"statement_error","error_code":40001,"message":"Tables require a PRIMARY KEY. Please define the PRIMARY KEY.","statementText":"CREATE TABLE IF NOT EXISTS EVENTS (LEVEL INTEGER, MESSAGE STRING) WITH (CLEANUP_POLICY='compact', KAFKA_TOPIC='events', KEY_FORMAT='KAFKA', PARTITIONS=1, VALUE_FORMAT='AVRO');","entities":[]}
DDL result: False, msg: {"@type":"statement_error","error_code":40001,"message":"Tables require a PRIMARY KEY. Please define the PRIMARY KEY.","statementText":"CREATE TABLE IF NOT EXISTS ORDERS_NULLABLE (CUSTOMERID INTEGER, REGION STRING, AMOUNT DECIMAL(38, 9)) WITH (CLEANUP_POLICY='compact', KAFKA_TOPIC='orders_nullable', KEY_FORMAT='KAFKA', PARTITIONS=1, VALUE_FORMAT='AVRO');","entities":[]}
DDL result: False, msg: {"@type":"statement_error","error_code":40001,"message":"Tables require a PRIMARY KEY. Please define the PRIMARY KEY.","statementText":"CREATE TABLE IF NOT EXISTS ORDERS_NULLABLE_KEY (CUSTOMERID INTEGER, AMOUNT DECIMAL(38, 9)) WITH (CLEANUP_POLICY='compact', KAFKA_TOPIC='orders_nullable_key', KEY_FORMAT='KAFKA', PARTITIONS=1, VALUE_FORMAT='AVRO');","entities":[]}
[xUnit.net 00:00:01.61]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT CustomerId, Region, SUM(Amount) AS Total FR"...) [FAIL]
[xUnit.net 00:00:01.61]       SELECT CustomerId, Region, SUM(Amount) AS Total FROM orders GROUP BY CustomerId, Region HAVING (SUM(Amount) > 500) EMIT CHANGES; failed: {"@type":"statement_error","error_code":40001,"message":"Line: 1, Col: 90: GROUP BY column 'REGION' cannot be resolved.","statementText":"EXPLAIN SELECT CustomerId, Region, SUM(Amount) AS Total FROM orders GROUP BY CustomerId, Region HAVING (SUM(Amount) > 500) EMIT CHANGES;","entities":[]}
[xUnit.net 00:00:01.61]       Expected: True
[xUnit.net 00:00:01.61]       Actual:   False
[xUnit.net 00:00:01.61]       Stack Trace:
[xUnit.net 00:00:01.61]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql)
[xUnit.net 00:00:01.61]         --- End of stack trace from previous location ---
[xUnit.net 00:00:01.62]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT CustomerId, SUM(Amount) AS Total, COUNT(*) "...) [FAIL]
[xUnit.net 00:00:01.62]       SELECT CustomerId, SUM(Amount) AS Total, COUNT(*) AS Count, AVG(Amount) AS Avg FROM orders GROUP BY CustomerId HAVING (((SUM(Amount) > 1000) AND (COUNT(*) > 5)) OR (AVG(Amount) > 500)) EMIT CHANGES; failed: {"@type":"statement_error","error_code":40001,"message":"Line: 1, Col: 134: HAVING column 'AMOUNT' cannot be resolved.","statementText":"EXPLAIN SELECT CustomerId, SUM(Amount) AS Total, COUNT(*) AS Count, AVG(Amount) AS Avg FROM orders GROUP BY CustomerId HAVING (((SUM(Amount) > 1000) AND (COUNT(*) > 5)) OR (AVG(Amount) > 500)) EMIT CHANGES;","entities":[]}
[xUnit.net 00:00:01.62]       Expected: True
[xUnit.net 00:00:01.62]       Actual:   False
[xUnit.net 00:00:01.62]       Stack Trace:
[xUnit.net 00:00:01.62]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql)
[xUnit.net 00:00:01.62]         --- End of stack trace from previous location ---
[xUnit.net 00:00:01.63]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT COUNT(*) FROM orders;") [FAIL]
[xUnit.net 00:00:01.63]       SELECT COUNT(*) FROM orders; failed: {"@type":"statement_error","error_code":40001,"message":"Pull queries don't support GROUP BY clauses. See https://cnfl.io/queries for more info.\nAdd EMIT CHANGES if you intended to issue a push query.","statementText":"EXPLAIN SELECT COUNT(*) FROM orders;","entities":[]}
[xUnit.net 00:00:01.63]       Expected: True
[xUnit.net 00:00:01.63]       Actual:   False
[xUnit.net 00:00:01.63]       Stack Trace:
[xUnit.net 00:00:01.63]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql)
[xUnit.net 00:00:01.63]         --- End of stack trace from previous location ---
[xUnit.net 00:00:01.63]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT CustomerId, Region, Amount FROM orders WHER"...) [FAIL]
[xUnit.net 00:00:01.63]       SELECT CustomerId, Region, Amount FROM orders WHERE Region NOT IN ('CN', 'RU') EMIT CHANGES; failed: {"@type":"statement_error","error_code":40001,"message":"Line: 1, Col: 61: WHERE column 'REGION' cannot be resolved.","statementText":"EXPLAIN SELECT CustomerId, Region, Amount FROM orders WHERE Region NOT IN ('CN', 'RU') EMIT CHANGES;","entities":[]}
[xUnit.net 00:00:01.63]       Expected: True
[xUnit.net 00:00:01.63]       Actual:   False
[xUnit.net 00:00:01.63]       Stack Trace:
[xUnit.net 00:00:01.63]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql)
[xUnit.net 00:00:01.63]         --- End of stack trace from previous location ---
[xUnit.net 00:00:01.65]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT CustomerId, SUM(Amount) AS Total, CASE WHEN"...) [FAIL]
[xUnit.net 00:00:01.65]       SELECT CustomerId, SUM(Amount) AS Total, CASE WHEN (SUM(Amount) > 1000) THEN 'VIP' ELSE 'Regular' END AS Status FROM orders GROUP BY CustomerId EMIT CHANGES; failed: {"@type":"statement_error","error_code":40001,"message":"Line: 1, Col: 32: SELECT column 'AMOUNT' cannot be resolved.","statementText":"EXPLAIN SELECT CustomerId, SUM(Amount) AS Total, CASE WHEN (SUM(Amount) > 1000) THEN 'VIP' ELSE 'Regular' END AS Status FROM orders GROUP BY CustomerId EMIT CHANGES;","entities":[]}
[xUnit.net 00:00:01.65]       Expected: True
[xUnit.net 00:00:01.65]       Actual:   False
[xUnit.net 00:00:01.65]       Stack Trace:
[xUnit.net 00:00:01.65]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql)
[xUnit.net 00:00:01.65]         --- End of stack trace from previous location ---
[xUnit.net 00:00:01.66]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT LATEST_BY_OFFSET(Id) AS Last FROM orders;") [FAIL]
[xUnit.net 00:00:01.66]       SELECT LATEST_BY_OFFSET(Id) AS Last FROM orders; failed: {"@type":"statement_error","error_code":40001,"message":"Line: 1, Col: 33: SELECT column 'ID' cannot be resolved.","statementText":"EXPLAIN SELECT LATEST_BY_OFFSET(Id) AS Last FROM orders;","entities":[]}
[xUnit.net 00:00:01.66]       Expected: True
[xUnit.net 00:00:01.66]       Actual:   False
[xUnit.net 00:00:01.66]       Stack Trace:
[xUnit.net 00:00:01.66]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql)
[xUnit.net 00:00:01.66]         --- End of stack trace from previous location ---
[xUnit.net 00:00:01.66]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT CustomerId, SUM(Amount) AS TotalAmount, SUM"...) [FAIL]
[xUnit.net 00:00:01.66]       SELECT CustomerId, SUM(Amount) AS TotalAmount, SUM(Count) AS TotalCount FROM orders GROUP BY CustomerId HAVING ((SUM(Amount) > 1000) OR (SUM(Count) > 5)) EMIT CHANGES; failed: {"@type":"statement_error","error_code":40001,"message":"Line: 1, Col: 126: HAVING column 'AMOUNT' cannot be resolved.","statementText":"EXPLAIN SELECT CustomerId, SUM(Amount) AS TotalAmount, SUM(Count) AS TotalCount FROM orders GROUP BY CustomerId HAVING ((SUM(Amount) > 1000) OR (SUM(Count) > 5)) EMIT CHANGES;","entities":[]}
[xUnit.net 00:00:01.66]       Expected: True
[xUnit.net 00:00:01.66]       Actual:   False
[xUnit.net 00:00:01.66]       Stack Trace:
[xUnit.net 00:00:01.66]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql)
[xUnit.net 00:00:01.66]         --- End of stack trace from previous location ---
[xUnit.net 00:00:01.77]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT UPPER(Region), SUM(Amount) AS TotalAmount F"...) [FAIL]
[xUnit.net 00:00:01.77]       SELECT UPPER(Region), SUM(Amount) AS TotalAmount FROM orders GROUP BY UPPER(Region) HAVING (SUM(Amount) > 500) EMIT CHANGES; failed: {"@type":"statement_error","error_code":40001,"message":"Line: 1, Col: 85: GROUP BY column 'REGION' cannot be resolved.","statementText":"EXPLAIN SELECT UPPER(Region), SUM(Amount) AS TotalAmount FROM orders GROUP BY UPPER(Region) HAVING (SUM(Amount) > 500) EMIT CHANGES;","entities":[]}
[xUnit.net 00:00:01.77]       Expected: True
[xUnit.net 00:00:01.77]       Actual:   False
[xUnit.net 00:00:01.77]       Stack Trace:
[xUnit.net 00:00:01.77]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql)
[xUnit.net 00:00:01.77]         --- End of stack trace from previous location ---
[xUnit.net 00:00:01.87]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT CustomerId, Region, SUM(Amount) AS Total FR"...) [FAIL]
[xUnit.net 00:00:01.87]       SELECT CustomerId, Region, SUM(Amount) AS Total FROM orders GROUP BY CustomerId, Region ORDER BY Total DESC EMIT CHANGES; failed: {"@type":"statement_error","error_code":40001,"message":"line 1:97: Syntax Error\n","statementText":"EXPLAIN SELECT CustomerId, Region, SUM(Amount) AS Total FROM orders GROUP BY CustomerId, Region ORDER BY Total DESC EMIT CHANGES;","entities":[]}
[xUnit.net 00:00:01.87]       Expected: True
[xUnit.net 00:00:01.87]       Actual:   False
[xUnit.net 00:00:01.87]       Stack Trace:
[xUnit.net 00:00:01.87]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql)
[xUnit.net 00:00:01.87]         --- End of stack trace from previous location ---
[xUnit.net 00:00:01.96]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT CustomerId, AVG(Amount) AS AverageAmount, M"...) [FAIL]
[xUnit.net 00:00:01.96]       SELECT CustomerId, AVG(Amount) AS AverageAmount, MIN(Amount) AS MinAmount, MAX(Amount) AS MaxAmount FROM orders GROUP BY CustomerId EMIT CHANGES; failed: {"@type":"statement_error","error_code":40001,"message":"Line: 1, Col: 32: SELECT column 'AMOUNT' cannot be resolved.","statementText":"EXPLAIN SELECT CustomerId, AVG(Amount) AS AverageAmount, MIN(Amount) AS MinAmount, MAX(Amount) AS MaxAmount FROM orders GROUP BY CustomerId EMIT CHANGES;","entities":[]}
[xUnit.net 00:00:01.96]       Expected: True
[xUnit.net 00:00:01.96]       Actual:   False
[xUnit.net 00:00:01.96]       Stack Trace:
[xUnit.net 00:00:01.96]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql)
[xUnit.net 00:00:01.96]         --- End of stack trace from previous location ---
[xUnit.net 00:00:01.97]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT CustomerId, SUM(Amount) AS Total FROM order"...) [FAIL]
[xUnit.net 00:00:01.97]       SELECT CustomerId, SUM(Amount) AS Total FROM orders GROUP BY CustomerId ORDER BY Total DESC EMIT CHANGES; failed: {"@type":"statement_error","error_code":40001,"message":"line 1:81: Syntax Error\n","statementText":"EXPLAIN SELECT CustomerId, SUM(Amount) AS Total FROM orders GROUP BY CustomerId ORDER BY Total DESC EMIT CHANGES;","entities":[]}
[xUnit.net 00:00:01.97]       Expected: True
[xUnit.net 00:00:01.97]       Actual:   False
[xUnit.net 00:00:01.97]       Stack Trace:
[xUnit.net 00:00:01.97]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql)
[xUnit.net 00:00:01.97]         --- End of stack trace from previous location ---
[xUnit.net 00:00:01.97]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT CustomerId, SUM(Amount) AS Total FROM Order"...) [FAIL]
[xUnit.net 00:00:01.97]       Assert.Contains() Failure
[xUnit.net 00:00:01.97]       Not found: Order
[xUnit.net 00:00:01.97]       In value:  List<String> ["orders", "customers", "events", "orders_nullable", "orders_nullable_key"]
[xUnit.net 00:00:01.97]       Stack Trace:
[xUnit.net 00:00:01.97]         C:\Users\seiji_yfc8940\final\final\physicalTests\TestSchema.cs(63,0): at Kafka.Ksql.Linq.Tests.Integration.TestSchema.ValidateDmlQuery(String query)
[xUnit.net 00:00:01.97]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(282,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql)
[xUnit.net 00:00:01.97]         --- End of stack trace from previous location ---
[xUnit.net 00:00:02.07]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT SUM(Amount) AS Sum FROM orders;") [FAIL]
[xUnit.net 00:00:02.07]       SELECT SUM(Amount) AS Sum FROM orders; failed: {"@type":"statement_error","error_code":40001,"message":"Line: 1, Col: 20: SELECT column 'AMOUNT' cannot be resolved.","statementText":"EXPLAIN SELECT SUM(Amount) AS Sum FROM orders;","entities":[]}
[xUnit.net 00:00:02.07]       Expected: True
[xUnit.net 00:00:02.07]       Actual:   False
[xUnit.net 00:00:02.07]       Stack Trace:
[xUnit.net 00:00:02.07]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql)
[xUnit.net 00:00:02.07]         --- End of stack trace from previous location ---
[xUnit.net 00:00:02.07]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT COUNT(*) FROM customers;") [FAIL]
[xUnit.net 00:00:02.07]       SELECT COUNT(*) FROM customers; failed: {"@type":"statement_error","error_code":40001,"message":"Pull queries don't support GROUP BY clauses. See https://cnfl.io/queries for more info.\nAdd EMIT CHANGES if you intended to issue a push query.","statementText":"EXPLAIN SELECT COUNT(*) FROM customers;","entities":[]}
[xUnit.net 00:00:02.07]       Expected: True
[xUnit.net 00:00:02.07]       Actual:   False
[xUnit.net 00:00:02.07]       Stack Trace:
[xUnit.net 00:00:02.07]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql)
[xUnit.net 00:00:02.07]         --- End of stack trace from previous location ---
[xUnit.net 00:00:02.27]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT COUNT(*) FROM orders_nullable_key;") [FAIL]
[xUnit.net 00:00:02.27]       SELECT COUNT(*) FROM orders_nullable_key; failed: {"@type":"statement_error","error_code":40001,"message":"Pull queries don't support GROUP BY clauses. See https://cnfl.io/queries for more info.\nAdd EMIT CHANGES if you intended to issue a push query.","statementText":"EXPLAIN SELECT COUNT(*) FROM orders_nullable_key;","entities":[]}
[xUnit.net 00:00:02.27]       Expected: True
[xUnit.net 00:00:02.27]       Actual:   False
[xUnit.net 00:00:02.27]       Stack Trace:
[xUnit.net 00:00:02.27]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql)
[xUnit.net 00:00:02.27]         --- End of stack trace from previous location ---
[xUnit.net 00:00:02.28]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT EARLIEST_BY_OFFSET(Id) AS First FROM orders"...) [FAIL]
[xUnit.net 00:00:02.28]       SELECT EARLIEST_BY_OFFSET(Id) AS First FROM orders; failed: {"@type":"statement_error","error_code":40001,"message":"Line: 1, Col: 35: SELECT column 'ID' cannot be resolved.","statementText":"EXPLAIN SELECT EARLIEST_BY_OFFSET(Id) AS First FROM orders;","entities":[]}
[xUnit.net 00:00:02.28]       Expected: True
[xUnit.net 00:00:02.28]       Actual:   False
[xUnit.net 00:00:02.28]       Stack Trace:
[xUnit.net 00:00:02.28]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql)
[xUnit.net 00:00:02.28]         --- End of stack trace from previous location ---
[xUnit.net 00:00:02.38]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT CustomerId, SUM(Amount) AS Total, SUM(CASE "...) [FAIL]
[xUnit.net 00:00:02.38]       SELECT CustomerId, SUM(Amount) AS Total, SUM(CASE WHEN IsHighPriority THEN Amount ELSE 0 END) AS HighPriorityTotal FROM orders GROUP BY CustomerId EMIT CHANGES; failed: {"@type":"statement_error","error_code":40001,"message":"Line: 1, Col: 32: SELECT column 'AMOUNT' cannot be resolved.","statementText":"EXPLAIN SELECT CustomerId, SUM(Amount) AS Total, SUM(CASE WHEN IsHighPriority THEN Amount ELSE 0 END) AS HighPriorityTotal FROM orders GROUP BY CustomerId EMIT CHANGES;","entities":[]}
[xUnit.net 00:00:02.38]       Expected: True
[xUnit.net 00:00:02.38]       Actual:   False
[xUnit.net 00:00:02.38]       Stack Trace:
[xUnit.net 00:00:02.38]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql)
[xUnit.net 00:00:02.38]         --- End of stack trace from previous location ---
[xUnit.net 00:00:02.39]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT COUNT(*) FROM orders_nullable;") [FAIL]
[xUnit.net 00:00:02.39]       SELECT COUNT(*) FROM orders_nullable; failed: {"@type":"statement_error","error_code":40001,"message":"Pull queries don't support GROUP BY clauses. See https://cnfl.io/queries for more info.\nAdd EMIT CHANGES if you intended to issue a push query.","statementText":"EXPLAIN SELECT COUNT(*) FROM orders_nullable;","entities":[]}
[xUnit.net 00:00:02.39]       Expected: True
[xUnit.net 00:00:02.39]       Actual:   False
[xUnit.net 00:00:02.39]       Stack Trace:
[xUnit.net 00:00:02.39]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql)
[xUnit.net 00:00:02.39]         --- End of stack trace from previous location ---
[xUnit.net 00:00:02.50]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT CustomerId, COUNT(*) AS Count FROM orders W"...) [FAIL]
[xUnit.net 00:00:02.50]       SELECT CustomerId, COUNT(*) AS Count FROM orders WHERE (Amount > 100) WINDOW TUMBLING (SIZE 5 MINUTES) GROUP BY CustomerId HAVING (COUNT(*) > 1) ORDER BY Key ASC EMIT CHANGES; failed: {"@type":"statement_error","error_code":40001,"message":"line 1:79: Syntax Error\n","statementText":"EXPLAIN SELECT CustomerId, COUNT(*) AS Count FROM orders WHERE (Amount > 100) WINDOW TUMBLING (SIZE 5 MINUTES) GROUP BY CustomerId HAVING (COUNT(*) > 1) ORDER BY Key ASC EMIT CHANGES;","entities":[]}
[xUnit.net 00:00:02.50]       Expected: True
[xUnit.net 00:00:02.50]       Actual:   False
[xUnit.net 00:00:02.50]       Stack Trace:
[xUnit.net 00:00:02.50]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql)
[xUnit.net 00:00:02.50]         --- End of stack trace from previous location ---
[xUnit.net 00:00:02.72]     Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.CreateAllObjectsByOnModelCreating [FAIL]
[xUnit.net 00:00:02.72]       DDL failed: {"@type":"statement_error","error_code":40001,"message":"Could not determine output schema for query due to error: Line: 1, Col: 89: WHERE column 'AMOUNT' cannot be resolved.","statementText":"CREATE TABLE ORDERS_BY_REGION WITH (CLEANUP_POLICY='compact', KAFKA_TOPIC='ORDERS_BY_REGION', PARTITIONS=1, REPLICAS=1, RETENTION_MS=[[REDACTED_PHONE]]) AS SELECT\n  REGION REGION,\n  SUM(AMOUNT) TOTAL\nFROM ORDERS ORDERS\nWHERE (AMOUNT > 100)\nGROUP BY REGION\nEMIT CHANGES;","entities":[]}
[xUnit.net 00:00:02.72]       Expected: True
[xUnit.net 00:00:02.72]       Actual:   False
[xUnit.net 00:00:02.72]       Stack Trace:
[xUnit.net 00:00:02.72]         C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(252,0): at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.CreateAllObjectsByOnModelCreating()
[xUnit.net 00:00:02.72]         --- End of stack trace from previous location ---
[xUnit.net 00:00:02.72]   Finished:    Kafka.Ksql.Linq.Tests.Integration
  Kafka.Ksql.Linq.Tests.Integration テスト 25 件のエラーで失敗しました (3.4 秒)
    C:\Users\seiji_yfc8940\final\final\physicalTests\DummyFlagMessageTests.cs(110): error TESTERROR:
      Kafka.Ksql.Linq.Tests.Integration.DummyFlagMessageTests.SendAsync_AddsDummyFlagHeader (10ms): エラー メッセージ: Assert.Equal()
       Failure
                ↓ (pos 0)
      Expected: true
      Actual:   True
                ↑ (pos 0)
      スタック トレース:
         at Kafka.Ksql.Linq.Tests.Integration.DummyFlagMessageTests.SendAsync_AddsDummyFlagHeader() in C:\Users\seiji_yfc8940
      \final\final\physicalTests\DummyFlagMessageTests.cs:line 110
      --- End of stack trace from previous location ---
    C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284): error TESTERROR:
      Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT Customer
      Id, Region, SUM(Amount) AS TotalAmo"...) (12ms): エラー メッセージ: SELECT CustomerId, Region, SUM(Amount) AS TotalAmount, COUN
      T(*) AS OrderCount, AVG(Amount) AS AverageAmount FROM orders GROUP BY CustomerId, Region HAVING (((SUM(Amount) > 1000)
      AND (COUNT(*) > 10)) OR (AVG(Amount) > 150)) EMIT CHANGES; failed: {"@type":"statement_error","error_code":40001,"messa
      ge":"Line: 1, Col: 150: GROUP BY column 'REGION' cannot be resolved.","statementText":"EXPLAIN SELECT CustomerId, Regio
      n, SUM(Amount) AS TotalAmount, COUNT(*) AS OrderCount, AVG(Amount) AS AverageAmount FROM orders GROUP BY CustomerId, Re
      gion HAVING (((SUM(Amount) > 1000) AND (COUNT(*) > 10)) OR (AVG(Amount) > 150)) EMIT CHANGES;","entities":[]}
      Expected: True
      Actual:   False
      スタック トレース:
         at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql) in
      C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs:line 284
      --- End of stack trace from previous location ---
    C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs(84): error TESTERROR:
      Kafka.Ksql.Linq.Tests.Integration.SchemaNameCaseSensitivityTests.MismatchedFieldCase_ShouldThrowException (131ms): エラー
      メッセージ: System.InvalidOperationException : FATAL: KsqlContext initialization failed. Application cannot continue without
       Kafka connectivity.
      ---- Kafka.Ksql.Linq.Serialization.Avro.Exceptions.AvroSchemaRegistrationException : Failed to register schema for Orde
      rCorrectCase
      -------- Confluent.SchemaRegistry.SchemaRegistryException : Schema being registered is incompatible with an earlier sch
      ema for subject "orders-value", details: [{errorType:'NAME_MISMATCH', description:'The name of the schema has changed (
      path '/name')', additionalInfo:'expected: OrderValue'}, {oldSchemaVersion: 1}, {oldSchema: '{"type":"record","name":"Or
      derValue","fields":[{"name":"CustomerId","type":"int"},{"name":"dummy","type":"string"}]}'}, {compatibility: 'BACKWARD'
      }]; error code: 409
      スタック トレース:
         at Kafka.Ksql.Linq.Application.KsqlContext..ctor() in C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs:line 84
         at Kafka.Ksql.Linq.Tests.Integration.SchemaNameCaseSensitivityTests.OrderContext..ctor()
         at System.RuntimeMethodHandle.InvokeMethod(Object target, Void** arguments, Signature sig, Boolean isConstructor)
         at System.Reflection.MethodBaseInvoker.InvokeWithNoArgs(Object obj, BindingFlags invokeAttr)
      ----- Inner Stack Trace -----
         at Kafka.Ksql.Linq.Application.KsqlContext.RegisterSchemasSync(IReadOnlyDictionary`2 configurations) in C:\Users\sei
      ji_yfc8940\final\final\src\KsqlContext.cs:line 203
         at Kafka.Ksql.Linq.Application.KsqlContext.InitializeWithSchemaRegistration() in C:\Users\seiji_yfc8940\final\final\
      src\KsqlContext.cs:line 151
         at Kafka.Ksql.Linq.Application.KsqlContext..ctor() in C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs:line 59
      ----- Inner Stack Trace -----
         at Confluent.SchemaRegistry.RestService.ExecuteOnOneInstanceAsync(Func`1 createRequest)
         at Confluent.SchemaRegistry.RestService.RequestAsync[T](String endPoint, HttpMethod method, Object[] jsonBody)
         at Confluent.SchemaRegistry.RestService.RegisterSchemaAsync(String subject, Schema schema, Boolean normalize)
         at Confluent.SchemaRegistry.CachedSchemaRegistryClient.RegisterSchemaAsync(String subject, Schema schema, Boolean no
      rmalize)
         at Kafka.Ksql.Linq.Serialization.Avro.Management.AvroSchemaRegistrationService.RegisterSchemaAsync(String subject, S
      tring avroSchema) in C:\Users\seiji_yfc8940\final\final\src\Serialization\Avro\Management\AvroSchemaRegistrationService
      .cs:line 100
         at Kafka.Ksql.Linq.Serialization.Avro.Management.AvroSchemaRegistrationService.RegisterEntitySchemaAsync(Type entity
      Type, AvroEntityConfiguration config) in C:\Users\seiji_yfc8940\final\final\src\Serialization\Avro\Management\AvroSchem
      aRegistrationService.cs:line 69
    C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs(84): error TESTERROR:
      Kafka.Ksql.Linq.Tests.Integration.DummyFlagSchemaRecognitionTests.Consumer_SkipsDummyMessages (136ms): エラー メッセージ: Syste
      m.InvalidOperationException : FATAL: KsqlContext initialization failed. Application cannot continue without Kafka conne
      ctivity.
      ---- Kafka.Ksql.Linq.Serialization.Avro.Exceptions.AvroSchemaRegistrationException : Failed to register schema for Orde
      r
      -------- Confluent.SchemaRegistry.SchemaRegistryException : Schema being registered is incompatible with an earlier sch
      ema for subject "orders-value", details: [{errorType:'NAME_MISMATCH', description:'The name of the schema has changed (
      path '/name')', additionalInfo:'expected: OrderValue'}, {oldSchemaVersion: 1}, {oldSchema: '{"type":"record","name":"Or
      derValue","fields":[{"name":"CustomerId","type":"int"},{"name":"dummy","type":"string"}]}'}, {compatibility: 'BACKWARD'
      }]; error code: 409
      スタック トレース:
         at Kafka.Ksql.Linq.Application.KsqlContext..ctor() in C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs:line 84
         at Kafka.Ksql.Linq.Tests.Integration.DummyFlagSchemaRecognitionTests.DummyContext..ctor()
         at System.RuntimeMethodHandle.InvokeMethod(Object target, Void** arguments, Signature sig, Boolean isConstructor)
         at System.Reflection.MethodBaseInvoker.InvokeWithNoArgs(Object obj, BindingFlags invokeAttr)
      ----- Inner Stack Trace -----
         at Kafka.Ksql.Linq.Application.KsqlContext.RegisterSchemasSync(IReadOnlyDictionary`2 configurations) in C:\Users\sei
      ji_yfc8940\final\final\src\KsqlContext.cs:line 203
         at Kafka.Ksql.Linq.Application.KsqlContext.InitializeWithSchemaRegistration() in C:\Users\seiji_yfc8940\final\final\
      src\KsqlContext.cs:line 151
         at Kafka.Ksql.Linq.Application.KsqlContext..ctor() in C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs:line 59
      ----- Inner Stack Trace -----
         at Confluent.SchemaRegistry.RestService.ExecuteOnOneInstanceAsync(Func`1 createRequest)
         at Confluent.SchemaRegistry.RestService.RequestAsync[T](String endPoint, HttpMethod method, Object[] jsonBody)
         at Confluent.SchemaRegistry.RestService.RegisterSchemaAsync(String subject, Schema schema, Boolean normalize)
         at Confluent.SchemaRegistry.CachedSchemaRegistryClient.RegisterSchemaAsync(String subject, Schema schema, Boolean no
      rmalize)
         at Kafka.Ksql.Linq.Serialization.Avro.Management.AvroSchemaRegistrationService.RegisterSchemaAsync(String subject, S
      tring avroSchema) in C:\Users\seiji_yfc8940\final\final\src\Serialization\Avro\Management\AvroSchemaRegistrationService
      .cs:line 100
         at Kafka.Ksql.Linq.Serialization.Avro.Management.AvroSchemaRegistrationService.RegisterEntitySchemaAsync(Type entity
      Type, AvroEntityConfiguration config) in C:\Users\seiji_yfc8940\final\final\src\Serialization\Avro\Management\AvroSchem
      aRegistrationService.cs:line 69
    C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs(84): error TESTERROR:
      Kafka.Ksql.Linq.Tests.Integration.DummyFlagSchemaRecognitionTests.DummyMessages_EnableQueries (224ms): エラー メッセージ: Syste
      m.InvalidOperationException : FATAL: KsqlContext initialization failed. Application cannot continue without Kafka conne
      ctivity.
      ---- Kafka.Ksql.Linq.Serialization.Avro.Exceptions.AvroSchemaRegistrationException : Failed to register schema for Orde
      r
      -------- Confluent.SchemaRegistry.SchemaRegistryException : Schema being registered is incompatible with an earlier sch
      ema for subject "orders-value", details: [{errorType:'NAME_MISMATCH', description:'The name of the schema has changed (
      path '/name')', additionalInfo:'expected: OrderValue'}, {oldSchemaVersion: 1}, {oldSchema: '{"type":"record","name":"Or
      derValue","fields":[{"name":"CustomerId","type":"int"},{"name":"dummy","type":"string"}]}'}, {compatibility: 'BACKWARD'
      }]; error code: 409
      スタック トレース:
         at Kafka.Ksql.Linq.Application.KsqlContext..ctor() in C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs:line 84
         at Kafka.Ksql.Linq.Tests.Integration.DummyFlagSchemaRecognitionTests.DummyContext..ctor()
         at InvokeStub_DummyContext..ctor(Object, Object, IntPtr*)
         at System.Reflection.MethodBaseInvoker.InvokeWithNoArgs(Object obj, BindingFlags invokeAttr)
      ----- Inner Stack Trace -----
         at Kafka.Ksql.Linq.Application.KsqlContext.RegisterSchemasSync(IReadOnlyDictionary`2 configurations) in C:\Users\sei
      ji_yfc8940\final\final\src\KsqlContext.cs:line 203
         at Kafka.Ksql.Linq.Application.KsqlContext.InitializeWithSchemaRegistration() in C:\Users\seiji_yfc8940\final\final\
      src\KsqlContext.cs:line 151
         at Kafka.Ksql.Linq.Application.KsqlContext..ctor() in C:\Users\seiji_yfc8940\final\final\src\KsqlContext.cs:line 59
      ----- Inner Stack Trace -----
         at Confluent.SchemaRegistry.RestService.ExecuteOnOneInstanceAsync(Func`1 createRequest)
         at Confluent.SchemaRegistry.RestService.RequestAsync[T](String endPoint, HttpMethod method, Object[] jsonBody)
         at Confluent.SchemaRegistry.RestService.RegisterSchemaAsync(String subject, Schema schema, Boolean normalize)
         at Confluent.SchemaRegistry.CachedSchemaRegistryClient.RegisterSchemaAsync(String subject, Schema schema, Boolean no
      rmalize)
         at Kafka.Ksql.Linq.Serialization.Avro.Management.AvroSchemaRegistrationService.RegisterSchemaAsync(String subject, S
      tring avroSchema) in C:\Users\seiji_yfc8940\final\final\src\Serialization\Avro\Management\AvroSchemaRegistrationService
      .cs:line 100
         at Kafka.Ksql.Linq.Serialization.Avro.Management.AvroSchemaRegistrationService.RegisterEntitySchemaAsync(Type entity
      Type, AvroEntityConfiguration config) in C:\Users\seiji_yfc8940\final\final\src\Serialization\Avro\Management\AvroSchem
      aRegistrationService.cs:line 69
    C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284): error TESTERROR:
      Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT Customer
      Id, Region, SUM(Amount) AS Total FR"...) (6ms): エラー メッセージ: SELECT CustomerId, Region, SUM(Amount) AS Total FROM orders
      GROUP BY CustomerId, Region HAVING (SUM(Amount) > 500) EMIT CHANGES; failed: {"@type":"statement_error","error_code":40
      001,"message":"Line: 1, Col: 90: GROUP BY column 'REGION' cannot be resolved.","statementText":"EXPLAIN SELECT Customer
      Id, Region, SUM(Amount) AS Total FROM orders GROUP BY CustomerId, Region HAVING (SUM(Amount) > 500) EMIT CHANGES;","ent
      ities":[]}
      Expected: True
      Actual:   False
      スタック トレース:
         at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql) in
      C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs:line 284
      --- End of stack trace from previous location ---
    C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284): error TESTERROR:
      Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT Customer
      Id, SUM(Amount) AS Total, COUNT(*) "...) (7ms): エラー メッセージ: SELECT CustomerId, SUM(Amount) AS Total, COUNT(*) AS Count,
      AVG(Amount) AS Avg FROM orders GROUP BY CustomerId HAVING (((SUM(Amount) > 1000) AND (COUNT(*) > 5)) OR (AVG(Amount) >
      500)) EMIT CHANGES; failed: {"@type":"statement_error","error_code":40001,"message":"Line: 1, Col: 134: HAVING column '
      AMOUNT' cannot be resolved.","statementText":"EXPLAIN SELECT CustomerId, SUM(Amount) AS Total, COUNT(*) AS Count, AVG(A
      mount) AS Avg FROM orders GROUP BY CustomerId HAVING (((SUM(Amount) > 1000) AND (COUNT(*) > 5)) OR (AVG(Amount) > 500))
       EMIT CHANGES;","entities":[]}
      Expected: True
      Actual:   False
      スタック トレース:
         at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql) in
      C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs:line 284
      --- End of stack trace from previous location ---
    C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284): error TESTERROR:
      Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT COUNT(*)
       FROM orders;") (6ms): エラー メッセージ: SELECT COUNT(*) FROM orders; failed: {"@type":"statement_error","error_code":40001,"m
      essage":"Pull queries don't support GROUP BY clauses. See https://cnfl.io/queries for more info.\nAdd EMIT CHANGES if y
      ou intended to issue a push query.","statementText":"EXPLAIN SELECT COUNT(*) FROM orders;","entities":[]}
      Expected: True
      Actual:   False
      スタック トレース:
         at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql) in
      C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs:line 284
      --- End of stack trace from previous location ---
    C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284): error TESTERROR:
      Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT Customer
      Id, Region, Amount FROM orders WHER"...) (7ms): エラー メッセージ: SELECT CustomerId, Region, Amount FROM orders WHERE Region N
      OT IN ('CN', 'RU') EMIT CHANGES; failed: {"@type":"statement_error","error_code":40001,"message":"Line: 1, Col: 61: WHE
      RE column 'REGION' cannot be resolved.","statementText":"EXPLAIN SELECT CustomerId, Region, Amount FROM orders WHERE Re
      gion NOT IN ('CN', 'RU') EMIT CHANGES;","entities":[]}
      Expected: True
      Actual:   False
      スタック トレース:
         at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql) in
      C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs:line 284
      --- End of stack trace from previous location ---
    C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284): error TESTERROR:
      Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT Customer
      Id, SUM(Amount) AS Total, CASE WHEN"...) (7ms): エラー メッセージ: SELECT CustomerId, SUM(Amount) AS Total, CASE WHEN (SUM(Amou
      nt) > 1000) THEN 'VIP' ELSE 'Regular' END AS Status FROM orders GROUP BY CustomerId EMIT CHANGES; failed: {"@type":"sta
      tement_error","error_code":40001,"message":"Line: 1, Col: 32: SELECT column 'AMOUNT' cannot be resolved.","statementTex
      t":"EXPLAIN SELECT CustomerId, SUM(Amount) AS Total, CASE WHEN (SUM(Amount) > 1000) THEN 'VIP' ELSE 'Regular' END AS St
      atus FROM orders GROUP BY CustomerId EMIT CHANGES;","entities":[]}
      Expected: True
      Actual:   False
      スタック トレース:
         at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql) in
      C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs:line 284
      --- End of stack trace from previous location ---
    C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284): error TESTERROR:
      Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT LATEST_B
      Y_OFFSET(Id) AS Last FROM orders;") (10ms): エラー メッセージ: SELECT LATEST_BY_OFFSET(Id) AS Last FROM orders; failed: {"@type
      ":"statement_error","error_code":40001,"message":"Line: 1, Col: 33: SELECT column 'ID' cannot be resolved.","statementT
      ext":"EXPLAIN SELECT LATEST_BY_OFFSET(Id) AS Last FROM orders;","entities":[]}
      Expected: True
      Actual:   False
      スタック トレース:
         at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql) in
      C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs:line 284
      --- End of stack trace from previous location ---
    C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284): error TESTERROR:
      Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT Customer
      Id, SUM(Amount) AS TotalAmount, SUM"...) (6ms): エラー メッセージ: SELECT CustomerId, SUM(Amount) AS TotalAmount, SUM(Count) AS
       TotalCount FROM orders GROUP BY CustomerId HAVING ((SUM(Amount) > 1000) OR (SUM(Count) > 5)) EMIT CHANGES; failed: {"@
      type":"statement_error","error_code":40001,"message":"Line: 1, Col: 126: HAVING column 'AMOUNT' cannot be resolved.","s
      tatementText":"EXPLAIN SELECT CustomerId, SUM(Amount) AS TotalAmount, SUM(Count) AS TotalCount FROM orders GROUP BY Cus
      tomerId HAVING ((SUM(Amount) > 1000) OR (SUM(Count) > 5)) EMIT CHANGES;","entities":[]}
      Expected: True
      Actual:   False
      スタック トレース:
         at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql) in
      C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs:line 284
      --- End of stack trace from previous location ---
    C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284): error TESTERROR:
      Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(ksql: "SELECT UPPER(Re
      gion), SUM(Amount) AS TotalAmount F"...) (10ms): エラー メッセージ: SELECT UPPER(Region), SUM(Amount) AS TotalAmount FROM order
      s GROUP BY UPPER(Region) HAVING (SUM(Amount) > 500) EMIT CHANGES; failed: {"@type":"statement_error","error_code":40001
      ,"message":"Line: 1, Col: 85: GROUP BY column 'REGION' cannot be resolved.","statementText":"EXPLAIN SELECT UPPER(Regio
      n), SUM(Amount) AS TotalAmount FROM orders GROUP BY UPPER(Region) HAVING (SUM(Amount) > 500) EMIT CHANGES;","entities":
      []}
      Expected: True
      Actual:   False
      スタック トレース:
         at Kafka.Ksql.Linq.Tests.Integration.DynamicKsqlGenerationTests.AllDmlQueries_ShouldBeValidInKsqlDb(String ksql) in
      C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs:line 284
      --- End of stack trace from previous location ---
    C:\Users\seiji_yfc8940\final\final\physicalTests\DynamicKsqlGenerationTests.cs(284): error TESTERROR:
      Kafka.Ksql.Linq.Tests.Integration.DynamicK
The file is too long and its contents have been truncated.
### tool — 2025-07-06T08:26:27.573292+00:00

Please remember to search the user's documents if an answer to their question is not contained in the above snippets. You cannot mclick into this file- if needed, you can use msearch to search it for additional information.
### assistant — 2025-07-06T08:26:54.104084+00:00

司令さん、[[REDACTED_PHONE]]:26 JSTです。

`SHOW TABLES;`の結果を拝見しました。

テーブルは５つ存在していますね。  
これはテストのCREATE TABLE文はテーブル作成自体は成功している可能性がありますが、

---

## 重要ポイント

- 先のエラーで「PRIMARY KEYがない」と言われていたので、テーブルの定義には必ずPRIMARY KEYを入れる必要があります。  
- しかしKSQL上の`SHOW TABLES`にはPRIMARY KEYの情報が出ないため、テーブルがあるだけでは「正しくPRIMARY KEYがある」とは限りません。  

---

## 次の確認・対応案

1. **テーブル定義の詳細を確認する**  
   KSQL CLIで以下コマンドを実行してテーブルの詳細DDLを確認してください。

   ```sql
   DESCRIBE EXTENDED ORDERS;
   DESCRIBE EXTENDED CUSTOMERS;
   ```

   これでテーブルのスキーマやPRIMARY KEY情報を確認できます。

2. **PRIMARY KEYが未設定なら再作成が必要**  
   - PRIMARY KEYが設定されていないテーブルは、DROPしてPRIMARY KEY指定付きで作り直すことをおすすめします。

3. **テストセットアップにDROP文を追加する**  
   - テスト実行前に既存のテーブル・ストリームをDROPすることでスキーマ競合を防止できます。

4. **Schema Registryのスキーマ状態も確認する**  
   - 古いスキーマ名や名前不一致による登録エラーが多いため、テスト用にスキーマを手動でリセットすることも検討してください。

---

テーブルの詳細情報を取得後、PRIMARY KEY有無と型の確認ができれば、次の修正案を具体的にお伝えできます。

---

必要でしたら、`DESCRIBE EXTENDED`の結果を教えてくださいね。
### user — 2025-07-06T08:26:54.370000+00:00

-----------------------------------------------------------------
ksql> show tables;

 Table Name          | Kafka Topic         | Key Format | Value Format | Windowed
----------------------------------------------------------------------------------
 CUSTOMERS           | customers           | KAFKA      | AVRO         | false
 ORDERS              | orders              | KAFKA      | AVRO         | false
 ORDERS_BY_REGION    | ORDERS_BY_REGION    | KAFKA      | AVRO         | false
 ORDERS_NULLABLE     | orders_nullable     | KAFKA      | AVRO         | false
 ORDERS_NULLABLE_KEY | orders_nullable_key | KAFKA      | AVRO         | false
----------------------------------------------------------------------------------
### assistant — 2025-07-06T08:27:57.089550+00:00

司令さん、[[REDACTED_PHONE]]:34 JSTです。

`ORDERS` と `CUSTOMERS` のテーブル定義にはPRIMARY KEYが正しく設定されていることが確認できました。  

これで以下の点はクリアです：

- PRIMARY KEY無しのエラーは回避可能な状態。
- テーブル定義自体はKSQL上で問題なさそう。

---
### しかし、テストで「REGION」や「AMOUNT」などのカラムが認識できないエラーが多発している原因としては、

- **テーブルのスキーマと実際に使われるAVROスキーマやスキーマレジストリの状態の不整合**  
- **テスト実行前に古いスキーマやテーブルが残ったままになっていることによる衝突・競合**  
- **テスト環境の初期化不足（DROPやスキーマ削除不足）**

が疑われます。

---

## 今後の対策としては

1. **テストセットアップにDROP TABLE文を追加する**  
   - `DROP TABLE IF EXISTS orders;` などをテスト実行前に入れることで既存のテーブル削除を明示的に行う。

2. **スキーマレジストリのスキーマをクリア（手動またはAPI）しておく**  
   - 過去のAVROスキーマが残っていると互換性エラーが起きるため、テスト環境ごとにスキーマリセットを行う。

3. **テストのスキーマ登録ロジックを見直す**  
   - 名前の不一致や型の不整合がないか、テストコードや初期スキーマ定義を再確認。

4. **テーブルのDDL実行とテスト実行のタイミングを整理**  
   - テーブル・ストリーム作成の成功を必ず確認してからテストを動かす。

---

もし可能なら、テストコードのテーブル/ストリーム作成部分にDROPを追加し、テスト前に環境をリセットしてから再実行してみてください。

何か必要があれば、テストコードの該当部分の修正例も作成しますのでお知らせください。
### user — 2025-07-06T08:27:57.303000+00:00

Name                 : ORDERS
 Field          | Type
-------------------------------------------------
 CUSTOMERID     | INTEGER          (primary key)
 ID             | INTEGER
 REGION         | VARCHAR(STRING)
 AMOUNT         | DECIMAL(38, 9)
 ISHIGHPRIORITY | BOOLEAN
 COUNT          | INTEGER
-------------------------------------------------
For runtime statistics and query details run: DESCRIBE <Stream,Table> EXTENDED;
ksql> DESCRIBE CUSTOMERS;

Name                 : CUSTOMERS
 Field | Type
----------------------------------------
 ID    | INTEGER          (primary key)
 NAME  | VARCHAR(STRING)
----------------------------------------
For runtime statistics and query details run: DESCRIBE <Stream,Table> EXTENDED;
### user — 2025-07-06T08:28:55.570000+00:00

いったんこっちで削除する
削除文を作成して
### assistant — 2025-07-06T08:28:55.601353+00:00

司令さん、[[REDACTED_PHONE]]:36 JSTです。

KSQLで既存のテーブルやストリームを削除するには、以下のようなDROP文を使います。

---
### テーブル削除（例）

```sql
DROP TABLE IF EXISTS orders DELETE TOPIC;
DROP TABLE IF EXISTS customers DELETE TOPIC;
DROP TABLE IF EXISTS orders_by_region DELETE TOPIC;
DROP TABLE IF EXISTS orders_nullable DELETE TOPIC;
DROP TABLE IF EXISTS orders_nullable_key DELETE TOPIC;
```

---
### ストリーム削除（存在すれば）

```sql
DROP STREAM IF EXISTS source DELETE TOPIC;
```

---

`DELETE TOPIC` を付けると対応するKafkaトピックも削除します。  
ただし、本番などでトピック削除が不要な場合は付けずにDROPのみでOKです。

---

これらを実行後にスキーマレジストリの状態も確認するとよりクリーンな状態になります。  
何かあればまたサポートしますね。
### user — 2025-07-06T08:31:30.396000+00:00

drop後の実行結果
### assistant — 2025-07-06T08:31:30.538358+00:00

司令さん、

アップロードされたログから読み取れる主な問題点は以下の通りです：

---
### 1. **スキーマ登録の衝突（SchemaRegistryException: NAME_MISMATCH）**

- エラー例：

```
Schema being registered is incompatible with an earlier schema for subject "orders-value"
details: [{errorType:'NAME_MISMATCH', description:'The name of the schema has changed (path '/name')', additionalInfo:'expected: OrderValue'}, ...]
```

- 原因  
  以前登録されたAvroスキーマの名前 (`OrderValue`) と、今回登録しようとしているスキーマ名 (`Order` など) が違うため、後方互換性が保てず登録拒否されている。

- 対策  
  - 既存スキーマの名前に合わせる（クラス名などを以前のスキーマ名 `OrderValue` に合わせる）  
  - スキーマレジストリ内の対象スキーマを手動で削除してリセットする（破壊的なので注意）  
  - スキーマの互換性設定（backward, full, none）を見直す  

---
### 2. **CREATE TABLE 文の PRIMARY KEY 指定不足**

- エラー例：

```
Tables require a PRIMARY KEY. Please define the PRIMARY KEY.
```

- 原因  
  KSQLのテーブル作成時に `PRIMARY KEY` が指定されていない。KSQLのテーブルは必ず `PRIMARY KEY` を持つ必要がある。

- 対策  
  - `CREATE TABLE` のDDL文に必ず `PRIMARY KEY` 指定を付ける。  
  例）  
  ```sql
  CREATE TABLE orders (
    CUSTOMERID INTEGER PRIMARY KEY,
    ID INTEGER,
    REGION STRING,
    AMOUNT DECIMAL(38,9),
    ISHIGHPRIORITY BOOLEAN,
    COUNT INTEGER
  ) WITH ( ... );
  ```

---
### 3. **クエリ中のカラム名解決エラー**

- エラー例：

```
GROUP BY column 'REGION' cannot be resolved.
SELECT column 'AMOUNT' cannot be resolved.
WHERE column 'REGION' cannot be resolved.
```

- 原因  
  - KSQLで参照しているストリームやテーブルのスキーマに該当カラムがない、または大文字小文字不一致  
  - テーブル名の大文字小文字違い（例：`orders` と `Orders`）  
  - カラム名のケースやスペルミス  

- 対策  
  - KSQLで定義済みのテーブル・ストリームのカラム名と完全一致させる  
  - カラム名の大文字小文字はKSQLでは大文字として扱われることが多いので注意  
  - `DESCRIBE` コマンドで実際のスキーマを確認して修正する  
  - クエリ中のテーブル名も正確に  

---
### 4. **プルクエリとプッシュクエリの誤用**

- エラー例：

```
Pull queries don't support GROUP BY clauses.
Add EMIT CHANGES if you intended to issue a push query.
```

- 原因  
  - `GROUP BY` を使うクエリは基本的にプッシュクエリ（ストリーム処理）になるため、`EMIT CHANGES`が必要  
  - プルクエリ（単純なスナップショット取得）には `GROUP BY` を含められない  

- 対策  
  - 集計クエリには必ず `EMIT CHANGES` を付ける  
  - プルクエリでは集計系を使わない  

---
### 5. **その他（ORDER BY句のSyntax Errorなど）**

- KSQLでは `ORDER BY` はPull Query限定、または特定条件のみ使用可能なため  
- `ORDER BY` をPush Query（ストリームクエリ）に付けるとエラーになることがある

---

## 今後の対応提案

1. **スキーマ登録名の整合を取る**  
   - C#のエンティティクラス名やAvroスキーマ名を既存登録のものに合わせるか、Schema Registryの該当スキーマを削除して初期化する。  
   - Schema Registryをリセットできるなら一度削除してクリーンな状態で再登録を試みる。

2. **DDL文のPRIMARY KEY指定を追加**  
   - 現行DDLのテーブル定義に `PRIMARY KEY` を必ず付けるよう修正してください。

3. **スキーマ・クエリの大文字小文字を見直し**  
   - KSQLのカラム・テーブル名は大文字が基本です。  
   - `Region` → `REGION` のように書き換えを推奨します。

4. **クエリのEMIT CHANGES付与**  
   - 集計クエリ、`GROUP BY` を含むクエリには必ず `EMIT CHANGES` を付けてください。

5. **テストコードの修正**  
   - テーブル・ストリーム名のケース、スキーマのPRIMARY KEY対応、クエリのEMIT CHANGES付加などをテストコード側で修正する必要があります。

---

もしSchema Registryを手動でクリアしたい場合は（注意して実行してください）、

```bash
# Schema RegistryのREST APIを使ってスキーマを削除
curl -X DELETE http://localhost:8081/subjects/orders-value
curl -X DELETE http://localhost:8081/subjects/customers-value
```

などでスキーマを削除し、その後テスト再実行をおすすめします。

---

必要であればDDLやクエリ修正例も作成しますので教えてくださいね。

  
[[REDACTED_PHONE]]:33 JST
### tool — 2025-07-06T08:31:38.673278+00:00

_(empty)_
