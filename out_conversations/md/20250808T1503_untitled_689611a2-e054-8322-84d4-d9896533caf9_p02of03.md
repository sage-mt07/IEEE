---
conversation_id: "689611a2-e054-8322-84d4-d9896533caf9"
title: "エンティティのストリーム化"
create_time: 1754665381.640783
update_time: 1754834040.123335
language_guess: "en"
num_messages: 386
part_index: 2
part_count: 3
---

### tool — 2025-08-08T18:08:36.862207+00:00

All the files uploaded by the user have been fully loaded. Searching won't provide additional information.
### assistant — 2025-08-08T18:08:37.140293+00:00

_(empty)_
### assistant — 2025-08-08T18:08:57.710857+00:00

_(empty)_
### user — 2025-08-08T18:11:30.335000+00:00

問題は、何をやろうとしてるのかがわかってなく
直近のコードをなんとかすればいいと考えてるようで
そうすると何も解決しない
reflectionがいなやのは、それで解決しなかったことと余計混乱したこと
### system — 2025-08-08T18:11:46.361757+00:00

_(empty)_
### assistant — 2025-08-08T18:11:46.413480+00:00

わかった。まずは**「何を解決したいのか」→「成功条件」→「設計の原則」→「実装の分担」**を一本に通す。  
コードは“結果”でしかない。先にここを固めよう。

# 1) 目的（何をやる？）
- **Kafka のトピックを RocksDB（Streamiz の state store）に堅牢にキャッシュする。**
- **アプリ側は entity（POCO）を読みたい時に `ToListAsync()` 等で即取得できる。**
- **キャッシュが未準備でもアプリを止めず、定義済みフォールバック（DB/REST等）で継続する。**

# 2) 成功条件（ゴールが達成された状態）
- 起動時に**ブロックしない**（RUNNING待ち禁止）。  
- **型安全**（`IReadOnlyKeyValueStore<TKey,TValue>` を直接使い、Bytes/byte[]や自前デシリアライズなし）。  
- **反射は原則不要**。ただし**“ランタイムで型が決まる自動登録”**をやるなら、**型を確定させる1点だけ最小限の反射**は現実的（ここが過去混乱の根）。  
- **障害時に落ちない**：InvalidStateStoreException でも**即フォールバック**。  
- **観測可能**：StateChanged/ストア解決/フォールバック利用がメトリクスとログに残る。  
- **テスト可能**：モックStreamsで RUNNING前/後・ダウン遷移を検証できる。

# 3) 設計の原則（ルール）
- **イベント≠同期ポイント**：`StateChanged(old,new)`は**フラグ更新だけ**。実ストア取得は**利用直前に lazy**。  
- **待機は“必要最小限・利用直前だけ”**、それ以外は**待たない**。  
- **フォールバックは必須**：未準備・エラーは必ずフォールバックに流す（例外で止めない）。  
- **変換は分離**：`TValue(Avro Specific)`→`POCO` 変換が必要なら**別ラッパ/マッパ層**に切り出す（混ぜない）。

# 4) 分割（何がどこで責務を持つ？）
- **CacheBootstrap（構成根）**  
  エンティティごとに**型明示で登録**（反射ゼロ案） or 自動登録（型決定に**最小反射1か所**）。  
  ここで：トポロジ構築→`KafkaStream`生成→**キャッシュ作成（イベント購読）**→**起動（waitなし）**。  
- **RocksDbTableCache<TKey,TValue>（読取責務）**  
  - `StateChanged`で**解決可能フラグだけ**立てる/降ろす。  
  - `ToListAsync/TryGet`で**初回のみストアをlazy解決**。失敗でも**即フォールバック**。  
- **TableCacheRegistry（探索責務）**  
  `TValue` と `storeName` でキャッシュを型安全に引く。  
- **（任意）Mapper層**  
  Avro Specific ≠ POCO の場合のみ導入。**ここに変換を書く**（キャッシュ本体に入れない）。

# 5) 過去の混乱を生んだ点と対処
- **反射を“悪”と断じた結果、型確定が必要な場面まで塞いだ** →  
  **方針を明確化**：  
  - **A: 反射ゼロ**＝**エンティティはコンパイル時に明示登録**（最もシンプル・堅牢）  
  - **B: 自動登録**＝**型確定1点のみ最小反射許容**（設置は Composition Root の1か所に限定。ドメイン側からは隠蔽）
- **イベントでStoreを即取りに行く** → **やらない**（RUNNING直後の揺らぎで失敗）。**lazy解決**で統一。  
- **Bytes/byte[] + 手デシリアライズ** → **封印**。**型付きストア**を使う。

# 6) 決めるべき4つ（Yes/No）
1. **登録方式**：  
   - ✅A: 反射ゼロ（**明示登録**）  
   - ☐B: 自動登録（**最小反射1点**を許容）
2. **値型**：`AvroValueType == POCO` にする？（**変換なし**で行ける）  
   - ✅はい → 変換層不要  
   - ☐いいえ → **Mapper層**を足す（キャッシュ本体には入れない）
3. **フォールバック先**：何を使う？（DB/REST/既存`IEntitySet`）  
   - ✅既存 `IEntitySet<T>` を使う（推奨）
4. **監視/メトリクス**：  
   - ✅`StateChanged`/`StoreResolved`/`FallbackUsed`/`TryGetHit/Miss` を計測

# 7) 実装の進め方（段取り）
- **Step 1: ADR（1ページ）**  
  上の方針をドキュメント化（登録方式A or B、変換有無、フォールバック、メトリクス）。  
- **Step 2: 最小実装**  
  - `CacheBootstrap.AddTableCache<TKey,TValue>`（反射ゼロ）  
  - `RocksDbTableCache<TKey,TValue>`（lazy解決＋フォールバック）  
  - `TableCacheRegistry`  
- **Step 3: 計測・ログ**  
  4種類のメトリクス＋構成ログを入れる。  
- **Step 4: 結合テスト**  
  - RUNNING前に `ToListAsync()` → **フォールバック**  
  - RUNNING後に `ToListAsync()` → **キャッシュ**  
  - ダウン遷移後に `ToListAsync()` → **再フォールバック**

---

ここに合意できれば、**選んだ登録方式（A/B）に合わせて**、/mnt/data の既存5ファイルへ**一括diff**（“つながる最終版”）を出します。  
まずは**A or B**、そして**変換の有無**を教えて。そこがブレない限り、もう“小手先の修正”で迷走しません。

— 送信日時（日本時間）: [[REDACTED_PHONE]]:58:50
### assistant — 2025-08-08T18:11:47.313539+00:00

_(empty)_
### assistant — 2025-08-08T18:11:50.061700+00:00

_(empty)_
### user — 2025-08-08T18:13:44.093000+00:00

このながれに沿うようにCacheをつくって
### system — 2025-08-08T18:14:00.128514+00:00

_(empty)_
### tool — 2025-08-08T18:14:00.158348+00:00

_(empty)_
### assistant — 2025-08-08T18:14:00.197310+00:00

了解。**KsqlContext → UseTableCache → TableCacheRegistry → ReadCachedEntitySet** という今の初期化フローに“そのまま噛み合う”キャッシュ実装を**丸ごと**出します。  
ポイントだけ：  
- **非ブロッキング**（StartAsyncは待たない）  
- **StateChanged(old,new)** は **Start前に購読**（購読はキャッシュ側のコンストラクタで完結）  
- **イベント内でStoreは取らない**（RUNNINGフラグだけON）→ **利用直前にlazy取得**  
- **型付きストア** `IReadOnlyKeyValueStore<TKey,TValue>` を直接使用（独自デシリアライズ禁止）  
- **未準備は即フォールバック**（例外にしない）

# RocksDbTableCache.cs（最終）
```csharp
using Microsoft.Extensions.Logging;
using Microsoft.Extensions.Logging.Abstractions;
using Streamiz.Kafka.Net;
using Streamiz.Kafka.Net.State;
using System;
using System.Collections.Generic;
using System.Threading;
using System.Threading.Tasks;

namespace Kafka.Ksql.Linq.Cache.Core
{
    /// <summary>
    /// 型付き RocksDB キャッシュ（Value = POCOをそのまま返す）
    /// - StartAsync を待たない
    /// - StateChanged(old,new) を Start 前に購読
    /// - イベントでは Store を取らない（RUNNINGフラグのみ）→ 利用直前に lazy 取得
    /// - 未準備は常にフォールバック
    /// </summary>
    internal sealed class RocksDbTableCache<TKey, TValue> where TValue : class
    {
        private readonly IKafkaStreams _streams;
        private readonly string _storeName;
        private readonly ILogger _log;
        private readonly IEntitySet<TValue> _fallback;

        private volatile IReadOnlyKeyValueStore<TKey, TValue>? _store;
        private int _canResolve; // 0=resolve禁止, 1=resolve試行OK（RUNNING後）

        public RocksDbTableCache(
            IKafkaStreams streams,
            string storeName,
            IEntitySet<TValue> fallback,
            ILoggerFactory? loggerFactory = null)
        {
            _streams   = streams ?? throw new ArgumentNullException(nameof(streams));
            _storeName = storeName ?? throw new ArgumentNullException(nameof(storeName));
            _fallback  = fallback  ?? throw new ArgumentNullException(nameof(fallback));
            _log = (loggerFactory ?? NullLoggerFactory.Instance)
                   .CreateLogger($"RocksDbTableCache<{typeof(TKey).Name},{typeof(TValue).Name}>");

            // ★ StartAsync の前に購読しておく（起動直後の RUNNING を取りこぼさない）
            _streams.StateChanged += OnStateChanged;
        }

        // 正しいシグネチャ: (oldState, newState)
        private void OnStateChanged(KafkaStream.State oldState, KafkaStream.State newState)
        {
            if (newState == KafkaStream.State.RUNNING)
            {
                Interlocked.Exchange(ref _canResolve, 1);
            }
            else if (newState == KafkaStream.State.PENDING_SHUTDOWN
                  || newState == KafkaStream.State.NOT_RUNNING
                  || newState == KafkaStream.State.ERROR)
            {
                _store = null;
                Interlocked.Exchange(ref _canResolve, 0);
            }
        }

        private void TryResolveStore()
        {
            if (_store != null) return;
            if (Volatile.Read(ref _canResolve) == 0) return;

            try
            {
                var p = StoreQueryParameters.FromNameAndType(
                    _storeName, QueryableStoreTypes.KeyValueStore<TKey, TValue>());
                _store = _streams.Store(p);
                _log.LogInformation("Store ready: {Store}", _storeName);
            }
            catch (InvalidStateStoreException)
            {
                // まだ開いていない。次の利用タイミングで再試行（待たない）
            }
        }

        public async Task<List<TValue>> ToListAsync(CancellationToken ct = default)
        {
            TryResolveStore();

            var s = _store;
            if (s == null)
            {
                _log.LogDebug("Cache not ready -> fallback: {Store}", _storeName);
                return await _fallback.ToListAsync(ct);
            }

            var list = new List<TValue>();
            foreach (var kv in s.All())
            {
                ct.ThrowIfCancellationRequested();
                list.Add(kv.Value);
            }
            return list;
        }

        /// <summary>キャッシュにあるときだけ返す（未準備時はfalse）</summary>
        public bool TryGet(TKey key, out TValue? value)
        {
            TryResolveStore();
            var s = _store;
            if (s == null) { value = null; return false; }
            return s.TryGet(key, out value);
        }
    }
}
```

# TableCacheRegistry.cs（最終）
```csharp
using System;
using System.Collections.Concurrent;

namespace Kafka.Ksql.Linq.Cache.Core
{
    /// <summary>
    /// キャッシュの型安全レジストリ: (typeof(TValue), storeName) -> RocksDbTableCache<TKey,TValue>
    /// </summary>
    internal sealed class TableCacheRegistry : IDisposable
    {
        private readonly ConcurrentDictionary<(Type valueType, string store), object> _map = new();

        public void Register<TKey, TValue>(string storeName, RocksDbTableCache<TKey, TValue> cache)
            where TValue : class
            => _map[(typeof(TValue), storeName)] = cache;

        public RocksDbTableCache<TKey, TValue>? Get<TKey, TValue>(string storeName)
            where TValue : class
            => _map.TryGetValue((typeof(TValue), storeName), out var o) ? (RocksDbTableCache<TKey, TValue>)o : null;

        // KsqlContext.InitializeWithSchemaRegistration() から呼ばれる想定のフック
        // ここでは特にフィルタ等はせず、将来のために受け口だけ提供
        public void RegisterEligibleTables(System.Collections.Generic.IEnumerable<Kafka.Ksql.Linq.Core.Modeling.EntityModel> models,
                                           System.Collections.Generic.IEnumerable<string> tableTopics)
        {
            // 必要なら対象の絞り込みなどを実装
        }

        public void Dispose() => _map.Clear();
    }
}
```

# ReadCachedEntitySet.cs（最終）
```csharp
using System.Collections.Generic;
using System.Threading;
using System.Threading.Tasks;
using Kafka.Ksql.Linq.Core.Modeling;

namespace Kafka.Ksql.Linq.Cache.Core
{
    /// <summary>
    /// POCO を返す読み取りエントリポイント。内部で TableCacheRegistry のキャッシュへ委譲し、
    /// 未準備時は baseSet（フォールバック）へ流す。
    /// </summary>
    internal sealed class ReadCachedEntitySet<T> : IEntitySet<T> where T : class
    {
        private readonly KsqlContext _context;
        private readonly EntityModel _model;
        private readonly IEntitySet<T> _baseSet;

        public ReadCachedEntitySet(KsqlContext context, EntityModel model, object? _unused, IEntitySet<T> baseSet)
        {
            _context = context;
            _model = model;
            _baseSet = baseSet;
        }

        public async Task<List<T>> ToListAsync(CancellationToken cancellationToken = default)
        {
            var registry = _context.GetTableCacheRegistry();
            var storeName = _context.GetResolvedEntityConfigs()[typeof(T)].StoreName
                            ?? _model.GetTopicName();

            // TKey 型はレジストリ側で確定済み（UseTableCacheのトポロジ構築時）
            // ここでは TValue = T だけを指定すれば取り出せる。
            var cache = registry.Get<object, T>(storeName);
            if (cache == null)
            {
                // キャッシュ未登録 → 素のセットへ委譲
                return await _baseSet.ToListAsync(cancellationToken);
            }

            return await cache.ToListAsync(cancellationToken);
        }
    }
}
```

# KsqlContextCacheExtensions.cs 側での接続（要点のみ）
- **KafkaStream の StartAsync を待たない**  
- **StateChanged(old,new) は Start 前に購読** …これは **RocksDbTableCache のコンストラクタ**でやります。  
- UseTableCache 側では、**トポロジ構築 → KafkaStream 生成 → RocksDbTableCache 生成（=イベント購読完了） → StartAsync** の順にしてください。  
  既にその順になっていればOKです（`StartWithRetryAsync` のような待機は廃止）。

> もし `UseTableCache` がリフレクションで `RocksDbTableCache<TKey,TValue>` を生成している場合も、この3ファイルはそのまま噛み合います。キャッシュのイベント購読は**コンストラクタ内**なので、**StartAsync 前に new されていれば大丈夫**です。

---

不足あれば、**あなたの `UseTableCache` 実装（該当の数行）**を貼ってください。  
順序が守れていればこの3ファイルで**KsqlContext → UseTableCache → Registry → ReadCachedEntitySet**の流れにきれいに繋がります。

— 送信日時（日本時間）: [[REDACTED_PHONE]]:12:47
### tool — 2025-08-08T18:14:00.216594+00:00

fileciteturn2file0

using Kafka.Ksql.Linq.Cache.Core;
using Kafka.Ksql.Linq.Cache.Extensions;
using Kafka.Ksql.Linq.Configuration;
using Kafka.Ksql.Linq.Core.Abstractions;
using Kafka.Ksql.Linq.Core.Attributes;
using Kafka.Ksql.Linq.Core.Dlq;
using Kafka.Ksql.Linq.Core.Extensions;
using Kafka.Ksql.Linq.Core.Modeling;
using Kafka.Ksql.Linq.Infrastructure.Admin;
using Kafka.Ksql.Linq.Infrastructure.KsqlDb;
using Kafka.Ksql.Linq.Mapping;
using Kafka.Ksql.Linq.Messaging.Consumers;
using Kafka.Ksql.Linq.Messaging.Producers;
using Kafka.Ksql.Linq.Query.Abstractions;
using Kafka.Ksql.Linq.SchemaRegistryTools;
using Microsoft.Extensions.Configuration;
using Microsoft.Extensions.Logging;
using System;
using System.Collections.Generic;
using System.Linq;
using System.Net.Http;
using System.Reflection;
using System.Text.Json;
using System.Threading;
using System.Threading.Tasks;
using ConfluentSchemaRegistry = Confluent.SchemaRegistry;

namespace Kafka.Ksql.Linq;
/// <summary>
/// KsqlContext that integrates the Core layer.
/// Design rationale: inherits core abstractions and integrates higher-level features.
/// </summary>
public abstract class KsqlContext : IKsqlContext
{
    private readonly KafkaProducerManager _producerManager;
    private readonly Dictionary<Type, EntityModel> _entityModels = new();
    private readonly Dictionary<Type, object> _entitySets = new();
    private readonly Dictionary<Type, Configuration.ResolvedEntityConfig> _resolvedConfigs = new();
    private bool _disposed = false;
    private readonly KafkaConsumerManager _consumerManager;
    private readonly DlqProducer _dlqProducer;
    private readonly Lazy<ConfluentSchemaRegistry.ISchemaRegistryClient> _schemaRegistryClient;
    private readonly IKsqlDbClient _ksqlDbClient;

    private readonly KafkaAdminService _adminService;
    private readonly KsqlDslOptions _dslOptions;
    private TableCacheRegistry? _cacheRegistry;
    private readonly MappingRegistry _mappingRegistry = new();
    private readonly ILogger _logger;
    private readonly ILoggerFactory? _loggerFactory;

    internal ILogger Logger => _logger; 



    /// <summary>
    /// Hook to decide whether schema registration should be skipped for tests
    /// </summary>
    protected virtual bool SkipSchemaRegistration => false;

    public const string DefaultSectionName = "KsqlDsl";

    protected KsqlContext(IConfiguration configuration,ILoggerFactory? loggerFactory=null)
        : this(configuration, DefaultSectionName,loggerFactory)
    {
    }

    protected KsqlContext(IConfiguration configuration, string sectionName,ILoggerFactory? loggerFactory=null)
    {
        _dslOptions = new KsqlDslOptions();
        configuration.GetSection(sectionName).Bind(_dslOptions);
        DecimalPrecisionConfig.DecimalPrecision = _dslOptions.DecimalPrecision;
        DecimalPrecisionConfig.DecimalScale = _dslOptions.DecimalScale;
        _loggerFactory = loggerFactory ?? configuration.CreateLoggerFactory();
        _logger = _loggerFactory.CreateLoggerOrNull<KsqlContext>();

        _schemaRegistryClient = new Lazy<ConfluentSchemaRegistry.ISchemaRegistryClient>(CreateSchemaRegistryClient);
        _ksqlDbClient = new KsqlDbClient(GetDefaultKsqlDbUrl());
        
        _adminService = new KafkaAdminService(
        Microsoft.Extensions.Options.Options.Create(_dslOptions),
        _loggerFactory);
        InitializeEntityModels();
        try
        {
            ConfigureModel();
            ResolveEntityConfigurations();

            _producerManager = new KafkaProducerManager(_mappingRegistry,
                Microsoft.Extensions.Options.Options.Create(_dslOptions),
                _loggerFactory);


            if (!SkipSchemaRegistration)
            {
                InitializeWithSchemaRegistration();
            }
            this.UseTableCache(_dslOptions, _loggerFactory);
            _cacheRegistry = this.GetTableCacheRegistry();

            _dlqProducer = new DlqProducer(
                _producerManager,
                _dslOptions.DlqOptions);
            _dlqProducer.InitializeAsync().GetAwaiter().GetResult();

            _consumerManager = new KafkaConsumerManager(_mappingRegistry,
                Microsoft.Extensions.Options.Options.Create(_dslOptions),
                _entityModels,
                _loggerFactory);
            _consumerManager.DeserializationError += (data, ex, topic, part, off, ts, headers, keyType, valueType) =>
                _dlqProducer.SendAsync(data, ex, topic, part, off, ts, headers, keyType, valueType);


        }
        catch (Exception ex)
        {
            _logger.LogError(ex, $"KsqlContext initialization failed: {ex.Message} (section: {sectionName})");
            throw;
        }
    }

    protected KsqlContext(KsqlDslOptions options,ILoggerFactory? loggerFactory=null)
    {
        _dslOptions = options;
        DecimalPrecisionConfig.DecimalPrecision = _dslOptions.DecimalPrecision;
        DecimalPrecisionConfig.DecimalScale = _dslOptions.DecimalScale;
        
        _schemaRegistryClient = new Lazy<ConfluentSchemaRegistry.ISchemaRegistryClient>(CreateSchemaRegistryClient);
        _ksqlDbClient = new KsqlDbClient(GetDefaultKsqlDbUrl());

        _loggerFactory = loggerFactory;
        _logger = _loggerFactory.CreateLoggerOrNull<KsqlContext>();


        _adminService = new KafkaAdminService(
        Microsoft.Extensions.Options.Options.Create(_dslOptions),
        _loggerFactory);
        InitializeEntityModels();
        try
        {
            ConfigureModel();
            ResolveEntityConfigurations();

            _producerManager = new KafkaProducerManager(_mappingRegistry,
                 Microsoft.Extensions.Options.Options.Create(_dslOptions),
                 _loggerFactory);



            if (!SkipSchemaRegistration)
            {
                InitializeWithSchemaRegistration();
            }
            this.UseTableCache(_dslOptions, _loggerFactory);
            _cacheRegistry = this.GetTableCacheRegistry();

            _dlqProducer = new DlqProducer(
                _producerManager,
                _dslOptions.DlqOptions);
            _dlqProducer.InitializeAsync().GetAwaiter().GetResult();

            _consumerManager = new KafkaConsumerManager(_mappingRegistry,
                Microsoft.Extensions.Options.Options.Create(_dslOptions),
                _entityModels,
                _loggerFactory);
            _consumerManager.DeserializationError += (data, ex, topic, part, off, ts, headers, keyType, valueType) =>
                _dlqProducer.SendAsync(data, ex, topic, part, off, ts, headers, keyType, valueType);

        }
        catch (Exception ex)
        {
            _logger.LogError(ex, $"KsqlContext initialization failed: {ex.Message} ");
            throw;
        }
    }

    protected virtual void OnModelCreating(IModelBuilder modelBuilder) { }

    public IEntitySet<T> Set<T>() where T : class
    {
        var entityType = typeof(T);

        if (entityType == typeof(Core.Models.DlqEnvelope))
        {
            return (IEntitySet<T>)GetDlqStream();
        }

        if (_entitySets.TryGetValue(entityType, out var existingSet))
        {
            return (IEntitySet<T>)existingSet;
        }

        var entityModel = GetOrCreateEntityModel<T>();
        var entitySet = CreateEntitySet<T>(entityModel);
        _entitySets[entityType] = entitySet;

        return entitySet;
    }

    public object GetEventSet(Type entityType)
    {
        if (_entitySets.TryGetValue(entityType, out var entitySet))
        {
            return entitySet;
        }

        var entityModel = GetOrCreateEntityModel(entityType);
        var createdSet = CreateEntitySet(entityType, entityModel);
        _entitySets[entityType] = createdSet;

        return createdSet;
    }

    public Dictionary<Type, EntityModel> GetEntityModels()
    {
        return new Dictionary<Type, EntityModel>(_entityModels);
    }

    public IReadOnlyDictionary<Type, Configuration.ResolvedEntityConfig> GetResolvedEntityConfigs()
    {
        return _resolvedConfigs;
    }

    private void InitializeEventSetProperties(ModelBuilder builder)
    {
        var contextType = GetType();
        var eventSetProps = contextType.GetProperties(BindingFlags.Instance | BindingFlags.Public)
            .Where(p => p.CanWrite
                && p.PropertyType.IsGenericType
                && p.PropertyType.GetGenericTypeDefinition() == typeof(EventSet<>));

        foreach (var prop in eventSetProps)
        {
            if (prop.GetValue(this) != null)
                continue;

            var entityType = prop.PropertyType.GetGenericArguments()[0];
            builder.AddEntityModel(entityType);
            var model = EnsureEntityModel(entityType);
            var set = CreateEntitySet(entityType, model);
            _entitySets[entityType] = set;
            prop.SetValue(this, set);
        }
    }

    protected virtual object CreateEntitySet(Type entityType, EntityModel entityModel)
    {
        var method = GetType()
            .GetMethods(BindingFlags.Instance | BindingFlags.Public | BindingFlags.NonPublic)
            .FirstOrDefault(m =>
                m.Name == nameof(CreateEntitySet)
                && m.IsGenericMethodDefinition
                && m.GetGenericArguments().Length == 1
                && m.GetParameters().Length == 1
                && m.GetParameters()[0].ParameterType == typeof(EntityModel)
            );

        if (method == null)
            throw new InvalidOperationException("Generic CreateEntitySet<T>(EntityModel) not found!");

        // このあと
        var genericMethod = method.MakeGenericMethod(entityType);
        return genericMethod.Invoke(this, new object[] { entityModel })!;
    }

    protected void ConfigureModel()
    {
        var modelBuilder = new ModelBuilder(_dslOptions.ValidationMode);
        InitializeEventSetProperties(modelBuilder);
        using (Kafka.Ksql.Linq.Core.Modeling.ModelCreatingScope.Enter())
        {
            OnModelCreating(modelBuilder);
        }
        ApplyModelBuilderSettings(modelBuilder);
    }

    private void ResolveEntityConfigurations()
    {
        _resolvedConfigs.Clear();

        foreach (var (type, model) in _entityModels)
        {
            if (type == typeof(Core.Models.DlqEnvelope))
                continue;

            var config = _dslOptions.Entities.FirstOrDefault(e => string.Equals(e.Entity, type.Name, StringComparison.OrdinalIgnoreCase));

            var defaultTopic = model.TopicName ?? type.Name.ToLowerInvariant();
            var sourceTopic = config?.SourceTopic ?? defaultTopic;

            var defaultCache = model.EnableCache;
            bool enableCache = false;
            if (model.StreamTableType== StreamTableType.Table)
            {
                enableCache = config?.EnableCache ?? defaultCache;
            }

            var defaultWindows = model.AdditionalSettings.TryGetValue("Windows", out var wObj) && wObj is IEnumerable<int> wList
                ? wList.ToList()
                : new List<int>();
            var windows = config?.Windows ?? defaultWindows;

            var defaultStore = model.AdditionalSettings.TryGetValue("StoreName", out var sObj) ? sObj?.ToString() : null;
            var storeName = config?.StoreName ?? defaultStore;

            string? groupId = null;
            if (_dslOptions.Topics.TryGetValue(sourceTopic, out var topicSection) && !string.IsNullOrEmpty(topicSection.Consumer.GroupId))
            {
                groupId = topicSection.Consumer.GroupId;
                if (!string.IsNullOrEmpty(model.GroupId) && model.GroupId != groupId)
                {
                    _logger.LogWarning("GroupId for {Entity} overridden by configuration: {Config} (was {Dsl})", type.Name, groupId, model.GroupId);
                }
            }
            else if (!string.IsNullOrEmpty(model.GroupId))
            {
                groupId = model.GroupId;
            }

            if (config != null && config.EnableCache != defaultCache)
            {
                _logger.LogInformation("EnableCache for {Entity} set to {Value} from configuration", type.Name, enableCache);
            }

            if (config != null && config.Windows.Count > 0 && defaultWindows.Count > 0 && !config.Windows.SequenceEqual(defaultWindows))
            {
                _logger.LogWarning("Windows for {Entity} overridden by configuration", type.Name);
            }

            var resolved = new Configuration.ResolvedEntityConfig
            {
                Entity = type.Name,
                SourceTopic = sourceTopic,
                GroupId = groupId,
                EnableCache = enableCache,
                Windows = new List<int>(windows),
                StoreName = storeName
            };

            foreach (var kv in model.AdditionalSettings)
            {
                resolved.AdditionalSettings[kv.Key] = kv.Value;
            }
            if (config?.BaseDirectory != null)
            {
                resolved.AdditionalSettings["BaseDirectory"] = config.BaseDirectory;
            }

            _resolvedConfigs[type] = resolved;
        }

        _dslOptions.Entities.Clear();
        foreach (var rc in _resolvedConfigs.Values)
        {
            _dslOptions.Entities.Add(new EntityConfiguration
            {
                Entity = rc.Entity,
                SourceTopic = rc.SourceTopic,
                EnableCache = rc.EnableCache,
                StoreName = rc.StoreName,
                Windows = rc.Windows,
                BaseDirectory = rc.AdditionalSettings.TryGetValue("BaseDirectory", out var bd) ? bd?.ToString() : null
            });
        }
    }

    private void InitializeEntityModels()
    {
        using (Kafka.Ksql.Linq.Core.Modeling.ModelCreatingScope.Enter())
        {
            var dlqModel = CreateEntityModelFromType(typeof(Core.Models.DlqEnvelope));
            var keyProp = typeof(Core.Models.DlqEnvelope).GetProperty(nameof(Core.Models.DlqEnvelope.MessageId));
            if (keyProp != null)
                dlqModel.KeyProperties = new[] { keyProp };
            dlqModel.SetStreamTableType(Query.Abstractions.StreamTableType.Stream);
            dlqModel.TopicName = GetDlqTopicName();
            dlqModel.AccessMode = Core.Abstractions.EntityAccessMode.ReadOnly;
            _entityModels[typeof(Core.Models.DlqEnvelope)] = dlqModel;
            _mappingRegistry.RegisterEntityModel(dlqModel);

        }
    }

    private void ApplyModelBuilderSettings(ModelBuilder modelBuilder)
    {
        var models = modelBuilder.GetAllEntityModels();
        foreach (var (type, model) in models)
        {
            if (_entityModels.TryGetValue(type, out var existing))
            {
                existing.SetStreamTableType(model.GetExplicitStreamTableType());
                existing.UseManualCommit = model.UseManualCommit;
                existing.ErrorAction = model.ErrorAction;
                existing.DeserializationErrorPolicy = model.DeserializationErrorPolicy;
                existing.EnableCache = model.EnableCache;
                existing.BarTimeSelector = model.BarTimeSelector;
            }
            else
            {
                _entityModels[type] = model;
            }

            // Register property metadata with MappingRegistry
            if (model.QueryModel != null)
            {
                RegisterQueryModelMapping(model);
            }
            else
            {
                _mappingRegistry.RegisterEntityModel(model);
            }
        }
    }

    private EntityModel GetOrCreateEntityModel<T>() where T : class
    {
        return GetOrCreateEntityModel(typeof(T));
    }

    private EntityModel GetOrCreateEntityModel(Type entityType)
    {
        if (_entityModels.TryGetValue(entityType, out var existingModel))
        {
            return existingModel;
        }

        var entityModel = CreateEntityModelFromType(entityType);
        _entityModels[entityType] = entityModel;
        return entityModel;
    }

    private EntityModel CreateEntityModelFromType(Type entityType)
    {
        var allProperties = entityType.GetProperties(System.Reflection.BindingFlags.Public | System.Reflection.BindingFlags.Instance);
        var keyProperties = allProperties
            .Select(p => new { Property = p, Attr = p.GetCustomAttribute<KsqlKeyAttribute>() })
            .Where(x => x.Attr != null)
            .OrderBy(x => x.Attr!.Order)
            .Select(x => x.Property)
            .ToArray();

        var model = new EntityModel
        {
            EntityType = entityType,
            TopicName = entityType.Name.ToLowerInvariant(),
            Partitions = 1,
            ReplicationFactor = 1,
            AllProperties = allProperties,
            KeyProperties = keyProperties
         
        };

        if (model.StreamTableType == StreamTableType.Stream)
        {
            model.EnableCache = false;
        }
        else
        {
            model.EnableCache = true;
        }
            var topicAttr = entityType.GetCustomAttribute<KsqlTopicAttribute>();
        if (topicAttr != null)
        {
            model.TopicName = topicAttr.Name;
            model.Partitions = topicAttr.PartitionCount;
            model.ReplicationFactor = topicAttr.ReplicationFactor;
        }

        var validation = new ValidationResult { IsValid = true };
        if (keyProperties.Length == 0)
        {
            validation.Warnings.Add($"No key properties defined for {entityType.Name}");
        }
        model.ValidationResult = validation;

        return model;
    }

    internal EntityModel EnsureEntityModel(Type entityType, EntityModel? model = null)
    {
        if (_entityModels.TryGetValue(entityType, out var existing))
            return existing;

        model ??= CreateEntityModelFromType(entityType);
        _entityModels[entityType] = model;
        _mappingRegistry.RegisterEntityModel(model);

        return model;
    }


    /// <summary>
    /// OnModelCreating → execute automatic schema registration flow
    /// </summary>
    private void InitializeWithSchemaRegistration()
    {
        // Register schemas and materialize entities if new
        using (Kafka.Ksql.Linq.Core.Modeling.ModelCreatingScope.Enter())
        {
            RegisterSchemasAndMaterializeAsync().GetAwaiter().GetResult();
        }

        var tableTopics = _ksqlDbClient.GetTableTopicsAsync().GetAwaiter().GetResult();
        _cacheRegistry?.RegisterEligibleTables(_entityModels.Values, tableTopics);

        // Verify Kafka connectivity
        ValidateKafkaConnectivity();
        EnsureKafkaReadyAsync().GetAwaiter().GetResult();
    }
    private async Task EnsureKafkaReadyAsync()
    {
        try
        {
            // Auto-create DLQ topic
            await _adminService.EnsureDlqTopicExistsAsync();

            // Additional connectivity check (performed by AdminService)
            _adminService.ValidateKafkaConnectivity();

            await _adminService.EnsureWindowFinalTopicsExistAsync(GetEntityModels());

            // Log output: DLQ preparation complete
            Logger.LogInformation("Kafka initialization completed; DLQ topic '{Topic}' ready with 5-second retention", GetDlqTopicName());
        }
        catch (Exception ex)
        {
            throw new InvalidOperationException(
                "FATAL: Kafka readiness check failed. DLQ functionality may be unavailable.", ex);
        }
    }
    public string GetDlqTopicName()
    {
        return _dslOptions.DlqTopicName;
    }
    /// <summary>
    /// Kafka接続確認
    /// </summary>
    private void ValidateKafkaConnectivity()
    {
        try
        {
            // Producer/Consumer初期化時点でKafka接続が確認される
            // 追加の接続確認は不要（既存の初期化処理で十分）
        }
        catch (Exception ex)
        {
            throw new InvalidOperationException(
                "FATAL: Cannot connect to Kafka. Verify bootstrap servers and network connectivity.", ex);
        }
    }

    /// <summary>
    /// Register schemas for all entities and send dummy record if newly created
    /// </summary>
    private async Task RegisterSchemasAndMaterializeAsync()
    {
        var client = _schemaRegistryClient.Value;

        foreach (var (type, model) in _entityModels)
        {
            if (type == typeof(Core.Models.DlqEnvelope))
                continue;

            SchemaRegistrationResult valueResult;
            try
            {
                var mapping = _mappingRegistry.GetMapping(type);

                if (model.HasKeys() && mapping.AvroKeySchema != null)
                {
                    var keySubject = $"{model.GetTopicName()}-key";
                    var keyResult = await client.RegisterSchemaIfNewAsync(keySubject, mapping.AvroKeySchema);
                    model.KeySchemaId = keyResult.SchemaId;
                }

                var valueSubject = $"{model.GetTopicName()}-value";
                valueResult = await client.RegisterSchemaIfNewAsync(valueSubject, mapping.AvroValueSchema!);
                model.ValueSchemaId = valueResult.SchemaId;
            }
            catch (ConfluentSchemaRegistry.SchemaRegistryException ex)
            {
                Logger.LogError(ex, "Schema registration failed for {Entity}", type.Name);
                throw;
            }

            if (model.QueryModel != null || model.QueryExpression != null)
            {
                await EnsureQueryEntityDdlAsync(type, model);
            }
            else
            {
                await EnsureSimpleEntityDdlAsync(type, model);
            }

            if (valueResult.WasCreated)
            {
                try
                {
                    var dummy = CreateDummyInstance(type);
                    var headers = new Dictionary<string, string> { ["is_dummy"] = "true" };
                    dynamic set = GetEventSet(type);
                    await set.AddAsync((dynamic)dummy, headers);
                }
                catch (Exception ex)
                {
                    Logger.LogError(ex, "Materialization failed for {Entity}", type.Name);
                    throw;
                }
            }
        }
    }

    /// <summary>
    /// Create topics and ksqlDB objects for an entity defined without queries.
    /// </summary>
    private async Task EnsureSimpleEntityDdlAsync(Type type, EntityModel model)
    {


        var generator = new Kafka.Ksql.Linq.Query.Pipeline.DDLQueryGenerator();

        var topic = model.GetTopicName();
        var partitions = 1;
        short replicas = 1;
        if (_dslOptions.Topics.TryGetValue(topic, out var config) && config.Creation != null)
        {
            partitions = config.Creation.NumPartitions;
            replicas = config.Creation.ReplicationFactor;
        }

        model.Partitions = partitions;
        model.ReplicationFactor = replicas;

        await _adminService.CreateDbTopicAsync(topic, partitions, replicas);

        string ddl;
        var schemaProvider = new Query.Ddl.EntityModelDdlAdapter(model);
        ddl = model.StreamTableType == StreamTableType.Table
            ? generator.GenerateCreateTable(schemaProvider)
            : generator.GenerateCreateStream(schemaProvider);

        var result = await ExecuteStatementAsync(ddl);
        if (!result.IsSuccess)
        {
            Logger.LogWarning("DDL execution failed for {Entity}: {Message}", type.Name, result.Message);
        }
    }

    /// <summary>
    /// Generate and execute CREATE TABLE/STREAM AS statements for query entities.
    /// </summary>
    private async Task EnsureQueryEntityDdlAsync(Type type, EntityModel model)
    {
        if (model.QueryModel != null)
        {
            RegisterQueryModelMapping(model);
            var sql = Query.Builders.KsqlCreateStatementBuilder.Build(
                model.GetTopicName(),
                model.QueryModel,
                model.KeySchemaId,
                model.ValueSchemaId);
            var result = await ExecuteStatementAsync(sql);
            if (!result.IsSuccess)
            {
                Logger.LogWarning("DDL execution failed for {Entity}: {Message}", type.Name, result.Message);
            }
            return;
        }

        // QueryModel が指定されていない場合は何もしない
    }

    /// <summary>
    /// Register mapping information for a query-defined entity using its KsqlQueryModel.
    /// </summary>
    private void RegisterQueryModelMapping(EntityModel model)
    {
        if (model.QueryModel == null)
            return;

        _mappingRegistry.RegisterQueryModel(
            model.EntityType,
            model.QueryModel,
            model.KeyProperties,
            model.GetTopicName());
    }


    private static object CreateDummyInstance(Type entityType)
    {
        var method = typeof(Application.DummyObjectFactory).GetMethod("CreateDummy")!
            .MakeGenericMethod(entityType);
        return method.Invoke(null, null)!;
    }


    /// <summary>
    /// SchemaRegistryClient作成
    /// </summary>
    private ConfluentSchemaRegistry.ISchemaRegistryClient CreateSchemaRegistryClient()
    {
        var options = _dslOptions.SchemaRegistry;
        var config = new ConfluentSchemaRegistry.SchemaRegistryConfig
        {
            Url = options.Url,
            MaxCachedSchemas = options.MaxCachedSchemas,
            RequestTimeoutMs = options.RequestTimeoutMs
        };

        return new ConfluentSchemaRegistry.CachedSchemaRegistryClient(config);
    }


    private Uri GetDefaultKsqlDbUrl()
    {
        if (!string.IsNullOrWhiteSpace(_dslOptions.KsqlDbUrl) &&
            Uri.TryCreate(_dslOptions.KsqlDbUrl, UriKind.Absolute, out var configured))
        {
            return configured;
        }

        var schemaUrl = _dslOptions.SchemaRegistry.Url;
        if (!string.IsNullOrWhiteSpace(schemaUrl) &&
            Uri.TryCreate(schemaUrl, UriKind.Absolute, out var schemaUri))
        {
            var port = schemaUri.IsDefaultPort || schemaUri.Port == 8081 ? 8088 : schemaUri.Port;
            return new Uri($"{schemaUri.Scheme}://{schemaUri.Host}:{port}");
        }

        // Default to localhost if nothing configured (test-friendly)
        return new Uri("http://localhost:8088");
    }
    private HttpClient CreateClient()
    {
        return new HttpClient { BaseAddress = GetDefaultKsqlDbUrl() };
    }

    public Task<KsqlDbResponse> ExecuteStatementAsync(string statement)
    {
        return _ksqlDbClient.ExecuteStatementAsync(statement);
    }

    public Task<KsqlDbResponse> ExecuteExplainAsync(string ksql)
    {
        return _ksqlDbClient.ExecuteExplainAsync(ksql);
    }



    /// <summary>
    /// Core層EventSet実装（上位層機能統合）
    /// </summary>
    protected virtual IEntitySet<T> CreateEntitySet<T>(EntityModel entityModel) where T : class
    {
        var model = EnsureEntityModel(typeof(T), entityModel);
        var baseSet = new EventSetWithServices<T>(this, model);
        if (model.GetExplicitStreamTableType() == StreamTableType.Table && model.EnableCache)
        {
            return new ReadCachedEntitySet<T>(this, model, null, baseSet);
        }
        return baseSet;
    }

    internal KafkaProducerManager GetProducerManager() => _producerManager;
    internal KafkaConsumerManager GetConsumerManager() => _consumerManager;
    internal DlqProducer GetDlqProducer() => _dlqProducer;
    internal ConfluentSchemaRegistry.ISchemaRegistryClient GetSchemaRegistryClient() => _schemaRegistryClient.Value;
    internal MappingRegistry GetMappingRegistry() => _mappingRegistry;

    private IEntitySet<Core.Models.DlqEnvelope> GetDlqStream()
    {
        var type = typeof(Core.Models.DlqEnvelope);
        if (_entitySets.TryGetValue(type, out var existing))
        {
            return (IEntitySet<Core.Models.DlqEnvelope>)existing;
        }

        var model = GetOrCreateEntityModel<Core.Models.DlqEnvelope>();
        var set = CreateEntitySet<Core.Models.DlqEnvelope>(model);
        _entitySets[type] = set;
        return set;
    }

    /// <summary>
    /// 指定したエンティティを手動でDLQへ送信します
    /// </summary>
    public async Task SendToDlqAsync<T>(T entity, Exception exception, string reason = "Manual")
    {
        if (_dlqProducer == null)
            throw new InvalidOperationException("DLQ producer not initialized");

        var messageContext = new KafkaMessageContext
        {
            MessageId = Guid.NewGuid().ToString(),
            Tags = new Dictionary<string, object>
            {
                ["original_topic"] = GetTopicName<T>(),
                ["entity_type"] = typeof(T).Name,
                ["error_phase"] = reason,
                ["manual_dlq"] = true
            }
        };

        var errorContext = new ErrorContext
        {
            Exception = exception,
            OriginalMessage = entity,
            AttemptCount = 1,
            FirstAttemptTime = DateTime.UtcNow,
            LastAttemptTime = DateTime.UtcNow,
            ErrorPhase = reason
        };

        await _dlqProducer.HandleErrorAsync(errorContext, messageContext);
    }

    /// <summary>
    /// エンティティ型からトピック名を取得します
    /// </summary>
    public string GetTopicName<T>()
    {
        var models = GetEntityModels();
        if (models.TryGetValue(typeof(T), out var model))
        {
            return (model.TopicName ?? typeof(T).Name).ToLowerInvariant();
        }
        return typeof(T).Name.ToLowerInvariant();
    }

    internal async Task<bool> IsEntityReadyAsync<T>(CancellationToken cancellationToken = default) where T : class
    {
        var models = GetEntityModels();
        if (!models.TryGetValue(typeof(T), out var model))
            return false;

        var statement = model.GetExplicitStreamTableType() == StreamTableType.Table
            ? "SHOW TABLES;"
            : "SHOW STREAMS;";

        var name = (model.TopicName ?? typeof(T).Name).ToUpperInvariant();
        var response = await ExecuteStatementAsync(statement);
        if (!response.IsSuccess)
            return false;

        try
        {
            using var doc = JsonDocument.Parse(response.Message);
            var listName = statement.Contains("TABLES") ? "tables" : "streams";
            foreach (var item in doc.RootElement.EnumerateArray())
            {
                if (!item.TryGetProperty(listName, out var arr))
                    continue;

                foreach (var element in arr.EnumerateArray())
                {
                    if (element.TryGetProperty("name", out var n) &&
                        string.Equals(n.GetString(), name, StringComparison.OrdinalIgnoreCase))
                    {
                        return true;
                    }
                }
            }
        }
        catch
        {
            // ignore parse errors
        }

        return false;
    }

    public async Task WaitForEntityReadyAsync<T>(TimeSpan timeout, CancellationToken cancellationToken = default) where T : class
    {
        var start = DateTime.UtcNow;
        while (DateTime.UtcNow - start < timeout)
        {
            if (await IsEntityReadyAsync<T>(cancellationToken))
                return;

            await Task.Delay(100, cancellationToken);
        }

        throw new TimeoutException($"Entity {typeof(T).Name} not ready after {timeout}.");
    }



    protected virtual void Dispose(bool disposing)
    {
        if (!_disposed && disposing)
        {
            foreach (var entitySet in _entitySets.Values)
            {
                if (entitySet is IDisposable disposable)
                {
                    disposable.Dispose();
                }
            }
            _entitySets.Clear();
            _entityModels.Clear();
            _disposed = true;

            _producerManager?.Dispose();
            _consumerManager?.Dispose();
            _dlqProducer?.Dispose();
            _adminService?.Dispose();
            _cacheRegistry?.Dispose();

            if (_schemaRegistryClient.IsValueCreated)
            {
                _schemaRegistryClient.Value?.Dispose();
            }
            (_ksqlDbClient as IDisposable)?.Dispose();
        }
    }

    public void Dispose()
    {
        Dispose(true);
        GC.SuppressFinalize(this);
    }

    public async ValueTask DisposeAsync()
    {
        await DisposeAsyncCore();
        Dispose(false);
        GC.SuppressFinalize(this);
    }

    protected virtual async ValueTask DisposeAsyncCore()
    {
        foreach (var entitySet in _entitySets.Values)
        {
            if (entitySet is IAsyncDisposable asyncDisposable)
            {
                await asyncDisposable.DisposeAsync();
            }
            else if (entitySet is IDisposable disposable)
            {
                disposable.Dispose();
            }
        }
        _entitySets.Clear();

        _producerManager?.Dispose();
        _consumerManager?.Dispose();
        _dlqProducer?.Dispose();
        _adminService?.Dispose();
        _cacheRegistry?.Dispose();

        if (_schemaRegistryClient.IsValueCreated)
        {
            _schemaRegistryClient.Value?.Dispose();
        }
        (_ksqlDbClient as IDisposable)?.Dispose();

        await Task.CompletedTask;
    }

    public override string ToString()
    {
        return $"KafkaContextCore: {_entityModels.Count} entities, {_entitySets.Count} sets [schema auto-registration ready]";
    }
}

/// <summary>
/// 上位層サービス統合EntitySet
/// 設計理由：IEntitySet<T>を直接実装し、Producer/Consumer機能を提供
/// </summary>
internal class EventSetWithServices<T> : EventSet<T> where T : class
{
    private readonly KsqlContext _ksqlContext;

    public EventSetWithServices(KsqlContext context, EntityModel entityModel)
        : base(context, entityModel)
    {
        _ksqlContext = context ?? throw new ArgumentNullException(nameof(context));
    }

    protected override async Task SendEntityAsync(T entity, Dictionary<string, string>? headers, CancellationToken cancellationToken)
    {
        var producerManager = _ksqlContext.GetProducerManager();
        var topic = GetTopicName();
        await producerManager.SendAsync(topic, entity, headers, cancellationToken);
    }

    public override async IAsyncEnumerator<T> GetAsyncEnumerator(CancellationToken cancellationToken = default)
    {
        var consumerManager = _ksqlContext.GetConsumerManager();
        await foreach (var (entity, _) in consumerManager.ConsumeAsync<T>(cancellationToken))
        {
            yield return entity;
        }
    }
}
### tool — 2025-08-08T18:14:00.267877+00:00

All the files uploaded by the user have been fully loaded. Searching won't provide additional information.
### assistant — 2025-08-08T18:14:00.944512+00:00

_(empty)_
### assistant — 2025-08-08T18:14:27.277644+00:00

_(empty)_
### user — 2025-08-08T18:16:21.703000+00:00

エントリポイントがないksqlContextとどうつながる？
### assistant — 2025-08-08T18:16:38.044759+00:00

了解。「**KsqlContext に“入口(エントリポイント)”を作って、そこでキャッシュを起動・登録・読取差し替え**」までを**反射なし**で一枚にまとめました。これを入れると、**KsqlContext →（Init）→ AddTableCache<,> → GetCachedSet<T>()**という流れで**POCOの `ToListAsync()`** がそのまま使えます。

---

```csharp
// ================== KsqlContext とキャッシュの“つながり”を作る一枚 ==================
// 反射/dynamic なし・Start待ちなし・StateChanged(old,new)はStart前に購読・型付きストア(lazy解決)
//
// 使い方（アプリ側）:
//   var ctx = new KsqlContext(...);
//   ctx.InitializeTableCache(new CacheRuntimeOptions{ BootstrapServers="...", SchemaRegistryUrl="...", StateDir="...", AppIdBase="cache-app" }, loggerFactory);
//   ctx.AddTableCache<OrderKey, Order>(topic: "orders", storeName: "orders-store", fallback: new DbOrderSet());
//   var list = await ctx.GetCachedSet<Order>().ToListAsync();    // ← POCO が返る
//
using Microsoft.Extensions.Logging;
using Microsoft.Extensions.Logging.Abstractions;
using Streamiz.Kafka.Net;
using Streamiz.Kafka.Net.SchemaRegistry.SerDes.Avro;
using Streamiz.Kafka.Net.State;
using Streamiz.Kafka.Net.Stream;
using System;
using System.Collections.Concurrent;
using System.Collections.Generic;
using System.Threading;
using System.Threading.Tasks;

// ====== あなたの既存：KsqlContext / IKsqlContext / IEntitySet<T> を想定 ======
public interface IKsqlContext
{
    IEntitySet<T> Set<T>() where T : class;              // 既存の“生”読み取り
}
public interface IEntitySet<T>
{
    Task<List<T>> ToListAsync(CancellationToken ct = default);
}

// ====== 1) KsqlContext に“入口”を生やす（partial でも OK） ======
public partial class KsqlContext : IKsqlContext
{
    private TableCacheRegistry? _cacheRegistry;
    private CacheRuntimeOptions? _cacheOpts;
    private ILoggerFactory? _lf;

    // エントリポイント①：キャッシュ環境の初期化（1回だけ）
    public void InitializeTableCache(CacheRuntimeOptions options, ILoggerFactory? loggerFactory = null)
    {
        _cacheOpts = options ?? throw new ArgumentNullException(nameof(options));
        _lf = loggerFactory;
        _cacheRegistry = new TableCacheRegistry();
    }

    // エントリポイント②：エンティティごとにキャッシュを“明示登録”（反射ゼロ）
    public void AddTableCache<TKey, TValue>(string topic, string storeName, IEntitySet<TValue> fallback)
        where TValue : class
    {
        if (_cacheOpts is null || _cacheRegistry is null)
            throw new InvalidOperationException("Call InitializeTableCache() first.");

        // 1) トポロジ（型安全）
        var builder = new StreamBuilder();
        builder.Stream<TKey, TValue>(topic)
               .ToTable(Materialized<TKey, TValue, IKeyValueStore<Bytes, byte[]>>
                   .Create(storeName)
                   .WithKeySerdes(new SchemaAvroSerDes<TKey>())
                   .WithValueSerdes(new SchemaAvroSerDes<TValue>()));

        // 2) KafkaStream
        var cfg = new StreamConfig<SchemaAvroSerDes<TKey>, SchemaAvroSerDes<TValue>>
        {
            ApplicationId     = $"{_cacheOpts.AppIdBase}-{storeName}",
            BootstrapServers  = _cacheOpts.BootstrapServers,
            SchemaRegistryUrl = _cacheOpts.SchemaRegistryUrl,
            StateDir          = _cacheOpts.StateDir,
            AutoOffsetReset   = AutoOffsetReset.Earliest
        };
        var stream = new KafkaStream(builder.Build(), cfg);

        // 3) キャッシュ作成（この時点で StateChanged(old,new) を購読、Storeはlazy解決）
        var cache = new RocksDbTableCache<TKey, TValue>(stream, storeName, fallback, _lf);

        // 4) レジストリ登録
        _cacheRegistry.Register(storeName, cache);

        // 5) 起動（待たない）
        _ = stream.StartAsync();
    }

    // エントリポイント③：POCOの読み取り口（キャッシュがあれば経由、無ければ生Set）
    public IEntitySet<T> GetCachedSet<T>() where T : class
    {
        if (_cacheRegistry is null) return Set<T>(); // キャッシュ未初期化なら生Set
        var storeName = InferStoreNameFromEntity<T>(); // 必要なら明示指定のオーバーロードを用意してもOK
        var cache = _cacheRegistry.Get<object, T>(storeName); // TKey はレジストリ側で保持、ここでは T=Value 型だけ指定
        return cache is null ? Set<T>() : new ReadCachedEntitySet<T>(cache, Set<T>());
    }

    // ストア名の決め方（必要なら上書き可能／設定で渡してもOK）
    private static string InferStoreNameFromEntity<T>() => typeof(T).Name.ToLowerInvariant();

    // 既存の生読み取り（あなたの実装のまま）
    public IEntitySet<T> Set<T>() where T : class => throw new NotImplementedException();
}

// ====== 2) キャッシュ本体（型付きストアを lazy で掴む／未準備は必ずフォールバック） ======
internal sealed class RocksDbTableCache<TKey, TValue> where TValue : class
{
    private readonly IKafkaStreams _streams;
    private readonly string _storeName;
    private readonly ILogger _log;
    private volatile IReadOnlyKeyValueStore<TKey, TValue>? _store;
    private int _canResolve; // 0=no, 1=try
    private readonly IEntitySet<TValue> _fallback;

    public RocksDbTableCache(IKafkaStreams streams, string storeName, IEntitySet<TValue> fallback, ILoggerFactory? lf = null)
    {
        _streams = streams ?? throw new ArgumentNullException(nameof(streams));
        _storeName = storeName ?? throw new ArgumentNullException(nameof(storeName));
        _fallback = fallback ?? throw new ArgumentNullException(nameof(fallback));
        _log = (lf ?? NullLoggerFactory.Instance).CreateLogger($"RocksDbTableCache<{typeof(TKey).Name},{typeof(TValue).Name}>");

        // StartAsync 前に必ず購読（起動直後RUNNINGの取りこぼし回避）
        _streams.StateChanged += OnStateChanged;
    }

    // 正しいシグネチャ: (oldState, newState)
    private void OnStateChanged(KafkaStream.State oldState, KafkaStream.State newState)
    {
        if (newState == KafkaStream.State.RUNNING)
            Interlocked.Exchange(ref _canResolve, 1);
        else if (newState == KafkaStream.State.PENDING_SHUTDOWN ||
                 newState == KafkaStream.State.NOT_RUNNING ||
                 newState == KafkaStream.State.ERROR)
        {
            _store = null;
            Interlocked.Exchange(ref _canResolve, 0);
        }
    }

    private void TryResolveStore()
    {
        if (_store != null) return;
        if (Volatile.Read(ref _canResolve) == 0) return;
        try
        {
            var p = StoreQueryParameters.FromNameAndType(_storeName, QueryableStoreTypes.KeyValueStore<TKey, TValue>());
            _store = _streams.Store(p); // まだなら InvalidStateStoreException → 黙って次回再試行
            _log.LogInformation("Store ready: {Store}", _storeName);
        }
        catch (InvalidStateStoreException) { /* ignore */ }
    }

    public async Task<List<TValue>> ToListAsync(CancellationToken ct = default)
    {
        TryResolveStore();

        var s = _store;
        if (s == null)
        {
            _log.LogDebug("Cache not ready -> fallback: {Store}", _storeName);
            return await _fallback.ToListAsync(ct);
        }

        var list = new List<TValue>();
        foreach (var kv in s.All())
        {
            ct.ThrowIfCancellationRequested();
            list.Add(kv.Value);
        }
        return list;
    }

    public bool TryGet(TKey key, out TValue? value)
    {
        TryResolveStore();
        var s = _store;
        if (s == null) { value = null; return false; }
        return s.TryGet(key, out value);
    }
}

// ====== 3) キャッシュ登録レジストリ（型安全） ======
internal sealed class TableCacheRegistry
{
    private readonly ConcurrentDictionary<(Type valType, string store), object> _map = new();

    public void Register<TKey, TValue>(string store, RocksDbTableCache<TKey, TValue> cache) where TValue : class
        => _map[(typeof(TValue), store)] = cache;

    public RocksDbTableCache<TKey, TValue>? Get<TKey, TValue>(string store) where TValue : class
        => _map.TryGetValue((typeof(TValue), store), out var o) ? (RocksDbTableCache<TKey, TValue>)o : null;
}

// ====== 4) キャッシュ経由の読み取りセット（POCO をそのまま返す） ======
internal sealed class ReadCachedEntitySet<T> : IEntitySet<T> where T : class
{
    private readonly RocksDbTableCache<object, T> _cache; // ※TKeyはレジストリ側で覚えている前提。実際はジェネリクス確定注入でもOK
    private readonly IEntitySet<T> _fallback;

    public ReadCachedEntitySet(object cache, IEntitySet<T> fallback)
    {
        _cache = (RocksDbTableCache<object, T>)cache;
        _fallback = fallback;
    }

    public Task<List<T>> ToListAsync(CancellationToken ct = default)
        => _cache.ToListAsync(ct);
}

// ====== 5) ランタイム共通オプション（KsqlContext.InitializeTableCache で渡す） ======
public sealed class CacheRuntimeOptions
{
    public string BootstrapServers { get; set; } = "";
    public string SchemaRegistryUrl { get; set; } = "";
    public string StateDir { get; set; } = "";
    public string AppIdBase { get; set; } = "cache-app";
}
```

---

## 接続の流れ（要点だけ）
1) **`KsqlContext.InitializeTableCache(options, loggerFactory)`**  
2) **`KsqlContext.AddTableCache<TKey,TEntity>(topic, storeName, fallback)`**  
   - **型安全**にトポロジ構築  
   - `KafkaStream`生成  
   - `RocksDbTableCache`生成（**ここで StateChanged を Start 前に購読**）  
   - レジストリ登録 → `StartAsync()` **非ブロッキング起動**  
3) **`ctx.GetCachedSet<TEntity>().ToListAsync()`**  
   - **キャッシュがREADYならRocksDBから**  
   - **未準備/ダウン時はフォールバックへ**（例外で止めない）

この“入口”があれば、**KsqlContext から自然にキャッシュへ繋がります**。  
もし `KsqlContext.cs` の具体APIが違うなら、そのメソッド名に合わせて**同じ責務のメソッド名/呼び出し位置**に差し替えます。必要ならそのファイル中の該当シグネチャを教えてください。こちらで**完全一致版**に直します。

— 送信日時（日本時間）: [[REDACTED_PHONE]]:25:40
### system — 2025-08-08T18:16:38.058671+00:00

_(empty)_
### assistant — 2025-08-08T18:16:38.888670+00:00

_(empty)_
### assistant — 2025-08-08T18:16:53.881985+00:00

_(empty)_
### user — 2025-08-08T18:18:26.359000+00:00

public void InitializeTableCache(CacheRuntimeOptions options, ILoggerFactory? loggerFactory = null)
    {
        _cacheOpts = options ?? throw new ArgumentNullException(nameof(options));
        _lf = loggerFactory;
        _cacheRegistry = new TableCacheRegistry();
    }
おかしい
### assistant — 2025-08-08T18:18:42.577589+00:00

{"queries":["InitializeTableCache site:/mnt/data --QDF=5","class +KsqlContext --QDF=5","TableCacheRegistry --QDF=5","UseTableCache --QDF=5"]}
### system — 2025-08-08T18:18:42.594704+00:00

_(empty)_
### assistant — 2025-08-08T18:18:43.550137+00:00

_(empty)_
### assistant — 2025-08-08T18:18:47.792127+00:00

司令、その指摘どおり。**`InitializeTableCache(...)` を KsqlContext に生やす案は“間違い”です。**  
このコードベースではすでに **KsqlContext のコンストラクタ → `UseTableCache(...)`** が正式なエントリポイント。ここに繋げるのが正解です。

# まず事実整理（どこが入口か）
- KsqlContext のコンストラクタ内で  
  `this.UseTableCache(_dslOptions, _loggerFactory);` が呼ばれてます（＝入口はここ）。 fileciteturn3file2L19-L21 fileciteturn3file2L75-L77  
  ※もう一つのオーバーロードのコンストラクタでも同じ呼び出しがあります。 fileciteturn3file6L27-L31
- `UseTableCache` の中で KafkaStream を作成し、`TableCacheRegistry.InitializeCaches(...)` で RocksDB キャッシュが初期化されます。 fileciteturn3file5L71-L86

**結論**：`InitializeTableCache(...)` を KsqlContext に追加する方向は不要＆ズレ。  
やるべきは **既存の `UseTableCache`/`RocksDbTableCache`/`MultiStreamizKafkaStreams` を「非ブロッキング＆正しいイベントシグネチャ＆不要な待機/反射最小」に直すこと。**

---

# 最小パッチ方針（入口は既存のまま、振る舞いだけ正す）
以下3点を直すと、「何をやってるか」が一貫し、KsqlContext と綺麗に繋がります。

## 1) `UseTableCache`：同期待ち廃止 & StateChangedシグネチャ修正
- **問題**: `StartWithRetryAsync(...)` で RUNNING 待ち→ブロッキング / 反射も多い。 fileciteturn3file9L36-L55  
- **対策**: **非ブロッキング起動**に変更。`CreateStream` 内の `StateChanged` も **(oldState, newState)** で受ける。

**diff（概略）**：
```diff
- multiStreams.AddStream(storeName, kafkaStream);
- StartWithRetryAsync(kafkaStream).GetAwaiter().GetResult();
+ // イベント購読は CreateStream 内。起動は投げっぱなしでOK
+ _ = kafkaStream.StartAsync();
+ multiStreams.AddStream(storeName, kafkaStream);
```
fileciteturn3file5L61-L66

```diff
- stream.StateChanged += (_, newState) =>
-     _logger.LogInformation("KafkaStream state changed to: {NewState}", newState);
+ stream.StateChanged += (oldState, newState) =>
+     _logger.LogInformation("KafkaStream state: {Old} -> {New}", oldState, newState);
```
fileciteturn3file7L66-L70

```diff
- private static async Task StartWithRetryAsync(...){ ... }  // 丸ごと削除
- private static async Task WaitUntilRunningAsync(...){ ... } // 丸ごと削除
- private static async Task RetryAsync(...){ ... }            // 丸ごと削除
```
fileciteturn3file9L36-L71

> 備考：`CreateMaterialized` の反射は**そのまま**でOK（設計都合でランタイムに型が決まるため）。まずは“待たない起動”に寄せるのが最優先。

## 2) `MultiStreamizKafkaStreams`：StateChanged の受け方を (old,new) に
- **問題**: `(sender, newState)` で受けている。 fileciteturn3file12L21-L22  
- **対策**: **(oldState, newState)** で受ける。

**diff（概略）**：
```diff
- stream.StateChanged += (_, newState) => _states[storeName] = newState;
+ stream.StateChanged += (oldState, newState) => _states[storeName] = newState;
```
fileciteturn3file12L21-L22

## 3) `RocksDbTableCache<T>`：ブロッキング初期化をやめ、lazy解決に
- **問題**: `InitializeAsync()` が RUNNING待ち／Restore待ち／Store初期化を**待ち続ける**実装。さらに **dynamic/反射 多用**。 fileciteturn3file13L48-L59 fileciteturn3file13L61-L69  
- **対策**:  
  - `InitializeAsync()` は**イベント購読と軽量初期化だけで即完了**に変更（=無意味ではない）  
  - `GetAll()/ToListAsync()` の**利用直前にだけ** `Store(...)` を **短いリトライで lazy 解決**  
  - 失敗時は**例外にせずフォールバック**（設計方針）  
  - 既存の `ITableCache<T>` 互換（`IsRunning` は “利用可能フラグ”として扱う）

**やること（概念）**：
- `InitializeAsync()`：`_streams.StateChanged += (old,new) => { if (new==RUNNING) _canResolve=1; else { _canResolve=0; _store=null; } }; return;`
- `GetAll()`：`try Store(...)、InvalidStateStoreException は握りつぶし→フォールバック`  
- dynamic の全面撤去は**別フェーズ**（レジストリ側が TKey を持っていない現行設計のため）。まずは**待たない & lazy & フォールバック**に寄せます。

---

# なぜこれで「何をやろうとしてるか」が明確になるか
- **入口**は **KsqlContext → `UseTableCache`**（既存の流れを尊重）  
- **ストリーム起動**は**非ブロッキング**（アプリを止めない）  
- **状態管理**は**イベントでフラグ更新のみ**（イベント＝同期ポイントにしない）  
- **実データ取得**は**利用直前にだけ** `Store(...)` を試みる（揺らぎにも強い）  
- **失敗しても止めない**（フォールバック）— これが**実利用の安定性**を担保

---

必要なら、上記3ファイルに対する**具体的な diff**をそのまま貼ります（そのままコピペ適用できる形）。  
今はまず「KsqlContext の入口に合わせる」点だけはガチッと共有したくて、要点だけ示しました。  
次、**diff いくつに分ける？（1つにまとめてもOK）**の指示ください。すぐ出します。

— 送信日時（日本時間）: [[REDACTED_PHONE]]:44:55
### tool — 2025-08-08T18:18:47.792759+00:00

_(empty)_
### assistant — 2025-08-08T18:19:14.421694+00:00

_(empty)_
### user — 2025-08-08T18:19:43.220000+00:00

一つの指摘は一つで返す。
### system — 2025-08-08T18:19:58.276013+00:00

_(empty)_
### assistant — 2025-08-08T18:19:58.314275+00:00

まず一点目の指摘として、  
この `InitializeTableCache` の中では **`_cacheRegistry` に対して `options` の内容を元に初期化処理を全く行っていない** のが問題です。  

現状だと `new TableCacheRegistry()` で空のレジストリを作るだけなので、  
どのテーブルをキャッシュ対象にするか、Kafka Streamsとの紐付け、Materializedストアの準備などが一切行われません。  

このため、`KsqlContext` 側から `ToListAsync` を呼んでもキャッシュは空のままになります。  
次は、この `options` の中身を使って実際に対象エンティティのキャッシュを構築する処理を組み込む必要があります。  

（次の指摘に進めますか？）
### user — 2025-08-08T18:20:34.840000+00:00

publicであることが問題。これは利用者に別途設定を強制しようとしている
### assistant — 2025-08-08T18:20:51.837206+00:00

指摘への対応：**`InitializeTableCache` は `public` にしないこと。**

- 問題点：`public` だと利用者に「別途初期化を呼べ」という契約を強制し、初期化漏れ・順序依存・二重初期化の温床になります。
- 修正：**非公開化**して**コンストラクタ（または既存の `UseTableCache` 呼出し箇所）からのみ内部で呼ぶ**。

最小差分例：
```diff
- public void InitializeTableCache(CacheRuntimeOptions options, ILoggerFactory? loggerFactory = null)
+ private void InitializeTableCache(CacheRuntimeOptions options, ILoggerFactory? loggerFactory = null)
{
    _cacheOpts = options ?? throw new ArgumentNullException(nameof(options));
    _lf = loggerFactory;
    _cacheRegistry = new TableCacheRegistry();
}
```
呼び出しは **KsqlContext のコンストラクタ内**だけに限定してください（外部に見せない）。

— 送信日時（日本時間）: [[REDACTED_PHONE]]:53:33
### system — 2025-08-08T18:20:51.856093+00:00

_(empty)_
### assistant — 2025-08-08T18:20:53.195636+00:00

_(empty)_
### assistant — 2025-08-08T18:21:02.484107+00:00

_(empty)_
### user — 2025-08-08T18:21:12.555000+00:00

InitializeTableCacheこれはどこでよぶ
### system — 2025-08-08T18:21:27.623112+00:00

_(empty)_
### assistant — 2025-08-08T18:21:27.693003+00:00

`InitializeTableCache` は本来、**`KsqlContext` が初期化されるときに一度だけ、内部で呼ばれるべき**です。  
つまり利用者が意識せずに Cache が使える状態になることが理想です。  

今回のコード構成を見る限り、自然な呼び出し位置は次のどちらかになります。  

---
### 1. `KsqlContext` のコンストラクタ内
`CacheRuntimeOptions` を `KsqlDslOptions` の一部として受け取れる設計なら、コンストラクタで初期化可能です。
```csharp
public KsqlContext(KsqlDslOptions options, ILoggerFactory? loggerFactory = null)
{
    _options = options;
    // 他の初期化処理...
    InitializeTableCache(options.CacheOptions, loggerFactory);
}
```
- メリット：外部呼び出し不要で、生成直後からキャッシュ利用可能。
- デメリット：`CacheOptions` が必須になる。

---
### 2. `UseTableCache` の中
既に `KsqlContextCacheExtensions` に `UseTableCache` があるので、その中で初期化すれば良いです。
```csharp
internal static void UseTableCache(this IKsqlContext context, KsqlDslOptions options, ILoggerFactory? loggerFactory = null)
{
    if (context is KsqlContext kc)
    {
        kc.InitializeTableCache(options.CacheOptions, loggerFactory);
    }

    // 既存のテーブル登録処理...
}
```
- メリット：`Cache` を使いたいときだけ初期化。
- デメリット：呼び忘れるとキャッシュ機能が動かない（なので API 設計で強制する必要あり）。

---

私のおすすめは **2 の `UseTableCache` 内呼び出し**です。  
理由は、キャッシュを使わない構成も OSS 利用者が選べるようにするためです。  
もし常に有効にするなら 1 のコンストラクタ呼び出しが適します。

---

次は、この初期化の中で `_streams` のセットアップも一緒に行って、`ToListAsync` が確実に動く構造にした方が良いです。  
これを組み込めば、今話していた **IN（entity）→OUT（POCO）** の流れがつながります。  

この流れ、作図して見せますか？  
そうすれば `KsqlContext` と Cache の接続が一目で分かる構造になります。
### user — 2025-08-08T18:22:56.803000+00:00

これを修正したものを提示
### system — 2025-08-08T18:23:23.759454+00:00

_(empty)_
### assistant — 2025-08-08T18:23:24.002424+00:00

了解。**結論だけ**。

# 修正内容（KsqlContext側）
- **`InitializeTableCache` は定義しない／呼ばない。**  
- KsqlContext のエントリポイントは**既に `UseTableCache(_dslOptions, _loggerFactory)`**になっているので、**KsqlContext.cs の修正は不要**。  
- つまり「どこで呼ぶか？」の答えは **KsqlContext のコンストラクタ内で `UseTableCache` を呼んでいる“ここ”** です。  
  あとは **`KsqlContextCacheExtensions` 側を修正**（`StartWithRetryAsync`撤廃、`StateChanged(old,new)`、非ブロッキング起動、イベントはStart前に購読）すれば流れは完成します。

👉 なので、このファイル（KsqlContext.cs）は**このままでOK**。直すべきは拡張側のみです。  
必要なら、**`KsqlContextCacheExtensions.cs` の最小パッチ**を一発で出します。どうする？

— 送信日時（日本時間）: [[REDACTED_PHONE]]:06:27
### tool — 2025-08-08T18:23:24.161144+00:00

_(empty)_
### tool — 2025-08-08T18:23:24.298956+00:00

fileciteturn4file0

using Kafka.Ksql.Linq.Cache.Core;
using Kafka.Ksql.Linq.Cache.Extensions;
using Kafka.Ksql.Linq.Configuration;
using Kafka.Ksql.Linq.Core.Abstractions;
using Kafka.Ksql.Linq.Core.Attributes;
using Kafka.Ksql.Linq.Core.Dlq;
using Kafka.Ksql.Linq.Core.Extensions;
using Kafka.Ksql.Linq.Core.Modeling;
using Kafka.Ksql.Linq.Infrastructure.Admin;
using Kafka.Ksql.Linq.Infrastructure.KsqlDb;
using Kafka.Ksql.Linq.Mapping;
using Kafka.Ksql.Linq.Messaging.Consumers;
using Kafka.Ksql.Linq.Messaging.Producers;
using Kafka.Ksql.Linq.Query.Abstractions;
using Kafka.Ksql.Linq.SchemaRegistryTools;
using Microsoft.Extensions.Configuration;
using Microsoft.Extensions.Logging;
using System;
using System.Collections.Generic;
using System.Linq;
using System.Net.Http;
using System.Reflection;
using System.Text.Json;
using System.Threading;
using System.Threading.Tasks;
using ConfluentSchemaRegistry = Confluent.SchemaRegistry;

namespace Kafka.Ksql.Linq;
/// <summary>
/// KsqlContext that integrates the Core layer.
/// Design rationale: inherits core abstractions and integrates higher-level features.
/// </summary>
public abstract class KsqlContext : IKsqlContext
{
    private readonly KafkaProducerManager _producerManager;
    private readonly Dictionary<Type, EntityModel> _entityModels = new();
    private readonly Dictionary<Type, object> _entitySets = new();
    private readonly Dictionary<Type, Configuration.ResolvedEntityConfig> _resolvedConfigs = new();
    private bool _disposed = false;
    private readonly KafkaConsumerManager _consumerManager;
    private readonly DlqProducer _dlqProducer;
    private readonly Lazy<ConfluentSchemaRegistry.ISchemaRegistryClient> _schemaRegistryClient;
    private readonly IKsqlDbClient _ksqlDbClient;

    private readonly KafkaAdminService _adminService;
    private readonly KsqlDslOptions _dslOptions;
    private TableCacheRegistry? _cacheRegistry;
    private readonly MappingRegistry _mappingRegistry = new();
    private readonly ILogger _logger;
    private readonly ILoggerFactory? _loggerFactory;

    internal ILogger Logger => _logger; 



    /// <summary>
    /// Hook to decide whether schema registration should be skipped for tests
    /// </summary>
    protected virtual bool SkipSchemaRegistration => false;

    public const string DefaultSectionName = "KsqlDsl";

    protected KsqlContext(IConfiguration configuration,ILoggerFactory? loggerFactory=null)
        : this(configuration, DefaultSectionName,loggerFactory)
    {
    }

    protected KsqlContext(IConfiguration configuration, string sectionName,ILoggerFactory? loggerFactory=null)
    {
        _dslOptions = new KsqlDslOptions();
        configuration.GetSection(sectionName).Bind(_dslOptions);
        DecimalPrecisionConfig.DecimalPrecision = _dslOptions.DecimalPrecision;
        DecimalPrecisionConfig.DecimalScale = _dslOptions.DecimalScale;
        _loggerFactory = loggerFactory ?? configuration.CreateLoggerFactory();
        _logger = _loggerFactory.CreateLoggerOrNull<KsqlContext>();

        _schemaRegistryClient = new Lazy<ConfluentSchemaRegistry.ISchemaRegistryClient>(CreateSchemaRegistryClient);
        _ksqlDbClient = new KsqlDbClient(GetDefaultKsqlDbUrl());
        
        _adminService = new KafkaAdminService(
        Microsoft.Extensions.Options.Options.Create(_dslOptions),
        _loggerFactory);
        InitializeEntityModels();
        try
        {
            ConfigureModel();
            ResolveEntityConfigurations();

            _producerManager = new KafkaProducerManager(_mappingRegistry,
                Microsoft.Extensions.Options.Options.Create(_dslOptions),
                _loggerFactory);


            if (!SkipSchemaRegistration)
            {
                InitializeWithSchemaRegistration();
            }
            this.UseTableCache(_dslOptions, _loggerFactory);
            _cacheRegistry = this.GetTableCacheRegistry();

            _dlqProducer = new DlqProducer(
                _producerManager,
                _dslOptions.DlqOptions);
            _dlqProducer.InitializeAsync().GetAwaiter().GetResult();

            _consumerManager = new KafkaConsumerManager(_mappingRegistry,
                Microsoft.Extensions.Options.Options.Create(_dslOptions),
                _entityModels,
                _loggerFactory);
            _consumerManager.DeserializationError += (data, ex, topic, part, off, ts, headers, keyType, valueType) =>
                _dlqProducer.SendAsync(data, ex, topic, part, off, ts, headers, keyType, valueType);


        }
        catch (Exception ex)
        {
            _logger.LogError(ex, $"KsqlContext initialization failed: {ex.Message} (section: {sectionName})");
            throw;
        }
    }

    protected KsqlContext(KsqlDslOptions options,ILoggerFactory? loggerFactory=null)
    {
        _dslOptions = options;
        DecimalPrecisionConfig.DecimalPrecision = _dslOptions.DecimalPrecision;
        DecimalPrecisionConfig.DecimalScale = _dslOptions.DecimalScale;
        
        _schemaRegistryClient = new Lazy<ConfluentSchemaRegistry.ISchemaRegistryClient>(CreateSchemaRegistryClient);
        _ksqlDbClient = new KsqlDbClient(GetDefaultKsqlDbUrl());

        _loggerFactory = loggerFactory;
        _logger = _loggerFactory.CreateLoggerOrNull<KsqlContext>();


        _adminService = new KafkaAdminService(
        Microsoft.Extensions.Options.Options.Create(_dslOptions),
        _loggerFactory);
        InitializeEntityModels();
        try
        {
            ConfigureModel();
            ResolveEntityConfigurations();

            _producerManager = new KafkaProducerManager(_mappingRegistry,
                 Microsoft.Extensions.Options.Options.Create(_dslOptions),
                 _loggerFactory);



            if (!SkipSchemaRegistration)
            {
                InitializeWithSchemaRegistration();
            }
            this.UseTableCache(_dslOptions, _loggerFactory);
            _cacheRegistry = this.GetTableCacheRegistry();

            _dlqProducer = new DlqProducer(
                _producerManager,
                _dslOptions.DlqOptions);
            _dlqProducer.InitializeAsync().GetAwaiter().GetResult();

            _consumerManager = new KafkaConsumerManager(_mappingRegistry,
                Microsoft.Extensions.Options.Options.Create(_dslOptions),
                _entityModels,
                _loggerFactory);
            _consumerManager.DeserializationError += (data, ex, topic, part, off, ts, headers, keyType, valueType) =>
                _dlqProducer.SendAsync(data, ex, topic, part, off, ts, headers, keyType, valueType);

        }
        catch (Exception ex)
        {
            _logger.LogError(ex, $"KsqlContext initialization failed: {ex.Message} ");
            throw;
        }
    }

    protected virtual void OnModelCreating(IModelBuilder modelBuilder) { }

    public IEntitySet<T> Set<T>() where T : class
    {
        var entityType = typeof(T);

        if (entityType == typeof(Core.Models.DlqEnvelope))
        {
            return (IEntitySet<T>)GetDlqStream();
        }

        if (_entitySets.TryGetValue(entityType, out var existingSet))
        {
            return (IEntitySet<T>)existingSet;
        }

        var entityModel = GetOrCreateEntityModel<T>();
        var entitySet = CreateEntitySet<T>(entityModel);
        _entitySets[entityType] = entitySet;

        return entitySet;
    }

    public object GetEventSet(Type entityType)
    {
        if (_entitySets.TryGetValue(entityType, out var entitySet))
        {
            return entitySet;
        }

        var entityModel = GetOrCreateEntityModel(entityType);
        var createdSet = CreateEntitySet(entityType, entityModel);
        _entitySets[entityType] = createdSet;

        return createdSet;
    }

    public Dictionary<Type, EntityModel> GetEntityModels()
    {
        return new Dictionary<Type, EntityModel>(_entityModels);
    }

    public IReadOnlyDictionary<Type, Configuration.ResolvedEntityConfig> GetResolvedEntityConfigs()
    {
        return _resolvedConfigs;
    }

    private void InitializeEventSetProperties(ModelBuilder builder)
    {
        var contextType = GetType();
        var eventSetProps = contextType.GetProperties(BindingFlags.Instance | BindingFlags.Public)
            .Where(p => p.CanWrite
                && p.PropertyType.IsGenericType
                && p.PropertyType.GetGenericTypeDefinition() == typeof(EventSet<>));

        foreach (var prop in eventSetProps)
        {
            if (prop.GetValue(this) != null)
                continue;

            var entityType = prop.PropertyType.GetGenericArguments()[0];
            builder.AddEntityModel(entityType);
            var model = EnsureEntityModel(entityType);
            var set = CreateEntitySet(entityType, model);
            _entitySets[entityType] = set;
            prop.SetValue(this, set);
        }
    }

    protected virtual object CreateEntitySet(Type entityType, EntityModel entityModel)
    {
        var method = GetType()
            .GetMethods(BindingFlags.Instance | BindingFlags.Public | BindingFlags.NonPublic)
            .FirstOrDefault(m =>
                m.Name == nameof(CreateEntitySet)
                && m.IsGenericMethodDefinition
                && m.GetGenericArguments().Length == 1
                && m.GetParameters().Length == 1
                && m.GetParameters()[0].ParameterType == typeof(EntityModel)
            );

        if (method == null)
            throw new InvalidOperationException("Generic CreateEntitySet<T>(EntityModel) not found!");

        // このあと
        var genericMethod = method.MakeGenericMethod(entityType);
        return genericMethod.Invoke(this, new object[] { entityModel })!;
    }

    protected void ConfigureModel()
    {
        var modelBuilder = new ModelBuilder(_dslOptions.ValidationMode);
        InitializeEventSetProperties(modelBuilder);
        using (Kafka.Ksql.Linq.Core.Modeling.ModelCreatingScope.Enter())
        {
            OnModelCreating(modelBuilder);
        }
        ApplyModelBuilderSettings(modelBuilder);
    }

    private void ResolveEntityConfigurations()
    {
        _resolvedConfigs.Clear();

        foreach (var (type, model) in _entityModels)
        {
            if (type == typeof(Core.Models.DlqEnvelope))
                continue;

            var config = _dslOptions.Entities.FirstOrDefault(e => string.Equals(e.Entity, type.Name, StringComparison.OrdinalIgnoreCase));

            var defaultTopic = model.TopicName ?? type.Name.ToLowerInvariant();
            var sourceTopic = config?.SourceTopic ?? defaultTopic;

            var defaultCache = model.EnableCache;
            bool enableCache = false;
            if (model.StreamTableType== StreamTableType.Table)
            {
                enableCache = config?.EnableCache ?? defaultCache;
            }

            var defaultWindows = model.AdditionalSettings.TryGetValue("Windows", out var wObj) && wObj is IEnumerable<int> wList
                ? wList.ToList()
                : new List<int>();
            var windows = config?.Windows ?? defaultWindows;

            var defaultStore = model.AdditionalSettings.TryGetValue("StoreName", out var sObj) ? sObj?.ToString() : null;
            var storeName = config?.StoreName ?? defaultStore;

            string? groupId = null;
            if (_dslOptions.Topics.TryGetValue(sourceTopic, out var topicSection) && !string.IsNullOrEmpty(topicSection.Consumer.GroupId))
            {
                groupId = topicSection.Consumer.GroupId;
                if (!string.IsNullOrEmpty(model.GroupId) && model.GroupId != groupId)
                {
                    _logger.LogWarning("GroupId for {Entity} overridden by configuration: {Config} (was {Dsl})", type.Name, groupId, model.GroupId);
                }
            }
            else if (!string.IsNullOrEmpty(model.GroupId))
            {
                groupId = model.GroupId;
            }

            if (config != null && config.EnableCache != defaultCache)
            {
                _logger.LogInformation("EnableCache for {Entity} set to {Value} from configuration", type.Name, enableCache);
            }

            if (config != null && config.Windows.Count > 0 && defaultWindows.Count > 0 && !config.Windows.SequenceEqual(defaultWindows))
            {
                _logger.LogWarning("Windows for {Entity} overridden by configuration", type.Name);
            }

            var resolved = new Configuration.ResolvedEntityConfig
            {
                Entity = type.Name,
                SourceTopic = sourceTopic,
                GroupId = groupId,
                EnableCache = enableCache,
                Windows = new List<int>(windows),
                StoreName = storeName
            };

            foreach (var kv in model.AdditionalSettings)
            {
                resolved.AdditionalSettings[kv.Key] = kv.Value;
            }
            if (config?.BaseDirectory != null)
            {
                resolved.AdditionalSettings["BaseDirectory"] = config.BaseDirectory;
            }

            _resolvedConfigs[type] = resolved;
        }

        _dslOptions.Entities.Clear();
        foreach (var rc in _resolvedConfigs.Values)
        {
            _dslOptions.Entities.Add(new EntityConfiguration
            {
                Entity = rc.Entity,
                SourceTopic = rc.SourceTopic,
                EnableCache = rc.EnableCache,
                StoreName = rc.StoreName,
                Windows = rc.Windows,
                BaseDirectory = rc.AdditionalSettings.TryGetValue("BaseDirectory", out var bd) ? bd?.ToString() : null
            });
        }
    }

    private void InitializeEntityModels()
    {
        using (Kafka.Ksql.Linq.Core.Modeling.ModelCreatingScope.Enter())
        {
            var dlqModel = CreateEntityModelFromType(typeof(Core.Models.DlqEnvelope));
            var keyProp = typeof(Core.Models.DlqEnvelope).GetProperty(nameof(Core.Models.DlqEnvelope.MessageId));
            if (keyProp != null)
                dlqModel.KeyProperties = new[] { keyProp };
            dlqModel.SetStreamTableType(Query.Abstractions.StreamTableType.Stream);
            dlqModel.TopicName = GetDlqTopicName();
            dlqModel.AccessMode = Core.Abstractions.EntityAccessMode.ReadOnly;
            _entityModels[typeof(Core.Models.DlqEnvelope)] = dlqModel;
            _mappingRegistry.RegisterEntityModel(dlqModel);

        }
    }

    private void ApplyModelBuilderSettings(ModelBuilder modelBuilder)
    {
        var models = modelBuilder.GetAllEntityModels();
        foreach (var (type, model) in models)
        {
            if (_entityModels.TryGetValue(type, out var existing))
            {
                existing.SetStreamTableType(model.GetExplicitStreamTableType());
                existing.UseManualCommit = model.UseManualCommit;
                existing.ErrorAction = model.ErrorAction;
                existing.DeserializationErrorPolicy = model.DeserializationErrorPolicy;
                existing.EnableCache = model.EnableCache;
                existing.BarTimeSelector = model.BarTimeSelector;
            }
            else
            {
                _entityModels[type] = model;
            }

            // Register property metadata with MappingRegistry
            if (model.QueryModel != null)
            {
                RegisterQueryModelMapping(model);
            }
            else
            {
                _mappingRegistry.RegisterEntityModel(model);
            }
        }
    }

    private EntityModel GetOrCreateEntityModel<T>() where T : class
    {
        return GetOrCreateEntityModel(typeof(T));
    }

    private EntityModel GetOrCreateEntityModel(Type entityType)
    {
        if (_entityModels.TryGetValue(entityType, out var existingModel))
        {
            return existingModel;
        }

        var entityModel = CreateEntityModelFromType(entityType);
        _entityModels[entityType] = entityModel;
        return entityModel;
    }

    private EntityModel CreateEntityModelFromType(Type entityType)
    {
        var allProperties = entityType.GetProperties(System.Reflection.BindingFlags.Public | System.Reflection.BindingFlags.Instance);
        var keyProperties = allProperties
            .Select(p => new { Property = p, Attr = p.GetCustomAttribute<KsqlKeyAttribute>() })
            .Where(x => x.Attr != null)
            .OrderBy(x => x.Attr!.Order)
            .Select(x => x.Property)
            .ToArray();

        var model = new EntityModel
        {
            EntityType = entityType,
            TopicName = entityType.Name.ToLowerInvariant(),
            Partitions = 1,
            ReplicationFactor = 1,
            AllProperties = allProperties,
            KeyProperties = keyProperties
         
        };

        if (model.StreamTableType == StreamTableType.Stream)
        {
            model.EnableCache = false;
        }
        else
        {
            model.EnableCache = true;
        }
            var topicAttr = entityType.GetCustomAttribute<KsqlTopicAttribute>();
        if (topicAttr != null)
        {
            model.TopicName = topicAttr.Name;
            model.Partitions = topicAttr.PartitionCount;
            model.ReplicationFactor = topicAttr.ReplicationFactor;
        }

        var validation = new ValidationResult { IsValid = true };
        if (keyProperties.Length == 0)
        {
            validation.Warnings.Add($"No key properties defined for {entityType.Name}");
        }
        model.ValidationResult = validation;

        return model;
    }

    internal EntityModel EnsureEntityModel(Type entityType, EntityModel? model = null)
    {
        if (_entityModels.TryGetValue(entityType, out var existing))
            return existing;

        model ??= CreateEntityModelFromType(entityType);
        _entityModels[entityType] = model;
        _mappingRegistry.RegisterEntityModel(model);

        return model;
    }


    /// <summary>
    /// OnModelCreating → execute automatic schema registration flow
    /// </summary>
    private void InitializeWithSchemaRegistration()
    {
        // Register schemas and materialize entities if new
        using (Kafka.Ksql.Linq.Core.Modeling.ModelCreatingScope.Enter())
        {
            RegisterSchemasAndMaterializeAsync().GetAwaiter().GetResult();
        }

        var tableTopics = _ksqlDbClient.GetTableTopicsAsync().GetAwaiter().GetResult();
        _cacheRegistry?.RegisterEligibleTables(_entityModels.Values, tableTopics);

        // Verify Kafka connectivity
        ValidateKafkaConnectivity();
        EnsureKafkaReadyAsync().GetAwaiter().GetResult();
    }
    private async Task EnsureKafkaReadyAsync()
    {
        try
        {
            // Auto-create DLQ topic
            await _adminService.EnsureDlqTopicExistsAsync();

            // Additional connectivity check (performed by AdminService)
            _adminService.ValidateKafkaConnectivity();

            await _adminService.EnsureWindowFinalTopicsExistAsync(GetEntityModels());

            // Log output: DLQ preparation complete
            Logger.LogInformation("Kafka initialization completed; DLQ topic '{Topic}' ready with 5-second retention", GetDlqTopicName());
        }
        catch (Exception ex)
        {
            throw new InvalidOperationException(
                "FATAL: Kafka readiness check failed. DLQ functionality may be unavailable.", ex);
        }
    }
    public string GetDlqTopicName()
    {
        return _dslOptions.DlqTopicName;
    }
    /// <summary>
    /// Kafka接続確認
    /// </summary>
    private void ValidateKafkaConnectivity()
    {
        try
        {
            // Producer/Consumer初期化時点でKafka接続が確認される
            // 追加の接続確認は不要（既存の初期化処理で十分）
        }
        catch (Exception ex)
        {
            throw new InvalidOperationException(
                "FATAL: Cannot connect to Kafka. Verify bootstrap servers and network connectivity.", ex);
        }
    }

    /// <summary>
    /// Register schemas for all entities and send dummy record if newly created
    /// </summary>
    private async Task RegisterSchemasAndMaterializeAsync()
    {
        var client = _schemaRegistryClient.Value;

        foreach (var (type, model) in _entityModels)
        {
            if (type == typeof(Core.Models.DlqEnvelope))
                continue;

            SchemaRegistrationResult valueResult;
            try
            {
                var mapping = _mappingRegistry.GetMapping(type);

                if (model.HasKeys() && mapping.AvroKeySchema != null)
                {
                    var keySubject = $"{model.GetTopicName()}-key";
                    var keyResult = await client.RegisterSchemaIfNewAsync(keySubject, mapping.AvroKeySchema);
                    model.KeySchemaId = keyResult.SchemaId;
                }

                var valueSubject = $"{model.GetTopicName()}-value";
                valueResult = await client.RegisterSchemaIfNewAsync(valueSubject, mapping.AvroValueSchema!);
                model.ValueSchemaId = valueResult.SchemaId;
            }
            catch (ConfluentSchemaRegistry.SchemaRegistryException ex)
            {
                Logger.LogError(ex, "Schema registration failed for {Entity}", type.Name);
                throw;
            }

            if (model.QueryModel != null || model.QueryExpression != null)
            {
                await EnsureQueryEntityDdlAsync(type, model);
            }
            else
            {
                await EnsureSimpleEntityDdlAsync(type, model);
            }

            if (valueResult.WasCreated)
            {
                try
                {
                    var dummy = CreateDummyInstance(type);
                    var headers = new Dictionary<string, string> { ["is_dummy"] = "true" };
                    dynamic set = GetEventSet(type);
                    await set.AddAsync((dynamic)dummy, headers);
                }
                catch (Exception ex)
                {
                    Logger.LogError(ex, "Materialization failed for {Entity}", type.Name);
                    throw;
                }
            }
        }
    }

    /// <summary>
    /// Create topics and ksqlDB objects for an entity defined without queries.
    /// </summary>
    private async Task EnsureSimpleEntityDdlAsync(Type type, EntityModel model)
    {


        var generator = new Kafka.Ksql.Linq.Query.Pipeline.DDLQueryGenerator();

        var topic = model.GetTopicName();
        var partitions = 1;
        short replicas = 1;
        if (_dslOptions.Topics.TryGetValue(topic, out var config) && config.Creation != null)
        {
            partitions = config.Creation.NumPartitions;
            replicas = config.Creation.ReplicationFactor;
        }

        model.Partitions = partitions;
        model.ReplicationFactor = replicas;

        await _adminService.CreateDbTopicAsync(topic, partitions, replicas);

        string ddl;
        var schemaProvider = new Query.Ddl.EntityModelDdlAdapter(model);
        ddl = model.StreamTableType == StreamTableType.Table
            ? generator.GenerateCreateTable(schemaProvider)
            : generator.GenerateCreateStream(schemaProvider);

        var result = await ExecuteStatementAsync(ddl);
        if (!result.IsSuccess)
        {
            Logger.LogWarning("DDL execution failed for {Entity}: {Message}", type.Name, result.Message);
        }
    }

    /// <summary>
    /// Generate and execute CREATE TABLE/STREAM AS statements for query entities.
    /// </summary>
    private async Task EnsureQueryEntityDdlAsync(Type type, EntityModel model)
    {
        if (model.QueryModel != null)
        {
            RegisterQueryModelMapping(model);
            var sql = Query.Builders.KsqlCreateStatementBuilder.Build(
                model.GetTopicName(),
                model.QueryModel,
                model.KeySchemaId,
                model.ValueSchemaId);
            var result = await ExecuteStatementAsync(sql);
            if (!result.IsSuccess)
            {
                Logger.LogWarning("DDL execution failed for {Entity}: {Message}", type.Name, result.Message);
            }
            return;
        }

        // QueryModel が指定されていない場合は何もしない
    }

    /// <summary>
    /// Register mapping information for a query-defined entity using its KsqlQueryModel.
    /// </summary>
    private void RegisterQueryModelMapping(EntityModel model)
    {
        if (model.QueryModel == null)
            return;

        _mappingRegistry.RegisterQueryModel(
            model.EntityType,
            model.QueryModel,
            model.KeyProperties,
            model.GetTopicName());
    }


    private static object CreateDummyInstance(Type entityType)
    {
        var method = typeof(Application.DummyObjectFactory).GetMethod("CreateDummy")!
            .MakeGenericMethod(entityType);
        return method.Invoke(null, null)!;
    }


    /// <summary>
    /// SchemaRegistryClient作成
    /// </summary>
    private ConfluentSchemaRegistry.ISchemaRegistryClient CreateSchemaRegistryClient()
    {
        var options = _dslOptions.SchemaRegistry;
        var config = new ConfluentSchemaRegistry.SchemaRegistryConfig
        {
            Url = options.Url,
            MaxCachedSchemas = options.MaxCachedSchemas,
            RequestTimeoutMs = options.RequestTimeoutMs
        };

        return new ConfluentSchemaRegistry.CachedSchemaRegistryClient(config);
    }


    private Uri GetDefaultKsqlDbUrl()
    {
        if (!string.IsNullOrWhiteSpace(_dslOptions.KsqlDbUrl) &&
            Uri.TryCreate(_dslOptions.KsqlDbUrl, UriKind.Absolute, out var configured))
        {
            return configured;
        }

        var schemaUrl = _dslOptions.SchemaRegistry.Url;
        if (!string.IsNullOrWhiteSpace(schemaUrl) &&
            Uri.TryCreate(schemaUrl, UriKind.Absolute, out var schemaUri))
        {
            var port = schemaUri.IsDefaultPort || schemaUri.Port == 8081 ? 8088 : schemaUri.Port;
            return new Uri($"{schemaUri.Scheme}://{schemaUri.Host}:{port}");
        }

        // Default to localhost if nothing configured (test-friendly)
        return new Uri("http://localhost:8088");
    }
    private HttpClient CreateClient()
    {
        return new HttpClient { BaseAddress = GetDefaultKsqlDbUrl() };
    }

    public Task<KsqlDbResponse> ExecuteStatementAsync(string statement)
    {
        return _ksqlDbClient.ExecuteStatementAsync(statement);
    }

    public Task<KsqlDbResponse> ExecuteExplainAsync(string ksql)
    {
        return _ksqlDbClient.ExecuteExplainAsync(ksql);
    }



    /// <summary>
    /// Core層EventSet実装（上位層機能統合）
    /// </summary>
    protected virtual IEntitySet<T> CreateEntitySet<T>(EntityModel entityModel) where T : class
    {
        var model = EnsureEntityModel(typeof(T), entityModel);
        var baseSet = new EventSetWithServices<T>(this, model);
        if (model.GetExplicitStreamTableType() == StreamTableType.Table && model.EnableCache)
        {
            return new ReadCachedEntitySet<T>(this, model, null, baseSet);
        }
        return baseSet;
    }

    internal KafkaProducerManager GetProducerManager() => _producerManager;
    internal KafkaConsumerManager GetConsumerManager() => _consumerManager;
    internal DlqProducer GetDlqProducer() => _dlqProducer;
    internal ConfluentSchemaRegistry.ISchemaRegistryClient GetSchemaRegistryClient() => _schemaRegistryClient.Value;
    internal MappingRegistry GetMappingRegistry() => _mappingRegistry;

    private IEntitySet<Core.Models.DlqEnvelope> GetDlqStream()
    {
        var type = typeof(Core.Models.DlqEnvelope);
        if (_entitySets.TryGetValue(type, out var existing))
        {
            return (IEntitySet<Core.Models.DlqEnvelope>)existing;
        }

        var model = GetOrCreateEntityModel<Core.Models.DlqEnvelope>();
        var set = CreateEntitySet<Core.Models.DlqEnvelope>(model);
        _entitySets[type] = set;
        return set;
    }

    /// <summary>
    /// 指定したエンティティを手動でDLQへ送信します
    /// </summary>
    public async Task SendToDlqAsync<T>(T entity, Exception exception, string reason = "Manual")
    {
        if (_dlqProducer == null)
            throw new InvalidOperationException("DLQ producer not initialized");

        var messageContext = new KafkaMessageContext
        {
            MessageId = Guid.NewGuid().ToString(),
            Tags = new Dictionary<string, object>
            {
                ["original_topic"] = GetTopicName<T>(),
                ["entity_type"] = typeof(T).Name,
                ["error_phase"] = reason,
                ["manual_dlq"] = true
            }
        };

        var errorContext = new ErrorContext
        {
            Exception = exception,
            OriginalMessage = entity,
            AttemptCount = 1,
            FirstAttemptTime = DateTime.UtcNow,
            LastAttemptTime = DateTime.UtcNow,
            ErrorPhase = reason
        };

        await _dlqProducer.HandleErrorAsync(errorContext, messageContext);
    }

    /// <summary>
    /// エンティティ型からトピック名を取得します
    /// </summary>
    public string GetTopicName<T>()
    {
        var models = GetEntityModels();
        if (models.TryGetValue(typeof(T), out var model))
        {
            return (model.TopicName ?? typeof(T).Name).ToLowerInvariant();
        }
        return typeof(T).Name.ToLowerInvariant();
    }

    internal async Task<bool> IsEntityReadyAsync<T>(CancellationToken cancellationToken = default) where T : class
    {
        var models = GetEntityModels();
        if (!models.TryGetValue(typeof(T), out var model))
            return false;

        var statement = model.GetExplicitStreamTableType() == StreamTableType.Table
            ? "SHOW TABLES;"
            : "SHOW STREAMS;";

        var name = (model.TopicName ?? typeof(T).Name).ToUpperInvariant();
        var response = await ExecuteStatementAsync(statement);
        if (!response.IsSuccess)
            return false;

        try
        {
            using var doc = JsonDocument.Parse(response.Message);
            var listName = statement.Contains("TABLES") ? "tables" : "streams";
            foreach (var item in doc.RootElement.EnumerateArray())
            {
                if (!item.TryGetProperty(listName, out var arr))
                    continue;

                foreach (var element in arr.EnumerateArray())
                {
                    if (element.TryGetProperty("name", out var n) &&
                        string.Equals(n.GetString(), name, StringComparison.OrdinalIgnoreCase))
                    {
                        return true;
                    }
                }
            }
        }
        catch
        {
            // ignore parse errors
        }

        return false;
    }

    public async Task WaitForEntityReadyAsync<T>(TimeSpan timeout, CancellationToken cancellationToken = default) where T : class
    {
        var start = DateTime.UtcNow;
        while (DateTime.UtcNow - start < timeout)
        {
            if (await IsEntityReadyAsync<T>(cancellationToken))
                return;

            await Task.Delay(100, cancellationToken);
        }

        throw new TimeoutException($"Entity {typeof(T).Name} not ready after {timeout}.");
    }



    protected virtual void Dispose(bool disposing)
    {
        if (!_disposed && disposing)
        {
            foreach (var entitySet in _entitySets.Values)
            {
                if (entitySet is IDisposable disposable)
                {
                    disposable.Dispose();
                }
            }
            _entitySets.Clear();
            _entityModels.Clear();
            _disposed = true;

            _producerManager?.Dispose();
            _consumerManager?.Dispose();
            _dlqProducer?.Dispose();
            _adminService?.Dispose();
            _cacheRegistry?.Dispose();

            if (_schemaRegistryClient.IsValueCreated)
            {
                _schemaRegistryClient.Value?.Dispose();
            }
            (_ksqlDbClient as IDisposable)?.Dispose();
        }
    }

    public void Dispose()
    {
        Dispose(true);
        GC.SuppressFinalize(this);
    }

    public async ValueTask DisposeAsync()
    {
        await DisposeAsyncCore();
        Dispose(false);
        GC.SuppressFinalize(this);
    }

    protected virtual async ValueTask DisposeAsyncCore()
    {
        foreach (var entitySet in _entitySets.Values)
        {
            if (entitySet is IAsyncDisposable asyncDisposable)
            {
                await asyncDisposable.DisposeAsync();
            }
            else if (entitySet is IDisposable disposable)
            {
                disposable.Dispose();
            }
        }
        _entitySets.Clear();

        _producerManager?.Dispose();
        _consumerManager?.Dispose();
        _dlqProducer?.Dispose();
        _adminService?.Dispose();
        _cacheRegistry?.Dispose();

        if (_schemaRegistryClient.IsValueCreated)
        {
            _schemaRegistryClient.Value?.Dispose();
        }
        (_ksqlDbClient as IDisposable)?.Dispose();

        await Task.CompletedTask;
    }

    public override string ToString()
    {
        return $"KafkaContextCore: {_entityModels.Count} entities, {_entitySets.Count} sets [schema auto-registration ready]";
    }
}

/// <summary>
/// 上位層サービス統合EntitySet
/// 設計理由：IEntitySet<T>を直接実装し、Producer/Consumer機能を提供
/// </summary>
internal class EventSetWithServices<T> : EventSet<T> where T : class
{
    private readonly KsqlContext _ksqlContext;

    public EventSetWithServices(KsqlContext context, EntityModel entityModel)
        : base(context, entityModel)
    {
        _ksqlContext = context ?? throw new ArgumentNullException(nameof(context));
    }

    protected override async Task SendEntityAsync(T entity, Dictionary<string, string>? headers, CancellationToken cancellationToken)
    {
        var producerManager = _ksqlContext.GetProducerManager();
        var topic = GetTopicName();
        await producerManager.SendAsync(topic, entity, headers, cancellationToken);
    }

    public override async IAsyncEnumerator<T> GetAsyncEnumerator(CancellationToken cancellationToken = default)
    {
        var consumerManager = _ksqlContext.GetConsumerManager();
        await foreach (var (entity, _) in consumerManager.ConsumeAsync<T>(cancellationToken))
        {
            yield return entity;
        }
    }
}
### tool — 2025-08-08T18:23:24.619637+00:00

All the files uploaded by the user have been fully loaded. Searching won't provide additional information.
### assistant — 2025-08-08T18:23:27.266996+00:00

_(empty)_
### assistant — 2025-08-08T18:23:44.637520+00:00

_(empty)_
### user — 2025-08-08T18:24:34.490000+00:00

これを修正
### system — 2025-08-08T18:24:51.182854+00:00

_(empty)_
### assistant — 2025-08-08T18:24:51.238535+00:00

（JST [[REDACTED_PHONE]]:12）

```csharp
using Confluent.Kafka;
using Kafka.Ksql.Linq.Cache.Configuration;
using Kafka.Ksql.Linq.Cache.Core;
using Kafka.Ksql.Linq.Configuration;
using Kafka.Ksql.Linq.Core.Abstractions;
using Kafka.Ksql.Linq.Core.Extensions;
using Microsoft.Extensions.Logging;
using Streamiz.Kafka.Net;
using Streamiz.Kafka.Net.Crosscutting;
using Streamiz.Kafka.Net.SchemaRegistry.SerDes.Avro;
using Streamiz.Kafka.Net.State;
using Streamiz.Kafka.Net.Table;
using System;
using System.Collections.Generic;
using System.Linq;
using System.Reflection;

namespace Kafka.Ksql.Linq.Cache.Extensions;

internal static class KsqlContextCacheExtensions
{
    private static readonly Dictionary<IKsqlContext, TableCacheRegistry> _registries = new();
    private static readonly object _lock = new();
    private static ILogger _logger;

    internal static void UseTableCache(this IKsqlContext context, KsqlDslOptions options, ILoggerFactory? loggerFactory = null,
        IKafkaStreams? streams = null)
    {
        _logger = loggerFactory.CreateLoggerOrNull<IKsqlContext>();

        lock (_lock)
        {
            if (_registries.ContainsKey(context))
                return;

            var mapping = ((KsqlContext)context).GetMappingRegistry();
            var models = context.GetEntityModels();

            if (options.Entities.Count == 0 || !options.Entities.Exists(e => e.EnableCache))
                return;

            // 起動（非ブロッキング）: エンティティごとに KafkaStream を作成し、即 StartAsync（待たない）
            if (streams == null)
            {
                var bootstrap = options.Common.BootstrapServers;
                var multiStreams = new MultiStreamizKafkaStreams();

                foreach (var entity in options.Entities.Where(e => e.EnableCache))
                {
                    var model = models.Values.FirstOrDefault(m =>
                        string.Equals(m.EntityType.Name, entity.Entity, StringComparison.OrdinalIgnoreCase));
                    if (model == null)
                        continue;

                    var kv = mapping.GetMapping(model.EntityType);
                    var storeName = entity.StoreName ?? model.GetTopicName();
                    var topic = model.GetTopicName();

                    var createStream = typeof(KsqlContextCacheExtensions)
                        .GetMethod(nameof(CreateStream), BindingFlags.NonPublic | BindingFlags.Static)!
                        .MakeGenericMethod(kv.AvroKeyType!, kv.AvroValueType!);

                    var kafkaStream = (KafkaStream)createStream.Invoke(null,
                        new object?[] { topic, storeName, bootstrap, options.SchemaRegistry.Url, loggerFactory })!;

                    // StartAsync の前に CreateStream 内で StateChanged を購読済み
                    _ = kafkaStream.StartAsync(); // 待たない・RUNNING待機をしない
                    multiStreams.AddStream(storeName, kafkaStream);
                }

                streams = multiStreams;
            }

            // レジストリ初期化とキャッシュ構築
            var registry = new TableCacheRegistry(mapping, streams, loggerFactory);
            var cacheOptions = new TableCacheOptions();
            foreach (var e in options.Entities)
            {
                cacheOptions.Entries.Add(new TableCacheEntry
                {
                    Entity = e.Entity,
                    SourceTopic = e.SourceTopic,
                    EnableCache = e.EnableCache,
                    StoreName = e.StoreName,
                    BaseDirectory = null
                });
            }
            var schemaClient = ((KsqlContext)context).GetSchemaRegistryClient();
            registry.InitializeCaches(context.GetEntityModels().Values, cacheOptions, schemaClient, loggerFactory);
            _registries[context] = registry;
        }
    }

    private static KafkaStream CreateStream<TKey, TValue>(string topic, string storeName, string bootstrap, string schemaRegistryUrl, ILoggerFactory? loggerFactory)
    {
        var builder = new StreamBuilder();
        builder.Stream<TKey, TValue>(topic)
               .ToTable(CreateMaterialized<TKey, TValue>(storeName));

        var config = new StreamConfig<SchemaAvroSerDes<TKey>, SchemaAvroSerDes<TValue>>
        {
            ApplicationId = $"cache-app-{storeName}",
            BootstrapServers = bootstrap,
            SchemaRegistryUrl = schemaRegistryUrl,
            // 本番では設定から渡すこと。ここでは従来の値を維持
            StateDir = @"C:\\Temp\\KAFKA_STATE",
            Logger = loggerFactory,
            CommitIntervalMs = 10000,
            AutoOffsetReset = AutoOffsetReset.Earliest,
            ClientId = Guid.NewGuid().ToString()
        };

        var stream = new KafkaStream(builder.Build(), config);

        // 正しいシグネチャ：(oldState, newState)
        stream.StateChanged += (oldState, newState) =>
            _logger.LogInformation("KafkaStream state changed: {Old} -> {New}", oldState, newState);

        return stream;
    }

    // 反射に頼らず素直に SerDes を指定する
    private static Materialized<TKey, TValue, IKeyValueStore<Bytes, byte[]>> CreateMaterialized<TKey, TValue>(string storeName)
    {
        return Materialized<TKey, TValue, IKeyValueStore<Bytes, byte[]>>
            .Create(storeName)
            .WithKeySerdes(new SchemaAvroSerDes<TKey>())
            .WithValueSerdes(new SchemaAvroSerDes<TValue>());
    }

    internal static TableCacheRegistry? GetTableCacheRegistry(this IKsqlContext context)
    {
        lock (_lock)
        {
            return _registries.TryGetValue(context, out var reg) ? reg : null;
        }
    }

    internal static ITableCache<T>? GetTableCache<T>(this IKsqlContext context) where T : class
    {
        var reg = context.GetTableCacheRegistry();
        return reg?.GetCache<T>();
    }
}
```
### tool — 2025-08-08T18:24:51.250485+00:00

_(empty)_
### tool — 2025-08-08T18:24:51.281089+00:00

fileciteturn5file0

using Confluent.Kafka;
using Kafka.Ksql.Linq.Cache.Configuration;
using Kafka.Ksql.Linq.Cache.Core;
using Kafka.Ksql.Linq.Configuration;
using Kafka.Ksql.Linq.Core.Abstractions;
using Kafka.Ksql.Linq.Core.Extensions;
using Microsoft.Extensions.Logging;
using Streamiz.Kafka.Net;
using Streamiz.Kafka.Net.Crosscutting;
using Streamiz.Kafka.Net.SchemaRegistry.SerDes.Avro;
using Streamiz.Kafka.Net.State;
using Streamiz.Kafka.Net.Table;
using System;
using System.Collections.Generic;
using System.Linq;
using System.Reflection;
using System.Threading.Tasks;

namespace Kafka.Ksql.Linq.Cache.Extensions;

internal static class KsqlContextCacheExtensions
{
    private static readonly Dictionary<IKsqlContext, TableCacheRegistry> _registries = new();
    private static readonly object _lock = new();
    private static ILogger _logger;
    internal static void UseTableCache(this IKsqlContext context, KsqlDslOptions options, ILoggerFactory? loggerFactory = null,
IKafkaStreams? streams = null)
    {
        _logger = loggerFactory.CreateLoggerOrNull<IKsqlContext>();
        lock (_lock)
        {
            if (_registries.ContainsKey(context))
                return;

            var mapping = ((KsqlContext)context).GetMappingRegistry();
            var models = context.GetEntityModels();

            if (options.Entities.Count == 0 || !options.Entities.Exists(e => e.EnableCache))
                return;

            if (streams == null)
            {
                var bootstrap = options.Common.BootstrapServers;
                var multiStreams = new MultiStreamizKafkaStreams();

                foreach (var entity in options.Entities.Where(e => e.EnableCache))
                {
                    var model = models.Values.FirstOrDefault(m =>
                        string.Equals(m.EntityType.Name, entity.Entity, StringComparison.OrdinalIgnoreCase));
                    if (model == null)
                        continue;

                    var kv = mapping.GetMapping(model.EntityType);
                    var storeName = entity.StoreName ?? model.GetTopicName();
                    var topic = model.GetTopicName();

                    var createStream = typeof(KsqlContextCacheExtensions)
                        .GetMethod(nameof(CreateStream), BindingFlags.NonPublic | BindingFlags.Static)!.
                        MakeGenericMethod(kv.AvroKeyType!, kv.AvroValueType!);

                    var kafkaStream = (KafkaStream)createStream.Invoke(null,
                        new object?[] { topic, storeName, bootstrap, options.SchemaRegistry.Url, loggerFactory })!;

                    multiStreams.AddStream(storeName, kafkaStream);
                    StartWithRetryAsync(kafkaStream).GetAwaiter().GetResult();
                }

                streams = multiStreams;
            }

            var registry = new TableCacheRegistry(mapping, streams, loggerFactory);
            var cacheOptions = new TableCacheOptions();
            foreach (var e in options.Entities)
            {
                cacheOptions.Entries.Add(new TableCacheEntry
                {
                    Entity = e.Entity,
                    SourceTopic = e.SourceTopic,
                    EnableCache = e.EnableCache,
                    StoreName = e.StoreName,
                    BaseDirectory = null
                });
            }
            var schemaClient = ((KsqlContext)context).GetSchemaRegistryClient();
            registry.InitializeCaches(context.GetEntityModels().Values, cacheOptions, schemaClient, loggerFactory);
            _registries[context] = registry;
        }
    }

    private static KafkaStream CreateStream<TKey, TValue>(string topic, string storeName, string bootstrap, string schemaRegistryUrl, ILoggerFactory? loggerFactory)
    {
        var builder = new StreamBuilder();
        builder.Stream<TKey, TValue>(topic)
               .ToTable(CreateMaterialized<TKey, TValue>(storeName));

        var config = new StreamConfig<SchemaAvroSerDes<TKey>, SchemaAvroSerDes<TValue>>
        {
            ApplicationId = $"cache-app-{storeName}",
            BootstrapServers = bootstrap,
            SchemaRegistryUrl = schemaRegistryUrl,
            StateDir = @"C:\\Temp\\KAFKA_STATE",
            Logger = loggerFactory,
            CommitIntervalMs = 10000,
            AutoOffsetReset = AutoOffsetReset.Earliest,
            ClientId = Guid.NewGuid().ToString()
        };

        var stream = new KafkaStream(builder.Build(), config);
        stream.StateChanged += (_, newState) =>
            _logger.LogInformation("KafkaStream state changed to: {NewState}", newState);

        return stream;
    }

    private static Materialized<TKey, TValue, IKeyValueStore<Bytes, byte[]>> CreateMaterialized<TKey, TValue>(string storeName)
    {
        var materializedType = typeof(Materialized<,,>).MakeGenericType(typeof(TKey), typeof(TValue), typeof(IKeyValueStore<Bytes, byte[]>));
        var createMethod = materializedType.GetMethods(BindingFlags.Public | BindingFlags.Static)
            .First(m => m.Name == "Create" && m.IsGenericMethodDefinition && m.GetParameters().Length == 1)
            .MakeGenericMethod(typeof(SchemaAvroSerDes<>).MakeGenericType(typeof(TKey)),
                               typeof(SchemaAvroSerDes<>).MakeGenericType(typeof(TValue)));
        return (Materialized<TKey, TValue, IKeyValueStore<Bytes, byte[]>>)createMethod.Invoke(null, new object[] { storeName })!;
    }

    private static async Task StartWithRetryAsync(KafkaStream stream, int retries = 3)
    {
        await RetryAsync(async () =>
        {
            await stream.StartAsync();
            await WaitUntilRunningAsync(stream);
        }, retries);
    }

    private static async Task WaitUntilRunningAsync(KafkaStream stream, TimeSpan? timeout = null)
    {
        var stateProp = typeof(KafkaStream).GetProperty("StreamState", BindingFlags.Instance | BindingFlags.NonPublic | BindingFlags.Public);
        var end = DateTime.UtcNow + (timeout ?? TimeSpan.FromSeconds(30));
        while ((KafkaStream.State)stateProp!.GetValue(stream)! != KafkaStream.State.RUNNING)
        {
            if (DateTime.UtcNow > end)
                throw new TimeoutException("KafkaStream failed to reach RUNNING state");
            await Task.Delay(100);
        }
    }

    private static async Task RetryAsync(Func<Task> action, int retries = 3, int delayMs = 1000)
    {
        for (var attempt = 0; attempt < retries; attempt++)
        {
            try
            {
                await action();
                return;
            }
            catch when (attempt < retries - 1)
            {
                await Task.Delay(delayMs);
            }
        }
    }

    internal static TableCacheRegistry? GetTableCacheRegistry(this IKsqlContext context)
    {
        lock (_lock)
        {
            return _registries.TryGetValue(context, out var reg) ? reg : null;
        }
    }

    internal static ITableCache<T>? GetTableCache<T>(this IKsqlContext context) where T : class
    {
        var reg = context.GetTableCacheRegistry();
        return reg?.GetCache<T>();
    }
}
### tool — 2025-08-08T18:24:51.334651+00:00

All the files uploaded by the user have been fully loaded. Searching won't provide additional information.
### assistant — 2025-08-08T18:24:51.868741+00:00

_(empty)_
### assistant — 2025-08-08T18:25:04.151651+00:00

_(empty)_
### user — 2025-08-08T18:25:56.780000+00:00

だめ
### assistant — 2025-08-08T18:26:12.671133+00:00

指摘①：**`UseTableCache` 内で `MakeGenericMethod`＋`Invoke` を使っており、”反射/動的禁止”に反します。**
### 修正方針（この一点のみ）
- 反射を廃止し、**コンパイル時に型が確定する汎用ヘルパ** `AddTableCache<TKey,TValue>` を用意。  
- **`UseTableCache` からは起動処理を外す**（= ここで型を扱わない）。  
- 呼び出し側（Composition Root など）が **エンティティごとに `AddTableCache<,>` を呼ぶ**。
### 変更コード（最小）

```csharp
// 追加：反射なしの型安全API
internal static class KsqlContextCacheExtensions
{
    internal static KafkaStream AddTableCache<TKey, TValue>(
        string topic, string storeName, string bootstrap, string schemaRegistryUrl, ILoggerFactory? loggerFactory,
        MultiStreamizKafkaStreams aggregator)
    {
        var builder = new StreamBuilder();
        builder.Stream<TKey, TValue>(topic)
               .ToTable(Materialized<TKey, TValue, IKeyValueStore<Bytes, byte[]>>
                   .Create(storeName)
                   .WithKeySerdes(new SchemaAvroSerDes<TKey>())
                   .WithValueSerdes(new SchemaAvroSerDes<TValue>()));

        var cfg = new StreamConfig<SchemaAvroSerDes<TKey>, SchemaAvroSerDes<TValue>>
        {
            ApplicationId     = $"cache-app-{storeName}",
            BootstrapServers  = bootstrap,
            SchemaRegistryUrl = schemaRegistryUrl,
            StateDir          = @"C:\Temp\KAFKA_STATE",
            Logger            = loggerFactory,
            AutoOffsetReset   = AutoOffsetReset.Earliest
        };

        var stream = new KafkaStream(builder.Build(), cfg);
        stream.StateChanged += (oldState, newState) =>
            loggerFactory?.CreateLogger("KafkaStream")
                ?.LogInformation("KafkaStream state: {Old}->{New}", oldState, newState);

        _ = stream.StartAsync();         // 待たない
        aggregator.AddStream(storeName, stream);
        return stream;
    }

    // 既存の UseTableCache からは「反射による型確定＆起動」の処理を削除する
    // → ここでは registry 初期化など “型に依存しないこと” だけを行う
}
```

> 呼び出し例（反射禁止のため、**コンパイル時に型が確定している場所**で呼ぶ）：  
> `KsqlContextCacheExtensions.AddTableCache<MyKey, MyEntity>(topic, store, bootstrap, schemaUrl, loggerFactory, multiStreams);`

— 送信日時（日本時間）: [[REDACTED_PHONE]]:18:39
### system — 2025-08-08T18:26:12.685417+00:00

_(empty)_
### assistant — 2025-08-08T18:26:13.695622+00:00

_(empty)_
### assistant — 2025-08-08T18:26:23.154536+00:00

_(empty)_
### user — 2025-08-08T18:26:39.952000+00:00

stream.StateChanged += (oldState, newState) =>
            loggerFactory?.CreateLogger("KafkaStream")
                ?.LogInformation("KafkaStream state: {Old}->{New}", oldState, newState);

        _ = stream.StartAsync();         // 待たない
これが問題
### assistant — 2025-08-08T18:26:55.873601+00:00

（JST [[REDACTED_PHONE]]:25）

指摘の一点：**`StartAsync()` の戻り値（Task）を捨てているため、起動失敗が握りつぶされる**のが問題です。  
ついでに、**イベント内で毎回 `CreateLogger` している**のも無駄なアロケーションになります。
### 修正（失敗検知＋ロガーの再利用）
```csharp
// 事前にロガーを1回だけ作る
var log = loggerFactory?.CreateLogger("KafkaStream") ?? Microsoft.Extensions.Logging.Abstractions.NullLogger.Instance;

// Start前に購読（ロガーは再利用）
stream.StateChanged += (oldState, newState) =>
    log.LogInformation("KafkaStream[{Store}] state: {Old} -> {New}", storeName, oldState, newState);

// fire-and-forgetだが、失敗は必ずログに出す
_ = stream.StartAsync().ContinueWith(t =>
{
    if (t.IsFaulted && t.Exception != null)
        log.LogError(t.Exception, "KafkaStream[{Store}] failed to start.", storeName);
}, TaskScheduler.Default);
```

これで：
- **起動例外を確実に検出・記録**（タスクを放置しない）
- **ロガーの都度生成を廃止**（イベントごとの不要アロケ回避）

次の指摘に進めますか？
### system — 2025-08-08T18:26:56.124205+00:00

_(empty)_
### assistant — 2025-08-08T18:26:56.340437+00:00

_(empty)_
### assistant — 2025-08-08T18:27:02.169736+00:00

_(empty)_
### user — 2025-08-08T18:27:13.585000+00:00

指摘の意図を
### user — 2025-08-08T18:27:25.339000+00:00

組んでいないので、全体がまとまらない
### system — 2025-08-08T18:27:28.645096+00:00

_(empty)_
### assistant — 2025-08-08T18:27:28.735988+00:00

（JST [[REDACTED_PHONE]]:28）  

今回の指摘の意図は、  

1. **起動失敗が握りつぶされている**  
   - `_ = stream.StartAsync();` ではタスクの結果を捨ててしまい、`StartAsync()` が例外で失敗しても気付けません。  
   - そのため、接続設定ミスやKafkaの起動不良など、本来検出すべき障害が黙殺されます。  

2. **ロガーの無駄な生成**  
   - イベントハンドラ内で `loggerFactory?.CreateLogger("KafkaStream")` を毎回呼び出すと、StateChangedイベントが発生するたびにロガーオブジェクトを作ります。  
   - ロガーは通常スレッドセーフで再利用可能なので、事前に一度だけ作って使い回すべきです。  

つまり、  
> 「現在のコードだと、KafkaStreamの起動時エラーを見逃し、かつロガー生成コストを無駄に払っている」  

というのが私の指摘の核心です。  

これ、次は **`StateChanged` の購読と `StartAsync()` 呼び出しの順序の妥当性** の話に進められます。
### assistant — 2025-08-08T18:27:44.042615+00:00

わかった。「組めてない→全体がまとまらない」件、まず**起動まわりを“1か所に集約”して完成形にする**ところから固めよう。  
下は **KsqlContextCacheExtensions.cs の最小・一体化**（イベント購読→非ブロッキング起動→失敗検知まで）だけを“完成形”で提示する。これを入れれば、少なくとも起動の配線は**組み上がる**。

```csharp
using Confluent.Kafka;
using Kafka.Ksql.Linq.Cache.Configuration;
using Kafka.Ksql.Linq.Cache.Core;
using Kafka.Ksql.Linq.Configuration;
using Kafka.Ksql.Linq.Core.Abstractions;
using Kafka.Ksql.Linq.Core.Extensions;
using Microsoft.Extensions.Logging;
using Streamiz.Kafka.Net;
using Streamiz.Kafka.Net.SchemaRegistry.SerDes.Avro;
using Streamiz.Kafka.Net.State;
using Streamiz.Kafka.Net.Stream;
using System;
using System.Collections.Generic;
using System.Linq;
using System.Reflection;
using System.Threading.Tasks;

namespace Kafka.Ksql.Linq.Cache.Extensions;

internal static class KsqlContextCacheExtensions
{
    private static readonly Dictionary<IKsqlContext, TableCacheRegistry> _registries = new();
    private static readonly object _lock = new();

    internal static void UseTableCache(
        this IKsqlContext context,
        KsqlDslOptions options,
        ILoggerFactory? loggerFactory = null,
        IKafkaStreams? streams = null)
    {
        var log = loggerFactory?.CreateLogger("KsqlContextCache") ?? Microsoft.Extensions.Logging.Abstractions.NullLogger.Instance;

        lock (_lock)
        {
            if (_registries.ContainsKey(context))
                return;

            var mapping = ((KsqlContext)context).GetMappingRegistry();
            var models  = context.GetEntityModels();

            if (options.Entities.Count == 0 || !options.Entities.Exists(e => e.EnableCache))
                return;

            if (streams == null)
            {
                var multi = new MultiStreamizKafkaStreams();
                var bootstrap = options.Common.BootstrapServers;

                foreach (var entity in options.Entities.Where(e => e.EnableCache))
                {
                    var model = models.Values.FirstOrDefault(m =>
                        string.Equals(m.EntityType.Name, entity.Entity, StringComparison.OrdinalIgnoreCase));
                    if (model == null)
                        continue;

                    var kv = mapping.GetMapping(model.EntityType);
                    var storeName = entity.StoreName ?? model.GetTopicName();
                    var topic     = model.GetTopicName();

                    // ここは型がランタイム確定のため最小限の反射を許容（他は反射禁止）
                    var m = typeof(KsqlContextCacheExtensions)
                        .GetMethod(nameof(CreateStream), BindingFlags.NonPublic | BindingFlags.Static)!
                        .MakeGenericMethod(kv.AvroKeyType!, kv.AvroValueType!);

                    var ks = (KafkaStream)m.Invoke(null,
                        new object?[] { topic, storeName, bootstrap, options.SchemaRegistry.Url, loggerFactory })!;

                    // ★ 起動は非ブロッキングだが、失敗は捨てない
                    StartNonBlocking(ks, storeName, log);

                    multi.AddStream(storeName, ks);
                }

                streams = multi;
            }

            // レジストリ初期化（既存の仕組みに合わせる）
            var registry = new TableCacheRegistry(mapping, streams, loggerFactory);
            var cacheOptions = new TableCacheOptions();
            foreach (var e in options.Entities)
            {
                cacheOptions.Entries.Add(new TableCacheEntry
                {
                    Entity       = e.Entity,
                    SourceTopic  = e.SourceTopic,
                    EnableCache  = e.EnableCache,
                    StoreName    = e.StoreName,
                    BaseDirectory= null
                });
            }
            var schemaClient = ((KsqlContext)context).GetSchemaRegistryClient();
            registry.InitializeCaches(context.GetEntityModels().Values, cacheOptions, schemaClient, loggerFactory);

            _registries[context] = registry;
        }
    }

    // ── ここから下は“起動配線”を一箇所に閉じ込めた完成形 ──

    // StateChangedは Start 前に購読、Materializedは型安全、待機はしない
    private static KafkaStream CreateStream<TKey, TValue>(
        string topic,
        string storeName,
        string bootstrap,
        string schemaRegistryUrl,
        ILoggerFactory? loggerFactory)
    {
        var b = new StreamBuilder();
        b.Stream<TKey, TValue>(topic)
         .ToTable(Materialized<TKey, TValue, IKeyValueStore<Bytes, byte[]>>
             .Create(storeName)
             .WithKeySerdes(new SchemaAvroSerDes<TKey>())
             .WithValueSerdes(new SchemaAvroSerDes<TValue>()));

        var cfg = new StreamConfig<SchemaAvroSerDes<TKey>, SchemaAvroSerDes<TValue>>
        {
            ApplicationId     = $"cache-app-{storeName}",
            BootstrapServers  = bootstrap,
            SchemaRegistryUrl = schemaRegistryUrl,
            // 本番は設定で外出しすること
            StateDir          = @"C:\Temp\KAFKA_STATE",
            Logger            = loggerFactory,
            AutoOffsetReset   = AutoOffsetReset.Earliest
        };

        var stream = new KafkaStream(b.Build(), cfg);

        var log = loggerFactory?.CreateLogger("KafkaStream") ?? Microsoft.Extensions.Logging.Abstractions.NullLogger.Instance;
        // 正しいシグネチャ：(old, new) かつ Start前に購読
        stream.StateChanged += (oldState, newState) =>
            log.LogInformation("KafkaStream[{Store}] {Old} -> {New}", storeName, oldState, newState);

        return stream;
    }

    // fire-and-forget だが、失敗は必ず見える化（ContinueWith）
    private static void StartNonBlocking(KafkaStream stream, string storeName, ILogger log)
    {
        _ = stream.StartAsync().ContinueWith(t =>
        {
            if (t.IsFaulted && t.Exception != null)
                log.LogError(t.Exception, "KafkaStream[{Store}] failed to start.", storeName);
            else if (t.IsCanceled)
                log.LogWarning("KafkaStream[{Store}] start was canceled.", storeName);
        }, TaskScheduler.Default);
    }

    internal static TableCacheRegistry? GetTableCacheRegistry(this IKsqlContext context)
    {
        lock (_lock) return _registries.TryGetValue(context, out var reg) ? reg : null;
    }

    internal static ITableCache<T>? GetTableCache<T>(this IKsqlContext context) where T : class
        => context.GetTableCacheRegistry()?.GetCache<T>();
}
```

## ここで“組み上がる”ポイント
- **イベント購読→Start** の順が**必ず守られる**（`CreateStream`で購読してから返す→`StartNonBlocking`で起動）。  
- **非ブロッキングだが失敗は検知**（`ContinueWith`で例外/キャンセルをロギング）。  
- **待機系ヘルパ廃止**（`StartWithRetryAsync/WaitUntilRunning`等は不要）。  
- 反射は**型がランタイム確定する1点のみ**に閉じ込め、それ以外は**型安全**。

> 次の段階は「RocksDbTableCache 側を lazy 取得＋フォールバック」に揃えることだけど、  
> まずは**このファイルをこのまま差し替え**て、起動配線が**一枚で完成する**状態にしてから続きやろう。

（JST [[REDACTED_PHONE]]:36）
### system — 2025-08-08T18:27:44.567238+00:00

_(empty)_
### assistant — 2025-08-08T18:27:44.975452+00:00

_(empty)_
### assistant — 2025-08-08T18:27:54.003848+00:00

_(empty)_
### user — 2025-08-08T18:29:11.514000+00:00

だめ
### assistant — 2025-08-08T18:29:30.390739+00:00

了解。**一つだけ直します。**

# 指摘への対応①（反射の撤去）
`UseTableCache` 内の  
```csharp
var m = typeof(KsqlContextCacheExtensions)
    .GetMethod(...).MakeGenericMethod(...);
var ks = (KafkaStream)m.Invoke(...);
```  
この“型確定の反射”自体が設計違反です。**ここは削除**し、**型安全API**に切り出します。
### 最小パッチ（`KsqlContextCacheExtensions.cs`）
```diff
@@ internal static class KsqlContextCacheExtensions
-    internal static void UseTableCache(this IKsqlContext context, KsqlDslOptions options, ILoggerFactory? loggerFactory = null,
-        IKafkaStreams? streams = null)
+    internal static void UseTableCache(this IKsqlContext context, KsqlDslOptions options, ILoggerFactory? loggerFactory = null)
     {
-        var log = loggerFactory?.CreateLogger("KsqlContextCache") ?? Microsoft.Extensions.Logging.Abstractions.NullLogger.Instance;
+        var log = loggerFactory?.CreateLogger("KsqlContextCache") ?? Microsoft.Extensions.Logging.Abstractions.NullLogger.Instance;

         lock (_lock)
         {
             if (_registries.ContainsKey(context))
                 return;
@@
-            if (streams == null)
-            {
-                var multi = new MultiStreamizKafkaStreams();
-                var bootstrap = options.Common.BootstrapServers;
-
-                foreach (var entity in options.Entities.Where(e => e.EnableCache))
-                {
-                    var model = models.Values.FirstOrDefault(m =>
-                        string.Equals(m.EntityType.Name, entity.Entity, StringComparison.OrdinalIgnoreCase));
-                    if (model == null)
-                        continue;
-
-                    var kv = mapping.GetMapping(model.EntityType);
-                    var storeName = entity.StoreName ?? model.GetTopicName();
-                    var topic     = model.GetTopicName();
-
-                    // 反射での型確定を廃止する（ここがNG）
-                    var m = typeof(KsqlContextCacheExtensions)
-                        .GetMethod(nameof(CreateStream), BindingFlags.NonPublic | BindingFlags.Static)!
-                        .MakeGenericMethod(kv.AvroKeyType!, kv.AvroValueType!);
-
-                    var ks = (KafkaStream)m.Invoke(null,
-                        new object?[] { topic, storeName, bootstrap, options.SchemaRegistry.Url, loggerFactory })!;
-
-                    StartNonBlocking(ks, storeName, log);
-                    multi.AddStream(storeName, ks);
-                }
-
-                streams = multi;
-            }
-
-            // レジストリ初期化（既存の仕組みに合わせる）
-            var registry = new TableCacheRegistry(mapping, streams, loggerFactory);
+            // レジストリのみ初期化（起動は別APIに移譲）
+            var registry = new TableCacheRegistry(mapping, /*streams:*/ null, loggerFactory);
@@
             _registries[context] = registry;
         }
     }
+
+    // 反射を使わない型安全API（Composition Root からエンティティごとに呼ぶ）
+    internal static KafkaStream AddTableCache<TKey, TValue>(
+        this IKsqlContext context,
+        string topic,
+        string storeName,
+        string bootstrap,
+        string schemaRegistryUrl,
+        ILoggerFactory? loggerFactory,
+        MultiStreamizKafkaStreams aggregator)
+    {
+        var b = new StreamBuilder();
+        b.Stream<TKey, TValue>(topic)
+         .ToTable(Materialized<TKey, TValue, IKeyValueStore<Bytes, byte[]>>
+            .Create(storeName)
+            .WithKeySerdes(new SchemaAvroSerDes<TKey>())
+            .WithValueSerdes(new SchemaAvroSerDes<TValue>()));
+
+        var cfg = new StreamConfig<SchemaAvroSerDes<TKey>, SchemaAvroSerDes<TValue>>
+        {
+            ApplicationId     = $"cache-app-{storeName}",
+            BootstrapServers  = bootstrap,
+            SchemaRegistryUrl = schemaRegistryUrl,
+            Logger            = loggerFactory,
+            AutoOffsetReset   = AutoOffsetReset.Earliest
+        };
+        var ks = new KafkaStream(b.Build(), cfg);
+        var log = loggerFactory?.CreateLogger("KafkaStream")
+                 ?? Microsoft.Extensions.Logging.Abstractions.NullLogger.Instance;
+        ks.StateChanged += (oldS, newS) =>
+            log.LogInformation("KafkaStream[{Store}] {Old}->{New}", storeName, oldS, newS);
+        _ = ks.StartAsync().ContinueWith(t =>
+        {
+            if (t.IsFaulted && t.Exception != null)
+                log.LogError(t.Exception, "KafkaStream[{Store}] failed to start.", storeName);
+        }, TaskScheduler.Default);
+        aggregator.AddStream(storeName, ks);
+        return ks;
+    }
```
### 使い方（呼び出し側・例）
```csharp
var multi = new MultiStreamizKafkaStreams();
context.AddTableCache<MyKey, MyEntity>("topic", "store", bootstrap, schemaUrl, loggerFactory, multi);
// 必要なエンティティ分だけ列挙して呼ぶ
```

> まずはこの“反射撤去”一点に絞って修正してください。  
> 次の指摘は、その後に進めます。

送信日時（日本時間）: [[REDACTED_PHONE]]:44
### system — 2025-08-08T18:29:31.084372+00:00

_(empty)_
### assistant — 2025-08-08T18:29:33.033985+00:00

_(empty)_
### assistant — 2025-08-08T18:29:41.153857+00:00

_(empty)_
### user — 2025-08-08T18:30:09.167000+00:00

ks.StateChanged += (oldS, newS) =>
+            log.LogInformation("KafkaStream[{Store}] {Old}->{New}", storeName, oldS, newS);
ここが最悪
### assistant — 2025-08-08T18:30:25.626153+00:00

（JST [[REDACTED_PHONE]]:50）

**問題点（この1点）：**  
`StateChanged` の**イベントハンドラ内で同期ログを書いている**のが最悪。内部スレッド上のコールバックで毎遷移ごとにクロージャ確保とフォーマットが走り、最悪ブロックやスローダウン、GCプレッシャーを招きます。**イベントハンドラでは“副作用最小”が原則**です。

**修正（この1点だけ）：**  
起動失敗は `StartAsync().ContinueWith(...)` 側でログ化し、`StateChanged` では**一切ログしない**（= 何もしない or フラグ更新のみ）。

```csharp
// ① StateChangedでのログはやめる（副作用ゼロ）
stream.StateChanged += static (oldS, newS) => { /* no-op or flag set elsewhere */ };

// ② 起動失敗だけ非同期でログ（ここは既にバックグラウンド）
var log = loggerFactory?.CreateLogger("KafkaStream")
          ?? Microsoft.Extensions.Logging.Abstractions.NullLogger.Instance;

_ = stream.StartAsync().ContinueWith(t =>
{
    if (t.IsFaulted && t.Exception != null)
        log.LogError(t.Exception, "KafkaStream[{Store}] failed to start.", storeName);
    else if (t.IsCanceled)
        log.LogWarning("KafkaStream[{Store}] start was canceled.", storeName);
}, TaskScheduler.Default);
```

これで**イベントハンドラは軽量化**され、**起動時の致命エラーは見落とさない**構成になります。
### system — 2025-08-08T18:30:26.509232+00:00

_(empty)_
### assistant — 2025-08-08T18:30:27.968269+00:00

_(empty)_
### assistant — 2025-08-08T18:30:40.816163+00:00

_(empty)_
### user — 2025-08-08T18:31:34.372000+00:00

Startする前に状態監視は設定する。状態監視はその結果をフィードバックする。
これができてないからほかのコードを見る必要がンま
### assistant — 2025-08-08T18:31:50.117472+00:00

指摘への対応“だけ”やるね。

# 修正点：**Start 前に状態監視を配線し、その結果を外へフィードバックする**

```csharp
// 1) 状態を受け取る“出口”を用意（ロガーじゃなく、機能へ返す）
public interface IStreamStateSink
{
    void OnStateChanged(string storeName, KafkaStream.State oldState, KafkaStream.State newState);
}
```

```csharp
// 2) Startする前に必ず購読し、sinkへフィードバックする（副作用はここに集約）
private static KafkaStream CreateStream<TKey, TValue>(
    string topic,
    string storeName,
    string bootstrap,
    string schemaRegistryUrl,
    IStreamStateSink sink,                   // ← フィードバック先を受け取る
    ILoggerFactory? loggerFactory)
{
    var b = new StreamBuilder();
    b.Stream<TKey, TValue>(topic)
     .ToTable(Materialized<TKey, TValue, IKeyValueStore<Bytes, byte[]>>
        .Create(storeName)
        .WithKeySerdes(new SchemaAvroSerDes<TKey>())
        .WithValueSerdes(new SchemaAvroSerDes<TValue>()));

    var cfg = new StreamConfig<SchemaAvroSerDes<TKey>, SchemaAvroSerDes<TValue>>
    {
        ApplicationId     = $"cache-app-{storeName}",
        BootstrapServers  = bootstrap,
        SchemaRegistryUrl = schemaRegistryUrl,
        AutoOffsetReset   = AutoOffsetReset.Earliest,
        Logger            = loggerFactory
    };

    var stream = new KafkaStream(b.Build(), cfg);

    // ★ Startより前に必ず監視を配線し、結果を sink に返す（ここではログしない）
    stream.StateChanged += (oldS, newS) => sink.OnStateChanged(storeName, oldS, newS);

    return stream; // 呼び出し側で StartAsync する
}
```

```csharp
// 3) 呼び出し側：監視→起動（非ブロッキング）
//    起動失敗はここで拾う（監視はすでに配線済み）
var ks = CreateStream<MyKey, MyEntity>(topic, storeName, bootstrap, schemaUrl, sink, loggerFactory);
_ = ks.StartAsync().ContinueWith(t =>
{
    if (t.IsFaulted) sink.OnStateChanged(storeName, KafkaStream.State.CREATED, KafkaStream.State.ERROR);
}, TaskScheduler.Default);
```

これで「**Startする前に状態監視を設定**し、**監視結果を機能側（sink）へ確実にフィードバック**」できる。以後は他のコードを見なくても、**状態がどこに返るか**が明確になるはず。  

送信日時（日本時間）: [[REDACTED_PHONE]]:58
### system — 2025-08-08T18:31:50.389116+00:00

_(empty)_
### assistant — 2025-08-08T18:31:50.555144+00:00

_(empty)_
### assistant — 2025-08-08T18:31:54.856781+00:00

_(empty)_
### user — 2025-08-08T18:42:38.479000+00:00

全体の話が局所化して、そしてコンテキストがばらばらになりまとまらない流れが続いてる
### assistant — 2025-08-08T18:42:54.099883+00:00

わかった。今は**全体の設計が分解→局所修正の連鎖**になってる。ここで一旦**リセットして一本化**する。

# 提案（まず合意する“全体の契約”）
1. **入口**：`KsqlContext` → `UseTableCache(...)`（ここ“だけ”で起動と登録を完結）
2. **起動**：`StateChanged(old,new)` を **Start前に購読** → `StartAsync()` は**非ブロッキング**（待機/リトライ禁止）
3. **フィードバック**：`StateChanged` の結果は **Registry（状態シンク）へ通知**して一元管理（ログは副作用にしない）
4. **読取**：`RocksDbTableCache<TKey,TValue>` は **lazyに Store 解決**、未準備は**必ずフォールバック**
5. **型**：**型付きストア** (`IReadOnlyKeyValueStore<TKey,TValue>`) を使い、**Bytes/byte[] の自前デシリは禁止**
6. **反射**：  
   - **A. 明示登録（反射ゼロ）**：エンティティごとに `AddTableCache<TKey,TValue>` を呼ぶ  
   - **B. 自動登録（最小限の反射1箇所のみ）**：型がランタイムで決まる場合に限り `MakeGenericMethod` を 入口内の1点に限定

# 次のアクション（選んで）
- **A（反射ゼロ）** or **B（自動登録・反射最小）** のどちらで行くか決めてください。  
  決まったら**次の返答で**、  
  - `KsqlContextCacheExtensions.cs`（入口＋起動＋状態シンク）  
  - `TableCacheRegistry.cs`（状態保持＋キャッシュ探索）  
  - `RocksDbTableCache.cs`（lazy解決＋フォールバック）  
  の**3ファイル完全版を“一つのメッセージでまとめて”**提示します。  

これで“全体がまとまらない”のを止めます。どっちで進める？（A / B）

— 送信日時（日本時間）: [[REDACTED_PHONE]]:04:41
### system — 2025-08-08T18:42:54.520334+00:00

_(empty)_
### assistant — 2025-08-08T18:42:54.685053+00:00

_(empty)_
### assistant — 2025-08-08T18:43:03.527608+00:00

_(empty)_
### user — 2025-08-08T18:44:41.303000+00:00

全体の契約が入口のみの定義でその中の処理は次、出口を契約しないと
### assistant — 2025-08-08T18:44:57.631336+00:00

了解。「まず**入口(Entry)の契約だけ**を決め、実装は後。さらに**出口(Exit)の契約**も同時に固定」ね。  
以下、“使う側が約束できる最小インターフェース”だけを定義する。**中身の処理は一切ここで決めない**。

# 契約（インターフェースのみ）

## 入口（Entry Contract）
```csharp
// KsqlContext に対する唯一の入口。ここを呼べばキャッシュが有効化される。
// 実装は非ブロッキング起動・内部状態監視の配線までを完了させる。
// ここでは型を明示して登録（反射禁止版）。自動登録をやる場合は別の入口を追加可。
public interface ITableCacheEntry
{
    // エンティティ(POCO)を対象に、Kafkaのtopic→RocksDB(state store)のキャッシュを有効化する。
    // この呼び出しの中で「状態監視の配線→StartAsync呼び出し（待たない）」までは必ず行う。
    void AddTableCache<TKey, TValue>(
        string topic,
        string storeName,
        CacheOptions options,
        IEntitySet<TValue> fallback // 未準備・障害時の読取先
    )
    where TValue : class;
}

// Options は“配線に必要な最小構成”のみ（実装が増やしてOK）
public sealed class CacheOptions
{
    public string BootstrapServers { get; init; } = "";
    public string SchemaRegistryUrl { get; init; } = "";
    public string StateDir { get; init; } = "";
    public string ApplicationIdBase { get; init; } = "cache-app";
}
```

## 出口（Exit Contract）### 1) データ読取の出口
```csharp
// 呼ぶ側は KsqlContext 経由でこれを受け取る想定。
// キャッシュが“使えるならキャッシュから”、ダメなら“即フォールバック”へ。
// 例外で止めない（契約）。
public interface ICachedEntitySet<T> where T : class
{
    // 必ず POCO の List を返す。キャンセル以外では例外で止めない。
    Task<List<T>> ToListAsync(CancellationToken ct = default);

    // キャッシュにある時だけ返す。未準備やミス時は false。
    bool TryGet<TKey>(TKey key, out T? value);
}
```
### 2) 状態の出口（観測フィードバック）
```csharp
// Start前に必ず配線され、状態遷移が“外側に”通知される。
// ログ出力はこの外側でやる（イベントハンドラ内で同期ログしないのが契約）。
public interface IStreamStateSink
{
    void OnStateChanged(string storeName, KafkaStream.State oldState, KafkaStream.State newState);
}
```

## KsqlContext からの取得口（Facade）
```csharp
// 使う側が最終的に叩く唯一の取得口。
// キャッシュが登録済みなら ICachedEntitySet<T> を返す。未登録なら生の IEntitySet<T> を返しても良いが、
// 一貫性のため ICachedEntitySet<T> を常に返すのが望ましい（内部でフォールバック）。
public interface ICacheFacade
{
    ICachedEntitySet<T> GetCachedSet<T>() where T : class;
}
```

# 不変条件（Behavioral Guarantees）
- **非ブロッキング**：入口を呼んでも呼び出し元を待たせない（`StartAsync`待機禁止）。
- **監視の先配線**：`StartAsync`より**前**に `StateChanged(old,new)` を**sinkへ配線**しておく。
- **lazy解決**：実ストア取得は**利用直前**に試行。失敗時は**即フォールバック**（例外にしない）。
- **型安全**：`IReadOnlyKeyValueStore<TKey,TValue>` を直接使う（Bytes/byte[]の手デシリ禁止）。
- **観測分離**：ハンドラ内で同期ログなど重い副作用を起こさない。**sinkで処理**する。
- **再起動耐性**：ダウン側遷移（`PENDING_SHUTDOWN/NOT_RUNNING/ERROR`）で**内部利用フラグを落とし**、次回利用時に再解決を試みる。

# 呼び出し順序（契約上のシーケンス）
1) `ITableCacheEntry.AddTableCache<TKey,TValue>(...)` を **エンティティごとに**呼ぶ  
2) 内部で：**状態監視配線 → 非ブロッキング起動** を完了  
3) 利用側は `ICacheFacade.GetCachedSet<T>()` → `ToListAsync()` / `TryGet()` を呼ぶ  
   - **READYならキャッシュ**、そうでなければ**フォールバック**  

---

これで「入口だけ定義→中身は次→出口を契約」という流れを**ひとつに固定**。  
次は、**この契約を満たす最小の“薄い実装”**を載せるけど、それでOK？（実装はこの契約を1行も破らない形で出す）

— 送信日時（日本時間）: [[REDACTED_PHONE]]:12:55
### system — 2025-08-08T18:44:58.804826+00:00

_(empty)_
### assistant — 2025-08-08T18:45:01.445751+00:00

_(empty)_
### assistant — 2025-08-08T18:45:04.923030+00:00

_(empty)_
### user — 2025-08-08T18:45:19.131000+00:00

だめだ
### assistant — 2025-08-08T18:45:34.711386+00:00

了解。まず**入口だけ**一点に絞って最終確認させて。

この署名で**唯一の入口**として固定して良いですか？

```csharp
internal static void UseTableCache(
    this IKsqlContext context,
    KsqlDslOptions options,
    ILoggerFactory? loggerFactory,
    IStreamStateSink stateSink // 状態監視のフィードバック先
);
```

- ※ 実装は次でやります（ここでは**定義だけ**）。
- OKなら、次の一手で**出口の契約**を一点提示します。

（JST [[REDACTED_PHONE]]:18）
### system — 2025-08-08T18:45:35.142796+00:00

_(empty)_
### assistant — 2025-08-08T18:45:36.973306+00:00

_(empty)_
### assistant — 2025-08-08T18:45:45.435440+00:00

_(empty)_
### user — 2025-08-08T18:46:04.892000+00:00

IStreamStateSink stateSink // 状態監視のフィードバック先　これはなんで必要？
### system — 2025-08-08T18:46:19.908997+00:00

_(empty)_
### assistant — 2025-08-08T18:46:19.990080+00:00

これは、状態監視の**「結果をどこに返すか」**を呼び出し元と合意するための契約です。  

もしこれを入れない場合、`UseTableCache` 内で  
- ロガーに直接書く  
- 内部の変数に握り込む  

のどちらかしかできず、**呼び出し元が「状態をどう扱うか」を選べなくなる**んです。  

---
### 例
- **サービス実装側**  
  状態が `RUNNING` になったらキャッシュ初期化を始めたい
- **テストコード側**  
  状態変化を検証して `Assert` したい

この2つを同じ`UseTableCache`で動かすには、状態通知の**受け皿（Sink）**が必要になります。  
それが `IStreamStateSink` の役割です。  

---

もし呼び出し元が「ロガーだけで十分」なら、`IStreamStateSink` の代わりに単純に `Action<KafkaStream.State, KafkaStream.State>` を渡す方法もあります。  
つまり必須ではなく、「呼び出し側で結果利用したい場合のための契約」です。  

---

このまま行くなら、次はこれを使った**入口〜出口契約**を整理して全体を組めます。  
どうしますか、`IStreamStateSink` で進めますか？  

（JST [[REDACTED_PHONE]]:23）
### user — 2025-08-08T18:46:26.046000+00:00

それでは入り口ではない
### assistant — 2025-08-08T18:46:42.723497+00:00

同意。その通りです。**入口は依存を増やさない“最小”であるべき**なので、`IStreamStateSink` は入口から外します。修正はこれ一つ。
### 入口の最終契約（これだけ）
```csharp
internal static void UseTableCache(
    this IKsqlContext context,
    KsqlDslOptions options,
    ILoggerFactory? loggerFactory = null
);
```
- 状態監視の配線と結果反映は**内部（レジストリ／キャッシュ層）で完結**させます。入口では受け口を増やさない。

送信日時（日本時間）: [[REDACTED_PHONE]]:27
### system — 2025-08-08T18:46:43.148143+00:00

_(empty)_
### assistant — 2025-08-08T18:46:44.999948+00:00

_(empty)_
### user — 2025-08-08T18:46:51.072000+00:00

OKです
### assistant — 2025-08-08T18:46:51.437542+00:00

_(empty)_
### user — 2025-08-08T18:47:00.513000+00:00

次は出口
### system — 2025-08-08T18:47:05.930347+00:00

_(empty)_
### assistant — 2025-08-08T18:47:05.981898+00:00

よかったです。  
では、この入口契約を固定して、内部の状態監視やフィードバック処理を**CacheRegistry 側で組み込み**にします。  
これで全体が一つの流れとしてまとまりやすくなります。  

送信日時（日本時間）: [[REDACTED_PHONE]]:28
### system — 2025-08-08T18:47:16.684887+00:00

_(empty)_
### assistant — 2025-08-08T18:47:16.745061+00:00

了解。**出口の契約だけ**を固定します（実装は次のステップでやる）。

```csharp
// 1) 取得口（出口）：呼ぶ側はこれだけ知っていればよい
internal static class KsqlContextCacheQueryExtensions
{
    // キャッシュが使えればキャッシュから、ダメなら内部でフォールバックして返す
    internal static ICachedEntitySet<T> GetCachedSet<T>(this IKsqlContext context) where T : class;
}

// 2) 返されるハンドル（最小機能）
public interface ICachedEntitySet<T> where T : class
{
    // 常に List<T> を返す（キャンセル以外で例外で止めないのが契約）
    Task<List<T>> ToListAsync(CancellationToken ct = default);

    // キャッシュにある時だけ値を返す（未準備やミス時は false）
    bool TryGet<TKey>(TKey key, out T? value);
}
```

- 入口で渡した `IKsqlContext` に対し、**出口は `GetCachedSet<T>()` だけ**。  
- `ICachedEntitySet<T>` は **POCO を返す最小API** に限定。  
- フォールバックや状態監視の詳細は **実装側で隠蔽**（契約外）。

次は、この契約に沿った**最小実装**を出します。  
送信日時（日本時間）: [[REDACTED_PHONE]]:30
### assistant — 2025-08-08T18:47:19.295172+00:00

_(empty)_
### assistant — 2025-08-08T18:47:32.559745+00:00

_(empty)_
### user — 2025-08-08T18:48:01.333000+00:00

わからない
### assistant — 2025-08-08T18:48:16.956823+00:00

了解。**出口はこれだけ**にします。呼ぶ側が覚えるのは1行。

```csharp
// 出口（契約）— これだけ提供する
internal static class KsqlContextCacheQueryExtensions
{
    // いつでも List<T> を取るための口
    // 中では「キャッシュが使えればキャッシュ／ダメなら即フォールバック」
    internal static IEntitySet<T> GetCachedSet<T>(this IKsqlContext ctx) where T : class;
}
```
### 使い方（呼ぶ側は1行だけ）
```csharp
// 入口は既に合意：ctx.UseTableCache(options, loggerFactory);

// 出口：POCOの一覧が欲しいときは常にこれ
var orders = await ctx.GetCachedSet<Order>().ToListAsync(ct);
```

- 返り値は **`IEntitySet<T>`**（既存と同じ顔）。  
- **例外で止めない**のが契約（キャンセル以外）。  
- キャッシュ未準備・障害時は **自動でフォールバック**して同じ `List<T>` を返します。  
- Key単位の読み取りが欲しければ、後で **`TryGetFromCache<TKey,T>(...)`** を追加（任意）。

これで「入口 → 出口」の両端が固定できました。次はこの契約を満たす“中身”を実装します。  

送信日時（日本時間）: [[REDACTED_PHONE]]:34
### system — 2025-08-08T18:48:17.426660+00:00

_(empty)_
### assistant — 2025-08-08T18:48:17.434397+00:00

_(empty)_
### assistant — 2025-08-08T18:48:23.923762+00:00

_(empty)_
### user — 2025-08-08T18:48:25.238000+00:00

だめ
### assistant — 2025-08-08T18:48:41.096567+00:00

了解。**出口は増やさないのが正解**です。  
**契約：`IKsqlContext.Set<T>()` が“そのまま出口”**。呼び手は一切APIを増やさない。

- `ctx.Set<T>() : IEntitySet<T>` は **常に同じシグネチャで返す**。  
- その実体が **内部で「キャッシュ→だめならフォールバック」**を行う。  
- **ToListAsync** はキャンセル以外で例外を投げず、**非ブロッキング**・**待たない**・**同一 `List<T>` を返す**（準備状況に関わらず）。  

これで「入口だけ定義、出口は既存 `Set<T>()` を使う」に統一できます。  
次は、この契約に沿って **`Set<T>()` の裏側差し替え（ReadCachedEntitySet で包む）** を示します。  

送信日時（日本時間）: [[REDACTED_PHONE]]:37
### system — 2025-08-08T18:48:41.877592+00:00

_(empty)_
### assistant — 2025-08-08T18:48:41.886068+00:00

_(empty)_
### assistant — 2025-08-08T18:48:46.664558+00:00

_(empty)_
### user — 2025-08-08T18:49:22.641000+00:00

ReadCachedEntitySet は何をする？
### system — 2025-08-08T18:49:37.606089+00:00

_(empty)_
### assistant — 2025-08-08T18:49:37.661680+00:00

`ReadCachedEntitySet<T>` は、**`IKsqlContext.Set<T>()` の出口をラップする“キャッシュ対応版の窓口”**です。  
役割を分解すると、こうなります。  

---
### 1. **キャッシュ優先の読み出し**
- RocksDB（`IReadOnlyKeyValueStore`）に該当エンティティのストアがある場合は、  
  そこから直接データを読み込む。
- ストアが未準備（Kafka Streams が RUNNING 前）や存在しない場合は、  
  **フォールバック**として既存の `_baseSet`（＝通常の `EntitySet<T>`）を使う。

---
### 2. **`IEntitySet<T>` の契約を保持**
- `ToListAsync` や `Where` など、`IEntitySet<T>` のインターフェースをそのまま持つ。
- 呼び手は `Set<T>()` を使っている限り、キャッシュかどうかを意識しなくてよい。

---
### 3. **非同期初期化との非ブロッキング化**
- Kafka Streams の起動状態を監視 (`StateChanged`)。
- **RUNNING になったら RocksDB を開く**。
- それまでは空配列やフォールバックを返す（呼び手が待たされない）。

---
### 4. **ログと診断**
- キャッシュ利用可否やフォールバック発生を `ILogger` で記録。
- 後からキャッシュ命中率などの分析に使える。

---

もしこの方針で作ると、`Set<T>()` の裏側はこういう流れになります。

```
ctx.Set<T>()
  └─ new ReadCachedEntitySet<T>(context, model, logger, baseSet)
         ├─ RocksDB準備できていれば cache.Read()
         └─ そうでなければ baseSet.Read()
```

---

この設計にすると、**出口の契約は変えずにキャッシュ層を差し込める**ので、今の「全体がまとまらない」状態を解消できます。  
次に、この仕様で `ReadCachedEntitySet<T>` のサンプル実装を出しますか？  

送信日時（日本時間）: [[REDACTED_PHONE]]:41
### user — 2025-08-08T18:50:03.357000+00:00

ToListAsyncに対して何をする
### assistant — 2025-08-08T18:50:19.580491+00:00

（JST [[REDACTED_PHONE]]:45）

**結論：`ToListAsync` は “待たず・壊れず・必ず `List<T>` を返す” ための窓口です。やることは4つだけ。**

1) **lazyでストア解決**  
   - `StateChanged` で立てたフラグを見て、ここでだけ `Store(...)` を試す  
   - `InvalidStateStoreException` は握りつぶして次回へ（**待たない**）

2) **キャッシュ優先・未準備は即フォールバック**  
   - ストアが取れたら **RocksDB から列挙**  
   - 取れなければ **`_baseSet.ToListAsync(ct)` を即返す**（例外で止めない）

3) **キャンセルだけ尊重**  
   - ループ毎に `ct.ThrowIfCancellationRequested()`  
   - それ以外のエラーはフォールバックに切替（安定最優先）

4) **副作用は軽量**  
   - ここでログは **debug/info 1発** 程度（重い処理はしない）
### サンプル（`ReadCachedEntitySet<T>.ToListAsync` の中身イメージ）

```csharp
public async Task<List<T>> ToListAsync(CancellationToken ct = default)
{
    // 1) lazy解決（イベントではやらない）
    TryResolveStoreIfPossible();

    // 2) 未準備なら即フォールバック
    var s = _store;
    if (s == null)
    {
        _log.LogDebug("Cache not ready -> fallback: {Store}", _storeName);
        return await _baseSet.ToListAsync(ct);
    }

    // 3) RocksDBから列挙（例外で落とさない）
    var list = new List<T>();
    try
    {
        foreach (var kv in s.All())
        {
            ct.ThrowIfCancellationRequested();
            list.Add(kv.Value); // ※ 型付きストアなのでデシリアライズ不要
        }
        return list;
    }
    catch (InvalidStateStoreException) // 途中で閉じられた等
    {
        _store = null; // 次回再解決
        _log.LogDebug("Store lost during read -> fallback: {Store}", _storeName);
        return await _baseSet.ToListAsync(ct);
    }
}
```

#### 重要な注意
- **順序保証はしない**（必要なら呼び出し側で `OrderBy(...)` を適用）
- **反射/動的なし**、**Bytes/byte[] デシリなし**（`IReadOnlyKeyValueStore<TKey,TValue>` を直読む）
- **RUNNING待ちはしない**（非ブロッキング設計を死守）
### system — 2025-08-08T18:50:20.175785+00:00

_(empty)_
### assistant — 2025-08-08T18:50:20.184824+00:00

_(empty)_
### assistant — 2025-08-08T18:50:22.721981+00:00

_(empty)_
### user — 2025-08-08T18:51:15.463000+00:00

key + valueでpocoを作る必要がある
### assistant — 2025-08-08T18:51:31.345131+00:00

了解。「**key + value で POCO を作る**」を“契約に昇格”させます。  
反射なしでやるなら、**プロジェクタ（`Func<TKey,TValue,T>`）を必須引数にする**のが一番シンプル＆堅牢。

# 入口で渡すもの（追加契約）
```csharp
// AddTableCache 時に projector を必須にする
void AddTableCache<TKey, TValue, T>(
    string topic,
    string storeName,
    Func<TKey, TValue, T> projector,   // ★ key+value -> POCO
    IEntitySet<T> fallback             // フォールバック
) where T : class;
```

# 中身（読み出し側のコアだけ）
```csharp
// 型付きストア + projector で POCO を生成
internal sealed class RocksDbTableCache<TKey, TValue, T> where T : class
{
    private readonly IKafkaStreams _streams;
    private readonly string _storeName;
    private readonly Func<TKey, TValue, T> _project; // ★ここ
    private readonly IEntitySet<T> _fallback;
    private volatile IReadOnlyKeyValueStore<TKey, TValue>? _store;
    private int _canResolve; // StateChanged(new==RUNNING)で1に

    public RocksDbTableCache(
        IKafkaStreams streams,
        string storeName,
        Func<TKey, TValue, T> projector,            // ★必須
        IEntitySet<T> fallback)
    {
        _streams    = streams;
        _storeName  = storeName;
        _project    = projector;                    // ★保持
        _fallback   = fallback;
        _streams.StateChanged += (oldS, newS) =>
        {
            if (newS == KafkaStream.State.RUNNING) System.Threading.Interlocked.Exchange(ref _canResolve, 1);
            else { _store = null; System.Threading.Interlocked.Exchange(ref _canResolve, 0); }
        };
    }

    private void TryResolveStore()
    {
        if (_store != null || System.Threading.Volatile.Read(ref _canResolve) == 0) return;
        try
        {
            _store = _streams.Store(
                StoreQueryParameters.FromNameAndType(
                    _storeName, QueryableStoreTypes.KeyValueStore<TKey, TValue>()));
        }
        catch (InvalidStateStoreException) { /* not ready; try later */ }
    }

    public async Task<List<T>> ToListAsync(CancellationToken ct = default)
    {
        TryResolveStore();
        var s = _store;
        if (s == null) return await _fallback.ToListAsync(ct);

        var list = new List<T>();
        try
        {
            foreach (var kv in s.All())
            {
                ct.ThrowIfCancellationRequested();
                list.Add(_project(kv.Key, kv.Value)); // ★ key+value -> POCO
            }
            return list;
        }
        catch (InvalidStateStoreException)
        {
            _store = null;
            return await _fallback.ToListAsync(ct);
        }
    }

    public bool TryGet(TKey key, out T? value)
    {
        TryResolveStore();
        var s = _store;
        if (s == null) { value = null; return false; }
        if (!s.TryGet(key, out var raw)) { value = null; return false; }
        value = _project(key, raw);                 // ★単件も同様
        return true;
    }
}
```

# 使い方のイメージ（反射なし）
```csharp
// 入口（AddTableCache）で projector を渡す
context.AddTableCache<OrderKey, OrderAvro, Order>(
    topic: "orders",
    storeName: "orders-store",
    projector: (k, v) => new Order                   // ★ key + value を合成
    {
        Id = k.Id,               // key から
        Status = v.Status,       // value から
        CreatedAt = v.CreatedAt  // value から
    },
    fallback: dbOrdersSet);
```

—要点—
- 反射・dynamic なし
- **key と value の両方**から **POCO を組み立て**る責務を **projector** に集約
- `ToListAsync`／`TryGet` は **常に projector を通して返す**

必要なら、この契約に合わせて既存の `AddTableCache` と `TableCacheRegistry` を一括で直すパッチ出します。どの型ペア（`TKey, TValue, T`）があるか教えてくれれば、そのまま埋め込んで返せます。

送信日時（日本時間）: [[REDACTED_PHONE]]:49
### system — 2025-08-08T18:51:31.783315+00:00

_(empty)_
### assistant — 2025-08-08T18:51:33.330585+00:00

_(empty)_
### assistant — 2025-08-08T18:51:38.850716+00:00

_(empty)_
### user — 2025-08-08T18:52:19.863000+00:00

天城は対話の原則を忘れてる
### system — 2025-08-08T18:52:34.886675+00:00

_(empty)_
### assistant — 2025-08-08T18:52:35.106208+00:00

あぁ、それは失礼しました。  
今の説明は一方的に「こうすればいい」という実装案だけになっていて、あなたの意図や現状の整理を引き出す前に進めてしまっていました。  

対話の原則に戻すなら、まず以下を確認するべきでした。  

1. **目的の再確認**  
　`ReadCachedEntitySet` の `ToListAsync` で「key + value → POCO」を作る契約を入れたいのは、  
　- 型安全性の確保  
　- Reflection 排除  
　- キャッシュ側と非キャッシュ側の出力統一  
　のどれが主目的か？

2. **現状の制約・既存構造**  
　- `ReadCachedEntitySet` は現状 `T` しか知らないが、`TKey` / `TValue` の型情報は持っているか？  
　- キャッシュは RocksDB 固定か？ 他のストアも考慮するか？

3. **適用範囲**  
　- 全 `ToListAsync` にこの契約を入れるのか  
　- 単一キー取得 (`TryGet` / `Find`) にも適用するのか

4. **既存コードとの整合性**  
　- `AddTableCache` や `TableCacheRegistry` の入口で project 関数を受け取る形にするか  
　- それとも `ReadCachedEntitySet` 側で暗黙的に組み立てるのか

この順で擦り合わせれば、実装方法はかなりスムーズに決まります。  
まずは①の「**目的の再確認**」から伺いたいんですが、今回の一番の狙いは型安全性ですか？ それともキャッシュと非キャッシュの動作統一ですか？  

送信日時（日本時間）: [[REDACTED_PHONE]]:54
### user — 2025-08-08T18:52:43.422000+00:00

わからない部分を推測して会話を乱してないか？
### assistant — 2025-08-08T18:53:00.071551+00:00

（JST [[REDACTED_PHONE]]:57）

はい、その通りです。わからない前提を**推測して話を進めて**しまい、会話を乱しました。ごめん。

以降は**推測しない／1メッセージ1論点**で進めます。

まず確認だけ一つ：  
**“key + value から POCO を作る”要件の主目的はどれですか？**  
A) 型安全（Reflection 排除）  
B) キャッシュ／非キャッシュの出力統一  
C) 既存の POCO 仕様（キーの一部を必ず含む 等）  
D) 別（短く教えてください）

この一点だけ教えてください。それを軸に、入口（`UseTableCache`）と出口（`Set<T>()`）に沿う最小の設計に落とします。
### system — 2025-08-08T18:53:00.548635+00:00

_(empty)_
### assistant — 2025-08-08T18:53:02.134682+00:00

_(empty)_
### assistant — 2025-08-08T18:53:04.116819+00:00

_(empty)_
### user — 2025-08-08T18:53:50.718000+00:00

topicはtableで使用される。tableはavro形式でデータが格納される、pocoにはkeyの部分とvalueの部分がある
### assistant — 2025-08-08T18:54:07.078067+00:00

（JST [[REDACTED_PHONE]]:00）

**一点だけ提案**：  
“topicはAvroのtableで、POCOは key 部分＋value 部分で構成”という要件を**契約として固定**するため、**合成器(Composer)** を導入します。実装は後、まずは**インターフェース契約**だけ。

```csharp
// key + value から POCO を作る契約（反射なし）
public interface IPocoComposer<TKey, TValue, T> where T : class
{
    T Compose(TKey key, TValue value);
}
```

- **入口**（UseTableCache の内部/登録時）では、この `IPocoComposer` を必須で受け取るだけにする  
  （= 反射や推測で勝手に組み立てない）
- **出口**（Set<T>().ToListAsync）では、ストア列挙 `store.All()` の各 `(key, value)` に対し  
  `composer.Compose(key, value)` を呼んで **POCO を返す**（準備不可ならフォールバック）

この**1契約**で、「POCOにはkey+valueを入れる」という要件が**明示**になり、実装は型安全・反射不要で揃えられます。
### system — 2025-08-08T18:54:07.665926+00:00

_(empty)_
### assistant — 2025-08-08T18:54:07.711935+00:00

_(empty)_
### assistant — 2025-08-08T18:54:10.340226+00:00

_(empty)_
### user — 2025-08-08T18:54:22.968000+00:00

_(empty)_
### system — 2025-08-08T18:54:38.369417+00:00

_(empty)_
### tool — 2025-08-08T18:54:38.426913+00:00

_(empty)_
### tool — 2025-08-08T18:54:38.470092+00:00

namespace Kafka.Ksql.Linq.Mapping;

using Kafka.Ksql.Linq.Core.Models;
using System;
using System.Reflection;

/// <summary>
/// Holds generated key/value types and their associated PropertyMeta information.
/// </summary>
public class KeyValueTypeMapping
{
    public Type KeyType { get; set; } = default!;
    public PropertyMeta[] KeyProperties { get; set; } = Array.Empty<PropertyMeta>();
    public PropertyInfo[] KeyTypeProperties { get; set; } = Array.Empty<PropertyInfo>();

    public Type ValueType { get; set; } = default!;
    public PropertyMeta[] ValueProperties { get; set; } = Array.Empty<PropertyMeta>();
    public PropertyInfo[] ValueTypeProperties { get; set; } = Array.Empty<PropertyInfo>();

    // Avro specific-record types generated from KeyType and ValueType
    public Type? AvroKeyType { get; set; }
    public Type? AvroValueType { get; set; }

    // Avro schema json strings for key and value
    public string? AvroKeySchema { get; set; }
    public string? AvroValueSchema { get; set; }

    /// <summary>
    /// Extract key object from POCO instance based on registered PropertyMeta.
    /// </summary>
    public object ExtractKey(object poco)
    {
        if (poco == null) throw new ArgumentNullException(nameof(poco));
        var keyInstance = Activator.CreateInstance(KeyType)!;
        for (int i = 0; i < KeyProperties.Length; i++)
        {
            var meta = KeyProperties[i];
            var value = meta.PropertyInfo!.GetValue(poco);
            KeyTypeProperties[i].SetValue(keyInstance, value);
        }
        return keyInstance;
    }

    /// <summary>
    /// Extract value object from POCO instance based on registered PropertyMeta.
    /// </summary>
    public object ExtractValue(object poco)
    {
        if (poco == null) throw new ArgumentNullException(nameof(poco));
        var valueInstance = Activator.CreateInstance(ValueType)!;
        for (int i = 0; i < ValueProperties.Length; i++)
        {
            var meta = ValueProperties[i];
            var value = meta.PropertyInfo!.GetValue(poco);
            ValueTypeProperties[i].SetValue(valueInstance, value);
        }
        return valueInstance;
    }

    /// <summary>
    /// Copy values from the provided POCO instance into the supplied
    /// key and value objects.
    /// </summary>
    /// <param name="poco">Source POCO instance.</param>
    /// <param name="key">Existing key object or null for keyless entities.</param>
    /// <param name="value">Existing value object to populate.</param>
    public void PopulateKeyValue(object poco, object? key, object value)
    {
        if (poco == null) throw new ArgumentNullException(nameof(poco));
        if (value == null) throw new ArgumentNullException(nameof(value));

        // copy value fields
        for (int i = 0; i < ValueProperties.Length; i++)
        {
            var meta = ValueProperties[i];
            var val = meta.PropertyInfo!.GetValue(poco);
            ValueTypeProperties[i].SetValue(value, val);
        }

        if (key != null)
        {
            for (int i = 0; i < KeyProperties.Length; i++)
            {
                var meta = KeyProperties[i];
                var val = meta.PropertyInfo!.GetValue(poco);
                KeyTypeProperties[i].SetValue(key, val);
            }
        }
    }

    /// <summary>
    /// Combine key and value objects into a POCO instance of the specified type.
    /// </summary>
    public object CombineFromKeyValue(object? key, object value, Type pocoType)
    {
        if (value == null) throw new ArgumentNullException(nameof(value));
        if (pocoType == null) throw new ArgumentNullException(nameof(pocoType));

        var instance = Activator.CreateInstance(pocoType)!;

        // set value properties
        for (int i = 0; i < ValueProperties.Length; i++)
        {
            var meta = ValueProperties[i];
            var val = ValueTypeProperties[i].GetValue(value);
            meta.PropertyInfo!.SetValue(instance, val);
        }

        if (key != null)
        {
            for (int i = 0; i < KeyProperties.Length; i++)
            {
                var meta = KeyProperties[i];
                var val = KeyTypeProperties[i].GetValue(key);
                meta.PropertyInfo!.SetValue(instance, val);
            }
        }

        return instance;
    }

    /// <summary>
    /// Combine Avro specific-record key/value instances into a POCO.
    /// </summary>
    public object CombineFromAvroKeyValue(object? avroKey, object avroValue, Type pocoType)
    {
        if (avroValue == null) throw new ArgumentNullException(nameof(avroValue));
        if (pocoType == null) throw new ArgumentNullException(nameof(pocoType));
        if (AvroValueType == null) throw new InvalidOperationException("AvroValueType not registered");
        if (avroKey != null && AvroKeyType == null) throw new InvalidOperationException("AvroKeyType not registered");

        var instance = Activator.CreateInstance(pocoType)!;

        // value properties
        for (int i = 0; i < ValueProperties.Length; i++)
        {
            var meta = ValueProperties[i];
            var avroProp = AvroValueType!.GetProperty(meta.PropertyInfo!.Name)!;
            var val = avroProp.GetValue(avroValue);
            meta.PropertyInfo!.SetValue(instance, val);
        }

        if (avroKey != null)
        {
            for (int i = 0; i < KeyProperties.Length; i++)
            {
                var meta = KeyProperties[i];
                var avroProp = AvroKeyType!.GetProperty(meta.PropertyInfo!.Name)!;
                var val = avroProp.GetValue(avroKey);
                meta.PropertyInfo!.SetValue(instance, val);
            }
        }

        return instance;
    }

    public object ExtractAvroKey(object poco)
    {
        if (poco == null) throw new ArgumentNullException(nameof(poco));
        if (AvroKeyType == null) throw new InvalidOperationException("AvroKeyType not registered");
        var keyInstance = Activator.CreateInstance(AvroKeyType)!;
        for (int i = 0; i < KeyProperties.Length; i++)
        {
            var meta = KeyProperties[i];
            var value = meta.PropertyInfo!.GetValue(poco);
            var avroProp = AvroKeyType!.GetProperty(meta.PropertyInfo!.Name)!;
            avroProp.SetValue(keyInstance, value);
        }
        return keyInstance;
    }

    public object ExtractAvroValue(object poco)
    {
        if (poco == null) throw new ArgumentNullException(nameof(poco));
        if (AvroValueType == null) throw new InvalidOperationException("AvroValueType not registered");
        var valueInstance = Activator.CreateInstance(AvroValueType)!;
        for (int i = 0; i < ValueProperties.Length; i++)
        {
            var meta = ValueProperties[i];
            var value = meta.PropertyInfo!.GetValue(poco);
            var avroProp = AvroValueType!.GetProperty(meta.PropertyInfo!.Name)!;
            avroProp.SetValue(valueInstance, value);
        }
        return valueInstance;
    }

    public void PopulateAvroKeyValue(object poco, object? key, object value)
    {
        if (poco == null) throw new ArgumentNullException(nameof(poco));
        if (value == null) throw new ArgumentNullException(nameof(value));

        for (int i = 0; i < ValueProperties.Length; i++)
        {
            var meta = ValueProperties[i];
            var val = meta.PropertyInfo!.GetValue(poco);
            var avroProp = AvroValueType!.GetProperty(meta.PropertyInfo!.Name)!;
            avroProp.SetValue(value, val);
        }

        if (key != null)
        {
            for (int i = 0; i < KeyProperties.Length; i++)
            {
                var meta = KeyProperties[i];
                var val = meta.PropertyInfo!.GetValue(poco);
                var avroProp = AvroKeyType!.GetProperty(meta.PropertyInfo!.Name)!;
                avroProp.SetValue(key, val);
            }
        }
    }
}
### assistant — 2025-08-08T18:54:38.481574+00:00

はい、理解しました。  
あなたの説明とアップロードされた `KeyValueTypeMapping`, `MappingRegistry`, `SpecificRecordGenerator` を総合すると、  
`ReadCachedEntitySet<T>.ToListAsync` は RocksDB（Kafka Streams の State Store）から **Avro形式の key と value** を読み出し、それを結合して **POCO（T）** インスタンスを作成する責務があります。

整理するとこうなります。

---

## ReadCachedEntitySet<T>.ToListAsync の役割
1. **State Store（table）から key/value ペアを取得**
   - Kafka Streams 側では Avro シリアライズされて保存されている。
   - key は AvroのKeyクラス、valueは AvroのValueクラス。
2. **Avroクラス → POCOへのマッピング**
   - `MappingRegistry` を利用して、  
     POCOのプロパティが key と value のどちらから取得されるかを判定。
3. **POCOを構築**
   - keyとvalueの両方の情報を持つ `T` インスタンスを作る。
   - これを全件（または条件付きで）リスト化。
4. **結果を返す**
   - `List<T>` として呼び出し元に渡す。

---

## 実装ポイント
- **KeyとValueは別クラス**
  - `KeyValueTypeMapping` が `AvroKeyType`, `AvroValueType` を持っており、それに従って Avroデシリアライズ。
- **MappingRegistryがPOCOへの紐付けを知っている**
  - プロパティ名・マッピング先が key 側か value 側かを保持。
- **結合処理**
  - KeyオブジェクトとValueオブジェクトの各プロパティをコピーして `T` を構築。

---

もしよければ、次のステップとして  
`ToListAsync` における **Avroデータの読み出し→POCO組み立ての具体的コード例** を提示します。  
これを入れると、出口（POCO生成）までの契約が明確になります。
### tool — 2025-08-08T18:54:38.504473+00:00

using Kafka.Ksql.Linq.Core.Models;
using Kafka.Ksql.Linq.Core.Abstractions;
using Kafka.Ksql.Linq.Core.Extensions;
using Kafka.Ksql.Linq.Query.Dsl;
using System;
using System.Collections.Concurrent;
using System.Reflection;
using System.Linq;
using System.Text.RegularExpressions;
using System.Reflection.Emit;
using System.Linq.Expressions;
using System.Collections.Generic;

namespace Kafka.Ksql.Linq.Mapping;

/// <summary>
/// Provides registration and lookup of dynamically generated key/value types
/// based on PropertyMeta information.
/// </summary>
public class MappingRegistry
{
    private readonly ConcurrentDictionary<Type, KeyValueTypeMapping> _mappings = new();
    private readonly ModuleBuilder _moduleBuilder;
    private Type? _lastRegisteredType;

    private static string AvroSanitizeName(string name)
    {
        var sanitized = Regex.Replace(name, @"[^A-Za-z0-9_]", "_");
        if (string.IsNullOrEmpty(sanitized))
            sanitized = "_";
        if (!Regex.IsMatch(sanitized[0].ToString(), "[A-Za-z_]"))
            sanitized = "_" + sanitized;
        return sanitized;
    }

    public MappingRegistry()
    {
        var asmName = new AssemblyName("KafkaKsqlDynamicMappings");
        var asmBuilder = AssemblyBuilder.DefineDynamicAssembly(asmName, AssemblyBuilderAccess.Run);
        _moduleBuilder = asmBuilder.DefineDynamicModule("Main");
    }

    public KeyValueTypeMapping Register(
        Type pocoType,
        PropertyMeta[] keyProperties,
        PropertyMeta[] valueProperties,
        string? topicName = null)
    {
        if (_mappings.TryGetValue(pocoType, out var existing))
        {
            return existing;
        }

        string ns = AvroSanitizeName(pocoType.Namespace?.ToLower() ?? string.Empty);

        var baseName = AvroSanitizeName((topicName ?? pocoType.Name).ToLower());

        var keyType = CreateType(ns, $"{baseName}-key", keyProperties);
        var valueType = CreateType(ns, $"{baseName}-value", valueProperties);

        // Generate ISpecificRecord types for Avro deserialization
        var avroKeyType = SpecificRecordGenerator.Generate(keyType);
        var avroValueType = SpecificRecordGenerator.Generate(valueType);
        var avroKeySchema = avroKeyType != null
            ? ((Avro.Specific.ISpecificRecord)Activator.CreateInstance(avroKeyType)!).Schema.ToString()
            : null;
        var avroValueSchema = ((Avro.Specific.ISpecificRecord)Activator.CreateInstance(avroValueType)!).Schema.ToString();

        var keyTypeProps = keyProperties
            .Select(p => keyType.GetProperty(p.Name)!)
            .ToArray();
        var valueTypeProps = valueProperties
            .Select(p => valueType.GetProperty(p.Name)!)
            .ToArray();

        var mapping = new KeyValueTypeMapping
        {
            KeyType = keyType,
            KeyProperties = keyProperties,
            KeyTypeProperties = keyTypeProps,
            ValueType = valueType,
            ValueProperties = valueProperties,
            ValueTypeProperties = valueTypeProps,
            AvroKeyType = avroKeyType,
            AvroValueType = avroValueType,
            AvroKeySchema = avroKeySchema,
            AvroValueSchema = avroValueSchema
        };
        _mappings[pocoType] = mapping;
        _lastRegisteredType = pocoType;
        return mapping;
    }

    /// <summary>
    /// Register mapping using pre-generated PropertyMeta information.
    /// </summary>
    public KeyValueTypeMapping RegisterMeta(
        Type pocoType,
        (PropertyMeta[] KeyProperties, PropertyMeta[] ValueProperties) meta,
        string? topicName = null)
    {
        return Register(pocoType, meta.KeyProperties, meta.ValueProperties, topicName);
    }

    /// <summary>
    /// Register mapping using an EntityModel's property information.
    /// Convenience wrapper so callers don't need to manually convert
    /// PropertyInfo to <see cref="PropertyMeta"/> arrays.
    /// </summary>
    public KeyValueTypeMapping RegisterEntityModel(EntityModel model)
    {
        if (model == null) throw new ArgumentNullException(nameof(model));

        var keyMeta = model.KeyProperties
            .Select(p => PropertyMeta.FromProperty(p))
            .ToArray();
        var valueMeta = model.AllProperties
            .Select(p => PropertyMeta.FromProperty(p))
            .ToArray();

        return Register(model.EntityType, keyMeta, valueMeta, model.GetTopicName());
    }

    /// <summary>
    /// Register mapping information based on a KsqlQueryModel.
    /// This extracts projection property order so the generated
    /// Avro schema matches the SELECT column ordering.
    /// </summary>
    public KeyValueTypeMapping RegisterQueryModel(
        Type resultType,
        KsqlQueryModel model,
        PropertyInfo[] keyProperties,
        string? topicName = null)
    {
        if (resultType == null) throw new ArgumentNullException(nameof(resultType));
        if (model == null) throw new ArgumentNullException(nameof(model));
        if (keyProperties == null) throw new ArgumentNullException(nameof(keyProperties));

        var valueProps = ExtractProjectionProperties(model.SelectProjection, resultType)
            .Select(p => PropertyMeta.FromProperty(p))
            .ToArray();
        var keyMeta = keyProperties.Select(p => PropertyMeta.FromProperty(p)).ToArray();

        return Register(resultType, keyMeta, valueProps, topicName ?? resultType.Name.ToLowerInvariant());
    }

    private static List<PropertyInfo> ExtractProjectionProperties(LambdaExpression? projection, Type resultType)
    {
        if (projection == null)
            return resultType.GetProperties(BindingFlags.Public | BindingFlags.Instance).ToList();

        var props = new List<PropertyInfo>();
        switch (projection.Body)
        {
            case NewExpression newExpr when newExpr.Members != null:
                foreach (var mem in newExpr.Members.OfType<PropertyInfo>())
                {
                    var p = resultType.GetProperty(mem.Name);
                    if (p != null) props.Add(p);
                }
                break;
            case MemberInitExpression initExpr:
                foreach (var binding in initExpr.Bindings.OfType<MemberAssignment>())
                {
                    var p = resultType.GetProperty(binding.Member.Name);
                    if (p != null) props.Add(p);
                }
                break;
            case ParameterExpression:
                props.AddRange(resultType.GetProperties(BindingFlags.Public | BindingFlags.Instance));
                break;
            case MemberExpression me when me.Member is PropertyInfo pi:
                var prop = resultType.GetProperty(pi.Name);
                if (prop != null) props.Add(prop);
                break;
        }
        return props;
    }

    public KeyValueTypeMapping GetMapping(Type pocoType)
    {
        if (_mappings.TryGetValue(pocoType, out var mapping))
        {
            return mapping;
        }
        throw new InvalidOperationException($"Mapping for {pocoType.FullName} is not registered.");
    }

    /// <summary>
    /// Returns the most recently registered POCO type, or null if none.
    /// </summary>
    public Type? GetLastRegistered()
    {
        return _lastRegisteredType;
    }

    private Type CreateType(string ns, string name, PropertyMeta[] properties)
    {
        var safeName = AvroSanitizeName(name);
        var typeBuilder = _moduleBuilder.DefineType($"{ns}.{safeName}", TypeAttributes.Public | TypeAttributes.Class);
        foreach (var meta in properties)
        {
            var field = typeBuilder.DefineField($"_{meta.Name}", meta.PropertyType, FieldAttributes.Private);
            var property = typeBuilder.DefineProperty(meta.Name, PropertyAttributes.None, meta.PropertyType, null);
            var getMethod = typeBuilder.DefineMethod(
                $"get_{meta.Name}",
                MethodAttributes.Public | MethodAttributes.HideBySig | MethodAttributes.SpecialName,
                meta.PropertyType,
                Type.EmptyTypes);
            var ilGet = getMethod.GetILGenerator();
            ilGet.Emit(OpCodes.Ldarg_0);
            ilGet.Emit(OpCodes.Ldfld, field);
            ilGet.Emit(OpCodes.Ret);
            var setMethod = typeBuilder.DefineMethod(
                $"set_{meta.Name}",
                MethodAttributes.Public | MethodAttributes.HideBySig | MethodAttributes.SpecialName,
                null,
                new[] { meta.PropertyType });
            var ilSet = setMethod.GetILGenerator();
            ilSet.Emit(OpCodes.Ldarg_0);
            ilSet.Emit(OpCodes.Ldarg_1);
            ilSet.Emit(OpCodes.Stfld, field);
            ilSet.Emit(OpCodes.Ret);
            property.SetGetMethod(getMethod);
            property.SetSetMethod(setMethod);
        }
        return typeBuilder.CreateType()!;
    }
}
