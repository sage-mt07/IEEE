---
conversation_id: "67b46951-1988-8007-8d60-c2c30241a4ad"
title: "KSQLログ確認方法"
create_time: 1739876689.387193
update_time: 1739876824.798848
language_guess: "en"
num_messages: 10
part_index: 1
part_count: 1
---

### system — 2025-02-18T11:04:49.386767+00:00

_(empty)_

### system — 2025-02-18T11:04:49.387193+00:00

_(empty)_

### system — 2025-02-18T11:04:49.387193+00:00

_(empty)_

### user — 2025-02-18T11:04:49.396590+00:00

KSQLのログを確認する方法

### tool — 2025-02-18T11:05:09.531641+00:00

**確認の手順を追う**

KSQLのログを確認する方法を見ている。ユーザー提供の文書がないので、標準的な手順を日本語で説明している。

**ログの所在を探って**

KSQLのログは通常、KafkaのデフォルトディレクトリやConfluentの設定ディレクトリにあることが多い。ログファイルの管理にはlog4jを使っている。

### assistant — 2025-02-18T11:05:09.531740+00:00

KSQL (Confluent PlatformのKSQL) が出力するログは、基本的にKafkaの他コンポーネントと同様にLog4jを使って管理されています。標準的なインストール手順に従っている場合、以下のような方法でログを確認できます。

1. **KSQLサーバーのログファイルを直接参照**  
   - 通常は「(Confluentをインストールしたディレクトリ)/logs/ksql」というディレクトリ、または「/var/log/ksql」のようにシステム管理者が設定した場所にログファイルが出力されます。  
   - 代表的には「ksql-server.log」や「server.log」といった名前でファイルが作成されますので、それをtailやlessなどで確認すると良いでしょう。

2. **log4jの設定ファイルを確認して出力先を特定する**  
   - KSQLもKafka同様にlog4jプロパティファイル（例: `ksql-server-log4j.properties`）によってログの設定が行われています。  
   - Confluent Platformの配下にある`etc/ksql/`ディレクトリや`config/`ディレクトリなどに存在する場合が多いので、そちらで`log4j.appender`の項目を探すと具体的なログファイルのパスが分かります。

3. **Docker/Kubernetes環境の場合**  
   - DockerでKSQLを起動している場合は、コンテナの標準出力にログが出る設定になっていることが多いため、次のコマンドでログを確認します。  
     ```
     docker logs <ksqlのコンテナ名>
     ```  
   - Kubernetesの場合はPodの標準出力としてログが出ていることが多いので、kubectl経由で次のように確認できます。  
     ```
     kubectl logs <ksqlのPod名>
     ```

4. **Confluent Control Centerから確認する**  
   - Confluent Control Center (商用環境で利用可能) を導入している場合、KSQLのアプリケーションログやサーバーログの一部をGUI上でモニタリングできます。  
   - ただし、詳細なスタックトレースなどを確認するには結局サーバー上に出力されるログを参照するほうが確実です。

5. **ログレベル変更の方法**  
   - ログが多すぎたり、逆に足りなかったりする場合は、log4jの設定ファイルやKSQLサーバーの起動プロパティでログレベルを調整できます。  
   - 例えば`WARN`から`DEBUG`に変更する場合は、`log4j.logger.io.confluent.ksql=DEBUG` のような設定を行います。  
   - 変更後にKSQLサーバーを再起動すると、新しい設定が反映されます。

上記の方法でKSQLのログを確認できるはずです。まずはサーバー上のKSQL用ログファイルの場所を特定し、必要に応じてログレベルを調整しながら調査するとよいでしょう。

### user — 2025-02-18T11:06:22.343043+00:00

k8sで動かす。エラーハンドリングの設定を示せ

### tool — 2025-02-18T11:07:03.901462+00:00

k8sで動かす。エラーハンドリングの設定を示す

KSQLのエラーハンドリング設定ոռ

**Deserialization errors**: fail stream or "ksql.streams.default.deserialization.exception.handler".

**Production errors**: DefaultProductionExceptionHandler or others.

**Timestamp extraction**: LogAndSkipOnInvalidTimestamp.

**Other settings**: ksql.enable.rocksdb.checksum, ksql.persistence.*, ksql.query.error.handling.

**KSQLデプロイメントの環境変数を設定する方法**

環境変数やconfig mapを用いて、エラーハンドリングの設定を追加することで、KSQLデプロイメントを成功に導く。

**持続的デプロイの設定**

ConfigMapを作成し、明示的に指定されたログハンドリング設定や耐久性のあるボリュームのマウント方法を示すことで、KSQLデプロイメントの手順を明確にする。

### assistant — 2025-02-18T11:07:03.901565+00:00

KSQL (KSQLDB) は実際には内部で Kafka Streams を用いており、メッセージのデシリアライズエラーやプロデューサーエラーなど、Kafka Streams 由来のエラーが発生する場合があります。これらのエラーの扱い方を制御するには、KSQL サーバーで設定する Kafka Streams のプロパティや KSQL 独自の設定を Kubernetes 環境で反映させる必要があります。本回答では、Kubernetes 上で KSQL を稼働させているケースを想定し、エラーハンドリングを設定する手順例を示します。

---

## 1. エラーハンドリングに関わる主な設定項目

### Kafka Streams 側の例外ハンドラ
KSQL では内部的に Kafka Streams を利用しており、以下のような Kafka Streams の例外ハンドラ設定を用いることで、エラー発生時の挙動を制御します。

1. **Deserialization Exception Handler (受信メッセージのデシリアライズエラー用)**
   - `ksql.streams.default.deserialization.exception.handler`
   - 例: 
     - `org.apache.kafka.streams.errors.LogAndContinueExceptionHandler`  
       エラーをログに出力してストリーム処理を継続する
     - `org.apache.kafka.streams.errors.LogAndFailExceptionHandler`  
       エラー発生時にアプリケーションを停止する (デフォルト)

2. **Production Exception Handler (出力先への書き込み時エラー用)**
   - `ksql.streams.default.production.exception.handler`
   - 例:
     - `org.apache.kafka.streams.errors.ProductionExceptionHandler$LogAndContinueExceptionHandler`
     - `org.apache.kafka.streams.errors.ProductionExceptionHandler$LogAndFailExceptionHandler`

これらを適切に設定することで、「不正なメッセージを無視しつつストリーム処理を継続する」「エラー発生時にアプリを停止させる」といった動作を切り替えられます。

### KSQL 独自のエラーハンドリング設定
KSQL には Kafka Streams の例外ハンドラ以外にも、処理エラー時の再トライやエラーイベントの取り扱いに関する独自設定が存在します。たとえば以下のような設定が挙げられます（バージョンにより名称が変わる場合があります）。

- `ksql.query.error.max.queue.size`
- `ksql.sink.repartition.errant.record.handler` 等

これらは複雑なユースケース（たとえば「エラーレコードだけを別トピックに退避する」など）で使用されます。まずは Kafka Streams 由来のエラーハンドラを把握し、必要に応じて追加設定を検討するのが一般的です。

---

## 2. Kubernetes での設定反映方法

Kubernetes 上で KSQL を動かす場合、**ConfigMap** や **Helm chart** の仕組みを使い、KSQL 用の設定ファイルや環境変数を注入するアプローチが一般的です。ここでは ConfigMap による設定を例示します。

### 2-1. ConfigMap の作成

以下のような `ksql-server.properties` ファイルを ConfigMap で管理するとします。ここではデシリアライズエラーとプロデューサーエラーに対して、それぞれ「ログ出力して処理継続」「ログ出力して処理失敗」という設定を例示します。

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: ksql-server-config
data:
  ksql-server.properties: |
    # Kafka Streams のエラーハンドラー設定例
    ksql.streams.default.deserialization.exception.handler=org.apache.kafka.streams.errors.LogAndContinueExceptionHandler
    ksql.streams.default.production.exception.handler=org.apache.kafka.streams.errors.ProductionExceptionHandler$LogAndFailExceptionHandler

    # 必要に応じて、KSQL 独自の設定もここに書く
    # ksql.query.error.max.queue.size=10
    # など
```

- `ksql.streams.*` で始まるプロパティは Kafka Streams 側の設定を行うための KSQL 設定です。
- バージョンによって利用可能なクラスが異なる場合がありますので、使用中の KSQL バージョン・Kafka Streams バージョンに合わせてドキュメントを確認してください。

### 2-2. Deployment へのマウント

次に、上記 ConfigMap を KSQL の Deployment（または StatefulSet）にマウントし、コンテナ起動時にその設定を読み込ませる例です。

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ksql-server
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ksql-server
  template:
    metadata:
      labels:
        app: ksql-server
    spec:
      containers:
      - name: ksql-server
        image: confluentinc/ksqldb-server:latest
        # volumeMounts で ConfigMap を /etc/ksql など任意の場所に配置
        volumeMounts:
          - name: ksql-config
            mountPath: /etc/ksql
            readOnly: true
        env:
          # KSQL_CONFIG_DIR など、KSQL が設定ファイルを参照できるように環境変数を定義
          - name: KSQL_CONFIG_DIR
            value: "/etc/ksql"
          # もしくは KSQL_xxx のプレフィックスで直接プロパティを注入することも可能
          # - name: KSQL_STREAMS_DEFAULT_DESERIALIZATION_EXCEPTION_HANDLER
          #   value: "org.apache.kafka.streams.errors.LogAndContinueExceptionHandler"
        ports:
          - containerPort: 8088
      volumes:
      - name: ksql-config
        configMap:
          name: ksql-server-config
```

上記例では、

1. `ksql-server-config` という ConfigMap をボリュームとしてマウント  
2. `/etc/ksql` 配下に `ksql-server.properties` を配置  
3. `KSQL_CONFIG_DIR=/etc/ksql` として KSQL に読み込ませる  

という流れになっています。イメージ内の起動スクリプトが `KSQL_CONFIG_DIR` を読み取り、自動的に `ksql-server.properties` の内容を KSQL サーバー起動時に反映するようになっています（Confluent 公式イメージの場合）。

---

## 3. よくあるパターンと注意点

1. **エラーをスキップするか・止めるか**  
   - 不正メッセージが入る可能性が高いストリームの場合は、  
     `org.apache.kafka.streams.errors.LogAndContinueExceptionHandler`  
     を指定し、問題のあるメッセージをスキップしつつログを確認するパターンが多いです。  
   - 重要なトピックで「そもそも不正データが混入してはいけない」という要件の場合には、  
     `LogAndFailExceptionHandler`  
     を指定してアプリを止めることが望ましいケースもあります。

2. **設定ファイル vs. 環境変数**  
   - KSQL (あるいは Kafka Streams) のほとんどのプロパティは、`KSQL_` や `KSQL_STREAMS_` のプレフィックス付き環境変数として与えることでも設定可能です。  
   - しかし、本番運用では設定ファイルにまとめて管理し、ConfigMap でバージョン管理する方法が見通しを良くします。

3. **バージョン差異に要注意**  
   - KSQL (KSQLDB) のバージョンや Confluent Platform のバージョンによって、利用できる例外ハンドラ・設定キーの名称が異なる場合があります。  
   - 公式ドキュメントやリリースノートでお使いのバージョンに対応したパラメータを確認してください。

4. **エラーメッセージの可視化**  
   - Kubernetes 上で稼働している場合、Pod のログは `kubectl logs <Pod名>` コマンドで確認できます。  
   - ログにエラーが大量に発生すると見落とす場合もあるので、ELK など外部ログ基盤を組み合わせておくと運用が楽になります。

---

## まとめ

- **Kafka Streams 由来の例外ハンドラを設定**することで、KSQL のエラー発生時の挙動（ログ出力のみ、継続実行、アプリ停止など）を制御可能です。  
- **Kubernetes 上では ConfigMap** や Helm chart で **`ksql-server.properties`** を管理するのが一般的なやり方で、エラーハンドリングに関する各種パラメータをまとめて反映します。  
- 運用要件によって「エラーはスキップして止まらないようにする」「エラー検知時にアプリを即停止して再起動をかける」といった切り替えが必要ですので、本番運用環境の要件に合わせて適切に設定してください。

これらを参考に、KSQL のエラーハンドリング設定を Kubernetes 上で反映する環境を構築することができます。
