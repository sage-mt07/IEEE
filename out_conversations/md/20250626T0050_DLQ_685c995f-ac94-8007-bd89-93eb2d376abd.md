---
conversation_id: "685c995f-ac94-8007-bd89-93eb2d376abd"
title: "DLQ送信クラスレビュー"
create_time: 1750899039.900166
update_time: 1751008276.732874
language_guess: "en"
num_messages: 31
part_index: 1
part_count: 1
---

### system — 2025-06-26T00:50:39.900166+00:00

_(empty)_

### user — 2025-06-26T00:50:39.900166+00:00

_(empty)_

### assistant — 2025-06-26T00:50:40.308157+00:00

🕘 2025年6月26日 09:28（日本時間）

確認しました。この `DlqProducer` クラスは、Kafkaメッセージ処理中に発生したエラーをDLQ（Dead Letter Queue）に送信するための実装として、以下の点で非常によく整理されています。

---

### ✅ 主な機能レビュー

#### 🔹 コンストラクタ
- `IKafkaProducer<DlqEnvelope>` を依存注入
- `IOptions<KsqlDslOptions>` からDLQトピック名を取得（デフォルト `"dead.letter.queue"`）

#### 🔹 `HandleErrorAsync<T>` メソッド
- ジェネリック型Tでメッセージ型を扱える汎用設計
- Avro（仮実装）でのシリアライズ後、`DlqEnvelope` を生成
- Kafkaの文脈情報（`KafkaMessageContext`）付きで送信
- ログ出力によりDLQ送信の成功／失敗を記録

#### 🔹 `SerializeToAvro<T>` メソッド
- 現在はJSON→UTF8の簡易実装
- Avroが導入されるまでの暫定手段として適切
- 失敗時のフォールバック処理もあるため堅牢

#### 🔹 `Dispose` 実装
- `IKafkaProducer`の破棄＋ログ出力あり
- 2重Dispose防止のため `_disposed` フラグあり

---

### 🛠 改善提案（必要に応じて）

| 点 | 提案 | 理由 |
|---|------|------|
| **Avroシリアライズ** | TODOの実装を進める | 本番運用ではJSON文字列ではなくAvro形式が必要 |
| **DLQトピックの動的作成** | 起動時にDLQトピックの存在確認／作成機能を別途設ける | 初回エラー時にKafkaトピックが無いと失敗するリスクあり |
| **ErrorContextの型** | `context.Tags["..."]` アクセスが多いため、共通の `DlqMetadata` にマップすると読みやすくなる | 型安全性と保守性向上 |
| **ログ拡張** | `CorrelationId` や `RetryCount` もログに含めると後追い調査がしやすくなる | 運用性向上 |

---

### 📦 名前空間構成について（補足）

このクラスは以下に配置されています：

```
namespace Kafka.Ksql.Linq.Messaging.Producers
```

これは非常に妥当です。`DlqProducer` は内部的には `IKafkaProducer` をラップしており、「高水準のプロデューサ」として `Messaging.Producers` に属するのが自然です。

`DlqEnvelope` も `Messaging.Models` に存在する前提で問題ありません。

---

### 🧩 使用想定コード（例）

```csharp
var producer = new DlqProducer(dlqKafkaProducer, options, logger);
await producer.HandleErrorAsync(order, ex, context);
```

---

必要であれば、`IDlqProducer` インターフェースを切り出して、モック化しやすい形にもできます。

ご希望であれば、Avro本実装・起動時トピックチェックコードなどもご提供可能です。どうされますか？

### user — 2025-06-26T00:50:40.479000+00:00

Dlqへの送信クラス
チェックして

### assistant — 2025-06-26T00:50:51.780491+00:00

_(empty)_

### tool — 2025-06-26T00:50:51.780598+00:00

_(empty)_

### tool — 2025-06-26T00:50:51.780649+00:00

using Kafka.Ksql.Linq.Configuration;
using Kafka.Ksql.Linq.Core.Abstractions;
using Kafka.Ksql.Linq.Messaging.Abstractions;
using Kafka.Ksql.Linq.Messaging.Contracts;
using Kafka.Ksql.Linq.Messaging.Models;
using Microsoft.Extensions.Logging;
using Microsoft.Extensions.Options;
using System;
using System.Collections.Generic;
using System.Threading;
using System.Threading.Tasks;

namespace Kafka.Ksql.Linq.Messaging.Producers;

public class DlqProducer : IErrorSink, IDisposable
{
    private readonly IKafkaProducer<DlqEnvelope> _producer;
    private readonly ILogger? _logger;
    private readonly string _dlqTopicName;
    private bool _disposed = false;

    public DlqProducer(
        IKafkaProducer<DlqEnvelope> producer,
        IOptions<KsqlDslOptions> options,
        ILogger<DlqProducer>? logger = null)
    {
        _producer = producer ?? throw new ArgumentNullException(nameof(producer));
        _logger = logger;
        _dlqTopicName = options?.Value?.DlqTopicName ?? "dead.letter.queue";
    }

    /// <summary>
    /// エラーレコードをDLQに送信
    /// </summary>
    public async Task HandleErrorAsync<T>(T originalMessage, Exception exception,
        KafkaMessageContext? context = null, CancellationToken cancellationToken = default)
        where T : class
    {
        if (originalMessage == null)
            throw new ArgumentNullException(nameof(originalMessage));
        if (exception == null)
            throw new ArgumentNullException(nameof(exception));

        try
        {
            // 元メッセージをAvroバイナリにシリアライズ
            var avroPayload = await SerializeToAvro(originalMessage);

            var dlqEnvelope = new DlqEnvelope
            {
                Topic = context?.Tags?.GetValueOrDefault("original_topic")?.ToString() ?? typeof(T).Name,
                Partition = (int)(context?.Tags?.GetValueOrDefault("original_partition") ?? 0),
                Offset = (long)(context?.Tags?.GetValueOrDefault("original_offset") ?? 0),
                AvroPayload = avroPayload,
                ExceptionType = exception.GetType().FullName ?? "Unknown",
                ExceptionMessage = exception.Message,
                StackTrace = exception.StackTrace,
                Timestamp = DateTime.UtcNow,
                RetryCount = (int)(context?.Tags?.GetValueOrDefault("retry_count") ?? 0),
                CorrelationId = context?.CorrelationId
            };

            var dlqContext = new KafkaMessageContext
            {
                MessageId = Guid.NewGuid().ToString(),
                CorrelationId = context?.CorrelationId,
                Tags = new Dictionary<string, object>
                {
                    ["dlq_source"] = "EventSet.ErrorHandling",
                    ["original_type"] = typeof(T).Name,
                    ["error_phase"] = context?.Tags?.GetValueOrDefault("error_phase") ?? "Unknown"
                }
            };

            await _producer.SendAsync(dlqEnvelope, dlqContext, cancellationToken);

            _logger?.LogInformation("Message sent to DLQ: {OriginalType} -> {DlqTopic}, Error: {ErrorType}",
                typeof(T).Name, _dlqTopicName, exception.GetType().Name);
        }
        catch (Exception ex)
        {
            _logger?.LogError(ex, "Failed to send message to DLQ: {OriginalType}, Original error: {OriginalError}",
                typeof(T).Name, exception.Message);
            throw;
        }
    }

    /// <summary>
    /// メッセージをAvroバイナリにシリアライズ
    /// </summary>
    private async Task<byte[]> SerializeToAvro<T>(T message) where T : class
    {
        try
        {
            // TODO: 実際のAvroシリアライザーを使用
            // 現在は簡易実装（JSON → UTF8バイト）
            var json = System.Text.Json.JsonSerializer.Serialize(message);
            return System.Text.Encoding.UTF8.GetBytes(json);
        }
        catch (Exception ex)
        {
            _logger?.LogWarning(ex, "Failed to serialize to Avro, using fallback: {MessageType}", typeof(T).Name);
            // フォールバック: ToString() → UTF8バイト
            return System.Text.Encoding.UTF8.GetBytes(message?.ToString() ?? "null");
        }
    }

    public void Dispose()
    {
        if (!_disposed)
        {
            _producer?.Dispose();
            _disposed = true;
            _logger?.LogDebug("DlqProducer disposed");
        }
    }
}

### tool — 2025-06-26T00:50:51.780693+00:00

All the files uploaded by the user have been fully loaded. Searching won't provide additional information.

### assistant — 2025-06-26T00:51:31.485644+00:00

🕘 2025年6月26日 09:33（日本時間）

はい、`SerializeToAvro` を **「そのままAvroのバイナリにする」**ことは可能です。ただし、以下の条件を満たす必要があります：

---

## ✅ 「そのままバイナリ」とは何か？

「JSON → UTF8 バイト配列」ではなく、**スキーマ定義に基づいたAvroバイナリ形式（Apache Avro binary encoding）**でシリアライズする、という意味ですよね？  
これは **Apache Avroの公式バイナリシリアライズ形式** を使えば実現可能です。

---

## 🛠 必要な実装要素

### 1. Avroスキーマの用意
- POCOクラス（例：`Order`）に対応するAvroスキーマを用意
- もしくは `AvroConvert.GenerateSchema(typeof(T))` などを使用して自動生成

### 2. バイナリシリアライズ用ライブラリ
- おすすめ：
  - [`Chr.Avro`](https://github.com/logicalclocks/avro)（C#でのスキーマベースシリアライズ）
  - [`Apache.Avro`](https://www.nuget.org/packages/Apache.Avro/)（公式）
  - [`SolTechnology.Avro`](https://www.nuget.org/packages/SolTechnology.Avro/)（便利）

### 3. 実装例（`SolTechnology.Avro`使用）

```csharp
private async Task<byte[]> SerializeToAvro<T>(T message) where T : class
{
    try
    {
        return AvroConvert.Serialize(message); // SolTechnology.Avro を使用
    }
    catch (Exception ex)
    {
        _logger?.LogWarning(ex, "Avroバイナリシリアライズ失敗、フォールバック使用: {MessageType}", typeof(T).Name);
        return System.Text.Encoding.UTF8.GetBytes(message?.ToString() ?? "null");
    }
}
```

> ※この実装には `SolTechnology.Avro` のNuGetパッケージが必要です。

---

## 🔍 なぜまだJSONなのか？

現在の `SerializeToAvro` はこうなっています：

```csharp
var json = System.Text.Json.JsonSerializer.Serialize(message);
return System.Text.Encoding.UTF8.GetBytes(json);
```

これは暫定実装であり、次の理由が考えられます：

- **Avroスキーマの定義と管理が未整備**
- **外部依存ライブラリをまだ入れたくない段階**
- **Kafka側（DLQコンシューマ）のAvroデシリアライズが未対応**

---

## 🔚 結論

「そのままバイナリ化」は **Avroシリアライザ導入で即可能**です。ただし：

- Avroスキーマの設計（整合性確認含む）
- Kafka Consumer側のAvro対応

もセットで進める必要があります。

---

必要であれば、SolTechnology.Avro版の完全な実装サンプルを生成します。  
また、Schema Registry連携型のAvro実装（Confluent互換）も対応可能です。ご希望ありますか？

### user — 2025-06-26T00:51:31.968000+00:00

SerializeToAvro　これはそのままバイナリとはできない？

### assistant — 2025-06-26T00:52:26.192855+00:00

🕘 2025年6月26日 09:39（日本時間）

了解です。では、現在の `SerializeToAvro` 実装をどうすべきか、以下の観点で整理して提案します。

---

## 🧭 方針を決めるための前提条件

以下のいずれかが導入済みか、または導入予定ですか？

| 要素                             | 状況        | コメント |
|----------------------------------|-------------|----------|
| ✅ Kafka ConsumerでAvro受信対応 | 未確認？    | DLQの読み手側がAvro対応済ならAvroバイナリにすべき |
| ✅ Avroスキーマ設計済             | 未確認？    | POCOに対応したAvroスキーマが必要 |
| ✅ Schema Registry導入済         | OSS開発中   | Confluent互換であればSchema Registry対応を考慮 |

---

## 🔧 推奨方針（今すぐ vs 将来）

### 🟢 **今すぐやるなら（暫定方針）**
```csharp
// 現在のままJSON UTF-8（暫定でOK）
// → DLQの可視性・デバッグ性重視（人間が確認しやすい）
// → まずDLQ送信処理全体の動作確認を優先
```

**理由：**
- AvroバイナリはKafkaコンシューマでの解析が面倒
- 現時点では、まずDLQ動作の確立が重要

---

### 🔵 **将来やるなら（本番移行時）**
```csharp
// Avro本実装 + スキーマ管理 + Schema Registry導入（本格運用）
```

- `SolTechnology.Avro` などでバイナリシリアライズを導入
- Schema RegistryでスキーマID付き送信（Confluent連携）
- Consumer側でもAvro反復利用

---

## 🎯 結論：どうすべき？

以下の段階的導入が **OSS・AI開発環境での実用にも最適**です：

---

### 🔸 ステップ1（今すぐ）
- 現在の JSON UTF-8 で運用開始（**そのまま**でOK）
- DLQの送信・構造・トラブルシュートを検証

### 🔸 ステップ2（DLQ活用が軌道に乗ったら）
- `AvroConvert.Serialize()` などを使ってAvroバイナリ対応
- POCOスキーマの明示的定義を設ける
- Schema Registry対応（Kafka側と整合が必要）

---

## ✍️ 最後に一言

DLQの設計においては「**人が見る段階**→**システムで読む段階**」と段階を分けるのがベストです。  
今は「人が見る段階」に焦点を当て、JSONで視認性を重視し、将来的にAvroへ移行すれば完璧です。

---

ご希望あれば、Avroバイナリ版の`SerializeToAvro`完全サンプルも即用意します！

### user — 2025-06-26T00:52:26.620000+00:00

どうすべき？

### assistant — 2025-06-26T00:53:50.180599+00:00

🕘 2025年6月26日 09:43（日本時間）

まさにその通りです！  
DLQ（Dead Letter Queue）の運用における考え方として、以下のように整理できます：

---

## ✅ DLQ運用の基本戦略（あなたの方針の要点）

### 💡 **1. 設計想定外の異常を一時隔離する場**
- 本来処理されるはずのメッセージが**何らかの原因で処理できない**場合に退避
- これは「即時対処はできない」ことを前提にしている

> 📌 **DLQはリアルタイム解決の場ではなく、後日調査・分析のための隔離エリア**

---

### 🕵️ **2. 後日のために“可視性”を最大限確保**
- **人間が見る**ことを前提に、最低限以下をログ・メッセージに含める：

| 情報種別          | 例                            |
|-------------------|-------------------------------|
| エラー発生元       | `Topic`, `Partition`, `Offset` |
| エラー内容         | `ExceptionType`, `Message`, `StackTrace` |
| 処理メッセージ     | シリアライズされた `AvroPayload`（現状はJSON） |
| 相関ID／再送回数   | `CorrelationId`, `RetryCount` |
| 発生時刻           | `Timestamp` |

> 📌 **バイナリ形式よりもJSONのほうが調査時に有利**

---

### 🧱 **3. 安定運用のための「遅延対処」戦略**
- DLQは即時修復の代わりに「処理不能ログを確保」することで、システム全体を**Fail-Fastにせず回避的に継続**できる
- → **処理不能 = 障害だが致命的停止にはしない**という堅牢設計の一部

---

## 🎯 今のDLQ運用方針（要約）

| 項目 | 方針 |
|------|------|
| 即時復旧 | ❌ 不要（想定外なので後日対応） |
| 可視性 | ✅ 重視（人間が見て理解できること） |
| フォーマット | ✅ JSON（Avroは将来的に検討） |
| ログ記録 | ✅ エラー種別・発生元・時刻を記録 |
| 本番導入時 | 🔜 Avro対応＋SchemaRegistry可 |

---

## ✅ 結論

> 「**DLQは“今は直せない問題”の墓場ではなく、“後で振り返るための証拠保全”**」

現状のJSONシリアライズは、
- **人間中心のデバッグフェーズに最適**
- **運用段階ではAvroへ移行可能**
という戦略的に理にかなった選択です。

---

必要であれば、DLQ運用設計としてREADMEなどに書くための文案も作成できます！

### user — 2025-06-26T00:53:50.679000+00:00

DLQの運用として
設計想定外のため、即時対応はできない
後日のために可視性を高める
の考え方？

### assistant — 2025-06-26T00:55:22.453083+00:00

🕘 2025年6月26日 09:49（日本時間）

はい、今回のDLQ運用方針（「設計想定外への即時対応は困難 → 可視性重視で後日対処」）は、**`oss_design_combined.md` の `6.2 デッドレターキュー` セクションに明記するのが最適**です。

---

## ✍️ 追記提案文（`6.2 デッドレターキュー` 末尾に追加）

以下のような文言を加えることで、設計思想と運用意図が明確になります：

---

### 🔧 推奨追記案：

```markdown
#### 運用上の基本方針

DLQ は、設計上の想定を超えた異常や、即時復旧が困難なケースに対応するための「一時隔離」と「後日調査」のための仕組みとして設計されています。

本フレームワークでは、DLQ を単なるログの退避先ではなく、以下のような設計哲学に基づいて実装・運用します：

- **即時対応は前提としない**  
  DLQ に送られるメッセージは、システム全体を止めずに「例外的状況を分離する」ためのものです。
  そのため、リアルタイムでの再処理や復旧は設計上必須ではなく、後日改めて解析・対処することを基本とします。

- **可視性の最大化を重視**  
  DLQメッセージには、エラー発生時の文脈情報（トピック、パーティション、オフセット、例外内容、再送回数、相関IDなど）を可能な限り含めることで、
  開発者や運用担当者が後日容易にトラブルシュートできるよう配慮されています。

- **メッセージ形式はJSONベース（暫定）**  
  現時点では、人間による確認・解析を優先し、DLQに格納されるメッセージはAvro形式ではなくJSONバイト列として格納されます。
  将来的にはスキーマ整備とConsumerの対応状況に応じて、Avroバイナリ形式への移行を検討します。

このように、DLQは「失敗を記録して放置する」のではなく、「将来の知見獲得と改善活動の起点」として位置づけられています。
```

---

ご希望であればこのまま文書に反映しますが、内容調整（口調、技術的細部など）や英訳追加も可能です。どうしますか？

### user — 2025-06-26T00:55:22.894000+00:00

これに記載？

### tool — 2025-06-26T00:55:33.525014+00:00

_(empty)_

### tool — 2025-06-26T00:55:33.525145+00:00

# OSS設計資料：統合ドキュメント

## Overview

### Readme

﻿# KSQL Entity Framework 要件定義書

## 目次 (Table of Contents)

- [1. 概要](#1-概要)
- [2. 基本原則](#2-基本原則)
- [3. 主要コンポーネント](#3-主要コンポーネント)
  - [3.1 トピック (Kafka Topics)](#31-トピック-kafka-topics)
  - [3.2 ストリーム (KSQL Streams)](#32-ストリーム-ksql-streams)
  - [3.3 テーブル (KSQL Tables)](#33-テーブル-ksql-tables)
  - [3.4 クエリと購読](#34-クエリと購読)
- [4. POCO (Plain Old CLR Objects) の設計](#4-poco-plain-old-clr-objects-の設計)
  - [4.1 基本定義](#41-基本定義)
  - [4.2 特殊型のサポート](#42-特殊型のサポート)
- [5. プロデュース/コンシューム操作](#5-プロデュースコンシューム操作)
  - [5.1 プロデューサー (データ送信)](#51-プロデューサー-データ送信)
  - [5.2 コンシューマー (データ受信)](#52-コンシューマー-データ受信)
  - [5.3 トランザクション処理](#53-トランザクション処理)
- [6. エラー処理とデータ品質](#6-エラー処理とデータ品質)
  - [6.1 エラー処理戦略](#61-エラー処理戦略)
  - [6.2 デッドレターキュー](#62-デッドレターキュー)
- [7. テーブル管理操作](#7-テーブル管理操作)
  - [7.1 テーブル作成と更新](#71-テーブル作成と更新)
  - [7.2 テーブルの再構築と管理](#72-テーブルの再構築と管理)
- [8. リリース計画](#8-リリース計画)
- [9. アーキテクチャ概要](#9-アーキテクチャ概要)
  - [コアコンポーネント](#コアコンポーネント)
  - [主要インターフェース](#主要インターフェース)
  - 
## 1. 概要

KSQL Entity Frameworkは、C#プログラマがEntityFrameworkライクなAPIを使用してKSQL/KafkaStreamsを操作できるようにするライブラリです。トピック中心の設計、POCOベースのクエリ定義、LINQライクなストリーム操作を特徴とします。

## 2. 基本原則

1. **トピック中心設計**: すべての操作はKafkaトピックを起点とする
2. **型安全性**: C#の型システムを活用してスキーマの整合性を確保
3. **使い慣れたAPI**: EntityFrameworkに類似したAPIデザイン
4. **LINQサポート**: ストリーム処理をLINQクエリとして表現
5. **段階的デプロイ**: 基本機能から高度な機能へと段階的に実装
6. **購読モードの固定化**: ストリーム定義時に自動コミット／手動コミットの方式を明示し、実行時に切り替え不可とする


## 3. POCO属性ベースDSL設計ルール（Fluent APIの排除方針）

本OSSでは、Kafka/KSQLの設定をすべてPOCOクラスの属性で定義する方式を採用する。
これは、Fluent APIを用いたDSL記述の柔軟性と引き換えに、「構成がPOCOに集約されている」という明快さを重視した設計方針である。

🏷️ クラスレベル属性一覧
|属性名	|説明|
|---|---|
[Topic("topic-name")]	|Kafkaトピック名の指定（Partitions, Replicationも設定可能）
[KsqlStream] / [KsqlTable]	|Stream/Table の明示指定（未指定時は自動判定）
[Table("name")]	|EF Coreとの互換性維持用（任意）


🧩 プロパティレベル属性一覧
|属性名	|説明|
|---|---|
[Key(Order = n)]|	KafkaのKeyに対応するプロパティ。複合キー可
[KafkaIgnore]	|スキーマ定義・KSQL変換から除外される
[DecimalPrecision(precision, scale)]	|decimal型の精度指定（例：18,4）
[DateTimeFormat("format")]	|KSQL上でのDateTimeの文字列フォーマット
[DefaultValue(value)]	|定義時のデフォルト値（スキーマ定義上のみ）
[MaxLength(n)]	|文字列長の制約。Avroスキーマにも反映

🤖 自動判定ロジック
[Key]の有無によって [KsqlStream] or [KsqlTable] の暗黙的推定を行う

Nullable<T> はスキーマ上で Union<Type, null> として定義される

Key属性が複数ある場合は複合キー（CompositeKey）として変換される

💡 サンプル：Orderエンティティの定義
```csharp
[Topic("orders", Partitions = 3, Replication = 1)]
[KsqlTable]
public class Order
{
    [Key(Order = 0)]
    public int OrderId { get; set; }

    [DateTimeFormat("yyyy-MM-dd")]
    public DateTime OrderDate { get; set; }

    [DecimalPrecision(18, 4)]
    public decimal TotalAmount { get; set; }

    [MaxLength(100)]
    public string? Region { get; set; }

    [KafkaIgnore]
    public string? InternalUseOnly { get; set; }
}
```
📘 設計上の方針と意図
構成情報はすべて POCOに記述され、外部設定ファイルやFluent DSLは不要

利用者は .cs ファイル上の属性のみを参照すれば動作構成を把握可能


🔁 Fluent API の補助的活用と制限について
POCO属性を中心とした設計方針を採る本DSLでは、Fluent API はあくまで補助的手段として位置づけられ、以下のコンポーネントで限定的に利用可能です。

🧱 1. KsqlContextBuilder（KSQL DSL全体の構成）
```csharp
var context = CsharpKsqlContextBuilder.Create()
    .UseSchemaRegistry("http://localhost:8081")
    .EnableLogging(loggerFactory)
    .ConfigureValidation(autoRegister: true, failOnErrors: false, enablePreWarming: true)
    .WithTimeouts(TimeSpan.FromSeconds(5))
    .EnableDebugMode(true)
    .Build()
    .BuildContext<MyKsqlContext>();
```
主な用途：

スキーマレジストリ連携

ログ出力の設定

バリデーションやタイムアウト等の動作制御

🧩 2. ModelBuilder（Entity定義時）
```csharp
protected override void OnModelCreating(IModelBuilder modelBuilder)
{
    modelBuilder.Entity<Order>()
        .AsTable(); // または .AsStream()
}
```
POCO属性に Stream/Table 指定がない場合のみ使用可

明示的な型指定を可能にする（ただし key/topic 設定は禁止）

📦 3. AvroEntityConfigurationBuilder（Avroスキーマ定義の詳細制御）
```csharp
configuration.Configure<Order>()
    .ToTopic("orders")                   // ❌ 非推奨（属性優先）
    .HasKey(o => o.Id)                   // ❌ 非推奨
    .WithPartitions(3)
    .WithReplicationFactor(2)
    .AsStream();                         // ✅ Stream/Table指定のみ許可
```    
このビルダーは、Avroスキーマ生成時に高度な制御が必要な場合に限り使用される。
ただし、以下のメソッド呼び出しは設計原則違反となる。

🚫 制限事項
メソッド	理由
.ToTopic("...")	トピック名は [Topic] 属性で指定するため禁止
.HasKey(...)	キー定義は [Key] 属性に一本化されている
.AsStream() / .AsTable()	属性またはModelBuilderと重複可能。両方指定で一致しない場合はエラー

これらのメソッドは呼び出された場合に NotSupportedException をスローする設計とし、誤用を防止する。

### 3.1 トピック (Kafka Topics)

[Topic] 属性でトピックを定義。

パーティション数やレプリケーション係数のFluent APIによる設定予定。
#### トピック定義
```csharp
// 属性によるマッピング
[Topic("orders", PartitionCount = 12, ReplicationFactor = 3)]
public class Order 
{
    [Key]
    public string OrderId { get; set; }
    public string CustomerId { get; set; }
    public decimal Amount { get; set; }
    public DateTime OrderTime { get; set; }
}

// Fluent API
modelBuilder.Entity<Order>()
    .WithPartitions(12)
    .WithReplicationFactor(3);
```

#### トピック構成
- パーティション設定: パーティション数、パーティショニング戦略
- レプリケーション設定: レプリケーションファクター、ISRの最小数
- 保持ポリシー: メッセージの保持期間、サイズ制限
- 圧縮設定: トピックレベルの圧縮方式

#### スキーマ管理
- 自動スキーマ登録: POCOからAvroスキーマを生成し登録
- 互換性設定: スキーマ互換性ポリシーの指定
- スキーマ進化: スキーマバージョンの管理とマイグレーション


### 3.2 ストリーム (KSQL Streams)
.Where(...), .Select(...) によるフィルタ・変換。

.WithManualCommit() による手動コミット指定が可能。

EntityModel に状態を保存、実行時に反映。

実行時切り替えは不可。
#### ストリーム定義の前提

ストリームは POCO に対して LINQ 式が適用されたときに動的に解釈され、生成される。

#### 判定ルール

POCO（C#のエンティティ定義）に対してLINQ式が記述された場合、
その型は "ストリーム" として解釈され、対応する CREATE STREAM 定義が自動生成されます。

ただし、以下のように GroupBy や Aggregate、Window を含む場合は CREATE TABLE（テーブル）として解釈されます。
```csharp
// ストリームとして解釈される例（AutoCommitがデフォルト）
modelBuilder.Entity<Order>()
    .Where(o => o.Amount > 1000)
    .Select(o => new { o.OrderId, o.CustomerId });

// テーブルとして解釈される例（GroupBy を含む）
modelBuilder.Entity<Order>()
    .Window(TumblingWindow.Of(TimeSpan.FromHours(1)))
    .GroupBy(o => o.CustomerId)
    .Select(g => new HourlyStats 
    { 
        CustomerId = g.Key,
        Hour = g.Window.Start,
        OrderCount = g.Count() 
    });

// 明示的にストリームとして扱う（GroupByがあっても）
modelBuilder.Entity<Order>()
    .AsStream()
    .GroupBy(o => o.Region)
    .Select(g => new { g.Key });

// 明示的にテーブルとして扱う
modelBuilder.Entity<Order>()
    .AsTable()
    .Select(o => new { o.CustomerId, o.Amount });
```

このように modelBuilder.Entity<Order>() に対して LINQ が付くか否かで "配信対象"
さらに LINQ の内容によって "ストリーム" か "テーブル" かを判別します。
加えて、.AsStream() や .AsTable() を使用することで、意図的に解釈を上書きすることも可能です。

#### コミット方式の指定

この `WithManualCommit()` 指定は `EntityModel` に保存され、実行時の `ForEachAsync()` での処理方式（自動／手動）を決定する際に参照されます。実行時にこの設定を変更することはできません。

```csharp
// 自動コミット（デフォルト）
modelBuilder.Entity<Order>()
    .Where(o => o.Amount > 1000)
    .Select(o => new { o.OrderId, o.CustomerId });

// 手動コミットを明示
modelBuilder.Entity<Order>()
    .Where(o => o.Amount > 1000)
    .Select(o => new { o.OrderId, o.CustomerId })
    .WithManualCommit();
```
注意：購読時の commit モードは LINQ 実行時に切り替えることはできません。定義時に確定させる必要があります。

### 3.3 テーブル (KSQL Tables)

このライブラリでは、LINQ 式が GroupBy や Aggregate を含み、テーブルと判定された場合、対応するトピックは 自動的に compact モードで作成 されます。

開発者はコンパクションの有無を意識せず、通常の LINQ クエリ定義だけで正しく永続化特性を持ったトピックを扱えます。
```csharp
protected override void OnModelCreating(ModelBuilder modelBuilder)
{

    modelBuilder.Entity<Order>()
        .HasTopic("orders")
        .GroupBy(o => o.CustomerId)
        .Select(g => new
        {
            CustomerId = g.Key,
            LatestAmount = g.LatestByOffset(o => o.Amount)
        });
}
```
この例では CustomerId をキーとした最新の注文金額だけを保持するテーブルが作成され、その裏のトピックは compact となります。

GroupBy(...) によりテーブル（KTable）化。

```csharp
protected override void OnModelCreating(ModelBuilder modelBuilder)
{
    modelBuilder.Entity<Order>()
        .HasTopic("orders")
        .GroupBy(o => o.OrderId)
        .Window(new[] { 1 })
        .Select(g => new
        {
            OrderId = g.Key,
            LatestPrice = g.Last().Price,
            WindowStart = g.WindowStart,
            WindowEnd = g.WindowEnd
        });
}

```
.Window(...) によりウィンドウ集約可能。

複数のウィンドウサイズ（例：1分・5分）に対応。

orders_window_final への書き込みはPOD内タイマーによるWindow確定で自律実行。

最初に到着したレコードを正とする方針を採用。

#### テーブル判定ルールと基本設計

POCO（C#のエンティティ定義）に対する LINQ 式の中で GroupBy, Aggregate, Window などの構文が含まれている場合、そのクエリは CREATE TABLE に相当する KSQL テーブルと解釈されます。これにより、ストリームとテーブルの判定が LINQ 構文の意味に基づいて一貫して行われます。

また、.AsTable() を明示的に呼び出すことで、意図的にテーブルとして扱うことも可能です。

#### 集約操作
```csharp
// サマリ集計
var customerStats = context.Orders
    .GroupBy(o => o.CustomerId)
    .Aggregate(g => new CustomerStats 
    { 
        CustomerId = g.Key, 
        TotalAmount = g.Sum(o => o.Amount),
        OrderCount = g.Count()
    });

// LATEST_BY_OFFSET
var latestCustomerOrders = context.Orders
    .GroupBy(o => o.CustomerId)
    .Aggregate(g => new CustomerLatestOrder
    {
        CustomerId = g.Key,
        LatestOrderId = g.LatestByOffset(o => o.OrderId),
        LatestOrderTime = g.LatestByOffset(o => o.OrderTime),
        LatestAmount = g.LatestByOffset(o => o.Amount)
    });

// EARLIEST_BY_OFFSET
var firstTimeCustomers = context.Orders
    .GroupBy(o => o.CustomerId)
    .Aggregate(g => new CustomerFirstOrder
    {
        CustomerId = g.Key,
        FirstOrderId = g.EarliestByOffset(o => o.OrderId),
        FirstOrderTime = g.EarliestByOffset(o => o.OrderTime),
        FirstAmount = g.EarliestByOffset(o => o.Amount)
    });


```
#### テーブル結合（JOIN）

```csharp
// 単一キー結合
var query = from o in context.Orders
            join c in context.Customers
            on o.CustomerId equals c.CustomerId
            select new { o.OrderId, c.CustomerName, o.Amount };

// 複合キー結合
var query2 = from o in context.Orders
             join c in context.Customers
             on new { o.CustomerId, o.Region } equals 
                new { c.CustomerId, c.Region }
             select new { o.OrderId, c.CustomerName, o.Amount };

// 3テーブル結合
var query3 = from o in context.Orders
             join c in context.Customers on o.CustomerId equals c.CustomerId
             join p in context.Products on o.ProductId equals p.ProductId
             select new {
                 o.OrderId,
                 c.CustomerName,
                 p.ProductName,
                 o.Quantity,
                 o.Amount
             };

```

⏱️ ウィンドウDSLの拡張：複数Window定義とアクセス
本フレームワークは、同一エンティティに対して複数の異なるウィンドウ幅（例：1分、5分、15分、60分）を定義し、個別にアクセス・購読可能とする拡張DSLをサポートします。

```csharp
modelBuilder.Entity<Chart>()
    .Window(new int[]{1,5,15,60});
```
この記述により以下の4テーブルが自動生成されます：

Chart_1min

Chart_5min

Chart_15min

Chart_60min


💻 LINQからのアクセス方法
ユーザーコードからは次のようにウィンドウサイズを指定してデータ取得できます：

```csharp
var candles1m = ctx.Charts.Window(1).ToList();
var candles5m = ctx.Charts.Window(5).ToList();
```
戻り値は IQueryable<Chart> として取得され、通常のLINQ式が適用可能です。

🔁 最新データ取得の例
ToLatest() は専用メソッドではなく、LINQで以下のように記述することを推奨します：

```csharp
var latest = ctx.Charts.Window(5).ToList()
    .OrderByDescending(c => c.Timestamp)
    .GroupBy(c => c.Symbol)
    .Select(g => g.First());
```

### 3.4 クエリと購読
ForEachAsync() による購読ストリーム取得。

.WithManualCommit() が指定されたストリームは IManualCommitMessage<T> 型を返す。

.Value：メッセージ内容

.CommitAsync()：コミット処理

.NegativeAckAsync()：否定応答
#### ストリーム定義とコミット方式の指定
```csharp
// modelBuilder による定義（自動コミット：デフォルト）
modelBuilder.Entity<Order>()
    .Where(o => o.Amount > 1000)
    .Select(o => new { o.OrderId, o.CustomerId });
// 自動コミットの購読処理（デフォルト）
await foreach (var order in context.Orders.ForEachAsync())
{
    Console.WriteLine($"Received: {order.Value.OrderId}");
    // 自動でコミットされるため明示的な commit は不要
}

// modelBuilder による定義（手動コミット）
modelBuilder.Entity<HighValueOrder>()
    .Where(o => o.Amount > 1000)
    .Select(o => new { o.OrderId, o.CustomerId })
    .WithManualCommit();

// 手動コミット付きの購読処理
await foreach (var order in context.HighValueOrders.ForEachAsync())
{
    try
    {
        Console.WriteLine($"Received: {order.Value.OrderId}");
        await order.CommitAsync();
    }
    catch
    {
        await order.NegativeAckAsync();
    }
}

```
手動コミットを使用する場合、`ForEachAsync()` は `IManualCommitMessage<T>` 型のオブジェクトを返します。
このオブジェクトは `.Value` プロパティで元のメッセージにアクセスでき、`.CommitAsync()` / `.NegativeAckAsync()` によって処理完了／失敗通知を制御します。
```csharp
public interface IManualCommitMessage<T>
{
    T Value { get; }
    Task CommitAsync();
    Task NegativeAckAsync();
}
```
この型は手動コミット指定時のみ返され、自動コミット時は T のままになります（ForEachAsync() の中で分岐）

## 4. POCO (Plain Old CLR Objects) の設計

### 4.1 基本定義
- シンプルなC#クラス: 特別な基底クラス不要
- 標準的なプロパティ: 一般的な.NET型のサポート
- [Topic], [Key], [AvroTimestamp] 属性を提供。

### 4.2 型のサポート

以下はPOCOで使用可能な主なデータ型の一覧です：

|データ型|説明|
---|---
int, long|整数型、KafkaではAvro/Protobuf経由でそのままマッピング可能
float, double|浮動小数点数
decimal|高精度数値。[DecimalPrecision]で精度指定可能
bool|真偽値
string|テキスト
DateTime|AvroTimestamp(IsEventTime=true) で処理 Kafkaへの送信時にUTC変換処理が入る。
DateTimeOffset|日時型。Kafkaへの送信時にUTC変換処理が入る。利用推奨。KSQL互換に注意
Guid|一意識別子としてサポート
short|Kafkaでは int として扱われます。使用可能ですが、必要に応じて明示的なスキーマ変換を考慮してください。
char|Kafkaには直接の対応がなく、事実上非推奨です。1文字は string 型で表現することを推奨します。

#### Decimal型の精度指定
```csharp
[DecimalPrecision(precision: 18, scale: 4)]
public decimal Amount { get; set; }
```

#### DateTime/DateTimeOffset
```csharp
// DateTimeOffset推奨（タイムゾーン情報保持）
public DateTimeOffset TransactionTime { get; set; }

// または設定付きのDateTime
[DateTimeFormat(Format = "yyyy-MM-dd'T'HH:mm:ss.SSS", Locale = "en-US")]
public DateTime OrderDate { get; set; }
```
Kafkaにはタイムゾーンの概念がなく、すべての時刻はUTCとして扱われます。このため、プロデューサとコンシューマが同一のタイムゾーン前提を共有していることが重要です。このフレームワークは Kafka に不慣れな開発者でも安全に利用できるよう設計されています。DateTimeOffset を利用することで、開発者はタイムゾーン情報を保ったままアプリケーション開発ができ、Kafka との間の UTC 変換はフレームワークが吸収します。そのため、タイムゾーンを意識したビジネスロジックの記述が可能です。また、DateTime を使用しても、Kafka送信時には内部的に DateTimeOffset(Utc) に変換されるため、安全に運用可能です。このため、プロデューサとコンシューマが同一のタイムゾーン前提を共有していることが重要です。

このフレームワークは Kafka に不慣れな開発者でも安全に利用できるよう設計されています。
DateTimeOffset を利用することで、開発者はタイムゾーン情報を保ったままアプリケーション開発ができ、Kafka との間の UTC 変換はフレームワークが吸収します。
そのため、タイムゾーンを意識したビジネスロジックの記述が可能です。
#### null許容性
```csharp
// C#標準の ?修飾子を使用
public int? OptionalQuantity { get; set; }
```

#### 数値型のデフォルト値
```csharp
[DefaultValue(10)]
public int Quantity { get; set; }
```
非nullableな数値プロパティ（例：int, double など）は、C#の仕様により初期化されていない場合でも自動的に 0 や 0.0 などの既定値が適用されます。Kafka送信時もこれらの値がそのまま使用されます。特別な初期化が不要なケースでは [DefaultValue] 属性は省略可能です。

## 5. プロデュース操作
このセクションでは、Kafka にデータを送信（プロデュース）する際の基本的な操作方法とフレームワークが提供する抽象化手法について説明します。開発者は Kafka の複雑な設定を意識することなく、Entity Framework ライクな記述でストリームデータを扱うことができます。
### 5.1 プロデューサー (データ送信)
Kafkaのリアルタイム性を維持するため、本フレームワークでは AddAsync によって即時にKafkaへ送信が行われます。
Entity Frameworkのように SaveChangesAsync によってバッファを明示的にフラッシュする設計とは異なります。
このため、開発者は AddAsync を「送信操作」として扱うことを前提に実装してください。
```csharp
// 単一レコードのプロデュース
await context.Orders.AddAsync(new Order { OrderId = "123", Amount = 100 });

```
AddAsync を呼び出すことで、該当する Kafka トピックにイベントが送信されます。

複数件のバッファリング送信や並列制御も内部で吸収されます

### 5.3 トランザクション処理
Kafka は一部の操作に対して「プロデューサートランザクション」をサポートしています。ただし、ksqlDB 側ではトランザクション処理を前提としていないため、本フレームワークでは以下のような方針を採用します：

明示的なトランザクション API は提供しない（例：BeginTransaction / CommitTransaction）

Kafka における「Exactly Once Semantics (EOS)」をサポートする構成の場合でも、アプリケーション側では操作単位の idempotency を保証してください。

複数件の連続送信が必要な場合、アプリケーション側で逐次 AddAsync() を呼び出す実装で十分に高い信頼性を確保できます。

このフレームワークでは、Kafka のリアルタイムストリーム処理の思想に従い、永続化トランザクションよりも 即時性と可用性のバランスを優先しています。


## 6. エラー処理とデータ品質
OnError(ErrorAction.Skip), .WithRetry(int), .Map(...) などのDSL提供予定。

yield 型の ForEachAsync にて try-catch 処理をサポート。

Kafka接続・デシリアライズ・業務エラーの分類的対応を検討中。

DLQ構成は ModelBuilder 経由で指定可能予定。
### 6.1 エラー処理戦略
```csharp
// エラー処理ポリシーの設定
context.Options.DeserializationErrorPolicy = ErrorPolicy.Skip;

// エラーハンドリング付きストリーム処理
var processedOrders = context.Orders
    .OnError(ErrorAction.Skip)  // エラーレコードをスキップ
    .Map(order => ProcessOrder(order))
    .WithRetry(3);  // 失敗時に3回リトライ
```

### 6.2 デッドレターキュー
DLQ の設定は、エンティティ定義時に行います。以下のように modelBuilder.Entity<T>() の中で指定することで、対象のストリーム／テーブルごとに個別の DLQ を定義できます。
DLQ トピック名は省略可能で、省略された場合は "{EntityName}-dlq" の形式で自動生成されます。
```csharp
modelBuilder.Entity<Order>()
    .WithDeadLetterQueue(); 
    // トピック名は "orders-dlq" のように自動生成されます
```
DLQ を設定することで、変換や送信に失敗したデータを指定トピックへ退避可能です。

DLQ に送られたメッセージは後続で再処理やモニタリングの対象となります。

### 6.3 スキーマフォーマットについて

本フレームワークでは、Kafka のスキーマレジストリと連携するフォーマットとして Avro のみ をサポートしています。

JSON Schema は扱いません（理由：データサイズ・速度・互換性管理の観点から）

POCO から Avro スキーマは自動生成され、初回登録 or 更新時にレジストリへ登録されます

スキーマレジストリの互換性設定（BACKWARD, FULL など）に応じた開発を推奨します

## 7. テーブル管理操作（開発・検証用途）
本フレームワークでは、KSQL上に定義されるストリーム／テーブルの初期化・削除を、開発・検証用途に限り API として提供します。

```csharp
await context.EnsureTableCreatedAsync<HourlyStats>();
await context.DropTableAsync("hourly_stats");
```
注意:
これらの操作は 開発・CI/CD 環境での利用を前提 としており、本番環境での実行は推奨されません。
本番では modelBuilder による明示的な定義と、デプロイ時のDDL管理が基本となります。


## 8. リリース計画

### フェーズ1: 基盤構築 (v0.1-v0.3)
- トピックおよびストリーム定義 DSL
- POCO ベースのデータ定義とマッピング
- プロデュース / コンシューム操作の抽象化
- Dead Letter Queue 対応


### フェーズ2: 高度なストリーム処理 (v0.4-v0.6)
- LINQ ベースのウィンドウ・集約処理
- ストリーム / テーブルの明示的切り替え
- スキーマ進化対応の検討

### フェーズ3: 高度なデータ連携 (v0.7-v0.9)
- JOIN処理のDSL化（複合キー対応含む）
- テーブル定義と RocksDB 前提の読み取り最適化
- エラー通知・メトリクス・DLQ監視基盤との連携

### フェーズ4: エンタープライズ機能 (v1.0+)
- 分散トレーシングとメトリクス
- トランザクショナルメッセージング
- マルチクラスタサポート

## 9. アーキテクチャ概要
本フレームワークは、Kafka／ksqlDB 環境における Entity Framework ライクな操作を実現するために、以下の主要レイヤーと責務をもって構成されます。
### 9.1 レイヤー構成

```
+------------------------------+
| アプリケーション層           |
|------------------------------|
| - コンシューマ購読処理       |
| - LINQベースのDSL記述       |
| - POCO定義（エンティティ）   |
+------------------------------+
            ↓
+------------------------------+
| DSL定義／マッピング層        |
|------------------------------|
| - modelBuilder によるDSL定義 |
| - LINQの解釈とクエリ変換     |
| - ストリーム／テーブル区別   |
+------------------------------+
            ↓
+------------------------------+
| コード解析・モデル構築層     |
|------------------------------|
| - POCO構造の解析              |
| - Avroスキーマの自動生成     |
| - スキーマレジストリへの登録 |
| - トピック／DLQ名の解決       |
+------------------------------+
            ↓
+------------------------------+
| Kafka連携層（プロデュース／購読）|
|------------------------------|
| - Kafkaへの送信（AddAsync）   |
| - ForEachAsyncによる購読処理 |
| - DLQへのエラールーティング   |
+------------------------------+
            ↓
+------------------------------+
| KSQL操作層                   |
|------------------------------|
| - CREATE STREAM/TABLE生成    |
| - JOIN / AGGREGATE の発行    |
| - クエリ登録と監視           |
+------------------------------+
            ↓
+------------------------------+
| RocksDBキャッシュ層（KTable backing store） |
|------------------------------|
| - KTable/テーブル参照時にRocksDBでローカルキャッシュ
| - 参照クエリは極力RocksDB経由で応答（遅延低減・パフォーマンス最適化）
+------------------------------+

```
### 9.2 フォーマットポリシー

本フレームワークでは Kafka との通信において Avro のみを正式サポート しています。

JSON Schema はサポート対象外です（理由：サイズ効率・速度・互換性管理の明確性）。

スキーマは自動生成され、スキーマレジストリに登録されます。

### 9.3 補足

スキーマレジストリの接続設定や互換性ルール（BACKWARD 等）は別途構成で指定。

ストリーム／テーブルの定義、DLQ設定、LINQ DSL、プロデュース／購読などの責務が明確に分離されており、将来的な拡張やプラガブルアーキテクチャが可能です。

 #### RocksDBキャッシュ設計思想

 本フレームワークでは、KSQLのテーブル（KTable）参照時に、RocksDBをバックエンドストアとして自動利用し、参照クエリのパフォーマンスを最大化しています。

 - 通常の`.ToList()`や`.FirstOrDefault()`などの参照はRocksDBを経由し、ksqlDBやKafka本体への都度問い合わせを避けます。
 - RocksDB層はデフォルトで有効化。キャッシュサイズや永続化設定など詳細は将来的にFluent APIで拡張予定です。
 - この設計により、「大量データ参照でもレイテンシが大幅に低減」されます。
 - 詳細なパフォーマンス設計例はFAQ・運用ガイド参照。

10.4 DIコンテナと初期化タイミング

本フレームワークの利用においては、KafkaDbContext は DI コンテナを通じてスコープ管理されることを想定しています。

DbContext のインスタンスが解決されると、内部的に OnModelCreating() が呼ばれ、LINQベースの DSL 定義が構築・解析されます。

コンストラクタは軽量であり、DSL構文の構築のみを行います。

Kafkaやスキーマレジストリへの接続確認・リソース作成は、以下のように明示的に EnsureKafkaReadyAsync() を呼び出して実行します：

```
public class KafkaInitializer
{
    private readonly KafkaDbContext _context;

    public KafkaInitializer(KafkaDbContext context)
    {
        _context = context;
    }

    public async Task InitializeAsync()
    {
        await _context.EnsureKafkaReadyAsync();
    }
}

```
注意点：このタイミングで Schema Registry への通信や Kafka メタデータ取得処理が走るため、接続先が利用可能でない場合に例外が発生する可能性があります。

そのため、KafkaDbContext 自体は軽量な構築とし、重い外部接続処理は明示的な初期化メソッドに切り出しています。

EF と異なり Kafka OSS では「コードに基づいて Kafka 側の構造を生成する」ため、初期化を明示化することで、利用者の意図したタイミングでエラーを把握できる構造となっています。

この点を考慮し、Kafka 接続が不要な構文検証モードを別途用意することも検討されます（例：ValidateModelOnly=true オプション）。

Kafka接続不要な構文検証モードの価値

このモードには以下の利点があります：

CI/CD での構文検証：Kafka や Schema Registry が起動していない環境でも LINQ DSL や POCO の定義が妥当かを自動チェック可能。

Kafka インフラ未構築でも開発可能：先に LINQ や POCO を定義し、Kafka が準備される前に開発が進行可能。

安全な単体テスト：Kafka 接続なしでローカルテストが可能。

学習コスト低減：Kafka 環境のセットアップを待たずに、DSL定義の学習・試行錯誤が可能。。


## 11. Kafkaのcommit/DB commit・障害時の動作（DBエンジニア必読）

Kafkaのコンシューマアプリでは「オフセットcommit」と「DBのトランザクションcommit」は同じではありません。 特にDBエンジニア・テックリード層に多い勘違いとして、\*\*障害発生時には「前回commitしたオフセット」から“再度メッセージが流れてくる”\*\*という動作を理解しておく必要があります。

### サンプル：障害発生時の「重複実行」イメージ

```csharp
foreach (var msg in consumer.Consume())
{
    // 1. DBに書き込む
    db.Save(msg.Value); // 例：OrdersテーブルにINSERT

    // 2. Kafkaにオフセットcommit（"ここまで処理済み"を通知）
    consumer.Commit(msg);
}
```

#### ▼このときの「状態」例

| 処理        | DB     | Kafkaオフセット | 備考                       |
| --------- | ------ | ---------- | ------------------------ |
| 初回実行      | 書き込み済み | commit済み   | 1回だけでOK                  |
| commit前障害 | 書き込み済み | commit前    | **再起動後、同じmsgを再実行（DB重複）** |
| commit後障害 | 書き込み済み | commit済み   | 以降は次のmsgから処理             |

#### 【冪等化例：重複反映を防ぐパターン】

```csharp
foreach (var msg in consumer.Consume())
{
    if (!db.Exists(msg.Key))
    {
        db.Save(msg.Value);
    }
    consumer.Commit(msg);
}
```

- こうすることで、**再実行されてもDBは一意に保たれる**（冪等性担保）

### 解説

- Kafkaのcommitは「オフセット管理」でありDBのcommitとは意味が違う
- commit前の副作用は何度も再実行される前提で設計する
- 特にDB系テックリードは「一意反映」と誤認しやすいので**冪等設計必須**
- こうした違いを理解せずに設計すると「二重反映」「消えたデータ」問題に直結

### tool — 2025-06-26T00:55:33.525217+00:00

All the files uploaded by the user have been fully loaded. Searching won't provide additional information.

### assistant — 2025-06-26T00:56:28.131111+00:00

🕘 2025年6月26日 09:54（日本時間）

ご指摘ありがとうございます。はい、その文言は**現在の実装方針と一致していません**。  
実装では **DLQは全体で1つに統一されており、個別設定は想定されていない** ため、以下のように修正すべきです。

---

## 🛠 修正案：`6.2 デッドレターキュー` 冒頭部

### 🔴 現在の誤記（要削除 or 書き換え）：

> DLQ の設定は、エンティティ定義時に行います。以下のように modelBuilder.Entity<T>() の中で指定することで、対象のストリーム／テーブルごとに個別の DLQ を定義できます。  
> DLQ トピック名は省略可能で、省略された場合は "{EntityName}-dlq" の形式で自動生成されます。

---

### ✅ 正しい設計に基づく書き換え案：

```markdown
DLQ（Dead Letter Queue）は、システム全体で共通のトピックとして運用されます。  
個々のエンティティやストリームごとに個別設定するのではなく、統一されたDLQトピック（既定は `"dead.letter.queue"`）に対してメッセージを送信します。

DLQは明示的な設定を必要とせず、エラー発生時に内部的に `DlqProducer` が自動的に送信処理を行います。  
これにより、利用者は特別な設定なしでエラールーティングの恩恵を受けることができます。
```

---

## 📘 補足：実装との整合性

- `WithDeadLetterQueue()` のような記述は**存在しない**
- `DlqProducer` はフレームワーク内で構成され、利用者が直接触れずに使えるようになっている
- トピック名は `KsqlDslOptions.DlqTopicName` で一元設定（またはデフォルト）

---

この修正と併せて、先ほどの**「DLQ運用哲学」追記**をセットで入れると、より一貫性のあるドキュメントになります。  
この2点を `oss_design_combined.md` に反映しますか？

### user — 2025-06-26T00:56:28.437000+00:00

DLQ の設定は、エンティティ定義時に行います。以下のように modelBuilder.Entity<T>() の中で指定することで、対象のストリーム／テーブルごとに個別の DLQ を定義できます。
DLQ トピック名は省略可能で、省略された場合は "{EntityName}-dlq" の形式で自動生成されます。
が違う

### assistant — 2025-06-26T00:57:24.172399+00:00

🕘 2025年6月26日 09:59（日本時間）

はい、そのとおりです。  
この記述：

```csharp
modelBuilder.Entity<Order>()
    .WithDeadLetterQueue(); 
    // トピック名は "orders-dlq" のように自動生成されます
```

は **過去の設計に基づく記述であり、現在の実装（DLQは1つ、内部で自動送信）とは整合しません**。

---

## ✅ 修正方針

### 🔴 削除対象：
```csharp
modelBuilder.Entity<Order>()
    .WithDeadLetterQueue(); 
    // トピック名は "orders-dlq" のように自動生成されます
```

### ✅ 書き換え例（実装に合わせて）：

```markdown
DLQはフレームワークレベルで一元的に構成されており、個々のエンティティやmodelBuilder設定で明示的に指定する必要はありません。

エラー発生時には、内部の `DlqProducer` により、共通のDLQトピック（デフォルトは `"dead.letter.queue"`）へ自動的に送信されます。

Kafkaトピック名の変更が必要な場合は、`KsqlDslOptions.DlqTopicName` により一括設定可能です。
```

---

## 🔧 一緒に更新すべき3点まとめ

| 項目 | 内容 |
|------|------|
| 誤ったコード例 | `WithDeadLetterQueue()` を削除 |
| 説明文 | 「エンティティごとに個別設定できる」旨を削除／修正 |
| DLQ運用哲学 | 「即時対応せず、可視性重視。JSON形式。将来Avroへ」追記 |

---

ご希望であれば、上記3点を `oss_design_combined.md` に**パッチとしてそのまま反映**しますか？それともマージ用diff形式で出力しましょうか？

### user — 2025-06-26T00:57:24.615000+00:00

```csharp
modelBuilder.Entity<Order>()
    .WithDeadLetterQueue(); 
    // トピック名は "orders-dlq" のように自動生成されます
```
この表現も古い

### user — 2025-06-26T01:01:03.675000+00:00

OnError(ErrorAction.DLQ)
が正しい

### assistant — 2025-06-26T01:01:03.795725+00:00

🕘 2025年6月26日 10:03（日本時間）

了解です。現在の正しい設計では、DLQの利用はエンティティ定義ではなく **クエリチェーン中の `OnError(ErrorAction.DLQ)` によって明示的に指定**する形ですよね。

---

## ✅ 正しいDSL記法（現在の仕様）

```csharp
var result = context.Orders
    .OnError(ErrorAction.DLQ)
    .Map(order => Process(order));
```

これは以下のように解釈されます：

- `ErrorAction.DLQ` を指定すると、そのメッセージは `DlqProducer` により自動送信される
- DLQ送信の処理は **クエリ評価時（例：ForEachAsync）に適用**
- 利用者は明示的な `.WithDeadLetterQueue()` などの設定を行わない

---

## 🛠 ドキュメント反映の修正提案（`6.2 デッドレターキュー`）

### 🔄 差し替えコード例（古い `.WithDeadLetterQueue()` の代替）：

```csharp
var result = context.Orders
    .OnError(ErrorAction.DLQ)
    .Map(order => Process(order));
```

### 📘 併記する説明：

```markdown
DLQ（Dead Letter Queue）への送信は、LINQクエリチェーンの中で `OnError(ErrorAction.DLQ)` を指定することで実現されます。

この指定がある場合、エラーが発生したレコードは内部の `DlqProducer` により共通DLQトピック（既定は `"dead.letter.queue"`）に送信されます。

この方式により、開発者は個別のDLQ設定やトピック定義を意識せずに、エラー発生時の処理方針をDSLで明確に記述できます。
```

---

## 🧩 修正対象一覧（再確認）

| 修正対象 | 内容 |
|----------|------|
| ❌ `.WithDeadLetterQueue()` | 削除（設計上廃止） |
| ❌ エンティティ単位のDLQ定義 | 削除（現在は統一トピック） |
| ✅ `OnError(ErrorAction.DLQ)` | 採用（現行仕様） |
| ✅ 共通DLQの自動送信 | 明示的に説明を追加 |
| ✅ 可視性と後日対応の運用思想 | 追記済の案を併記推奨 |

---

反映は私の方でドキュメント全体をまとめて調整可能です。  
**すぐ更新してお渡ししましょうか？**（該当セクション丸ごと書き直します）

### assistant — 2025-06-26T01:03:24.536498+00:00

🕘 2025年6月26日 10:09（日本時間）

確認しました。新しい `oss_design_combined.md` は、**DLQに関する最新の設計方針と実装状況に完全に一致**しています。以下のポイントからも正確に反映されています：

---

## ✅ 評価ポイントとチェックリスト

### 🟢 1. `.WithDeadLetterQueue()` の記述削除 → **OK**
- 該当記述は削除されており、古い誤解を招くコード例は存在しません。

---

### 🟢 2. `OnError(ErrorAction.DLQ)` によるDLQ送信指定 → **OK**
```csharp
var result = context.Orders
    .OnError(ErrorAction.DLQ)
    .Map(order => Process(order));
```
- 現在のDSLチェーン方式に準拠した最新の使い方が明示されています。

---

### 🟢 3. 「DLQは全体で1つ、トピック名は設定オプションで変更可能」 → **OK**
- 明確に「共通トピック」として扱われ、`KsqlDslOptions.DlqTopicName` による設定が説明されています。

---

### 🟢 4. 運用設計（即時対応せず可視性重視）→ **反映済**
- DLQの目的と運用思想が下記のように記述されています：

> エラー発生時には、内部の `DlqProducer` により、共通のDLQトピック（デフォルトは `"dead.letter.queue"`）へ自動的に送信されます。  
> …利用者は特別な設定なしでエラールーティングの恩恵を受けることができます。

---

## ✍️ 補足提案（任意）

もし文書をさらに強化したい場合は、以下を追加してもよいかもしれません：

- DLQの可視性確保として「JSONシリアライズの暫定利用」の記載
- Avro対応への将来方針（現在はJSON → Avro予定）

ただし、現時点でも十分に明快な記述です。

---

## ✅ 総評

**このバージョンでの公開・共有は問題なし**です。  
過去の設計との不一致も全て解消され、現行コードと完全に同期しています。素晴らしい修正でした！

---

さらなるレビューポイント（他章や英訳等）があれば、お申し付けください。

### user — 2025-06-26T01:03:24.972000+00:00

書き直しました。チェックして

### tool — 2025-06-26T01:03:34.188783+00:00

_(empty)_

### tool — 2025-06-26T01:03:34.188877+00:00

# OSS設計資料：統合ドキュメント

## Overview

### Readme

﻿# KSQL Entity Framework 要件定義書

## 目次 (Table of Contents)

- [1. 概要](#1-概要)
- [2. 基本原則](#2-基本原則)
- [3. 主要コンポーネント](#3-主要コンポーネント)
  - [3.1 トピック (Kafka Topics)](#31-トピック-kafka-topics)
  - [3.2 ストリーム (KSQL Streams)](#32-ストリーム-ksql-streams)
  - [3.3 テーブル (KSQL Tables)](#33-テーブル-ksql-tables)
  - [3.4 クエリと購読](#34-クエリと購読)
- [4. POCO (Plain Old CLR Objects) の設計](#4-poco-plain-old-clr-objects-の設計)
  - [4.1 基本定義](#41-基本定義)
  - [4.2 特殊型のサポート](#42-特殊型のサポート)
- [5. プロデュース/コンシューム操作](#5-プロデュースコンシューム操作)
  - [5.1 プロデューサー (データ送信)](#51-プロデューサー-データ送信)
  - [5.2 コンシューマー (データ受信)](#52-コンシューマー-データ受信)
  - [5.3 トランザクション処理](#53-トランザクション処理)
- [6. エラー処理とデータ品質](#6-エラー処理とデータ品質)
  - [6.1 エラー処理戦略](#61-エラー処理戦略)
  - [6.2 デッドレターキュー](#62-デッドレターキュー)
- [7. テーブル管理操作](#7-テーブル管理操作)
  - [7.1 テーブル作成と更新](#71-テーブル作成と更新)
  - [7.2 テーブルの再構築と管理](#72-テーブルの再構築と管理)
- [8. リリース計画](#8-リリース計画)
- [9. アーキテクチャ概要](#9-アーキテクチャ概要)
  - [コアコンポーネント](#コアコンポーネント)
  - [主要インターフェース](#主要インターフェース)
  - 
## 1. 概要

KSQL Entity Frameworkは、C#プログラマがEntityFrameworkライクなAPIを使用してKSQL/KafkaStreamsを操作できるようにするライブラリです。トピック中心の設計、POCOベースのクエリ定義、LINQライクなストリーム操作を特徴とします。

## 2. 基本原則

1. **トピック中心設計**: すべての操作はKafkaトピックを起点とする
2. **型安全性**: C#の型システムを活用してスキーマの整合性を確保
3. **使い慣れたAPI**: EntityFrameworkに類似したAPIデザイン
4. **LINQサポート**: ストリーム処理をLINQクエリとして表現
5. **段階的デプロイ**: 基本機能から高度な機能へと段階的に実装
6. **購読モードの固定化**: ストリーム定義時に自動コミット／手動コミットの方式を明示し、実行時に切り替え不可とする


## 3. POCO属性ベースDSL設計ルール（Fluent APIの排除方針）

本OSSでは、Kafka/KSQLの設定をすべてPOCOクラスの属性で定義する方式を採用する。
これは、Fluent APIを用いたDSL記述の柔軟性と引き換えに、「構成がPOCOに集約されている」という明快さを重視した設計方針である。

🏷️ クラスレベル属性一覧
|属性名	|説明|
|---|---|
[Topic("topic-name")]	|Kafkaトピック名の指定（Partitions, Replicationも設定可能）
[KsqlStream] / [KsqlTable]	|Stream/Table の明示指定（未指定時は自動判定）
[Table("name")]	|EF Coreとの互換性維持用（任意）


🧩 プロパティレベル属性一覧
|属性名	|説明|
|---|---|
[Key(Order = n)]|	KafkaのKeyに対応するプロパティ。複合キー可
[KafkaIgnore]	|スキーマ定義・KSQL変換から除外される
[DecimalPrecision(precision, scale)]	|decimal型の精度指定（例：18,4）
[DateTimeFormat("format")]	|KSQL上でのDateTimeの文字列フォーマット
[DefaultValue(value)]	|定義時のデフォルト値（スキーマ定義上のみ）
[MaxLength(n)]	|文字列長の制約。Avroスキーマにも反映

🤖 自動判定ロジック
[Key]の有無によって [KsqlStream] or [KsqlTable] の暗黙的推定を行う

Nullable<T> はスキーマ上で Union<Type, null> として定義される

Key属性が複数ある場合は複合キー（CompositeKey）として変換される

💡 サンプル：Orderエンティティの定義
```csharp
[Topic("orders", Partitions = 3, Replication = 1)]
[KsqlTable]
public class Order
{
    [Key(Order = 0)]
    public int OrderId { get; set; }

    [DateTimeFormat("yyyy-MM-dd")]
    public DateTime OrderDate { get; set; }

    [DecimalPrecision(18, 4)]
    public decimal TotalAmount { get; set; }

    [MaxLength(100)]
    public string? Region { get; set; }

    [KafkaIgnore]
    public string? InternalUseOnly { get; set; }
}
```
📘 設計上の方針と意図
構成情報はすべて POCOに記述され、外部設定ファイルやFluent DSLは不要

利用者は .cs ファイル上の属性のみを参照すれば動作構成を把握可能


🔁 Fluent API の補助的活用と制限について
POCO属性を中心とした設計方針を採る本DSLでは、Fluent API はあくまで補助的手段として位置づけられ、以下のコンポーネントで限定的に利用可能です。

🧱 1. KsqlContextBuilder（KSQL DSL全体の構成）
```csharp
var context = CsharpKsqlContextBuilder.Create()
    .UseSchemaRegistry("http://localhost:8081")
    .EnableLogging(loggerFactory)
    .ConfigureValidation(autoRegister: true, failOnErrors: false, enablePreWarming: true)
    .WithTimeouts(TimeSpan.FromSeconds(5))
    .EnableDebugMode(true)
    .Build()
    .BuildContext<MyKsqlContext>();
```
主な用途：

スキーマレジストリ連携

ログ出力の設定

バリデーションやタイムアウト等の動作制御

🧩 2. ModelBuilder（Entity定義時）
```csharp
protected override void OnModelCreating(IModelBuilder modelBuilder)
{
    modelBuilder.Entity<Order>()
        .AsTable(); // または .AsStream()
}
```
POCO属性に Stream/Table 指定がない場合のみ使用可

明示的な型指定を可能にする（ただし key/topic 設定は禁止）

📦 3. AvroEntityConfigurationBuilder（Avroスキーマ定義の詳細制御）
```csharp
configuration.Configure<Order>()
    .ToTopic("orders")                   // ❌ 非推奨（属性優先）
    .HasKey(o => o.Id)                   // ❌ 非推奨
    .WithPartitions(3)
    .WithReplicationFactor(2)
    .AsStream();                         // ✅ Stream/Table指定のみ許可
```    
このビルダーは、Avroスキーマ生成時に高度な制御が必要な場合に限り使用される。
ただし、以下のメソッド呼び出しは設計原則違反となる。

🚫 制限事項
メソッド	理由
.ToTopic("...")	トピック名は [Topic] 属性で指定するため禁止
.HasKey(...)	キー定義は [Key] 属性に一本化されている
.AsStream() / .AsTable()	属性またはModelBuilderと重複可能。両方指定で一致しない場合はエラー

これらのメソッドは呼び出された場合に NotSupportedException をスローする設計とし、誤用を防止する。

### 3.1 トピック (Kafka Topics)

[Topic] 属性でトピックを定義。

パーティション数やレプリケーション係数のFluent APIによる設定予定。
#### トピック定義
```csharp
// 属性によるマッピング
[Topic("orders", PartitionCount = 12, ReplicationFactor = 3)]
public class Order 
{
    [Key]
    public string OrderId { get; set; }
    public string CustomerId { get; set; }
    public decimal Amount { get; set; }
    public DateTime OrderTime { get; set; }
}

// Fluent API
modelBuilder.Entity<Order>()
    .WithPartitions(12)
    .WithReplicationFactor(3);
```

#### トピック構成
- パーティション設定: パーティション数、パーティショニング戦略
- レプリケーション設定: レプリケーションファクター、ISRの最小数
- 保持ポリシー: メッセージの保持期間、サイズ制限
- 圧縮設定: トピックレベルの圧縮方式

#### スキーマ管理
- 自動スキーマ登録: POCOからAvroスキーマを生成し登録
- 互換性設定: スキーマ互換性ポリシーの指定
- スキーマ進化: スキーマバージョンの管理とマイグレーション


### 3.2 ストリーム (KSQL Streams)
.Where(...), .Select(...) によるフィルタ・変換。

.WithManualCommit() による手動コミット指定が可能。

EntityModel に状態を保存、実行時に反映。

実行時切り替えは不可。
#### ストリーム定義の前提

ストリームは POCO に対して LINQ 式が適用されたときに動的に解釈され、生成される。

#### 判定ルール

POCO（C#のエンティティ定義）に対してLINQ式が記述された場合、
その型は "ストリーム" として解釈され、対応する CREATE STREAM 定義が自動生成されます。

ただし、以下のように GroupBy や Aggregate、Window を含む場合は CREATE TABLE（テーブル）として解釈されます。
```csharp
// ストリームとして解釈される例（AutoCommitがデフォルト）
modelBuilder.Entity<Order>()
    .Where(o => o.Amount > 1000)
    .Select(o => new { o.OrderId, o.CustomerId });

// テーブルとして解釈される例（GroupBy を含む）
modelBuilder.Entity<Order>()
    .Window(TumblingWindow.Of(TimeSpan.FromHours(1)))
    .GroupBy(o => o.CustomerId)
    .Select(g => new HourlyStats 
    { 
        CustomerId = g.Key,
        Hour = g.Window.Start,
        OrderCount = g.Count() 
    });

// 明示的にストリームとして扱う（GroupByがあっても）
modelBuilder.Entity<Order>()
    .AsStream()
    .GroupBy(o => o.Region)
    .Select(g => new { g.Key });

// 明示的にテーブルとして扱う
modelBuilder.Entity<Order>()
    .AsTable()
    .Select(o => new { o.CustomerId, o.Amount });
```

このように modelBuilder.Entity<Order>() に対して LINQ が付くか否かで "配信対象"
さらに LINQ の内容によって "ストリーム" か "テーブル" かを判別します。
加えて、.AsStream() や .AsTable() を使用することで、意図的に解釈を上書きすることも可能です。

#### コミット方式の指定

この `WithManualCommit()` 指定は `EntityModel` に保存され、実行時の `ForEachAsync()` での処理方式（自動／手動）を決定する際に参照されます。実行時にこの設定を変更することはできません。

```csharp
// 自動コミット（デフォルト）
modelBuilder.Entity<Order>()
    .Where(o => o.Amount > 1000)
    .Select(o => new { o.OrderId, o.CustomerId });

// 手動コミットを明示
modelBuilder.Entity<Order>()
    .Where(o => o.Amount > 1000)
    .Select(o => new { o.OrderId, o.CustomerId })
    .WithManualCommit();
```
注意：購読時の commit モードは LINQ 実行時に切り替えることはできません。定義時に確定させる必要があります。

### 3.3 テーブル (KSQL Tables)

このライブラリでは、LINQ 式が GroupBy や Aggregate を含み、テーブルと判定された場合、対応するトピックは 自動的に compact モードで作成 されます。

開発者はコンパクションの有無を意識せず、通常の LINQ クエリ定義だけで正しく永続化特性を持ったトピックを扱えます。
```csharp
protected override void OnModelCreating(ModelBuilder modelBuilder)
{

    modelBuilder.Entity<Order>()
        .HasTopic("orders")
        .GroupBy(o => o.CustomerId)
        .Select(g => new
        {
            CustomerId = g.Key,
            LatestAmount = g.LatestByOffset(o => o.Amount)
        });
}
```
この例では CustomerId をキーとした最新の注文金額だけを保持するテーブルが作成され、その裏のトピックは compact となります。

GroupBy(...) によりテーブル（KTable）化。

```csharp
protected override void OnModelCreating(ModelBuilder modelBuilder)
{
    modelBuilder.Entity<Order>()
        .HasTopic("orders")
        .GroupBy(o => o.OrderId)
        .Window(new[] { 1 })
        .Select(g => new
        {
            OrderId = g.Key,
            LatestPrice = g.Last().Price,
            WindowStart = g.WindowStart,
            WindowEnd = g.WindowEnd
        });
}

```
.Window(...) によりウィンドウ集約可能。

複数のウィンドウサイズ（例：1分・5分）に対応。

orders_window_final への書き込みはPOD内タイマーによるWindow確定で自律実行。

最初に到着したレコードを正とする方針を採用。

#### テーブル判定ルールと基本設計

POCO（C#のエンティティ定義）に対する LINQ 式の中で GroupBy, Aggregate, Window などの構文が含まれている場合、そのクエリは CREATE TABLE に相当する KSQL テーブルと解釈されます。これにより、ストリームとテーブルの判定が LINQ 構文の意味に基づいて一貫して行われます。

また、.AsTable() を明示的に呼び出すことで、意図的にテーブルとして扱うことも可能です。

#### 集約操作
```csharp
// サマリ集計
var customerStats = context.Orders
    .GroupBy(o => o.CustomerId)
    .Aggregate(g => new CustomerStats 
    { 
        CustomerId = g.Key, 
        TotalAmount = g.Sum(o => o.Amount),
        OrderCount = g.Count()
    });

// LATEST_BY_OFFSET
var latestCustomerOrders = context.Orders
    .GroupBy(o => o.CustomerId)
    .Aggregate(g => new CustomerLatestOrder
    {
        CustomerId = g.Key,
        LatestOrderId = g.LatestByOffset(o => o.OrderId),
        LatestOrderTime = g.LatestByOffset(o => o.OrderTime),
        LatestAmount = g.LatestByOffset(o => o.Amount)
    });

// EARLIEST_BY_OFFSET
var firstTimeCustomers = context.Orders
    .GroupBy(o => o.CustomerId)
    .Aggregate(g => new CustomerFirstOrder
    {
        CustomerId = g.Key,
        FirstOrderId = g.EarliestByOffset(o => o.OrderId),
        FirstOrderTime = g.EarliestByOffset(o => o.OrderTime),
        FirstAmount = g.EarliestByOffset(o => o.Amount)
    });


```
#### テーブル結合（JOIN）

```csharp
// 単一キー結合
var query = from o in context.Orders
            join c in context.Customers
            on o.CustomerId equals c.CustomerId
            select new { o.OrderId, c.CustomerName, o.Amount };

// 複合キー結合
var query2 = from o in context.Orders
             join c in context.Customers
             on new { o.CustomerId, o.Region } equals 
                new { c.CustomerId, c.Region }
             select new { o.OrderId, c.CustomerName, o.Amount };

// 3テーブル結合
var query3 = from o in context.Orders
             join c in context.Customers on o.CustomerId equals c.CustomerId
             join p in context.Products on o.ProductId equals p.ProductId
             select new {
                 o.OrderId,
                 c.CustomerName,
                 p.ProductName,
                 o.Quantity,
                 o.Amount
             };

```

⏱️ ウィンドウDSLの拡張：複数Window定義とアクセス
本フレームワークは、同一エンティティに対して複数の異なるウィンドウ幅（例：1分、5分、15分、60分）を定義し、個別にアクセス・購読可能とする拡張DSLをサポートします。

```csharp
modelBuilder.Entity<Chart>()
    .Window(new int[]{1,5,15,60});
```
この記述により以下の4テーブルが自動生成されます：

Chart_1min

Chart_5min

Chart_15min

Chart_60min


💻 LINQからのアクセス方法
ユーザーコードからは次のようにウィンドウサイズを指定してデータ取得できます：

```csharp
var candles1m = ctx.Charts.Window(1).ToList();
var candles5m = ctx.Charts.Window(5).ToList();
```
戻り値は IQueryable<Chart> として取得され、通常のLINQ式が適用可能です。

🔁 最新データ取得の例
ToLatest() は専用メソッドではなく、LINQで以下のように記述することを推奨します：

```csharp
var latest = ctx.Charts.Window(5).ToList()
    .OrderByDescending(c => c.Timestamp)
    .GroupBy(c => c.Symbol)
    .Select(g => g.First());
```

### 3.4 クエリと購読
ForEachAsync() による購読ストリーム取得。

.WithManualCommit() が指定されたストリームは IManualCommitMessage<T> 型を返す。

.Value：メッセージ内容

.CommitAsync()：コミット処理

.NegativeAckAsync()：否定応答
#### ストリーム定義とコミット方式の指定
```csharp
// modelBuilder による定義（自動コミット：デフォルト）
modelBuilder.Entity<Order>()
    .Where(o => o.Amount > 1000)
    .Select(o => new { o.OrderId, o.CustomerId });
// 自動コミットの購読処理（デフォルト）
await foreach (var order in context.Orders.ForEachAsync())
{
    Console.WriteLine($"Received: {order.Value.OrderId}");
    // 自動でコミットされるため明示的な commit は不要
}

// modelBuilder による定義（手動コミット）
modelBuilder.Entity<HighValueOrder>()
    .Where(o => o.Amount > 1000)
    .Select(o => new { o.OrderId, o.CustomerId })
    .WithManualCommit();

// 手動コミット付きの購読処理
await foreach (var order in context.HighValueOrders.ForEachAsync())
{
    try
    {
        Console.WriteLine($"Received: {order.Value.OrderId}");
        await order.CommitAsync();
    }
    catch
    {
        await order.NegativeAckAsync();
    }
}

```
手動コミットを使用する場合、`ForEachAsync()` は `IManualCommitMessage<T>` 型のオブジェクトを返します。
このオブジェクトは `.Value` プロパティで元のメッセージにアクセスでき、`.CommitAsync()` / `.NegativeAckAsync()` によって処理完了／失敗通知を制御します。
```csharp
public interface IManualCommitMessage<T>
{
    T Value { get; }
    Task CommitAsync();
    Task NegativeAckAsync();
}
```
この型は手動コミット指定時のみ返され、自動コミット時は T のままになります（ForEachAsync() の中で分岐）

## 4. POCO (Plain Old CLR Objects) の設計

### 4.1 基本定義
- シンプルなC#クラス: 特別な基底クラス不要
- 標準的なプロパティ: 一般的な.NET型のサポート
- [Topic], [Key], [AvroTimestamp] 属性を提供。

### 4.2 型のサポート

以下はPOCOで使用可能な主なデータ型の一覧です：

|データ型|説明|
---|---
int, long|整数型、KafkaではAvro/Protobuf経由でそのままマッピング可能
float, double|浮動小数点数
decimal|高精度数値。[DecimalPrecision]で精度指定可能
bool|真偽値
string|テキスト
DateTime|AvroTimestamp(IsEventTime=true) で処理 Kafkaへの送信時にUTC変換処理が入る。
DateTimeOffset|日時型。Kafkaへの送信時にUTC変換処理が入る。利用推奨。KSQL互換に注意
Guid|一意識別子としてサポート
short|Kafkaでは int として扱われます。使用可能ですが、必要に応じて明示的なスキーマ変換を考慮してください。
char|Kafkaには直接の対応がなく、事実上非推奨です。1文字は string 型で表現することを推奨します。

#### Decimal型の精度指定
```csharp
[DecimalPrecision(precision: 18, scale: 4)]
public decimal Amount { get; set; }
```

#### DateTime/DateTimeOffset
```csharp
// DateTimeOffset推奨（タイムゾーン情報保持）
public DateTimeOffset TransactionTime { get; set; }

// または設定付きのDateTime
[DateTimeFormat(Format = "yyyy-MM-dd'T'HH:mm:ss.SSS", Locale = "en-US")]
public DateTime OrderDate { get; set; }
```
Kafkaにはタイムゾーンの概念がなく、すべての時刻はUTCとして扱われます。このため、プロデューサとコンシューマが同一のタイムゾーン前提を共有していることが重要です。このフレームワークは Kafka に不慣れな開発者でも安全に利用できるよう設計されています。DateTimeOffset を利用することで、開発者はタイムゾーン情報を保ったままアプリケーション開発ができ、Kafka との間の UTC 変換はフレームワークが吸収します。そのため、タイムゾーンを意識したビジネスロジックの記述が可能です。また、DateTime を使用しても、Kafka送信時には内部的に DateTimeOffset(Utc) に変換されるため、安全に運用可能です。このため、プロデューサとコンシューマが同一のタイムゾーン前提を共有していることが重要です。

このフレームワークは Kafka に不慣れな開発者でも安全に利用できるよう設計されています。
DateTimeOffset を利用することで、開発者はタイムゾーン情報を保ったままアプリケーション開発ができ、Kafka との間の UTC 変換はフレームワークが吸収します。
そのため、タイムゾーンを意識したビジネスロジックの記述が可能です。
#### null許容性
```csharp
// C#標準の ?修飾子を使用
public int? OptionalQuantity { get; set; }
```

#### 数値型のデフォルト値
```csharp
[DefaultValue(10)]
public int Quantity { get; set; }
```
非nullableな数値プロパティ（例：int, double など）は、C#の仕様により初期化されていない場合でも自動的に 0 や 0.0 などの既定値が適用されます。Kafka送信時もこれらの値がそのまま使用されます。特別な初期化が不要なケースでは [DefaultValue] 属性は省略可能です。

## 5. プロデュース操作
このセクションでは、Kafka にデータを送信（プロデュース）する際の基本的な操作方法とフレームワークが提供する抽象化手法について説明します。開発者は Kafka の複雑な設定を意識することなく、Entity Framework ライクな記述でストリームデータを扱うことができます。
### 5.1 プロデューサー (データ送信)
Kafkaのリアルタイム性を維持するため、本フレームワークでは AddAsync によって即時にKafkaへ送信が行われます。
Entity Frameworkのように SaveChangesAsync によってバッファを明示的にフラッシュする設計とは異なります。
このため、開発者は AddAsync を「送信操作」として扱うことを前提に実装してください。
```csharp
// 単一レコードのプロデュース
await context.Orders.AddAsync(new Order { OrderId = "123", Amount = 100 });

```
AddAsync を呼び出すことで、該当する Kafka トピックにイベントが送信されます。

複数件のバッファリング送信や並列制御も内部で吸収されます

### 5.3 トランザクション処理
Kafka は一部の操作に対して「プロデューサートランザクション」をサポートしています。ただし、ksqlDB 側ではトランザクション処理を前提としていないため、本フレームワークでは以下のような方針を採用します：

明示的なトランザクション API は提供しない（例：BeginTransaction / CommitTransaction）

Kafka における「Exactly Once Semantics (EOS)」をサポートする構成の場合でも、アプリケーション側では操作単位の idempotency を保証してください。

複数件の連続送信が必要な場合、アプリケーション側で逐次 AddAsync() を呼び出す実装で十分に高い信頼性を確保できます。

このフレームワークでは、Kafka のリアルタイムストリーム処理の思想に従い、永続化トランザクションよりも 即時性と可用性のバランスを優先しています。


## 6. エラー処理とデータ品質
OnError(ErrorAction.Skip), .WithRetry(int), .Map(...) などのDSL提供予定。

yield 型の ForEachAsync にて try-catch 処理をサポート。

Kafka接続・デシリアライズ・業務エラーの分類的対応を検討中。

DLQ構成は ModelBuilder 経由で指定可能予定。
### 6.1 エラー処理戦略
```csharp
// エラー処理ポリシーの設定
context.Options.DeserializationErrorPolicy = ErrorPolicy.Skip;

// エラーハンドリング付きストリーム処理
var processedOrders = context.Orders
    .OnError(ErrorAction.Skip)  // エラーレコードをスキップ
    .Map(order => ProcessOrder(order))
    .WithRetry(3);  // 失敗時に3回リトライ
```

### 6.2 デッドレターキュー
DLQはフレームワークレベルで一元的に構成されており、個々のエンティティやmodelBuilder設定で明示的に指定する必要はありません。

エラー発生時には、内部の `DlqProducer` により、共通のDLQトピック（デフォルトは `"dead.letter.queue"`）へ自動的に送信されます。

Kafkaトピック名の変更が必要な場合は、`KsqlDslOptions.DlqTopicName` により一括設定可能です。


DLQは明示的な設定を必要とせず、エラー発生時に内部的に `DlqProducer` が自動的に送信処理を行います。  
これにより、利用者は特別な設定なしでエラールーティングの恩恵を受けることができます。


```csharp
var result = context.Orders
    .OnError(ErrorAction.DLQ)
    .Map(order => Process(order));
    // 共通のDLQトピックに送信されます
```
DLQ（Dead Letter Queue）への送信は、LINQクエリチェーンの中で `OnError(ErrorAction.DLQ)` を指定することで実現されます。

この指定がある場合、エラーが発生したレコードは内部の `DlqProducer` により共通DLQトピック（既定は `"dead.letter.queue"`）に送信されます。

この方式により、開発者は個別のDLQ設定やトピック定義を意識せずに、エラー発生時の処理方針をDSLで明確に記述できます。


### 6.3 スキーマフォーマットについて

本フレームワークでは、Kafka のスキーマレジストリと連携するフォーマットとして Avro のみ をサポートしています。

JSON Schema は扱いません（理由：データサイズ・速度・互換性管理の観点から）

POCO から Avro スキーマは自動生成され、初回登録 or 更新時にレジストリへ登録されます

スキーマレジストリの互換性設定（BACKWARD, FULL など）に応じた開発を推奨します

## 7. テーブル管理操作（開発・検証用途）
本フレームワークでは、KSQL上に定義されるストリーム／テーブルの初期化・削除を、開発・検証用途に限り API として提供します。

```csharp
await context.EnsureTableCreatedAsync<HourlyStats>();
await context.DropTableAsync("hourly_stats");
```
注意:
これらの操作は 開発・CI/CD 環境での利用を前提 としており、本番環境での実行は推奨されません。
本番では modelBuilder による明示的な定義と、デプロイ時のDDL管理が基本となります。


## 8. リリース計画

### フェーズ1: 基盤構築 (v0.1-v0.3)
- トピックおよびストリーム定義 DSL
- POCO ベースのデータ定義とマッピング
- プロデュース / コンシューム操作の抽象化
- Dead Letter Queue 対応


### フェーズ2: 高度なストリーム処理 (v0.4-v0.6)
- LINQ ベースのウィンドウ・集約処理
- ストリーム / テーブルの明示的切り替え
- スキーマ進化対応の検討

### フェーズ3: 高度なデータ連携 (v0.7-v0.9)
- JOIN処理のDSL化（複合キー対応含む）
- テーブル定義と RocksDB 前提の読み取り最適化
- エラー通知・メトリクス・DLQ監視基盤との連携

### フェーズ4: エンタープライズ機能 (v1.0+)
- 分散トレーシングとメトリクス
- トランザクショナルメッセージング
- マルチクラスタサポート

## 9. アーキテクチャ概要
本フレームワークは、Kafka／ksqlDB 環境における Entity Framework ライクな操作を実現するために、以下の主要レイヤーと責務をもって構成されます。
### 9.1 レイヤー構成

```
+------------------------------+
| アプリケーション層           |
|------------------------------|
| - コンシューマ購読処理       |
| - LINQベースのDSL記述       |
| - POCO定義（エンティティ）   |
+------------------------------+
            ↓
+------------------------------+
| DSL定義／マッピング層        |
|------------------------------|
| - modelBuilder によるDSL定義 |
| - LINQの解釈とクエリ変換     |
| - ストリーム／テーブル区別   |
+------------------------------+
            ↓
+------------------------------+
| コード解析・モデル構築層     |
|------------------------------|
| - POCO構造の解析              |
| - Avroスキーマの自動生成     |
| - スキーマレジストリへの登録 |
| - トピック／DLQ名の解決       |
+------------------------------+
            ↓
+------------------------------+
| Kafka連携層（プロデュース／購読）|
|------------------------------|
| - Kafkaへの送信（AddAsync）   |
| - ForEachAsyncによる購読処理 |
| - DLQへのエラールーティング   |
+------------------------------+
            ↓
+------------------------------+
| KSQL操作層                   |
|------------------------------|
| - CREATE STREAM/TABLE生成    |
| - JOIN / AGGREGATE の発行    |
| - クエリ登録と監視           |
+------------------------------+
            ↓
+------------------------------+
| RocksDBキャッシュ層（KTable backing store） |
|------------------------------|
| - KTable/テーブル参照時にRocksDBでローカルキャッシュ
| - 参照クエリは極力RocksDB経由で応答（遅延低減・パフォーマンス最適化）
+------------------------------+

```
### 9.2 フォーマットポリシー

本フレームワークでは Kafka との通信において Avro のみを正式サポート しています。

JSON Schema はサポート対象外です（理由：サイズ効率・速度・互換性管理の明確性）。

スキーマは自動生成され、スキーマレジストリに登録されます。

### 9.3 補足

スキーマレジストリの接続設定や互換性ルール（BACKWARD 等）は別途構成で指定。

ストリーム／テーブルの定義、DLQ設定、LINQ DSL、プロデュース／購読などの責務が明確に分離されており、将来的な拡張やプラガブルアーキテクチャが可能です。

 #### RocksDBキャッシュ設計思想

 本フレームワークでは、KSQLのテーブル（KTable）参照時に、RocksDBをバックエンドストアとして自動利用し、参照クエリのパフォーマンスを最大化しています。

 - 通常の`.ToList()`や`.FirstOrDefault()`などの参照はRocksDBを経由し、ksqlDBやKafka本体への都度問い合わせを避けます。
 - RocksDB層はデフォルトで有効化。キャッシュサイズや永続化設定など詳細は将来的にFluent APIで拡張予定です。
 - この設計により、「大量データ参照でもレイテンシが大幅に低減」されます。
 - 詳細なパフォーマンス設計例はFAQ・運用ガイド参照。

10.4 DIコンテナと初期化タイミング

本フレームワークの利用においては、KafkaDbContext は DI コンテナを通じてスコープ管理されることを想定しています。

DbContext のインスタンスが解決されると、内部的に OnModelCreating() が呼ばれ、LINQベースの DSL 定義が構築・解析されます。

コンストラクタは軽量であり、DSL構文の構築のみを行います。

Kafkaやスキーマレジストリへの接続確認・リソース作成は、以下のように明示的に EnsureKafkaReadyAsync() を呼び出して実行します：

```
public class KafkaInitializer
{
    private readonly KafkaDbContext _context;

    public KafkaInitializer(KafkaDbContext context)
    {
        _context = context;
    }

    public async Task InitializeAsync()
    {
        await _context.EnsureKafkaReadyAsync();
    }
}

```
注意点：このタイミングで Schema Registry への通信や Kafka メタデータ取得処理が走るため、接続先が利用可能でない場合に例外が発生する可能性があります。

そのため、KafkaDbContext 自体は軽量な構築とし、重い外部接続処理は明示的な初期化メソッドに切り出しています。

EF と異なり Kafka OSS では「コードに基づいて Kafka 側の構造を生成する」ため、初期化を明示化することで、利用者の意図したタイミングでエラーを把握できる構造となっています。

この点を考慮し、Kafka 接続が不要な構文検証モードを別途用意することも検討されます（例：ValidateModelOnly=true オプション）。

Kafka接続不要な構文検証モードの価値

このモードには以下の利点があります：

CI/CD での構文検証：Kafka や Schema Registry が起動していない環境でも LINQ DSL や POCO の定義が妥当かを自動チェック可能。

Kafka インフラ未構築でも開発可能：先に LINQ や POCO を定義し、Kafka が準備される前に開発が進行可能。

安全な単体テスト：Kafka 接続なしでローカルテストが可能。

学習コスト低減：Kafka 環境のセットアップを待たずに、DSL定義の学習・試行錯誤が可能。。


## 11. Kafkaのcommit/DB commit・障害時の動作（DBエンジニア必読）

Kafkaのコンシューマアプリでは「オフセットcommit」と「DBのトランザクションcommit」は同じではありません。 特にDBエンジニア・テックリード層に多い勘違いとして、\*\*障害発生時には「前回commitしたオフセット」から“再度メッセージが流れてくる”\*\*という動作を理解しておく必要があります。

### サンプル：障害発生時の「重複実行」イメージ

```csharp
foreach (var msg in consumer.Consume())
{
    // 1. DBに書き込む
    db.Save(msg.Value); // 例：OrdersテーブルにINSERT

    // 2. Kafkaにオフセットcommit（"ここまで処理済み"を通知）
    consumer.Commit(msg);
}
```

#### ▼このときの「状態」例

| 処理        | DB     | Kafkaオフセット | 備考                       |
| --------- | ------ | ---------- | ------------------------ |
| 初回実行      | 書き込み済み | commit済み   | 1回だけでOK                  |
| commit前障害 | 書き込み済み | commit前    | **再起動後、同じmsgを再実行（DB重複）** |
| commit後障害 | 書き込み済み | commit済み   | 以降は次のmsgから処理             |

#### 【冪等化例：重複反映を防ぐパターン】

```csharp
foreach (var msg in consumer.Consume())
{
    if (!db.Exists(msg.Key))
    {
        db.Save(msg.Value);
    }
    consumer.Commit(msg);
}
```

- こうすることで、**再実行されてもDBは一意に保たれる**（冪等性担保）

### 解説

- Kafkaのcommitは「オフセット管理」でありDBのcommitとは意味が違う
- commit前の副作用は何度も再実行される前提で設計する
- 特にDB系テックリードは「一意反映」と誤認しやすいので**冪等設計必須**
- こうした違いを理解せずに設計すると「二重反映」「消えたデータ」問題に直結

### tool — 2025-06-26T01:03:34.188927+00:00

All the files uploaded by the user have been fully loaded. Searching won't provide additional information.
