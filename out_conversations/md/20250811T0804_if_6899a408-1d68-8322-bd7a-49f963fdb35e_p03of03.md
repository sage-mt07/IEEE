---
conversation_id: "6899a408-1d68-8322-bd7a-49f963fdb35e"
title: "if条件改善案"
create_time: 1754899494.597029
update_time: 1754914148.442342
language_guess: "en"
num_messages: 365
part_index: 3
part_count: 3
---

### assistant — 2025-08-11T10:36:20.978929+00:00

了解。`KafkaConsumerManager.cs` に**最小限の追記のみ**で、  
- ConsumerManager が **commit 用の準備(Prepare)** を行い、  
- 各レコードの **meta を CommitManager に紐付け(Track)** できるようにします。  

既存の `ConsumeAsync<TPOCO>(CancellationToken)` は**そのまま**残し、  
新しく **registrar 付きオーバーロード**を追加します。  
内部ループはコピペ最小のため、既存とは別の private 汎用メソッドを1つ足すだけです。

以下のコードを **そのまま差し込んで**ください（既存行は変更せず、追記のみ）:

```csharp
// 1) 追加：Commit 前準備＆トラッキング用の極小IF
namespace Kafka.Ksql.Linq.Messaging.Consumers
{
    /// <summary>
    /// ConsumerManagerがcommit用の準備(Prepare)と、メッセージ受信時のmeta紐付け(Track)を通知するための任意実装IF。
    /// 実装側（CommitManagerなど）が存在しない場合は無視されます。
    /// </summary>
    public interface ICommitPrepAndTrack
    {
        // POCO種別 / Topic / GroupId を事前通知（appsettings.json + Fluent API 由来）
        void Prepare(Type pocoType, string topic, string groupId);

        // 受信したPOCOとそのMessageMetaを紐付け（POCO参照をキーにmeta管理できる）
        void Track(object entity, MessageMeta meta);
    }
}
```

```csharp
// 2) 追加：registrar付きのConsumeAsyncオーバーロード（既存はそのまま温存）
public async IAsyncEnumerable<(TPOCO, Dictionary<string, string>, MessageMeta)> ConsumeAsync<TPOCO>(
    ICommitPrepAndTrack? registrar,
    [EnumeratorCancellation] CancellationToken cancellationToken = default) where TPOCO : class
{
    var model = GetEntityModel<TPOCO>();
    var topic = model.GetTopicName();
    var mapping = _mappingRegistry.GetMapping(typeof(TPOCO));
    var config = BuildConsumerConfig(topic, null);

    // ★ commit用の準備を1回だけ通知（Topic/GroupId は appsettings/FluentAPI 由来）
    if (registrar is not null)
    {
        var groupId = string.IsNullOrWhiteSpace(config.GroupId) ? "default-group" : config.GroupId!;
        registrar.Prepare(typeof(TPOCO), topic, groupId);
    }

    var method = typeof(KafkaConsumerManager)
        .GetMethod(nameof(ConsumeInternalWithRegistrar), System.Reflection.BindingFlags.NonPublic | System.Reflection.BindingFlags.Instance)!
        .MakeGenericMethod(mapping.AvroKeyType!, mapping.AvroValueType!, typeof(TPOCO));

    var enumerable = (IAsyncEnumerable<(TPOCO, Dictionary<string, string>, MessageMeta)>)method
        .Invoke(this, new object?[] { topic, config, mapping, registrar, cancellationToken })!;

    await foreach (var item in enumerable.WithCancellation(cancellationToken))
        yield return item;
}
```

```csharp
// 3) 追加：registrar対応の内部汎用メソッド（既存のConsumeInternalは触らない）
private async IAsyncEnumerable<(TPOCO, Dictionary<string, string>, MessageMeta)> ConsumeInternalWithRegistrar<TKey, TValue, TPOCO>(
    string topicName,
    ConsumerConfig config,
    KeyValueTypeMapping mapping,
    ICommitPrepAndTrack? registrar,
    [EnumeratorCancellation] CancellationToken cancellationToken)
    where TKey : class where TValue : class where TPOCO : class
{
    using var consumer = CreateConsumer<TKey, TValue>(config);
    consumer.Subscribe(topicName);

    while (!cancellationToken.IsCancellationRequested)
    {
        ConsumeResult<TKey, TValue>? result;
        try
        {
            result = consumer.Consume(cancellationToken);
        }
        catch (OperationCanceledException)
        {
            break;
        }
        if (result == null || result.IsPartitionEOF)
            continue;

        TPOCO entity;
        Dictionary<string, string> headers;
        MessageMeta meta;
        try
        {
            entity = (TPOCO)mapping.CombineFromAvroKeyValue(result.Message.Key, result.Message.Value!, typeof(TPOCO));
            headers = new Dictionary<string, string>();
            if (result.Message.Headers != null)
            {
                foreach (var h in result.Message.Headers)
                    headers[h.Key] = System.Text.Encoding.UTF8.GetString(h.GetValueBytes());
            }

            meta = new MessageMeta(
                Topic: result.Topic,
                Partition: result.Partition,
                Offset: result.Offset,
                TimestampUtc: result.Message.Timestamp.UtcDateTime,
                SchemaIdKey: TryGetSchemaId(result.Message.Key as byte[]),
                SchemaIdValue: TryGetSchemaId(result.Message.Value as byte[]),
                KeyIsNull: result.Message.Key is null,
                HeaderAllowList: ExtractAllowedHeaders(result.Message.Headers, _dlq.HeaderAllowList, _dlq.HeaderValueMaxLength)
            );
        }
        catch (Exception ex)
        {
            await HandleMappingException(result, ex, _dlqProducer, consumer, _dlq, _limiter, cancellationToken).ConfigureAwait(false);
            continue;
        }

        // ★ ここでPOCO→metaを通知（CommitManager側で参照同一性キーに登録できる）
        registrar?.Track(entity!, meta);

        yield return (entity, headers, meta);
        await Task.CompletedTask;
    }
}
```

これで、  
- **ConsumerManager が commit 用の準備**（`Prepare`）を**1回**行い、  
- 各メッセージで **meta を CommitManager に渡す**（`Track`）——のフローが最小改変で実現できます。  
既存の `ConsumeAsync<TPOCO>(CancellationToken)` / `ConsumeInternal<...>` は**無変更**、後方互換そのままです。fileciteturn5file0

> 受け側（CommitManager 側）では、`ICommitPrepAndTrack` を実装して  
> - `Prepare` で **PocoType→Topic/GroupId** を記録  
> - `Track` で **Poco参照→MessageMeta** を保持  
> - `Commit(PocoType, Pocoインスタンス)` で **保持している meta を見て offset commit**、同 **Topic の ≤ そのoffset を開放**  
> とすれば、あなたの要件（topic毎に位置保持／poco単位管理／meta活用／commit時に過去を解放）を満たせます。

もし EventSet 側から使うなら、`EventSet` で `_commitManager as ICommitPrepAndTrack` を検出してこの **新オーバーロード**を呼び出すだけでOKです（EventSetの小改変のみで完結します）。

必要なら、EventSet/ManualCommitManager 側のサンプル実装も続けて出します。  

— 送信日時: [[REDACTED_PHONE]]:21 (JST)
### system — 2025-08-11T10:36:21.394582+00:00

_(empty)_
### tool — 2025-08-11T10:36:21.400318+00:00

_(empty)_
### tool — 2025-08-11T10:36:21.409697+00:00

fileciteturn5file0

using Confluent.Kafka;
using Confluent.Kafka.SyncOverAsync;
using Confluent.SchemaRegistry.Serdes;
using Kafka.Ksql.Linq.Configuration;
using Kafka.Ksql.Linq.Configuration.Abstractions;
using Kafka.Ksql.Linq.Core.Abstractions;
using Kafka.Ksql.Linq.Core.Extensions;
using Kafka.Ksql.Linq.Mapping;
using Kafka.Ksql.Linq.Messaging.Configuration;
using Kafka.Ksql.Linq.Core.Dlq;
using Kafka.Ksql.Linq.Messaging.Producers;
using Microsoft.Extensions.Logging;
using Microsoft.Extensions.Options;
using System;
using System.Collections.Generic;
using System.Runtime.CompilerServices;
using System.Threading;
using System.Threading.Tasks;
using ConfluentSchemaRegistry = Confluent.SchemaRegistry;

namespace Kafka.Ksql.Linq.Messaging.Consumers;

internal sealed class KafkaConsumerManager : IDisposable
{
    private readonly KsqlDslOptions _options;
    private readonly ILogger? _logger;
    private readonly Lazy<ConfluentSchemaRegistry.ISchemaRegistryClient> _schemaRegistryClient;
    private readonly Dictionary<Type, EntityModel> _entityModels;
    private readonly MappingRegistry _mappingRegistry;
    private readonly DlqOptions _dlq;
    private readonly IRateLimiter _limiter;
    private readonly IDlqProducer _dlqProducer;
    private bool _disposed;

#pragma warning disable CS0067 // Event is never used
    public event Func<byte[]?, Exception, string, int, long, DateTime, Headers?, string, string, Task>? DeserializationError;
#pragma warning restore CS0067

    public KafkaConsumerManager(
        MappingRegistry mapping,
        IOptions<KsqlDslOptions> options,
        Dictionary<Type, EntityModel> entityModels,
        IDlqProducer dlqProducer,
        ILoggerFactory? loggerFactory = null,
        IRateLimiter? limiter = null)
    {
        _mappingRegistry = mapping;
        _options = options?.Value ?? throw new ArgumentNullException(nameof(options));
        _entityModels = entityModels ?? new();
        _dlqProducer = dlqProducer;
        _logger = loggerFactory?.CreateLogger<KafkaConsumerManager>();
        _schemaRegistryClient = new Lazy<ConfluentSchemaRegistry.ISchemaRegistryClient>(CreateSchemaRegistryClient);
        _dlq = _options.DlqOptions;
        _limiter = limiter ?? new SimpleRateLimiter(_dlq.MaxPerSecond);
    }



    public async IAsyncEnumerable<(TPOCO, Dictionary<string, string>, MessageMeta)> ConsumeAsync<TPOCO>(
        [EnumeratorCancellation] CancellationToken cancellationToken = default) where TPOCO : class
    {
        var model = GetEntityModel<TPOCO>();
        var topic = model.GetTopicName();
        var mapping = _mappingRegistry.GetMapping(typeof(TPOCO));
        var config = BuildConsumerConfig(topic, null);

        var method = typeof(KafkaConsumerManager)
            .GetMethod(nameof(ConsumeInternal), System.Reflection.BindingFlags.NonPublic | System.Reflection.BindingFlags.Instance)!
            .MakeGenericMethod(mapping.AvroKeyType!, mapping.AvroValueType!, typeof(TPOCO));

        var enumerable = (IAsyncEnumerable<(TPOCO, Dictionary<string, string>, MessageMeta)>)method
            .Invoke(this, new object?[] { topic, config, mapping, cancellationToken })!;

        await foreach (var item in enumerable.WithCancellation(cancellationToken))
            yield return item;
    }

    private async IAsyncEnumerable<(TPOCO, Dictionary<string, string>, MessageMeta)> ConsumeInternal<TKey, TValue, TPOCO>(
        string topicName,
        ConsumerConfig config,
        KeyValueTypeMapping mapping,
        [EnumeratorCancellation] CancellationToken cancellationToken)
        where TKey : class where TValue : class where TPOCO : class
    {
        using var consumer = CreateConsumer<TKey, TValue>(config);
        consumer.Subscribe(topicName);

        while (!cancellationToken.IsCancellationRequested)
        {
            ConsumeResult<TKey, TValue>? result;
            try
            {
                result = consumer.Consume(cancellationToken);
            }
            catch (OperationCanceledException)
            {
                break;
            }
            if (result == null || result.IsPartitionEOF)
                continue;

            TPOCO entity;
            Dictionary<string, string> headers;
            MessageMeta meta;
            try
            {
                entity = (TPOCO)mapping.CombineFromAvroKeyValue(result.Message.Key, result.Message.Value!, typeof(TPOCO));
                headers = new Dictionary<string, string>();
                if (result.Message.Headers != null)
                {
                    foreach (var h in result.Message.Headers)
                        headers[h.Key] = System.Text.Encoding.UTF8.GetString(h.GetValueBytes());
                }

                meta = new MessageMeta(
                    Topic: result.Topic,
                    Partition: result.Partition,
                    Offset: result.Offset,
                    TimestampUtc: result.Message.Timestamp.UtcDateTime,
                    SchemaIdKey: TryGetSchemaId(result.Message.Key as byte[]),
                    SchemaIdValue: TryGetSchemaId(result.Message.Value as byte[]),
                    KeyIsNull: result.Message.Key is null,
                    HeaderAllowList: ExtractAllowedHeaders(result.Message.Headers, _dlq.HeaderAllowList, _dlq.HeaderValueMaxLength)
                );
            }
            catch (Exception ex)
            {
                await HandleMappingException(result, ex, _dlqProducer, consumer, _dlq, _limiter, cancellationToken).ConfigureAwait(false);
                continue;
            }

            yield return (entity, headers, meta);
            await Task.CompletedTask;
        }
    }

    internal static async Task HandleMappingException<TKey, TValue>(
        ConsumeResult<TKey, TValue> result,
        Exception ex,
        IDlqProducer dlqProducer,
        IConsumer<TKey, TValue> consumer,
        DlqOptions options,
        IRateLimiter limiter,
        CancellationToken cancellationToken)
        where TKey : class where TValue : class
    {
        if (options.EnableForDeserializationError && DlqGuard.ShouldSend(options, limiter, ex.GetType()))
        {
            var allowHeaders = ExtractAllowedHeaders(result.Message.Headers, options.HeaderAllowList, options.HeaderValueMaxLength);
            var env = DlqEnvelopeFactory.From(result, ex,
                options.ApplicationId, options.ConsumerGroup, options.Host, allowHeaders,
                options.ErrorMessageMaxLength, options.StackTraceMaxLength, options.NormalizeStackTraceWhitespace);
            await dlqProducer.ProduceAsync(env, cancellationToken).ConfigureAwait(false);
        }
        consumer.Commit(result);
    }

    private IConsumer<TKey, TValue> CreateConsumer<TKey, TValue>(ConsumerConfig config)
        where TKey : class where TValue : class
    {
        return new ConsumerBuilder<TKey, TValue>(config)
            .SetKeyDeserializer(new AvroDeserializer<TKey>(_schemaRegistryClient.Value).AsSyncOverAsync())
            .SetValueDeserializer(new AvroDeserializer<TValue>(_schemaRegistryClient.Value).AsSyncOverAsync())
            .Build();
    }

    private ConfluentSchemaRegistry.ISchemaRegistryClient CreateSchemaRegistryClient()
    {
        var cfg = new ConfluentSchemaRegistry.SchemaRegistryConfig { Url = _options.SchemaRegistry.Url };
        return new ConfluentSchemaRegistry.CachedSchemaRegistryClient(cfg);
    }

    private EntityModel GetEntityModel<T>() where T : class
    {
        if (_entityModels.TryGetValue(typeof(T), out var model))
            return model;
        throw new InvalidOperationException($"Entity model not found for {typeof(T).Name}");
    }

    private ConsumerConfig BuildConsumerConfig(string topicName, KafkaSubscriptionOptions? subscriptionOptions)
    {
        var topicConfig = _options.Topics.TryGetValue(topicName, out var cfg) ? cfg : new TopicSection();
        var groupId = subscriptionOptions?.GroupId ?? topicConfig.Consumer.GroupId;
        if (string.IsNullOrWhiteSpace(groupId))
            groupId = "default-group";

        var consumerConfig = new ConsumerConfig
        {
            BootstrapServers = _options.Common.BootstrapServers,
            ClientId = _options.Common.ClientId,
            GroupId = groupId,
            AutoOffsetReset = Enum.Parse<AutoOffsetReset>(topicConfig.Consumer.AutoOffsetReset),
            EnableAutoCommit = topicConfig.Consumer.EnableAutoCommit,
            AutoCommitIntervalMs = topicConfig.Consumer.AutoCommitIntervalMs,
            SessionTimeoutMs = topicConfig.Consumer.SessionTimeoutMs,
            HeartbeatIntervalMs = topicConfig.Consumer.HeartbeatIntervalMs,
            MaxPollIntervalMs = topicConfig.Consumer.MaxPollIntervalMs,
            FetchMinBytes = topicConfig.Consumer.FetchMinBytes,
            FetchMaxBytes = topicConfig.Consumer.FetchMaxBytes,
            IsolationLevel = Enum.Parse<IsolationLevel>(topicConfig.Consumer.IsolationLevel)
        };

        if (subscriptionOptions != null)
        {
            if (subscriptionOptions.AutoCommit.HasValue)
                consumerConfig.EnableAutoCommit = subscriptionOptions.AutoCommit.Value;
            if (subscriptionOptions.SessionTimeout.HasValue)
                consumerConfig.SessionTimeoutMs = (int)subscriptionOptions.SessionTimeout.Value.TotalMilliseconds;
            if (subscriptionOptions.HeartbeatInterval.HasValue)
                consumerConfig.HeartbeatIntervalMs = (int)subscriptionOptions.HeartbeatInterval.Value.TotalMilliseconds;
            if (subscriptionOptions.MaxPollInterval.HasValue)
                consumerConfig.MaxPollIntervalMs = (int)subscriptionOptions.MaxPollInterval.Value.TotalMilliseconds;
        }

        if (_options.Common.SecurityProtocol != SecurityProtocol.Plaintext)
        {
            consumerConfig.SecurityProtocol = _options.Common.SecurityProtocol;
            if (_options.Common.SaslMechanism.HasValue)
            {
                consumerConfig.SaslMechanism = _options.Common.SaslMechanism.Value;
                consumerConfig.SaslUsername = _options.Common.SaslUsername;
                consumerConfig.SaslPassword = _options.Common.SaslPassword;
            }

            if (!string.IsNullOrEmpty(_options.Common.SslCaLocation))
            {
                consumerConfig.SslCaLocation = _options.Common.SslCaLocation;
                consumerConfig.SslCertificateLocation = _options.Common.SslCertificateLocation;
                consumerConfig.SslKeyLocation = _options.Common.SslKeyLocation;
                consumerConfig.SslKeyPassword = _options.Common.SslKeyPassword;
            }
        }

        foreach (var kvp in topicConfig.Consumer.AdditionalProperties)
            consumerConfig.Set(kvp.Key, kvp.Value);

        return consumerConfig;
    }

    public void ResetOffsetsToBeginning<TPOCO>() where TPOCO : class
    {
        var model = GetEntityModel<TPOCO>();
        var topic = model.GetTopicName();
        var mapping = _mappingRegistry.GetMapping(typeof(TPOCO));
        var config = BuildConsumerConfig(topic, null);
        config.EnableAutoCommit = false;
        var method = typeof(KafkaConsumerManager)
            .GetMethod(nameof(ResetOffsetsToBeginningInternal), System.Reflection.BindingFlags.NonPublic | System.Reflection.BindingFlags.Instance)!
            .MakeGenericMethod(mapping.AvroKeyType!, mapping.AvroValueType!);
        method.Invoke(this, new object?[] { topic, config, model.Partitions });
    }

    private void ResetOffsetsToBeginningInternal<TKey, TValue>(string topic, ConsumerConfig config, int partitions)
        where TKey : class where TValue : class
    {
        using var consumer = CreateConsumer<TKey, TValue>(config);
        var tps = new List<TopicPartitionOffset>(partitions);
        for (var i = 0; i < partitions; i++)
            tps.Add(new TopicPartitionOffset(topic, new Partition(i), new Offset(0)));
        consumer.Assign(tps);
        consumer.Commit(tps);
    }

    public void Dispose()
    {
        if (_disposed) return;
        if (_schemaRegistryClient.IsValueCreated)
            _schemaRegistryClient.Value.Dispose();
        _disposed = true;
    }

    private static int? TryGetSchemaId(byte[]? payload)
    {
        if (payload is { Length: >= 5 } && payload[0] == 0)
            return System.Buffers.Binary.BinaryPrimitives.ReadInt32BigEndian(payload.AsSpan(1, 4));
        return null;
    }

    private static System.Collections.Generic.IReadOnlyDictionary<string, string> ExtractAllowedHeaders(
        Headers? headers, System.Collections.Generic.IEnumerable<string> allowList, int maxLen = 1024)
    {
        var dict = new System.Collections.Generic.Dictionary<string, string>(System.StringComparer.OrdinalIgnoreCase);
        if (headers is null) return dict;

        var set = allowList is System.Collections.Generic.HashSet<string> hs ? hs :
                  new System.Collections.Generic.HashSet<string>(allowList ?? System.Array.Empty<string>(), System.StringComparer.OrdinalIgnoreCase);

        foreach (var h in headers)
        {
            if (!set.Contains(h.Key)) continue;
            var bytes = h.GetValueBytes() ?? System.Array.Empty<byte>();
            string val;
            try
            {
                val = System.Text.Encoding.UTF8.GetString(bytes);
                if (!System.Text.Encoding.UTF8.GetBytes(val).AsSpan().SequenceEqual(bytes))
                    val = "base64:" + System.Convert.ToBase64String(bytes);
            }
            catch
            {
                val = "base64:" + System.Convert.ToBase64String(bytes);
            }
            if (val.Length > maxLen) val = val[..maxLen];
            dict[h.Key] = val;
        }
        return dict;
    }
}
### tool — 2025-08-11T10:36:21.424406+00:00

All the files uploaded by the user have been fully loaded. Searching won't provide additional information.
### assistant — 2025-08-11T10:36:22.057792+00:00

_(empty)_
### assistant — 2025-08-11T10:36:57.715263+00:00

_(empty)_
### user — 2025-08-11T10:38:13.977000+00:00

groupidがパラメータ化されていることに違和感しかない
### assistant — 2025-08-11T10:38:18.107280+00:00

OK、その違和感はごもっとも。**groupId を外からパラメータで回すのはやめ**て、  
**CommitManager 自身が appsettings.json / Fluent API から解決**する形にします。  
ConsumerManager には手を入れず、**EventSet + ManualCommitManager だけ**で完結します。

---

# 変更はこの2点だけ

## 1) EventSet.cs（最小差分）
- POCOで列挙できる `ForEachPocoAsync` を追加（既存の `IAsyncEnumerable<object>` は温存）
- POCOをそのまま渡せる `Commit(T entity)` を追加
- `ConsumeAsync` の流れを**1行ラップ**して、返ってくる `(poco, meta)` を **_commitManager に登録**（※groupIdは渡さない）

```csharp
// EventSet<T> の追記（既存メソッドは残す）

// 1) POCO列挙（キャスト不要）
public async IAsyncEnumerable<T> ForEachPocoAsync(
    [EnumeratorCancellation] CancellationToken cancellationToken = default)
{
    await foreach (var item in GetAsyncEnumeratorWrapper(cancellationToken))
        yield return item;
}

// 2) POCOを指定してcommit（autocommit時はNoopCommitManagerがno-op）
public void Commit(T entity)
{
    if (entity is null) throw new ArgumentNullException(nameof(entity));
    _commitManager?.Commit(typeof(T), entity);
}

// 3) meta登録フック（internal/ private でOK。groupIdは扱わない）
private interface ITracksOffset
{
    void Track(Type pocoType, object entity, MessageMeta meta);
}

protected override IAsyncEnumerable<(T Entity, Dictionary<string,string> Headers, MessageMeta Meta)>
    ConsumeAsync(KsqlContext context, CancellationToken cancellationToken)
{
    var src = context.GetConsumerManager().ConsumeAsync<T>(cancellationToken); // 既存：(T, Headers, Meta)
    var tracker = _commitManager as ITracksOffset;

    return TrackIfSupported(src, tracker, cancellationToken);

    async IAsyncEnumerable<(T, Dictionary<string,string>, MessageMeta)> TrackIfSupported(
        IAsyncEnumerable<(T, Dictionary<string,string>, MessageMeta)> source,
        ITracksOffset? t,
        [EnumeratorCancellation] CancellationToken ct = default)
    {
        await foreach (var (entity, headers, meta) in source.WithCancellation(ct))
        {
            t?.Track(typeof(T), entity!, meta); // ★ groupId不要。metaにTopic/Partition/Offsetが入っている
            yield return (entity, headers, meta);
        }
    }
}
```

> これで **ConsumerManager は無改変**のまま、meta を CommitManager に渡せます。

---

## 2) ManualCommitManager.cs（新規1クラス）
- **POCO参照 → meta** を `ConditionalWeakTable` で保持（参照同一性・GCフレンドリー）  
- **Topicごと**に「pending最大 offset」「committed最大 offset」を保持（“戻さない”保証）  
- `Commit(Type pocoType, object poco)` では  
  1) 登録済み meta から **topic/partition/offset** を取得  
  2) **appsettings.json / Fluent API** から **その topic の consumer 設定（GroupId含む）を自分で解決**  
  3) **一時 consumer を内部で生成**して **nextOffset** を commit  
  4) その **topic の ≤committed** な登録情報を掃除

```csharp
using System.Collections.Concurrent;
using System.Runtime.CompilerServices;
using Confluent.Kafka;
using Microsoft.Extensions.Options;

internal sealed class ManualCommitManager : ICommitManager, EventSet<T_dummy>.ITracksOffset
{
    // 参照同一性で POCO → Meta を保持
    private readonly ConditionalWeakTable<object, MessageMeta> _metas = new();

    // Topicごとの pending/committed 最大“現在オフセット”
    private readonly ConcurrentDictionary<string, long> _pendingMax = new();
    private readonly ConcurrentDictionary<string, long> _committedMax = new();

    // appsettings.json / Fluent API を包んだオプション（あなたの実体に合わせてください）
    private readonly IOptions<KsqlDslOptions> _options;
    private readonly ITopicConfigResolver _topicResolver; // Topic → ConsumerConfig を引ける小さなヘルパ（Fluent/API結合）

    public ManualCommitManager(IOptions<KsqlDslOptions> options, ITopicConfigResolver topicResolver)
    {
        _options = options ?? throw new ArgumentNullException(nameof(options));
        _topicResolver = topicResolver ?? throw new ArgumentNullException(nameof(topicResolver));
    }

    // EventSetから毎レコード呼ばれる（groupIdは不要。metaに必要情報が入っている）
    public void Track(Type pocoType, object entity, MessageMeta meta)
    {
        // 同一参照を最新metaで上書き
        try { _metas.Remove(entity); } catch { /* ignore */ }
        _metas.Add(entity, meta);
    }

    // POCO指定でcommit（TypeはTopic解決のヒントに使えるが、基本はmeta.Topicが源泉）
    public void Commit(Type pocoType, object entity)
    {
        if (!_metas.TryGetValue(entity, out var meta))
            throw new InvalidOperationException("Entity is not tracked for commit.");

        var topic = meta.Topic;
        var partition = meta.Partition;
        var offset = meta.Offset.Value; // “現在”のオフセット

        // Topic単位の最大更新（キュー不要・O(1)）
        _pendingMax.AddOrUpdate(topic, offset, static (_, cur) => offset > cur ? offset : cur);

        // “戻さない”：既にcommit済最大以下なら何もしない
        if (_committedMax.TryGetValue(topic, out var committed) && offset <= committed)
            return;

        // appsettings.json / Fluent API からこのTopicの ConsumerConfig を解決（GroupIdは内部で取得）
        var config = _topicResolver.GetConsumerConfigForTopic(topic); // EnableAutoCommit=false を含む設定
        using var consumer = new ConsumerBuilder<byte[], byte[]>(config).Build();

        // nextOffset で commit
        var next = new Offset(offset + 1);
        var tpo = new TopicPartitionOffset(topic, partition, next);
        consumer.Assign(tpo);
        consumer.Commit(new[] { tpo });

        // 確定済み最大を更新
        _committedMax.AddOrUpdate(topic, offset, static (_, cur) => offset > cur ? offset : cur);

        // ≤committed を掃除（粗くてもOK：直近の参照は必ず消す）
        CleanupTopicEntriesUpTo(topic, _committedMax[topic]);
    }

    private void CleanupTopicEntriesUpTo(string topic, long committed)
    {
        // CWT は列挙が弱いので「最近commitしたentityを確実にRemove」→
        // 追加で「Topic一致かつ Offset<=committed なエントリ」を見つけ次第Remove
        // ここは必要十分な範囲で（性能重視なら索引追加も可）

        // 最低限：CWT から “最近commitしたentity” をRemoveする運用で十分にリークを防げる
        // より厳密にやるなら Topic→offset 索引を別途持って ≤committed を一括削除する実装に差し替え可能
    }
}
```

> 重要: **groupId を外からパラメータで渡していません**。  
> `ManualCommitManager` は **自分で topic → ConsumerConfig を解決**し、そこに含まれる `GroupId` を使って一時 consumer を作り **nextOffset** を commit します。  
> これはあなたの `KafkaConsumerManager.ResetOffsetsToBeginningInternal` がやっている方式（「一時 consumer を構築してオフセット操作」）に沿っています。

---

## 呼び出し側（テスト）の置き換えはこれだけ
```diff
- await foreach (var obj in ctx.Samples.ForEachAsync(consumeCts.Token))
- {
-     var msg = (IManualCommitMessage<ManualCommitContext.Sample>)obj;
-     if (msg.Value.Id == 3) { await msg.CommitAsync(); break; }
- }
+ await foreach (var sample in ctx.Samples.ForEachPocoAsync(consumeCts.Token))
+ {
+     if (sample.Id == 3) { ctx.Samples.Commit(sample); break; }
+ }
```

- **キャスト撤廃**  
- **autocommit ⇄ manual** の切替でも、呼び出し側は **`Commit(poco)` を呼ぶ/呼ばない**だけ  
- **groupId はどこにも露出しない**

---

必要なら、`ITopicConfigResolver` の最小実装（`KsqlDslOptions.Topics["..."].Consumer.GroupId` を引くだけ）も出します。  
この方針なら **“groupId がパラメータで飛び交う不安”を完全に排除**しつつ、改変範囲も極小です。

— 送信日時: [[REDACTED_PHONE]]:46 (JST)
### system — 2025-08-11T10:38:18.120046+00:00

_(empty)_
### assistant — 2025-08-11T10:38:18.861797+00:00

_(empty)_
### assistant — 2025-08-11T10:38:55.581359+00:00

_(empty)_
### user — 2025-08-11T10:40:05.150000+00:00

根本的に思想が違うことが分かった
### assistant — 2025-08-11T10:40:08.975574+00:00

了解です。ここまで提案してきた流れが、司令の設計思想とズレていること、はっきり受け止めました。無理に続けず、一旦リセットします。

もし、この先を進めるなら——

- 司令の**コア原則（3〜5行）**だけ教えてください。  
  例）「Commit は必ず ConsumerManager 経由」「groupId は外に出さない」「poco単位で commit」「ConsumerManager は meta を返すだけ／もしくは commit まで責務を持つ」「改変は EventSet + CommitManager のみ」など。

その原則に**完全寄せ**で、コードを最小差分で出します。  
要らなければここで打ち切りでもOK。おまかせします。

— 送信日時: [[REDACTED_PHONE]]:52 (JST)
### system — 2025-08-11T10:40:08.988888+00:00

_(empty)_
### assistant — 2025-08-11T10:40:09.642436+00:00

_(empty)_
### assistant — 2025-08-11T10:40:22.736066+00:00

_(empty)_
### user — 2025-08-11T10:40:42.496000+00:00

commitはconsumerに対してお
### assistant — 2025-08-11T10:40:46.206278+00:00

了解。「commit は **その consumer に対して**行う」ですね。  
だったら“同じ consumer への commit デリゲート”を**列挙中にだけ**有効化する形が最小で堅いです。**キューもフラッシュ関数も不要**。変更は少しだけ。

# 方針（超最小）
- `KafkaConsumerManager` の内部ループで、POCO を組み立てたときに **その consumer で commit する Action** を作る  
- その Action と `MessageMeta` を **CommitManager に一時登録**（POCO参照＝キー）  
- 呼び出し側が `ctx.Samples.Commit(poco)` を **列挙中に**呼ぶと、その Action が実行され **同じ consumer に対して commit** される  
- **非減少**は CommitManager 側で「最後に commit 済みの offset」より小さい要求を無視して担保  
- groupId を渡さない／一時 consumer を作らない

---

## 1) KafkaConsumerManager（差分：registrar 経由で Action を渡すだけ）
```csharp
// 追加（内部で使う小IF。既存コードの上部に置けばOK）
namespace Kafka.Ksql.Linq.Messaging.Consumers
{
    internal interface ICommitRegistrar
    {
        // POCO参照で meta と commit Action を登録
        void Track(object entity, MessageMeta meta, Action commitAction);
    }
}
```

```csharp
// 既存の ConsumeInternal<TKey,TValue,TPOCO> に 1引数だけ追加（registrar）
// 呼び出し元は EventSet 側で _commitManager as ICommitRegistrar を渡す（後述）

// （中略）ループ内で POCO と meta を作った直後に：
var commitAction = new Action(() =>
{
    // nextOffset を同じ consumer でコミット
    var next = new TopicPartitionOffset(meta.Topic, meta.Partition, meta.Offset + 1);
    consumer.Commit(new[] { next });
});

// これを登録
(registrar as ICommitRegistrar)?.Track(entity!, meta, commitAction);

// yield は従来どおり
yield return (entity, headers, meta);
```

> これで **“その consumer で commit する処理”が Action として外へ渡る**ので、  
> 列挙中に呼べば**同じスレッド／同じ consumer** に対して実行されます。  
> （`await foreach` の中で呼ぶ想定なので、別スレッド問題は起きません）

---

## 2) EventSet（POCOで列挙＋Commitを委譲）
```csharp
// 追加：POCOで列挙（既存の object 版は残す）
public async IAsyncEnumerable<T> ForEachPocoAsync(
    [EnumeratorCancellation] CancellationToken ct = default)
{
    await foreach (var item in GetAsyncEnumeratorWrapper(ct))
        yield return item;
}

// 追加：POCOを渡してcommit（autocommit時は Noop で無害）
public void Commit(T entity)
{
    if (entity is null) throw new ArgumentNullException(nameof(entity));
    _commitManager?.Commit(entity); // 実体は下の ManualCommitManager
}

// 既存の ConsumeAsync で、registrar を渡すだけ（1行）
protected override IAsyncEnumerable<(T Entity, Dictionary<string,string> Headers, MessageMeta Meta)>
    ConsumeAsync(KsqlContext context, CancellationToken ct)
{
    var registrar = _commitManager as Kafka.Ksql.Linq.Messaging.Consumers.ICommitRegistrar;
    return context.GetConsumerManager().ConsumeAsync<T>(registrar, ct);
}
```

---

## 3) ManualCommitManager（超小実装：参照→Action 登録＆非減少）
```csharp
using System.Collections.Concurrent;
using System.Runtime.CompilerServices;
using Kafka.Ksql.Linq.Messaging.Consumers;

internal sealed class ManualCommitManager : ICommitManager, ICommitRegistrar
{
    // POCO参照 → commitAction
    private readonly ConditionalWeakTable<object, Action> _actions = new();

    // topic-partition 毎の「最後にcommitした現在オフセット」
    private readonly ConcurrentDictionary<string, long> _committedMax = new();
    private static string Key(string topic, int partition) => $"{topic}:{partition}";

    // KafkaConsumerManager から毎レコード渡される
    public void Track(object entity, MessageMeta meta, Action commitAction)
    {
        try { _actions.Remove(entity); } catch { /* ignore */ }
        // meta.Offset は“現在”なので、非減少チェック用に辞書を更新しておくのも可
        _actions.Add(entity, () =>
        {
            // 非減少：すでに大きいオフセットをcommit済みなら無視
            var k = Key(meta.Topic, meta.Partition);
            if (_committedMax.TryGetValue(k, out var cur) && meta.Offset.Value <= cur) return;

            // 同じ consumer で commit（Action 本体は consumer に閉じている）
            commitAction();

            // “現在オフセット”を記録（Kafkaへは nextOffset を投げている）
            _committedMax.AddOrUpdate(k, meta.Offset.Value, (_, prev) => Math.Max(prev, meta.Offset.Value));
        });
    }

    // 呼び出し側：ctx.Samples.Commit(poco)
    public void Commit(object entity)
    {
        if (_actions.TryGetValue(entity, out var act))
        {
            act();                 // ← その consumer に対して commit 実行
            _actions.Remove(entity); // 二重防止
        }
        // 見つからなければ何もしない（autocommit時など）
    }
}
```

- **consumer を新たに作らない**  
- **groupId を外に出さない**  
- **キュー／フラッシュ関数なし**  
- **非減少**は `ManualCommitManager` の内部で、**最後に commit した“現在オフセット”**との比較で防止

---

## 使い方（テスト側）
```csharp
await foreach (var sample in ctx.Samples.ForEachPocoAsync(consumeCts.Token))
{
    if (sample.Id == 3)
    {
        ctx.Samples.Commit(sample); // ← その場で“同じ consumer”に対して commit
        break;
    }
}
```

必要なら、この差分をそのまま当てられるパッチ形式でも出します。  
「commit は consumer に対して行う」を守りつつ、改変はこの程度で収まります。

— 送信日時: [[REDACTED_PHONE]]:05 (JST)
### system — 2025-08-11T10:40:46.222915+00:00

_(empty)_
### assistant — 2025-08-11T10:40:46.905788+00:00

_(empty)_
### assistant — 2025-08-11T10:41:12.163773+00:00

_(empty)_
### user — 2025-08-11T10:44:25.432000+00:00

なんかへん
ConsumerManagerはcomsumerを作成する。このconsumerに対してcommitをおこなう
ManualCommitManager を作るなら、consumerに対してアクセスできないといけない
### assistant — 2025-08-11T10:44:28.721196+00:00

了解。「**commitは、そのConsumerManagerが作成した“同じconsumer”に対して行う**」前提で、最小改変のコードを提示します。  
触るのは **3か所だけ**です（小さなオーバーロード＋小IF＋薄い実装）。既存の挙動は壊しません。

---

# 1) 追加：consumer を受け取れる極小IF

```csharp
// Messaging/Consumers/IConsumerAttachable.cs （新規 or 既存namespace内に追加）
using Confluent.Kafka;

namespace Kafka.Ksql.Linq.Messaging.Consumers
{
    /// <summary>
    /// KafkaConsumerManager が生成した IConsumer を、列挙期間中だけアタッチするための極小IF。
    /// Detach は finally で必ず呼ばれる想定。
    /// </summary>
    internal interface IConsumerAttachable
    {
        void Attach(IConsumer<byte[], byte[]> consumer);
        void Detach();
    }
}
```

---

# 2) KafkaConsumerManager.cs：**オーバーロードを1つだけ追加**

既存の `ConsumeAsync<TPOCO>(CancellationToken)` はそのまま。  
手動コミットを使う呼び出しからだけ、**attachable を渡せる版**を使います。

```csharp
// ★ 追加：attachable 付きオーバーロード（既存は無変更で温存）
public async IAsyncEnumerable<(TPOCO, Dictionary<string, string>, MessageMeta)> ConsumeAsync<TPOCO>(
    Kafka.Ksql.Linq.Messaging.Consumers.IConsumerAttachable? attachable,
    [EnumeratorCancellation] CancellationToken cancellationToken = default) where TPOCO : class
{
    var model   = GetEntityModel<TPOCO>();
    var topic   = model.GetTopicName();
    var mapping = _mappingRegistry.GetMapping(typeof(TPOCO));
    var config  = BuildConsumerConfig(topic, null);

    // 既存の ConsumeInternal とほぼ同形。consumer のライフサイクル中だけ attach。
    using var consumer = CreateConsumer<object, object>(config); // 実際は TKey/TValue の generic を既存に合わせて
    attachable?.Attach(consumer);
    try
    {
        consumer.Subscribe(topic);
        while (!cancellationToken.IsCancellationRequested)
        {
            ConsumeResult<object, object>? result;
            try { result = consumer.Consume(cancellationToken); }
            catch (OperationCanceledException) { break; }
            if (result == null || result.IsPartitionEOF) continue;

            // 既存と同様に POCO/headers/meta を作成
            var entity  = (TPOCO)mapping.CombineFromAvroKeyValue(result.Message.Key, result.Message.Value!, typeof(TPOCO));
            var headers = new Dictionary<string, string>();
            if (result.Message.Headers != null)
            {
                foreach (var h in result.Message.Headers)
                    headers[h.Key] = System.Text.Encoding.UTF8.GetString(h.GetValueBytes());
            }
            var meta = new MessageMeta(
                Topic:          result.Topic,
                Partition:      result.Partition,
                Offset:         result.Offset,
                TimestampUtc:   result.Message.Timestamp.UtcDateTime,
                SchemaIdKey:    TryGetSchemaId(result.Message.Key as byte[]),
                SchemaIdValue:  TryGetSchemaId(result.Message.Value as byte[]),
                KeyIsNull:      result.Message.Key is null,
                HeaderAllowList:ExtractAllowedHeaders(result.Message.Headers, _dlq.HeaderAllowList, _dlq.HeaderValueMaxLength)
            );

            // 呼び出し側（EventSet/CommitManager）が meta を使えるように返す
            yield return (entity, headers, meta);
            await Task.CompletedTask;
        }
    }
    finally
    {
        attachable?.Detach(); // ← 必ず同じ consumer 参照を外す
    }
}
```

> ポイント  
> - **consumer を外に“直接公開”しない**。でも **ManualCommitManager が Attach された期間だけ内部参照できる**。  
> - commit は **ManualCommitManager が保持する“この consumer 参照”** に対して実行されます。  
> - 既存のメソッドは触らないので、既存呼び出しには影響ゼロ。

---

# 3) ManualCommitManager（consumer 参照を Attach/Detach で受け取り、POCO→meta で commit）

```csharp
using System.Collections.Concurrent;
using System.Runtime.CompilerServices;
using Confluent.Kafka;
using Kafka.Ksql.Linq.Messaging.Consumers;

internal sealed class ManualCommitManager :
    ICommitManager,                  // 既存IF：Commit(object) or Commit(Type, object) など、あなたの現IFに合わせて
    IConsumerAttachable              // ★ 追加：consumer を列挙期間だけ受け取る
{
    // 列挙期間中に KafkaConsumerManager から渡される consumer
    private IConsumer<byte[], byte[]>? _consumer;

    // POCO参照 → meta
    private readonly ConditionalWeakTable<object, MessageMeta> _metas = new();

    // topic-partition 毎の「確定済み “現在オフセット”」（非減少保証）
    private readonly ConcurrentDictionary<(string topic, int partition), long> _committedMax = new();

    // ==== IConsumerAttachable ====
    public void Attach(IConsumer<byte[], byte[]> consumer) => _consumer = consumer;
    public void Detach() => _consumer = null;

    // EventSet 側から（Trackは EventSet 内で t?.Track(typeof(T), entity, meta) を呼ぶ実装を別途セット）
    public void Track(object entity, MessageMeta meta)
    {
        try { _metas.Remove(entity); } catch { /* ignore */ }
        _metas.Add(entity, meta);
    }

    // ==== ICommitManager（POCOでcommit）====
    public void Commit(object entity)
    {
        if (_consumer is null) return; // autocommit時 or 非列挙時は何もしない
        if (!_metas.TryGetValue(entity, out var meta))
            throw new InvalidOperationException("The entity is not tracked for commit.");

        var key = (meta.Topic, meta.Partition.Value);
        var cur = _committedMax.TryGetValue(key, out var c) ? c : -1;

        // 非減少：既に大きい offset を commit 済みなら無視
        var off = meta.Offset.Value;
        if (off <= cur) return;

        // 同じ consumer に対して nextOffset で commit（←要求仕様）
        var next = new TopicPartitionOffset(meta.Topic, meta.Partition, off + 1);
        _consumer.Commit(new[] { next });

        // 確定済み更新（“現在オフセット”で持つ）
        _committedMax.AddOrUpdate(key, off, (_, prev) => off > prev ? off : prev);

        // ≤committed な登録情報をできるだけ解放（必要最小限でOK）
        try { _metas.Remove(entity); } catch { /* ignore */ }
        // さらに厳密にやるなら Topic/Partition/Offset の索引を別途持って一括削除も可（改変を最小にしたいので割愛）
    }
}
```

> ここでは **consumer インスタンスに直接アクセス**できるので、  
> 「**commit はその consumer に対して**」を満たします。  
> また、**非減少**は `topic-partition` ごとの `committedMax` で保証。

---

# 4) EventSet の呼び出し（小変更）
- **POCO列挙**でキャスト撤廃  
- **Commit(poco)** を委譲  
- **ConsumeAsync** 呼び出しで **attachable** を渡す（ManualCommitManager が入っている時だけ）

```csharp
// POCO列挙（既存の object 版は温存）
public async IAsyncEnumerable<T> ForEachPocoAsync(
    [EnumeratorCancellation] CancellationToken ct = default)
{
    await foreach (var item in GetAsyncEnumeratorWrapper(ct))
        yield return item;
}

// Commit（autocommit時はNoop実装で無害）
public void Commit(T entity)
{
    if (entity is null) throw new ArgumentNullException(nameof(entity));
    _commitManager?.Commit(entity);
}

// ConsumeAsync で attachable を渡す（ManualCommitManager のときだけ）
protected override IAsyncEnumerable<(T Entity, Dictionary<string, string> Headers, MessageMeta Meta)>
    ConsumeAsync(KsqlContext context, CancellationToken ct)
{
    var attachable = _commitManager as Kafka.Ksql.Linq.Messaging.Consumers.IConsumerAttachable;
    // 既存の ConsumeAsync<T>(ct) を壊さず、attachable 付きオーバーロードを使う
    return context.GetConsumerManager().ConsumeAsync<T>(attachable, ct);
}

// さらに、meta を登録したい場合（POCO→meta を保持）：
private interface ITracksOffset { void Track(object entity, MessageMeta meta); }
// …上の ConsumeAsync の while で (entity, headers, meta) を受けたら
(_commitManager as ITracksOffset)?.Track(entity, meta);
```

---

## 使い方（テスト側）
```csharp
await foreach (var sample in ctx.Samples.ForEachPocoAsync(consumeCts.Token))
{
    if (sample.Id == 3)
    {
        ctx.Samples.Commit(sample); // ← “同じ consumer”に対して commit
        break;
    }
}
```

---
### なぜこれが“変じゃない”のか
- **ConsumerManager が consumer を作成**し、その**参照を ManualCommitManager に一時添付**（Attach/Detach）  
  → 「commit はその consumer に対して」厳守  
- **groupId を露出しない**、**一時 consumer を作らない**  
- **オーバーロード1本と小IF1つ**の追加だけで成立（改変範囲は極小）  
- **POCO列挙**でキャスト撤廃、**CommitはPOCO単位**で呼べる

必要なら、あなたの現行 `KafkaConsumerManager.cs / EventSet.cs` に当て込める **差分（.patch）** を作ります。どこから貼りましょう？

— 送信日時: [[REDACTED_PHONE]]:18 (JST)
### system — 2025-08-11T10:44:28.735883+00:00

_(empty)_
### assistant — 2025-08-11T10:44:31.159292+00:00

_(empty)_
### assistant — 2025-08-11T10:44:55.011286+00:00

_(empty)_
### user — 2025-08-11T10:48:06.263000+00:00

attachable?.Attach(consumer);
これではどのpocoのものかわからない
### system — 2025-08-11T10:48:10.002341+00:00

_(empty)_
### assistant — 2025-08-11T10:48:10.909969+00:00

_(empty)_
### assistant — 2025-08-11T10:48:40.458389+00:00

なるほど、その通り。`attachable?.Attach(consumer);` だけだと「この consumer はどの POCO（どの Topic）のものか」が識別できません。  
最小改変で“POCO/Topic を明示してバインド”できるようにしましょう。

# 要点
- **ConsumerManager** 側：`Bind(typeof(TPOCO), topic, consumer)` を呼ぶ（`Unbind`で解除）。ループ中は `Register(entity, meta)` で POCO→meta を渡す  
- **ManualCommitManager** 側：`(Type, Topic)`→`consumer` を保持、`POCO参照`→`meta(topic, partition, offset)` を保持  
- **Commit(poco)**：`meta` から `topic/partition/offset` を取り、**同じ topic の consumer** を拾って `nextOffset` を commit（非減少チェックつき）

---

## 1) 追加する極小IF（2メソッド＋1）
```csharp
// Messaging/Consumers/IConsumerBinder.cs
using Confluent.Kafka;
namespace Kafka.Ksql.Linq.Messaging.Consumers
{
    internal interface IConsumerBinder
    {
        void Bind(Type pocoType, string topic, IConsumer<byte[], byte[]> consumer);
        void Unbind(Type pocoType, string topic);
        void Register(object entity, MessageMeta meta); // POCO参照→meta 紐付け
    }
}
```

## 2) KafkaConsumerManager 側（オーバーロードに “binder” を渡せるように）
既存は触らず、新オーバーロードだけ追加。**どの POCO/Topic かを bind** してから処理します。

```csharp
public async IAsyncEnumerable<(TPOCO, Dictionary<string,string>, MessageMeta)> ConsumeAsync<TPOCO>(
    Kafka.Ksql.Linq.Messaging.Consumers.IConsumerBinder? binder,
    [EnumeratorCancellation] CancellationToken cancellationToken = default) where TPOCO : class
{
    var model   = GetEntityModel<TPOCO>();
    var topic   = model.GetTopicName();
    var mapping = _mappingRegistry.GetMapping(typeof(TPOCO));
    var config  = BuildConsumerConfig(topic, null);

    using var consumer = CreateConsumer<object, object>(config); // 実際は既存のジェネリックに合わせて
    binder?.Bind(typeof(TPOCO), topic, consumer);
    try
    {
        consumer.Subscribe(topic);
        while (!cancellationToken.IsCancellationRequested)
        {
            ConsumeResult<object, object>? result;
            try { result = consumer.Consume(cancellationToken); }
            catch (OperationCanceledException) { break; }
            if (result == null || result.IsPartitionEOF) continue;

            var entity  = (TPOCO)mapping.CombineFromAvroKeyValue(result.Message.Key, result.Message.Value!, typeof(TPOCO));
            var headers = new Dictionary<string,string>();
            if (result.Message.Headers != null)
                foreach (var h in result.Message.Headers)
                    headers[h.Key] = System.Text.Encoding.UTF8.GetString(h.GetValueBytes());

            var meta = new MessageMeta(
                result.Topic, result.Partition, result.Offset,
                result.Message.Timestamp.UtcDateTime,
                TryGetSchemaId(result.Message.Key as byte[]),
                TryGetSchemaId(result.Message.Value as byte[]),
                result.Message.Key is null,
                ExtractAllowedHeaders(result.Message.Headers, _dlq.HeaderAllowList, _dlq.HeaderValueMaxLength)
            );

            binder?.Register(entity!, meta); // ← POCO参照→meta を登録
            yield return (entity, headers, meta);
            await Task.CompletedTask;
        }
    }
    finally
    {
        binder?.Unbind(typeof(TPOCO), topic); // ← どの POCO/Topic の consumer か明示して解除
    }
}
```

## 3) EventSet 側（1行差し替え＋Commitの薄い委譲）
```csharp
// POCO列挙（既存の object 版は温存）
public async IAsyncEnumerable<T> ForEachPocoAsync([EnumeratorCancellation] CancellationToken ct = default)
{
    await foreach (var item in GetAsyncEnumeratorWrapper(ct))
        yield return item;
}

// Commit（autocommit時はNoop）
public void Commit(T entity)
{
    if (entity is null) throw new ArgumentNullException(nameof(entity));
    _commitManager?.Commit(typeof(T), entity);
}

// ConsumeAsync 内で binder を渡す（ManualCommitManager が実装）
protected override IAsyncEnumerable<(T Entity, Dictionary<string,string> Headers, MessageMeta Meta)>
    ConsumeAsync(KsqlContext context, CancellationToken ct)
{
    var binder = _commitManager as Kafka.Ksql.Linq.Messaging.Consumers.IConsumerBinder;
    return context.GetConsumerManager().ConsumeAsync<T>(binder, ct);
}
```

## 4) ManualCommitManager（consumer と meta を保持し、同じ consumer に対して commit）
```csharp
using System.Collections.Concurrent;
using System.Runtime.CompilerServices;
using Confluent.Kafka;
using Kafka.Ksql.Linq.Messaging.Consumers;

internal sealed class ManualCommitManager : ICommitManager, IConsumerBinder
{
    // (PocoType, Topic) → consumer（列挙中のみ保持）
    private readonly ConcurrentDictionary<(Type, string), IConsumer<byte[], byte[]>> _consumers = new();

    // POCO参照 → meta
    private readonly ConditionalWeakTable<object, MessageMeta> _metas = new();

    // 非減少チェック用： (topic, partition) → committed “現在オフセット”
    private readonly ConcurrentDictionary<(string topic, int partition), long> _committedMax = new();

    // ==== IConsumerBinder ====
    public void Bind(Type pocoType, string topic, IConsumer<byte[], byte[]> consumer)
        => _consumers[(pocoType, topic)] = consumer;

    public void Unbind(Type pocoType, string topic)
        => _consumers.TryRemove((pocoType, topic), out _);

    public void Register(object entity, MessageMeta meta)
    {
        try { _metas.Remove(entity); } catch { /* ignore */ }
        _metas.Add(entity, meta);
    }

    // ==== ICommitManager（Type + POCOでcommit）====
    public void Commit(Type pocoType, object entity)
    {
        if (!_metas.TryGetValue(entity, out var meta))
            throw new InvalidOperationException("Entity is not tracked for commit.");

        // どの consumer に対して commit するか： (Type, Topic) で引く
        if (!_consumers.TryGetValue((pocoType, meta.Topic), out var consumer))
            throw new InvalidOperationException("No consumer bound for this POCO/Topic.");

        var key = (meta.Topic, meta.Partition.Value);
        var cur = _committedMax.TryGetValue(key, out var c) ? c : -1;
        var off = meta.Offset.Value;

        // 非減少：既に大きい offset を commit 済みならスキップ
        if (off <= cur) return;

        // 同じ consumer に対して nextOffset を commit
        var next = new TopicPartitionOffset(meta.Topic, meta.Partition, off + 1);
        consumer.Commit(new[] { next });

        // 確定済みを更新 & このPOCOの登録を解放
        _committedMax.AddOrUpdate(key, off, (_, prev) => off > prev ? off : prev);
        try { _metas.Remove(entity); } catch { /* ignore */ }
        // 必要なら、ここで “≤committed” な登録をさらに掃除する索引を追加可能（最小改変のため割愛）
    }
}
```

---

これで：

- **どの POCO（どの Topic）か**は `Bind(typeof(Poco), topic, consumer)` で**明示**  
- `ManualCommitManager` は **同じ consumer に対して** commit を実行  
- **groupId を外に出さない**、**一時 consumer を作らない**  
- 変更は **小さなIF＋KafkaConsumerManagerの新オーバーロード＋EventSetの1行＋ManualCommitManager** だけ

必要なら、このまま貼れる diff 形式でもお出しします。  

— 送信日時: [[REDACTED_PHONE]]:48 (JST)
### assistant — 2025-08-11T10:48:40.876239+00:00

_(empty)_
### user — 2025-08-11T10:54:59.614000+00:00

void Bind(Type pocoType, string topic, IConsumer<byte[], byte[]> consumer);
型になってないのでエラーになる
   using var consumer = CreateConsumer<object, object>(config); // 実際は既存のジェネリックに合わせて
    binder?.Bind(typeof(TPOCO), topic, consumer);
常にやらない autocommit以外でこれをおこなう
  binder?.Register(entity!, meta); // ← POCO参照→meta を登録
これもautocommit以外でこれをおこなう
それか、その外側からnullを渡す制御をするか
### assistant — 2025-08-11T10:55:03.756168+00:00

了解。ポイントは3つ：

1) `Bind` の引数に **ジェネリック IConsumer\<,> を直接置かない**（型が合わずエラー）  
2) **autocommit では一切バインド/登録しない**（= binder に null を渡す）  
3) `Register` も **binder != null** のときだけ呼ぶ

そこで、**非ジェネリックのコミット用アダプタ**を挟みます。最小差分で動きます。

---

# 追加する極小IF

```csharp
// Messaging/Consumers/IConsumerCommitter.cs
using Confluent.Kafka;
using System.Collections.Generic;

namespace Kafka.Ksql.Linq.Messaging.Consumers
{
    // 非ジェネリック：Commit だけ切り出した薄い橋渡し
    internal interface IConsumerCommitter
    {
        void Commit(IReadOnlyList<TopicPartitionOffset> offsets);
    }
}
```

```csharp
// Messaging/Consumers/IConsumerBinder.cs
using System;
using Confluent.Kafka;

namespace Kafka.Ksql.Linq.Messaging.Consumers
{
    internal interface IConsumerBinder
    {
        // どの POCO/Topic の consumer かを明示して紐付け
        void Bind(Type pocoType, string topic, IConsumerCommitter committer);
        void Unbind(Type pocoType, string topic);

        // POCO参照 → meta 紐付け（poco単位の管理）
        void Register(object entity, MessageMeta meta);
    }
}
```

---

# KafkaConsumerManager 側（オーバーロードとアダプタ）

```csharp
// アダプタ：IConsumer<TKey,TValue> を IConsumerCommitter に変換
internal sealed class ConsumerCommitter<TKey, TValue> : Kafka.Ksql.Linq.Messaging.Consumers.IConsumerCommitter
{
    private readonly Confluent.Kafka.IConsumer<TKey, TValue> _consumer;
    public ConsumerCommitter(Confluent.Kafka.IConsumer<TKey, TValue> consumer) => _consumer = consumer;
    public void Commit(IReadOnlyList<Confluent.Kafka.TopicPartitionOffset> offsets) => _consumer.Commit(offsets);
}
```

```csharp
// 既存は残す。手動コミット用に binder 付き版を追加
public async IAsyncEnumerable<(TPOCO, Dictionary<string, string>, MessageMeta)> ConsumeAsync<TPOCO>(
    Kafka.Ksql.Linq.Messaging.Consumers.IConsumerBinder? binder,
    [EnumeratorCancellation] CancellationToken cancellationToken = default) where TPOCO : class
{
    var model   = GetEntityModel<TPOCO>();
    var topic   = model.GetTopicName();
    var mapping = _mappingRegistry.GetMapping(typeof(TPOCO));
    var config  = BuildConsumerConfig(topic, null);

    // 既存の内部ジェネリックに沿って consumer を作成
    var method = typeof(KafkaConsumerManager)
        .GetMethod(nameof(ConsumeInternal), System.Reflection.BindingFlags.NonPublic | System.Reflection.BindingFlags.Instance)!
        .MakeGenericMethod(mapping.AvroKeyType!, mapping.AvroValueType!, typeof(TPOCO));

    // ↓↓↓ ランタイムに “binderあり版” を呼ぶための小ラッパ
    var enumerable = ConsumeInternalWithBinderInvoker(method, topic, config, mapping, binder, cancellationToken);
    await foreach (var item in enumerable.WithCancellation(cancellationToken))
        yield return item;
}

// 非公開：実 consumer を作ってバインド/登録（binder == null なら一切やらない）
private async IAsyncEnumerable<(TPOCO, Dictionary<string, string>, MessageMeta)> ConsumeInternalWithBinderInvoker<TPOCO>(
    System.Reflection.MethodInfo consumeInternalMethod,
    string topic,
    Confluent.Kafka.ConsumerConfig config,
    KeyValueTypeMapping mapping,
    Kafka.Ksql.Linq.Messaging.Consumers.IConsumerBinder? binder,
    [EnumeratorCancellation] CancellationToken ct) where TPOCO : class
{
    // CreateConsumer<TKey,TValue> を直接呼ぶために型引数を展開
    var genericArgs = consumeInternalMethod.GetGenericArguments(); // [TKey, TValue, TPOCO]
    var keyType   = genericArgs[0];
    var valType   = genericArgs[1];

    // CreateConsumer<TKey,TValue>(config) を反射で呼ぶ
    var create = typeof(KafkaConsumerManager)
        .GetMethod("CreateConsumer", System.Reflection.BindingFlags.NonPublic | System.Reflection.BindingFlags.Instance)!
        .MakeGenericMethod(keyType, valType);

    using var consumer = (dynamic)create.Invoke(this, new object?[] { config })!;
    Kafka.Ksql.Linq.Messaging.Consumers.IConsumerCommitter? committer = null;

    // ★ autocommit 以外（= manual）のときだけバインド。外側（EventSet）で null を渡す制御でもOK
    if (binder is not null)
    {
        // ConsumerCommitter<TKey,TValue> を動的生成
        var adapterType = typeof(ConsumerCommitter<,>).MakeGenericType(keyType, valType);
        committer = (Kafka.Ksql.Linq.Messaging.Consumers.IConsumerCommitter)Activator.CreateInstance(adapterType, consumer)!;
        binder.Bind(typeof(TPOCO), topic, committer);
    }

    try
    {
        consumer.Subscribe(topic);
        while (!ct.IsCancellationRequested)
        {
            Confluent.Kafka.ConsumeResult<dynamic, dynamic>? result;
            try { result = consumer.Consume(ct); }
            catch (OperationCanceledException) { break; }
            if (result == null || result.IsPartitionEOF) continue;

            // 既存どおり POCO/headers/meta を作成
            var entity  = (TPOCO)mapping.CombineFromAvroKeyValue(result.Message.Key, result.Message.Value!, typeof(TPOCO));
            var headers = new Dictionary<string, string>();
            if (result.Message.Headers != null)
                foreach (var h in result.Message.Headers)
                    headers[h.Key] = System.Text.Encoding.UTF8.GetString(h.GetValueBytes());

            var meta = new MessageMeta(
                result.Topic, result.Partition, result.Offset,
                result.Message.Timestamp.UtcDateTime,
                TryGetSchemaId(result.Message.Key as byte[]),
                TryGetSchemaId(result.Message.Value as byte[]),
                result.Message.Key is null,
                ExtractAllowedHeaders(result.Message.Headers, _dlq.HeaderAllowList, _dlq.HeaderValueMaxLength)
            );

            // ★ manual のときだけ登録（binderがnullなら何もしない）
            binder?.Register(entity!, meta);

            yield return (entity, headers, meta);
            await Task.CompletedTask;
        }
    }
    finally
    {
        binder?.Unbind(typeof(TPOCO), topic);
    }
}
```

> 重要: **autocommit では binder=null を渡す**（外側で制御）。  
> すると `Bind` / `Register` は一切呼ばれません。ご要望どおりです。

---

# EventSet 側（binder を渡す or 渡さない）

```csharp
// POCO列挙（既存 object 版は温存）
public async IAsyncEnumerable<T> ForEachPocoAsync([EnumeratorCancellation] CancellationToken ct = default)
{
    await foreach (var item in GetAsyncEnumeratorWrapper(ct))
        yield return item;
}

// Commit（autocommit時はNoopのまま）
public void Commit(T entity)
{
    if (entity is null) throw new ArgumentNullException(nameof(entity));
    _commitManager?.Commit(typeof(T), entity);
}

// ConsumeAsync で binder を渡す/渡さない を制御
protected override IAsyncEnumerable<(T Entity, Dictionary<string,string> Headers, MessageMeta Meta)>
    ConsumeAsync(KsqlContext context, CancellationToken ct)
{
    var binder = _entityModel.UseManualCommit
        ? _commitManager as Kafka.Ksql.Linq.Messaging.Consumers.IConsumerBinder
        : null; // ★ autocommit のときは null を渡す

    return context.GetConsumerManager().ConsumeAsync<T>(binder, ct);
}
```

---

# ManualCommitManager（binder 実装：consumer へ直接 commit）

```csharp
using System.Collections.Concurrent;
using System.Runtime.CompilerServices;
using Confluent.Kafka;
using Kafka.Ksql.Linq.Messaging.Consumers;

internal sealed class ManualCommitManager : ICommitManager, IConsumerBinder
{
    // (PocoType, Topic) → committer（列挙中のみ有効）
    private readonly ConcurrentDictionary<(Type, string), IConsumerCommitter> _committers = new();

    // POCO参照 → meta（参照同一性）
    private readonly ConditionalWeakTable<object, MessageMeta> _metas = new();

    // 非減少： (topic, partition) → committed “現在オフセット”
    private readonly ConcurrentDictionary<(string topic, int partition), long> _committedMax = new();

    // ==== IConsumerBinder ====
    public void Bind(Type pocoType, string topic, IConsumerCommitter committer)
        => _committers[(pocoType, topic)] = committer;

    public void Unbind(Type pocoType, string topic)
        => _committers.TryRemove((pocoType, topic), out _);

    public void Register(object entity, MessageMeta meta)
    {
        try { _metas.Remove(entity); } catch { /* ignore */ }
        _metas.Add(entity, meta);
    }

    // ==== ICommitManager（Type+POCO指定でcommit）====
    public void Commit(Type pocoType, object entity)
    {
        if (!_metas.TryGetValue(entity, out var meta))
            throw new InvalidOperationException("Entity is not tracked for commit.");

        if (!_committers.TryGetValue((pocoType, meta.Topic), out var committer))
            throw new InvalidOperationException("No consumer bound for this POCO/Topic.");

        var key = (meta.Topic, meta.Partition.Value);
        var cur = _committedMax.TryGetValue(key, out var c) ? c : -1;
        var off = meta.Offset.Value;

        // 非減少：既に大きい offset をcommit済みなら無視
        if (off <= cur) return;

        // nextOffset で commit（コミッターは“同じconsumer”に紐付いている）
        committer.Commit(new[] { new TopicPartitionOffset(meta.Topic, meta.Partition, off + 1) });

        // 確定済み更新 & このPOCOの登録解除（必要最小限の掃除）
        _committedMax.AddOrUpdate(key, off, (_, prev) => off > prev ? off : prev);
        try { _metas.Remove(entity); } catch { /* ignore */ }
        // さらに厳密に掃除したければ Topic/Partition/Offset 索引を後付け
    }
}
```

---

## これで解決できること
- `Bind(Type, string, IConsumerCommitter)` は **非ジェネリック**なので**型エラーなし**  
- **autocommit では binder=null** を渡すので、**Bind/Register を一切しない**  
- **manual のときだけ** Bind/Register 実行  
- **commit は同じ consumer に対して**行われる（`IConsumerCommitter` 経由）  
- **poco単位**の commit、**topic/partition毎の非減少**も保持

必要ならこのままパッチ化します。  

— 送信日時: [[REDACTED_PHONE]]:33 (JST)
### system — 2025-08-11T10:55:04.149072+00:00

_(empty)_
### assistant — 2025-08-11T10:55:04.349001+00:00

_(empty)_
### assistant — 2025-08-11T10:55:30.168335+00:00

_(empty)_
### user — 2025-08-11T11:00:29.378000+00:00

binder はConsumerManager側で解決できるので外側で判断しない
### assistant — 2025-08-11T11:00:32.801062+00:00

了解。「binder を渡す/渡さない」は**外側（EventSetなど）で判断しない**。  
**ConsumerManager 内部で autocommit かどうかを見て勝手に解決**し、必要なときだけ Bind/Register します。既存の `ConsumeAsync<TPOCO>(CancellationToken)` シグネチャはそのままです。

以下、**改変最小**コードです（追加IF＋`KafkaConsumerManager`の数行追記だけ）。

---
### 1) 追加する極小IF（非ジェネリック、型エラー回避）

```csharp
// Messaging/Consumers/IConsumerCommitter.cs
using Confluent.Kafka;
using System.Collections.Generic;

namespace Kafka.Ksql.Linq.Messaging.Consumers
{
    // “同じ consumer で commit する”ための薄いアダプタ
    internal interface IConsumerCommitter
    {
        void Commit(IReadOnlyList<TopicPartitionOffset> offsets);
    }
}
```

```csharp
// Messaging/Consumers/IConsumerBinder.cs
using System;
using Kafka.Ksql.Linq.Messaging.Consumers;

namespace Kafka.Ksql.Linq.Messaging.Consumers
{
    // ConsumerManager が「どの POCO/Topic の consumer か」を内側でバインドし、
    // POCO参照→meta を登録できるようにするためのIF
    internal interface IConsumerBinder
    {
        void Bind(Type pocoType, string topic, IConsumerCommitter committer);
        void Unbind(Type pocoType, string topic);
        void Register(object entity, MessageMeta meta);
    }
}
```

> Binder の実体（例：ManualCommitManager）がこの IF を実装します。  
> ※ここで GroupId は出しません・渡しません。

---
### 2) `KafkaConsumerManager.cs` の最小追記

- 既存の `ConsumeAsync<TPOCO>(CancellationToken)` **をそのまま修正**（オーバーロード増やしません）
- **autocommit では何もしない**／**manual のときだけ** Bind/Register を行う
- Binder の実体は **ConsumerManager 内部で解決**（DI など。例では `_binderResolver` から取得）

```csharp
// (1) 追加: Consumer を IConsumerCommitter に変換する小アダプタ（private nestedでもOK）
private sealed class ConsumerCommitter<TKey, TValue> : Kafka.Ksql.Linq.Messaging.Consumers.IConsumerCommitter
{
    private readonly Confluent.Kafka.IConsumer<TKey, TValue> _consumer;
    public ConsumerCommitter(Confluent.Kafka.IConsumer<TKey, TValue> consumer) => _consumer = consumer;
    public void Commit(IReadOnlyList<Confluent.Kafka.TopicPartitionOffset> offsets) => _consumer.Commit(offsets);
}
```

```csharp
// (2) 追加: Binder を内部で解決するための任意依存（DIでnull可）
private readonly Kafka.Ksql.Linq.Messaging.Consumers.IConsumerBinder? _binder; // ← コンストラクタで注入（nullでも可）
```

```csharp
// (3) 既存の ConsumeAsync<TPOCO>(CancellationToken) を“数行だけ”拡張
public async IAsyncEnumerable<(TPOCO, Dictionary<string, string>, MessageMeta)> ConsumeAsync<TPOCO>(
    [EnumeratorCancellation] CancellationToken cancellationToken = default) where TPOCO : class
{
    var model = GetEntityModel<TPOCO>();
    var topic = model.GetTopicName();
    var mapping = _mappingRegistry.GetMapping(typeof(TPOCO));
    var config = BuildConsumerConfig(topic, null);

    // 既存どおり TKey/TValue で consumer 作成
    var method = typeof(KafkaConsumerManager)
        .GetMethod(nameof(ConsumeInternal), BindingFlags.NonPublic | BindingFlags.Instance)!
        .MakeGenericMethod(mapping.AvroKeyType!, mapping.AvroValueType!, typeof(TPOCO));

    using var consumer = (dynamic)typeof(KafkaConsumerManager)
        .GetMethod("CreateConsumer", BindingFlags.NonPublic | BindingFlags.Instance)!
        .MakeGenericMethod(mapping.AvroKeyType!, mapping.AvroValueType!)
        .Invoke(this, new object?[] { config })!;

    // ★ ここが肝：autocommit でない時だけ、内側で binder を有効化
    var manual = model.UseManualCommit; // ← Fluent/API の設定
    Kafka.Ksql.Linq.Messaging.Consumers.IConsumerCommitter? committer = null;
    if (manual && _binder is not null)
    {
        var adapterType = typeof(ConsumerCommitter<,>).MakeGenericType(mapping.AvroKeyType!, mapping.AvroValueType!);
        committer = (Kafka.Ksql.Linq.Messaging.Consumers.IConsumerCommitter)
            Activator.CreateInstance(adapterType, consumer)!;
        _binder.Bind(typeof(TPOCO), topic, committer);
    }

    try
    {
        consumer.Subscribe(topic);

        while (!cancellationToken.IsCancellationRequested)
        {
            Confluent.Kafka.ConsumeResult<dynamic, dynamic>? result;
            try { result = consumer.Consume(cancellationToken); }
            catch (OperationCanceledException) { break; }
            if (result == null || result.IsPartitionEOF) continue;

            // 既存どおり POCO/headers/meta を作成
            var entity = (TPOCO)mapping.CombineFromAvroKeyValue(result.Message.Key, result.Message.Value!, typeof(TPOCO));
            var headers = new Dictionary<string, string>();
            if (result.Message.Headers != null)
                foreach (var h in result.Message.Headers)
                    headers[h.Key] = System.Text.Encoding.UTF8.GetString(h.GetValueBytes());

            var meta = new MessageMeta(
                Topic: result.Topic,
                Partition: result.Partition,
                Offset: result.Offset,
                TimestampUtc: result.Message.Timestamp.UtcDateTime,
                SchemaIdKey: TryGetSchemaId(result.Message.Key as byte[]),
                SchemaIdValue: TryGetSchemaId(result.Message.Value as byte[]),
                KeyIsNull: result.Message.Key is null,
                HeaderAllowList: ExtractAllowedHeaders(result.Message.Headers, _dlq.HeaderAllowList, _dlq.HeaderValueMaxLength)
            );

            // ★ manual のときだけ登録（外側での判定は不要。ConsumerManager内で完結）
            if (manual && _binder is not null)
                _binder.Register(entity!, meta);

            yield return (entity, headers, meta);
            await Task.CompletedTask;
        }
    }
    finally
    {
        if (manual && _binder is not null)
            _binder.Unbind(typeof(TPOCO), topic);
    }
}
```

> これで **外側は一切判断不要**。`ConsumerManager` が `model.UseManualCommit` を見て勝手にやります。  
> 既存の API/署名はそのまま。autocommit のときは Bind/Register は一切呼ばれません。

---
### 3) ManualCommitManager 側（IConsumerBinder 実装のごく薄い例）

```csharp
using System.Collections.Concurrent;
using System.Runtime.CompilerServices;
using Confluent.Kafka;
using Kafka.Ksql.Linq.Messaging.Consumers;

internal sealed class ManualCommitManager : ICommitManager, IConsumerBinder
{
    // (Type, Topic) → “同じ consumer に commit する”ための committer
    private readonly ConcurrentDictionary<(Type, string), IConsumerCommitter> _committers = new();

    // POCO参照 → meta（参照同一性）
    private readonly ConditionalWeakTable<object, MessageMeta> _metas = new();

    // 非減少： (topic, partition) → commit済み“現在オフセット”
    private readonly ConcurrentDictionary<(string topic, int partition), long> _committedMax = new();

    // IConsumerBinder
    public void Bind(Type pocoType, string topic, IConsumerCommitter committer)
        => _committers[(pocoType, topic)] = committer;
    public void Unbind(Type pocoType, string topic)
        => _committers.TryRemove((pocoType, topic), out _);
    public void Register(object entity, MessageMeta meta)
    {
        try { _metas.Remove(entity); } catch { /* ignore */ }
        _metas.Add(entity, meta);
    }

    // 既存IFに合わせて：Type + POCO or POCOのみ、どちらでも
    public void Commit(Type pocoType, object entity)
    {
        if (!_metas.TryGetValue(entity, out var meta))
            throw new InvalidOperationException("Entity is not tracked for commit.");

        if (!_committers.TryGetValue((pocoType, meta.Topic), out var committer))
            throw new InvalidOperationException("No consumer bound for this POCO/Topic.");

        var key = (meta.Topic, meta.Partition.Value);
        var cur = _committedMax.TryGetValue(key, out var c) ? c : -1;
        var off = meta.Offset.Value;

        // 非減少：戻さない
        if (off <= cur) return;

        // 同じ consumer に nextOffset で commit
        committer.Commit(new[] { new TopicPartitionOffset(meta.Topic, meta.Partition, off + 1) });

        _committedMax.AddOrUpdate(key, off, (_, prev) => off > prev ? off : prev);

        // 必要最小限の解放（厳密掃除が必要なら索引追加も可）
        try { _metas.Remove(entity); } catch { /* ignore */ }
    }
}
```

---
### 4) EventSet 側（外側は一切判断しない）

EventSet はいつもどおりでOK。  
- 既存 `ForEachAsync(object)` は温存  
- **POCOで列挙したい場合だけ**下の薄い追加を使う  
- Commit は `_commitManager.Commit(typeof(T), poco)` に委譲

```csharp
public async IAsyncEnumerable<T> ForEachPocoAsync(
    [EnumeratorCancellation] CancellationToken ct = default)
{
    await foreach (var item in GetAsyncEnumeratorWrapper(ct))
        yield return item;
}

public void Commit(T entity)
{
    if (entity is null) throw new ArgumentNullException(nameof(entity));
    _commitManager?.Commit(typeof(T), entity);
}
```

> **autocommit でも manual でも**、外側のコードは一定。  
> manual のときだけ ConsumerManager 内部が自動で Bind/Register します。

---

これで：

- binder は **ConsumerManager 内部でだけ**解決＆発火（外側は関知しない）
- **autocommit のときは一切バインド/登録しない**
- **commit は“同じ consumer”に対して**行われ、**非減少**も保証
- 既存の公開APIはほぼ据え置き、**改変範囲は最小**

必要なら、この変更をそのまま当てられる `.patch` 形式にしてお渡しします。  

— 送信日時: [[REDACTED_PHONE]]:43 (JST)
### system — 2025-08-11T11:00:33.528844+00:00

_(empty)_
### assistant — 2025-08-11T11:00:33.545642+00:00

_(empty)_
### assistant — 2025-08-11T11:01:02.032679+00:00

_(empty)_
### user — 2025-08-11T11:02:47.034000+00:00

public async IAsyncEnumerable<(TPOCO, Dictionary<string, string>, MessageMeta)> ConsumeAsync<TPOCO>(
        [EnumeratorCancellation] CancellationToken cancellationToken = default) where TPOCO : class
    {
        var model = GetEntityModel<TPOCO>();
        var topic = model.GetTopicName();
        var mapping = _mappingRegistry.GetMapping(typeof(TPOCO));
        var config = BuildConsumerConfig(topic, null);
このconfigに指定されてるということはFluejhn
### system — 2025-08-11T11:02:50.680014+00:00

_(empty)_
### assistant — 2025-08-11T11:02:50.757277+00:00

なるほど、「`config = BuildConsumerConfig(topic, null)` に入ってくる設定って、つまり（appsettings.json と）Fluent API で指定したものが反映されてるってことで合ってる？」という確認ですよね。

結論：**その理解でOK**です。ふつうは下の順序で合成されます（実装にもよりますが定石）：

1) 共通設定（BootstrapServers など）  
2) topic セクションの個別設定（`Topics[topic].Consumer.*`）  
3) Fluent API での上書き（GroupId / AutoOffsetReset / UseManualCommit など）

だから **GroupId も EnableAutoCommit も、Fluent API の指定があればここ（`config`）に入ってきます。**  
この前提があれば、外から groupId を回したり、外側で manual/auto を判定したりする必要はありません。

実装面のおすすめはこれだけです（改変最小）：

```csharp
var model   = GetEntityModel<TPOCO>();
var topic   = model.GetTopicName();
var mapping = _mappingRegistry.GetMapping(typeof(TPOCO));
var config  = BuildConsumerConfig(topic, null);

// manual かは Fluent API のフラグで判定（外側で判断しない）
var manual = model.UseManualCommit;

// safety: manual なら EnableAutoCommit は false を強制 or 検証
if (manual && config.EnableAutoCommit == true)
    config.EnableAutoCommit = false; // あるいは throw で逸脱検知

using var consumer = CreateConsumer<TKey, TValue>(config);
if (manual && _binder is not null)
{
    // “同じ consumer に対して commit する”ための橋渡しだけ内側で用意
    var committer = new ConsumerCommitter<TKey, TValue>(consumer); // 非ジェネリックIFにラップ
    _binder.Bind(typeof(TPOCO), topic, committer);
}

consumer.Subscribe(topic);
while (!cancellationToken.IsCancellationRequested)
{
    var result = consumer.Consume(cancellationToken);
    if (result == null || result.IsPartitionEOF) continue;

    var entity = (TPOCO)mapping.CombineFromAvroKeyValue(result.Message.Key, result.Message.Value!, typeof(TPOCO));
    var meta   = new MessageMeta(/* topic/partition/offset など result から組み立て */);

    // manual のときだけ POCO→meta を登録（autocommit では何もしない）
    if (manual && _binder is not null) _binder.Register(entity!, meta);

    yield return (entity, headers, meta);
}

if (manual && _binder is not null)
    _binder.Unbind(typeof(TPOCO), topic);
```

要点はこの2つだけ：
- **manual/auto の判定は ConsumerManager 内で `model.UseManualCommit` を見る**（外側で判断させない）
- **commit は “同じ consumer” に対して行う**ため、manual のときだけ **内部で committer を Bind/Register** する

これで「設定は appsettings.json＋Fluent API から `config` に反映」「groupId を外へ出さない」「外側で binder を渡す/渡さないの分岐もしない」という思想に揃います。

— 送信日時: [[REDACTED_PHONE]]:55 (JST)
### assistant — 2025-08-11T11:02:53.123204+00:00

_(empty)_
### assistant — 2025-08-11T11:03:08.593825+00:00

_(empty)_
### user — 2025-08-11T11:07:54.005000+00:00

これでいけそうなのでcodexに依頼文をお願いします。また　   // 必要最小限の解放（厳密掃除が必要なら索引追加も可）　は厳密掃除してください
### assistant — 2025-08-11T11:07:57.856250+00:00

了解です。Codex に渡す「依頼文」を用意しました。これで実装＆厳密掃除まで一気に反映できます。

---

# Codex依頼文：Manual Commit（同一consumerでのcommit）実装 + 厳密掃除

## 目的
- `ConsumerManager` が **appsettings.json + Fluent API** から構成した **同じ consumer** に対して commit を行えるようにする。
- autocommit ⇄ manual commit の切替は **ConsumerManager 内部で判定（`model.UseManualCommit`）**。外側に分岐を持ち込まない。
- 呼び出し側は **POCO列挙**（キャスト不要）＆ **`ctx.Samples.Commit(poco)`** でオフセット commit。
- **非減少（offset を戻さない）** を保証し、**commit 確定後は ≤committed のエントリを厳密に解放**する。

## 変更範囲（最小）
1) `KafkaConsumerManager.cs`：**数行の追記のみ**  
   - manual 時のみ内部で “同一consumer commit” のバインドと POCO→meta 登録を行う。
2) **新規2IF**（非ジェネリック、小物）：  
   - `IConsumerCommitter`（commit だけ切り出す非ジェネリック・アダプタ）  
   - `IConsumerBinder`（`Bind/Unbind(Register)` で consumer と POCO→meta を結びつける）
3) `ManualCommitManager.cs`（新規1クラス）  
   - `ICommitManager` + `IConsumerBinder` を実装。  
   - **POCO参照→meta** と **(topic,partition)→committedMax** を保持。  
   - commit 時に **同一consumer**へ `nextOffset` を commit、**厳密掃除**を実施。
4) `EventSet.cs`（最小追記）  
   - `ForEachPocoAsync()` を追加（POCO列挙）。  
   - `Commit(T entity)` を追加（内部で `_commitManager.Commit(typeof(T), entity)` へ委譲）。  
   - 既存の `ForEachAsync(object)` は温存。

> 既存の `ConsumeAsync<TPOCO>(CancellationToken)` の **公開シグネチャは変えない**こと。

---

## 実装詳細
### A) 追加IF

```csharp
// Messaging/Consumers/IConsumerCommitter.cs
using Confluent.Kafka;
using System.Collections.Generic;

namespace Kafka.Ksql.Linq.Messaging.Consumers
{
    internal interface IConsumerCommitter
    {
        void Commit(IReadOnlyList<TopicPartitionOffset> offsets);
    }
}
```

```csharp
// Messaging/Consumers/IConsumerBinder.cs
using System;

namespace Kafka.Ksql.Linq.Messaging.Consumers
{
    internal interface IConsumerBinder
    {
        void Bind(Type pocoType, string topic, IConsumerCommitter committer);
        void Unbind(Type pocoType, string topic);
        void Register(object entity, MessageMeta meta);
    }
}
```
### B) KafkaConsumerManager.cs（内部だけで manual/auto を判断して実施）
- **private nested アダプタ**を追加：`ConsumerCommitter<TKey,TValue> : IConsumerCommitter`  
- フィールドに `IConsumerBinder? _binder`（DIで既存 `CommitManager` を注入、無ければ `null` でOK）。
- 既存 `ConsumeAsync<TPOCO>(CancellationToken)` の **内部**に下記を数行追加：

```csharp
var manual = model.UseManualCommit;           // Fluent/API のフラグ
// safety: manualなら EnableAutoCommit=false を強制/検証してもよい

using var consumer = CreateConsumer<TKey, TValue>(config);

// ★ manual のときだけ、同一consumerコミット用
### system — 2025-08-11T11:07:58.559863+00:00

_(empty)_
### assistant — 2025-08-11T11:07:59.918867+00:00

_(empty)_
### assistant — 2025-08-11T11:08:07.324571+00:00

_(empty)_
### user — 2025-08-11T11:08:52.798000+00:00

駄目です　ForEachPocoAsync　なぜIFを増やす？
### system — 2025-08-11T11:08:55.420172+00:00

_(empty)_
### assistant — 2025-08-11T11:08:55.466117+00:00

なるほど、司令が言いたいのは  

- わざわざ `ForEachPocoAsync` みたいな新しいIFを増やす方向じゃなく、  
- 既存の `ForEachAsync` で **最初からPOCO型として返せる** ようにしてしまえばいい、  
- つまり「object返し＋キャスト」構造をやめたい  

ということですよね。  

そうなると設計方針はこう整理できます。

---

## 方針（IF追加なし）

1. **`EventSet.ForEachAsync` をジェネリック化**  
   - `ForEachAsync<TPOCO>(CancellationToken)` に変更し、返り値は `IAsyncEnumerable<TPOCO>`。  
   - manual commit の場合は内部で meta を登録してから POCO を返す。  
   - autocommit の場合は単純に POCO を返す。  
2. **manual commit の commit 呼び出しは POCOベース**  
   - 例えば `ctx.Samples.Commit(poco)` で内部の meta 辞書を見て offset commit。  
3. **meta 管理は ConsumerManager 内部で統一**  
   - ConsumerManager が manual のときだけ POCO→meta 登録処理を差し込む。  
   - CommitManager は POCO→meta→consumer.commit を実行し、古い offset 情報を厳密に削除。  

---

## メリット
- 呼び出し側のコードは `await foreach (var msg in ctx.Samples.ForEachAsync(...))` でOK（キャスト不要）。
- autocommit⇔manual の切替でも **呼び出し側コード変更なし**。
- IFを増やさず既存構造を維持できる。

---

もしこの方針で行くなら、Codex依頼文も短く済みますし、司令の違和感（IF追加や二重ループ）も消えます。  

この形で Codex 用の最小改修依頼文を作りますか？  
それとも今すぐコード案までまとめますか？
### user — 2025-08-11T11:09:23.643000+00:00

そうです
### system — 2025-08-11T11:09:29.067345+00:00

_(empty)_
### assistant — 2025-08-11T11:09:29.184921+00:00

了解。以下をそのまま Codex に渡してください。**IFは増やさず、`ForEachAsync` を POCO 返しに統一**、commit は **同一 consumer** に対して実行、**厳密掃除**まで含めた依頼文です。

---

# Codex依頼文：`ForEachAsync` を POCO 返しへ統一 + manual commit（同一consumer）+ 厳密掃除

## 背景とゴール
- 既存の `EventSet<T>.ForEachAsync` は `IAsyncEnumerable<object>` を返し、manual 時はキャストが必要。  
- 要件：**新しい IF は増やさない**（`ForEachPocoAsync` など追加しない）。  
- `ForEachAsync` を **POCO 返し**（`IAsyncEnumerable<T>`）に変更し、autocommit⇄manual 切替でも呼び出し側のコードを変えない。  
- manual commit は **KafkaConsumerManager が作成した“同じ consumer”に対して**行う。  
- **groupId を外に出さない**（paramで回さない）。  
- **厳密掃除**：commit 確定時に **同一 (topic, partition) の ≤ committed offset** に紐づく POCO 参照を**確実に解放**。

## 変更ポリシー（最小）
- 既存公開IFは極力維持。ただし `EventSet<T>.ForEachAsync` の戻り型は **POCO 返しへ変更**（破壊的だが必須）。  
- **新しい公開メソッドは作らない**（`ForEachPocoAsync` など追加しない）。  
- manual/auto の判定は **ConsumerManager 内部**で `model.UseManualCommit` を見る（外側で分岐しない）。  
- commit は **同じ consumer** に対して行う。**一時 consumer は作らない**。  
- `groupId` は **外へ露出しない**。  
- 掃除は **<= committed offset** を**厳密**に対象とする。

---

## 実装タスク
### 1) EventSet.cs
- `ForEachAsync` を **POCO返し**に変更（**IF追加なし／既存の object 版は置き換え**）:
  ```csharp
  // 変更前
  public virtual async IAsyncEnumerable<object> ForEachAsync(
      [EnumeratorCancellation] CancellationToken cancellationToken = default)

  // 変更後
  public virtual async IAsyncEnumerable<T> ForEachAsync(
      [EnumeratorCancellation] CancellationToken cancellationToken = default)
  {
      await foreach (var item in GetAsyncEnumeratorWrapper(cancellationToken))
          yield return item;
  }
  ```
- `Commit(T entity)` を公開し、内部の `_commitManager` に委譲（autocommit時は Noop 実装が no-op）:
  ```csharp
  public void Commit(T entity)
  {
      if (entity is null) throw new ArgumentNullException(nameof(entity));
      _commitManager?.Commit(typeof(T), entity);
  }
  ```
- `ConsumeAsync` の中身は既存どおり **KafkaConsumerManager から `(T, Headers, Meta)` を受け取る**。  
  meta 登録・バインド判定は **KafkaConsumerManager 側で内部処理**するので、EventSet 側での分岐は不要。
### 2) KafkaConsumerManager.cs
- **公開シグネチャは変更しない**：`ConsumeAsync<TPOCO>(CancellationToken)` のまま。  
- 内部で manual/auto を判定：`var manual = model.UseManualCommit;`
- **非ジェネリックの薄いアダプタ IF を追加**（型崩れを防ぐため）：
  ```csharp
  // Messaging/Consumers/IConsumerCommitter.cs
  internal interface IConsumerCommitter
  {
      void Commit(IReadOnlyList<TopicPartitionOffset> offsets);
  }

  // Messaging/Consumers/IConsumerBinder.cs
  internal interface IConsumerBinder
  {
      void Bind(Type pocoType, string topic, IConsumerCommitter committer);
      void Unbind(Type pocoType, string topic);
      void Register(object entity, MessageMeta meta);
  }
  ```
- `KafkaConsumerManager` に **private nested adapter** を追加：
  ```csharp
  private sealed class ConsumerCommitter<TKey, TValue> : IConsumerCommitter
  {
      private readonly IConsumer<TKey, TValue> _consumer;
      public ConsumerCommitter(IConsumer<TKey, TValue> c) => _consumer = c;
      public void Commit(IReadOnlyList<TopicPartitionOffset> offsets) => _consumer.Commit(offsets);
  }
  ```
- `KafkaConsumerManager` に `IConsumerBinder? _binder` を **DI 注入**（null可）。  
- `ConsumeAsync<TPOCO>` 内で consumer を作成後、  
  - **manual のときだけ**: `var committer = new ConsumerCommitter<TKey,TValue>(consumer); _binder?.Bind(typeof(TPOCO), topic, committer);`  
  - ループで `(entity, headers, meta)` を作ったら **manual のときだけ** `_binder?.Register(entity!, meta);`  
  - `finally` で **manual のときだけ** `_binder?.Unbind(typeof(TPOCO), topic);`  
- これにより、**“どの POCO/Topic のどの consumer か”** を **ConsumerManager 内部で** Binder に明示し、  
  **同じ consumer に対して commit** できるようにする。  
- **外側では binder を渡さない／分岐しない**。
### 3) ManualCommitManager.cs（新規）— CommitManager の実体＋厳密掃除
- `ICommitManager`（既存IF）＋ `IConsumerBinder` を実装。  
- **POCO参照→meta** を `ConditionalWeakTable<object, MessageMeta>` で保持（参照同一性）。  
- **(Type, Topic) → IConsumerCommitter** を保持（列挙中のみ有効）。  
- **(topic, partition) → committedMax（long）** を保持（“非減少”保証）。  
- `Commit(Type, object poco)` の流れ：
  1) `_metas.TryGetValue(poco, out meta)` で `(topic, partition, offset)` を得る。  
  2) `_committers.TryGetValue((type, meta.Topic), out committer)` で **同じ consumer** の committer を得る。  
  3) `if (offset <= committedMax[(topic,partition)]) return;`（非減少）  
  4) `committer.Commit(new[] { new TopicPartitionOffset(meta.Topic, meta.Partition, offset + 1) });`  
  5) `committedMax[(topic,partition)] = offset;` に更新  
  6) **厳密掃除**：同一 `(topic,partition)` の **`offset ≤ committed`** に紐づく POCO 登録を**全削除**
- **厳密掃除の実装**（索引方式）：  
  - 追加で **索引**を持つ：`ConcurrentDictionary<(string topic,int partition), SortedDictionary<long, List<WeakReference<object>>>> _index`  
  - `Register(entity, meta)` 時に `index[(t,p)][meta.Offset]` に `WeakReference(entity)` を追加  
  - `Commit` 成功後、`var committed = committedMax[(t,p)];` とし、  
    `SortedDictionary` の **`Keys <= committed`** を列挙 → 各リストの WeakRef を `TryGetTarget` して **CWT.Remove(target)** → そのキーを削除。  
  - これで **≤ committed の POCO 参照はすべて確実に解除**される（GC解放可）。
- スレッド安全：`SortedDictionary` は per (topic,partition) 単位で `lock` を取り、他は `ConcurrentDictionary` を用いる。

疑似コード（厳密掃除部抜粋）：
```csharp
public void Register(object entity, MessageMeta meta)
{
    try { _metas.Remove(entity); } catch {}
    _metas.Add(entity, meta);

    var key = (meta.Topic, meta.Partition.Value);
    var dict = _index.GetOrAdd(key, _ => new SortedDictionary<long, List<WeakReference<object>>>());
    lock (dict)
    {
        if (!dict.TryGetValue(meta.Offset.Value, out var list))
            dict[meta.Offset.Value] = list = new List<WeakReference<object>>();
        list.Add(new WeakReference<object>(entity));
    }
}

public void Commit(Type pocoType, object entity)
{
    if (!_metas.TryGetValue(entity, out var meta))
        throw new InvalidOperationException("Entity is not tracked for commit.");

    if (!_committers.TryGetValue((pocoType, meta.Topic), out var committer))
        throw new InvalidOperationException("No consumer bound for this POCO/Topic.");

    var partKey = (meta.Topic, meta.Partition.Value);
    var current = _committedMax.TryGetValue(partKey, out var v) ? v : -1;
    var off = meta.Offset.Value;
    if (off <= current) return;

    committer.Commit(new[] { new TopicPartitionOffset(meta.Topic, meta.Partition, off + 1) });
    _committedMax.AddOrUpdate(partKey, off, (_, prev) => off > prev ? off : prev);

    // ★ 厳密掃除：≤ committed を全削除
    if (_index.TryGetValue(partKey, out var dict))
    {
        lock (dict)
        {
            var toRemove = new List<long>();
            foreach (var kv in dict)
            {
                if (kv.Key > off) break; // off == committed
                foreach (var wr in kv.Value)
                    if (wr.TryGetTarget(out var obj))
                        try { _metas.Remove(obj); } catch {}
                toRemove.Add(kv.Key);
            }
            foreach (var k in toRemove) dict.Remove(k);
        }
    }
}
```
### 4) NoopCommitManager.cs
- autocommit 用の既存 Noop 実装はそのまま（`Commit` が空実装）。

---

## 受け入れ条件（テスト）
- 既存の `ManualCommit_PersistsOffset` テストを以下の**新IF**に合わせて書き換え、成功すること：  
  - `await foreach (var x in ctx.Samples.ForEachAsync(ct)) { if (x.Id == 3) { ctx.Samples.Commit(x); break; } }`  
  - 再度消費を開始した時に **Id==4 から始まる**。  
- autocommit モードでは同じコードでも **`Commit(x)` は no-op** で動作に影響しないこと。  
- 高頻度/複数回の `Commit(poco)` 呼び出しでも **offset が戻らない**こと（`committedMax` により非減少が保証される）。  
- commit 成功後に **(topic,partition) の ≤ committed offset に紐づく POCO 登録が全て解除**されること（厳密掃除）。

---

## 注意
- **新しい公開IFは増やさない**（`ForEachPocoAsync` など不可）。  
- `EventSet<T>.ForEachAsync` を **POCO返し**に**置き換える**のが唯一のIF変更。  
- **ConsumerManager 内部**で manual/auto を判定して Binder/Register を実施。外側は無関知。  
- **groupId を外に出さない**。  
- **同一 consumer に対して commit**（`IConsumerCommitter` 経由）。  
- **厳密掃除**は SortedDictionary 索引で **≤ committed** を完全削除。

---

必要なファイル：  
- 既存: `EventSet.cs`, `KafkaConsumerManager.cs`, `ICommitManager.cs`, `NoopCommitManager.cs`  
- 追加: `Messaging/Consumers/IConsumerCommitter.cs`, `Messaging/Consumers/IConsumerBinder.cs`, `ManualCommitManager.cs`（1クラス）

---

以上。実装後、該当テストを走らせて合格させてください。

— 送信日時: [[REDACTED_PHONE]]:59 (JST)
### assistant — 2025-08-11T11:09:32.574624+00:00

_(empty)_
### assistant — 2025-08-11T11:09:42.577226+00:00

_(empty)_
### user — 2025-08-11T11:11:18.487000+00:00

NoopCommitManagerこれは不要になる認識
### system — 2025-08-11T11:11:21.043758+00:00

_(empty)_
### assistant — 2025-08-11T11:11:21.093605+00:00

はい、その認識で合っています。  

今回の設計では、**autocommit の場合でも ManualCommitManager を使い、ただ `Commit()` が no-op になるように内部で制御**すれば、NoopCommitManager の存在意義はなくなります。  
### 理由
- 旧設計では  
  - autocommit → NoopCommitManager  
  - manual commit → ManualCommitManager  
  の二系統が必要だった  
- 新設計では  
  - **CommitManager は常に同じ実装（ManualCommitManager）**  
  - manualモード時だけ Binder/Register を行い、Commit 処理を有効化  
  - autocommitモード時は Binder/Register をスキップ、`Commit()` 呼び出しは `metaが無ければreturn` で即終了  

この方法にすると、**NoopCommitManager は削除可能**で、クラス構成がシンプルになります。  

もし希望されれば、この形に沿って **NoopCommitManager 削除版の最小コード修正案**を提示できます。
### user — 2025-08-11T11:11:48.121000+00:00

削除版で再度指示文をください
### assistant — 2025-08-11T11:11:51.793301+00:00

了解です。**NoopCommitManager を削除**する前提で、実装担当（Codex）向けの指示文をまとめました。これをそのまま渡してください。

---

# Codex依頼文：Noop削除版 — POCO列挙＋manual commit（同一consumer）＋厳密掃除

## 目的
- `EventSet<T>.ForEachAsync` を **POCO返し (`IAsyncEnumerable<T>`) に統一**（キャスト撤廃・新IF追加なし）。
- **commit は KafkaConsumerManager が生成した “同じ consumer” に対して実行**（一時 consumer を作らない、groupId を外に出さない）。
- **autocommit でも CommitManager は同一実装（ManualCommitManager）**を使用。autocommit では **内部で Binder/Register を行わない**ため、`Commit()` は **自然に no-op**。
- **非減少（offset を戻さない）** を厳守。
- commit 確定後、**同一 (topic, partition) の ≤ committed offset に紐づく POCO 登録を厳密に解放**。

## 変更範囲（最小）
- `EventSet.cs`：戻り値を POCO に変更＋`Commit(T)` を追加（委譲のみ）。**公開新IFは増やさない**。
- `KafkaConsumerManager.cs`：**既存の公開シグネチャは維持**。内部で manual 判定し、**manual 時のみ**同一consumerコミットのためのバインド/登録を行う。
- **新規2ファイル（非ジェネリック小IF）**：
  - `Messaging/Consumers/IConsumerCommitter.cs`（consumer.Commit を薄くラップ）
  - `Messaging/Consumers/IConsumerBinder.cs`（Bind/Unbind/Register）
- `ManualCommitManager.cs`：`ICommitManager + IConsumerBinder` を実装。**常にこの1実装のみ**を使う（＝**NoopCommitManager を削除**）。
- **NoopCommitManager.cs を削除**し、参照箇所を ManualCommitManager に置換。

---

## 実装タスク
### 1) EventSet.cs
- 既存の `ForEachAsync` を **POCO返し**に置き換え（破壊的変更・新IF追加はしない）:
  ```csharp
  // 変更前
  public virtual async IAsyncEnumerable<object> ForEachAsync(
      [EnumeratorCancellation] CancellationToken cancellationToken = default)

  // 変更後
  public virtual async IAsyncEnumerable<T> ForEachAsync(
      [EnumeratorCancellation] CancellationToken cancellationToken = default)
  {
      await foreach (var item in GetAsyncEnumeratorWrapper(cancellationToken))
          yield return item;
  }
  ```
- `Commit(T entity)` を追加（**委譲のみ**。autocommit時は後述の理由で自然に何も起きない）:
  ```csharp
  public void Commit(T entity)
  {
      if (entity is null) throw new ArgumentNullException(nameof(entity));
      _commitManager?.Commit(typeof(T), entity);
  }
  ```
- `ConsumeAsync` は従来どおり **KafkaConsumerManager から `(T, Headers, MessageMeta)` を受け取る**。  
  manual/auto の分岐や Binder の呼び分けは **ConsumerManager 内部で完結**させる。EventSet 側では何もしない。
### 2) 新規IF（非ジェネリック／小物）
`Messaging/Consumers/IConsumerCommitter.cs`
```csharp
using Confluent.Kafka;
using System.Collections.Generic;

namespace Kafka.Ksql.Linq.Messaging.Consumers
{
    internal interface IConsumerCommitter
    {
        void Commit(IReadOnlyList<TopicPartitionOffset> offsets);
    }
}
```

`Messaging/Consumers/IConsumerBinder.cs`
```csharp
using System;

namespace Kafka.Ksql.Linq.Messaging.Consumers
{
    internal interface IConsumerBinder
    {
        void Bind(Type pocoType, string topic, IConsumerCommitter committer);
        void Unbind(Type pocoType, string topic);
        void Register(object entity, MessageMeta meta);
    }
}
```
### 3) KafkaConsumerManager.cs（公開シグネチャは変更しない）
- フィールドに `IConsumerBinder? _binder` を DI で注入（null 可）。
- **private nested adapter** を追加（consumer を IConsumerCommitter にラップ）:
  ```csharp
  private sealed class ConsumerCommitter<TKey, TValue> : IConsumerCommitter
  {
      private readonly Confluent.Kafka.IConsumer<TKey, TValue> _consumer;
      public ConsumerCommitter(Confluent.Kafka.IConsumer<TKey, TValue> consumer) => _consumer = consumer;
      public void Commit(IReadOnlyList<TopicPartitionOffset> offsets) => _consumer.Commit(offsets);
  }
  ```
- `ConsumeAsync<TPOCO>(CancellationToken)` の内部で：
  - `var manual = model.UseManualCommit;` で **manual/auto を内部判定**。
  - consumer 作成後、**manual 時のみ**:
    - `var committer = new ConsumerCommitter<TKey,TValue>(consumer);`
    - `_binder?.Bind(typeof(TPOCO), topic, committer);`
  - ループで `(entity, headers, meta)` を生成したら、**manual 時のみ** `_binder?.Register(entity!, meta);`
  - `finally` で **manual 時のみ** `_binder?.Unbind(typeof(TPOCO), topic);`
- **groupId を外に出さない**。**同一 consumer**に対する commit は後述の ManualCommitManager から committer 経由で実行される。
### 4) ManualCommitManager.cs（唯一の CommitManager 実装）
- `ICommitManager`（既存IF：`Commit(Type, object poco)` もしくは現行に合わせる）＋ `IConsumerBinder` を実装。
- 保持構造：
  - **(Type, Topic) → IConsumerCommitter**：列挙期間中のみ有効（Bind/Unbindで出し入れ）。
  - **POCO参照 → MessageMeta**：`ConditionalWeakTable<object, MessageMeta>`（参照同一性）。
  - **(topic, partition) → committedMax（long）**：直近 commit 済み “現在オフセット”（非減少判定用）。
  - **厳密掃除用索引**：  
    `ConcurrentDictionary<(string topic,int partition), SortedDictionary<long, List<WeakReference<object>>>> _index`
- `Register(entity, meta)`：
  - CWT に `entity→meta` を登録（同キーがあれば上書き）。
  - `_index[(topic,partition)][meta.Offset]` に `WeakReference(entity)` を追加（`SortedDictionary` は per key で `lock`）。
- `Commit(Type pocoType, object entity)`：
  1) CWT から `meta` を取得。`topic/partition/offset` を得る。
  2) `_committers[(pocoType, topic)]` から **同じ consumer** の `committer` を取得。無ければ例外。
  3) 非減少チェック：`if (off <= committedMax[(topic,partition)]) return;`
  4) `committer.Commit(new[] { new TopicPartitionOffset(topic, partition, off + 1) });`
  5) `committedMax[(topic,partition)] = off;`
  6) **厳密掃除**：`_index[(topic,partition)]` の `SortedDictionary` を `lock` し、  
     **キー `k <= off` の全リストを走査** → `WeakRef.TryGetTarget` で生存POCOを得て **CWT.Remove(target)** → キーごと削除。  
     さらに **今回の `entity` 自身も CWT から Remove**（二重防止）。
- 注意：`SortedDictionary` の `lock` は **(topic,partition) 単位**に限定し、他は全て `ConcurrentDictionary` で lock-free に。
### 5) NoopCommitManager を削除
- ファイル `NoopCommitManager.cs` を削除。
- 参照箇所（DI登録・new など）を **ManualCommitManager** に置換。  
  **autocommit の場合でも** `KafkaConsumerManager` が Binder/Register を行わないので、`Commit()` は CWT に meta が無く **自然に no-op** となる。

---

## 受け入れ条件（テスト）
- 既存 `ManualCommit_PersistsOffset` を **POCO前提**に置換：  
  ```csharp
  await foreach (var sample in ctx.Samples.ForEachAsync(consumeCts.Token))
  {
      if (sample.Id == 3)
      {
          ctx.Samples.Commit(sample); // 同一consumerに対して nextOffset を commit
          break;
      }
  }
  ```
  再開時に **Id==4 から**始まること。
- autocommit モードでも **同じ呼び出し**が **挙動に影響しない（no-op）** こと。
- **非減少**：同一 (topic,partition) で、過去オフセットへの commit が無視される（戻らない）。
- **厳密掃除**：commit 後、当該 (topic,partition) の **≤ committed offset** に紐づく POCO 登録が **CWT と索引の両方から確実に解放**されていること。

---

## 禁則／注意
- **新しい公開メソッドを増やさない**（`ForEachPocoAsync` など不可）。`ForEachAsync` を **POCO返しに置換**するのみ。
- **groupId を外へ露出しない**／パラメータで回さない。
- **一時 consumer を作らない**（commit は **同じ consumer** に対して行う）。
- 例外／失敗時の扱いは現行方針に合わせる（リトライ方針があれば踏襲）。

---

以上。実装後はテストを通し、「Noop 削除」「POCO 列挙」「manual commit（同一consumer）」「厳密掃除（≤ committed）」「非減少」の各要件が満たされることを確認してください。

— 送信日時: [[REDACTED_PHONE]]:09 (JST)
### system — 2025-08-11T11:11:52.294200+00:00

_(empty)_
### assistant — 2025-08-11T11:11:54.024981+00:00

_(empty)_
### assistant — 2025-08-11T11:12:02.975046+00:00

_(empty)_
### user — 2025-08-11T11:51:21.953000+00:00

IFが以下に変わった。なんで？
   await foreach (var order in orders.ForEachAsync())
      {
        try
        {
            // メッセージ処理
            await ProcessOrder(order);

            // ✅ 処理成功時にコミット
            orders.Commit(order);

            Console.WriteLine($"Successfully processed and committed order: {order.Id}");
        }
        catch (Exception ex)
        {
            Console.WriteLine($"Failed to process order: {ex.Message}");
            throw;
        }
      }
### system — 2025-08-11T11:51:25.259001+00:00

_(empty)_
### assistant — 2025-08-11T11:51:25.311221+00:00

その変化は、私が提示した指示文の中で **`ForEachAsync` の戻り値を `object` → POCO 型に変更**し、さらに **`Commit` メソッドを `EventSet<T>` に直接追加**する設計にしたために起きたものです。  

つまり：

---
### 元の状態
```csharp
await foreach (var obj in orders.ForEachAsync())
{
    var msg = (IManualCommitMessage<ManualCommitContext.Sample>)obj;
    orders.Commit(msg); // Commit には IManualCommitMessage を渡す
}
```
- **ForEachAsync** は `object` を返していた  
- manual commit 用に **IManualCommitMessage** をキャストして meta を取り出す必要があった  

---
### 今回の変更後
```csharp
await foreach (var order in orders.ForEachAsync())
{
    await ProcessOrder(order);
    orders.Commit(order); // POCO をそのまま渡す
}
```
- **ForEachAsync** が `IAsyncEnumerable<TPOCO>` を返すようになった  
- `Commit(TPOCO)` を直接呼べるので、キャストや `IManualCommitMessage` の存在を意識しなくてよくなった  
- internal に `ConditionalWeakTable<object, MessageMeta>` で POCO インスタンス → メタ情報 を紐付けているので、引数が POCO だけでも commit 可能  

---
### これが変わった理由
- 「manual/auto commit のコード差分を無くしたい」という要望に合わせたため
- `IManualCommitMessage` の存在を外部コードから隠し、**POCO ベースの API**に統一するため
- autocommit の場合でも `Commit(order)` を呼んでも何も起こらない（no-op）設計にしてあるため、処理フローが同じで済む

---

もし元の `IManualCommitMessage` 型を維持したいなら、`ForEachAsync` を POCO返しに変えず、object返しのまま中でラップする形に戻す必要がありますが、それだと今回の **「コード変更なしで auto/manual 切り替え」** という目的は達成できません。  

---

このまま **POCO返し** に統一で進めますか？  
それとも **IManualCommitMessage キャスト式に戻す案**も作りますか？
### user — 2025-08-11T11:52:13.300000+00:00

利用者は継続してメッセージを受けとれる？
### assistant — 2025-08-11T11:52:18.703823+00:00

はい、**そのコードのままで継続して受信できます。**  
`ForEachAsync()` の列挙が続く限り、`ConsumerManager` は同じ consumer でポーリングを続けます。`orders.Commit(order)` は**オフセットを記録するだけ**で購読を止めません。

止まるのは次のときだけです：
- `await foreach` を抜けた（`break` / `return` / トークン取消）
- 例外を**外へ投げた**（あなたのサンプルは `throw;` しているので、そこで列挙終了）

継続運転したいなら：
```csharp
await foreach (var order in orders.ForEachAsync())
{
    try
    {
        await ProcessOrder(order);  // 正常処理
        orders.Commit(order);       // 同じconsumerへcommit
    }
    catch (Exception ex)
    {
        // ここでログやDLQへ送って、列挙は継続
        Console.WriteLine($"Failed to process order: {ex.Message}");
        // rethrowしない（= 継続）
        continue;
    }
}
```

要点メモ
- **commitは同期**ですが、**購読ループは継続**します（同一consumerに対するcommitで安全）。
- 失敗時に commit しなければ、そのメッセージは再配信される（少なくとも1回配送）。
- `break` や `throw` を入れない限り、**利用者はメッセージを受け取り続けます。**

— 送信日時: [[REDACTED_PHONE]]:18 (JST)
### system — 2025-08-11T11:52:19.591316+00:00

_(empty)_
### assistant — 2025-08-11T11:52:21.195778+00:00

_(empty)_
### assistant — 2025-08-11T11:52:38.735608+00:00

_(empty)_
### user — 2025-08-11T11:53:01.280000+00:00

そうするとDLQの関係はどうなる？
### system — 2025-08-11T11:53:06.088789+00:00

_(empty)_
### assistant — 2025-08-11T11:53:06.216731+00:00

ざっくり結論：

- **デコード/マッピング失敗（POCOに変換できない）**は、`KafkaConsumerManager` 側の既存DLQ処理でハンドリングされます。対象 レコードはDLQへ送られ、**同じconsumerがその場で次へ進む**（このときのコミットはマネージャ側で実施）。アプリ側にPOCOは渡らないので `Commit(order)` は関与しません。
- **アプリ処理失敗（POCOは取れたが `ProcessOrder` で失敗）**は、あなたのハンドリング方針次第：
  - **再試行したい** → `Commit(order)` を**呼ばない**（オフセット進めない）。同じメッセージが再配信されます。
  - **DLQへ送ってスキップしたい** → アプリ側で**DLQへ書いてから** `Commit(order)` を呼ぶ（以後は次のメッセージへ）。
### 典型コード（継続受信しつつDLQへ逃がすパターン）
```csharp
await foreach (var order in orders.ForEachAsync(ct))
{
    try
    {
        await ProcessOrder(order);
        orders.Commit(order); // 正常時だけcommit
    }
    catch (Exception ex)
    {
        // 1) アプリ側のDLQへ送る（独自ProducerでOK。payload+meta+例外情報）
        await dlqProducer.ProduceAsync("orders-dlq", BuildDlqMessage(order, ex));

        // 2) そのメッセージはスキップ（再配信させない）
        orders.Commit(order);

        // 3) ループは継続（rethrowしない）
        continue;
    }
}
```

#### DLQに載せると良い情報（ヘッダ/ペイロード例）
- 元の`topic/partition/offset`, `timestamp`
- 例外タイプ/メッセージ/スタックトレース（サイズに注意）
- 失敗時の入力POCO（JSON化）
- 任意で相関ID/トレースID
### トランザクション（任意）
「DLQへ書けたら**必ず**commitされる」を厳密に担保したい場合は、**Idempotent + Transactional Producer**で  
「`DLQ produce` と `offset commit` を同一トランザクション」にまとめる設計が最強です（Exactly-Once）。  
ただしライブラリ側の大改修が要るので、当面は**DLQ→commitの順**で「少なくとも一度」を満たすのが現実的です。
- 障害窓：DLQ書き込み成功後にcommit前にクラッシュ→同じレコードが再処理され、DLQ重複の可能性。  
  → DLQ側で重複抑止キー（`topic-partition-offset`）を使うと緩和できます。
### おさらい：どこが何をするか
- **フレームワークDLQ（Manager内）**：デシリアライズ/マッピング失敗を捕捉→DLQ送信→同consumerで先へ。  
  アプリ側は関知不要、POCOも受け取りません。
- **アプリDLQ（あなたのコード）**：ビジネス処理の失敗を捕捉→DLQ送信→`Commit(order)` で先へ進む or 再試行なら未commit。

必要なら、`BuildDlqMessage(order, ex)` の具体例（ヘッダ設定やJSON化）も出します。どう運用したいです？

— 送信日時: [[REDACTED_PHONE]]:28（JST）
### assistant — 2025-08-11T11:53:08.387320+00:00

_(empty)_
### assistant — 2025-08-11T11:53:34.668488+00:00

_(empty)_
### user — 2025-08-11T11:54:04.395000+00:00

だめ　却下　戻して
### system — 2025-08-11T11:54:08.064091+00:00

_(empty)_
### assistant — 2025-08-11T11:54:08.111750+00:00

了解です、DLQ まわりは**元の設計に戻す**方向ですね。  
つまり今のままの流れ——

- **ConsumerManager 内で**デコード/マッピング失敗を検知して DLQ へ送信  
- Manual commit モードでも、このケースは **アプリ側に POCO を渡さない**  
- アプリは `Commit(order)` を呼ぶのは**正常処理できた場合だけ**  
- ビジネス処理失敗時に DLQ へ送るか再配信するかは**アプリの責務外**（既存の autocommit 相当の動き）

で進める、という理解で合ってますか？  
もしそうなら、今の commit 呼び出し仕様のまま、DLQ 部分はまったく手を触れずに残せます。  

— 送信日時: [[REDACTED_PHONE]]:34 (JST)
### user — 2025-08-11T11:55:47.618000+00:00

await context.Orders
    .OnError(ErrorAction.DLQ)
    .WithRetry(3)
    .ForEachAsync((order, headers, meta) => Handle(order));
これができなくなるIFは駄目です
### assistant — 2025-08-11T11:55:56.579474+00:00

了解。**その Fluent IF は絶対に壊しません。**  
`await context.Orders.OnError(...).WithRetry(3).ForEachAsync((order, headers, meta) => Handle(order));` は現状のまま動作させます。

やることは中身だけ差し替え・追加で、公開APIは据え置きです。

# 変更方針（非破壊）

- `ForEachAsync((T order, IDictionary<string,string> headers, MessageMeta meta) => ...)` この**デリゲート版 ForEachAsync はそのまま**。  
- `OnError(...)` / `WithRetry(...)` のチェーンも**そのまま**。  
- `orders.Commit(order)` を**追加**（POCO受け取り）しても、**既存IFには影響なし**。呼び出すかどうかは利用側の自由。  
- **manual/auto の判定は ConsumerManager 内部**で `model.UseManualCommit` を見て実施。外側での分岐不要。  
- **commit は “ConsumerManager が作った同じ consumer” に対して**行う（一時consumerは作らない／groupIdを外に出さない）。  
- **DLQ と Retry**は現行実装（ConsumerManager内のDLQハンドリング、WithRetryの再試行）を**そのまま維持**。

# 最小実装メモ

- EventSet.cs
  - 既存の `ForEachAsync(Func<T, IDictionary<string,string>, MessageMeta, Task> handler, ...)` は**無変更**。
  - `Commit(T entity)` を**追加**（内部で CommitManager に委譲）。デリゲート内から `orders.Commit(order)` が呼べる。

- KafkaConsumerManager.cs
  - 公開シグネチャ**無変更**。
  - 内部で `var manual = model.UseManualCommit;` を見て、**manual 時のみ**  
    - consumer を **IConsumerCommitter** にラップして **Bind(typeof(T), topic, committer)**  
    - POCO/メタ生成後に **Register(order, meta)**  
    - finally で **Unbind**  
  - これにより、**同一consumerに対するcommit**が可能に。

- ManualCommitManager.cs（唯一の CommitManager）
  - **IConsumerBinder** を実装し、`(Type, Topic) -> IConsumerCommitter` と `POCO -> meta` を保持。
  - `Commit(Type, object poco)` で meta を引き、**committer.Commit(new TopicPartitionOffset(topic, partition, offset+1))** を実行。  
  - **非減少**を (topic, partition) ごとの committedMax で保証。  
  - **厳密掃除**：`(topic,partition)` ごとの `SortedDictionary<long, List<WeakReference<object>>>` 索引で **≤ committed** の POCO登録を完全削除。

> これで、利用者コードは今まで通り：
```csharp
await context.Orders
    .OnError(ErrorAction.DLQ)
    .WithRetry(3)
    .ForEachAsync(async (order, headers, meta) =>
    {
        await ProcessOrder(order);
        context.Orders.Commit(order); // manual時だけ実コミット。autocommit時は内部no-op
    });
```
- 失敗時再試行は `WithRetry(3)` が担保。  
- デコード/マッピング失敗の DLQ は従来どおり ConsumerManager 側で処理。  
- APIの形は**一切変わりません**。

この方針でコード差分を出します。必要ならパッチ形式でまとめます。

— 送信日時: [[REDACTED_PHONE]]:41 (JST)
### system — 2025-08-11T11:55:56.900543+00:00

_(empty)_
### assistant — 2025-08-11T11:55:57.636712+00:00

_(empty)_
### assistant — 2025-08-11T11:56:11.459560+00:00

_(empty)_
### user — 2025-08-11T12:07:55.686000+00:00

指示文をください　前回のものとまとめて
### system — 2025-08-11T12:08:20.238995+00:00

_(empty)_
### assistant — 2025-08-11T12:08:20.333612+00:00

わかりました。では前回の指示文に今回の「**既存 Fluent API (`OnError` / `WithRetry` / `ForEachAsync`) を壊さず `Commit(poco)` を追加**」方針を統合した形でまとめます。  

---

## Codex 向け統合指示文
### 背景
- 現在の `EventSet.ForEachAsync` は `(TPOCO, headers, meta)` 形式で処理でき、`OnError()` や `WithRetry()` の Fluent チェーンが利用可能。
- manual commit モードと autocommit モードで API シグネチャが変わるのは避けたい。
- 利用者は、既存コードのままでも動くようにしつつ、manual commit モードでは `Commit(poco)` を呼び出すことでオフセットを明示的に記録できるようにしたい。
- commit は必ず **ConsumerManager が生成した同じ consumer** に対して行う。新たに consumer を作らない。
- commit 時は Kafka の「オフセット非減少」ルールを守る必要がある。
- commit 後はそのオフセット以前の meta 情報をすべて破棄する（厳密掃除）。

---
### 実装要件

1. **既存 Fluent API を壊さない**
   - `await context.Orders.OnError(...).WithRetry(...).ForEachAsync((order, headers, meta) => Handle(order));`  
     の形は変更しない。
   - `OnError()` / `WithRetry()` / `ForEachAsync()` の戻り型や引数は現状維持。

2. **Commit(poco) の追加**
   - `EventSet<T>` に `Commit(T entity)` メソッドを追加。
   - manual commit モード時のみ、保持している meta 情報を使って commit を実行。
   - autocommit モード時は no-op（即 return）。
   - 呼び出し元は ForEachAsync デリゲート内で `context.Orders.Commit(order)` を呼べる。

3. **ManualCommitManager の導入（NoopCommitManager は廃止）**
   - ManualCommitManager は全モードで共通使用。autocommit 時は内部で commit をスキップ。
   - `(Type pocoType, string topic, IConsumer<byte[], byte[]> consumer)` を Bind し、`(POCO -> meta)` を Register できる。
   - `Commit(Type, object poco)` で meta 情報から TopicPartitionOffset を取得し、consumer.Commit() 実行。
   - commit 時に **そのパーティションで committedMax 以下の meta 情報を削除**（厳密掃除）。

4. **ConsumerManager 側の対応**
   - manual commit モード時のみ binder に Bind/Register を行う。
   - autocommit モード時は binder 呼び出しをスキップ。
   - consumer は既存の CreateConsumer で生成したものを使用。

5. **厳密掃除の仕様**
   - `(topic, partition)` ごとに SortedDictionary<long, WeakReference<object>> を保持。
   - commit 完了後、そのパーティションで committed offset 以下のエントリを削除。
   - WeakReference で POCO が GC 済みなら不要エントリとしても削除。

---
### 完成イメージ（利用者側）

```csharp
await context.Orders
    .OnError(ErrorAction.DLQ)
    .WithRetry(3)
    .ForEachAsync(async (order, headers, meta) =>
    {
        await ProcessOrder(order);
        context.Orders.Commit(order); // manual時のみ有効
    });
```

- 失敗時は `WithRetry()` が再試行、DLQ は既存 ConsumerManager 内処理が担当。
- API シグネチャ・チェーンは従来通り。

---

この条件で Codex に実装依頼してください。  

---

この形で出せば、Codexは**既存のIF維持＋内部差し替え＋Commit追加＋Noop削除＋厳密掃除**を一気にやってくれます。  

この統合指示文を使って依頼しますか？  
（必要なら、既存ファイルパスと一緒に添付形式にできます）
