---
conversation_id: "68b2adf0-2e50-8324-9633-eca0cbc358f1"
title: "README.md整理提案"
create_time: 1756540401.148854
update_time: 1756540425.158675
language_guess: "en"
num_messages: 16
part_index: 1
part_count: 1
---

### assistant — 2025-08-30T07:53:20.976108+00:00

_(empty)_

### system — 2025-08-30T07:53:21.148854+00:00

_(empty)_

### user — 2025-08-30T07:53:21.148854+00:00

_(empty)_

### system — 2025-08-30T07:53:21.148854+00:00

_(empty)_

### system — 2025-08-30T07:53:21.200907+00:00

_(empty)_

### tool — 2025-08-30T07:53:21.213503+00:00

_(empty)_

### user — 2025-08-30T07:53:21.258000+00:00

readme.mdの整理
主要なドキュメントを添付したのでこれをもとに整理する

### tool — 2025-08-30T07:53:22.688006+00:00

Make sure to include `【message_idx†source】` markers to provide citations based on this file, where [message_idx] is provided at the beginning of this message
# <img src="./LinqKsql-logo.png?raw=true" alt="Kafka.Ksql.Linq Icon" height="32" style="vertical-align:-5px;"/><span>&nbsp;  </span> Kafka.Ksql.Linq


Kafka.Ksql.Linq は C# から Kafka/ksqlDB のクエリを LINQ 風に記述できる DSL ライブラリです。
Entity Framework の経験がある開発者がストリーム処理ロジックを直感的に書けることを目指しています。

## 特徴
- LINQ ライクな DSL で Kafka/ksqlDB のクエリを構築
- Schema Registry の SpecificRecord と連携した Avro シリアライズ
- Window ベースの集約と Push Query 生成をサポート

## Quick Start
1. .NET 6 SDK をインストールし、リポジトリを取得して依存関係を復元します。
   ```bash
   git clone <repository-url>
   cd rc01
   dotnet restore
   ```
2. Kafka/ksqlDB/Schema Registry を起動します。
   ```bash
   docker-compose -f tools/docker-compose.kafka.yml up -d
   ```
3. サンプルを実行します。
   ```bash
   cd examples/hello-world
   dotnet run
   ```
   さらに詳しいサンプルや誤用例/推奨パターンは [docs/examples_reference.md](docs/examples_reference.md) を参照してください。

## 📖 公式ドキュメントセット
- [Getting Started](docs/getting-started.md)
- [API Reference](docs/api_reference.md)
- [Configuration Reference](docs/docs_configuration_reference.md)
- [Advanced Rules](docs/docs_advanced_rules.md)

## 📚 ドキュメント構成ガイド
### 🧑‍🔧 現場担当者
- [docs/getting-started.md](docs/getting-started.md)
- [docs/troubleshooting.md](docs/troubleshooting.md)
- [docs/physical_test_minimum.md](docs/physical_test_minimum.md)

### 🧑‍🏫 初級〜中級者
- [docs/sqlserver-to-kafka-guide.md](docs/sqlserver-to-kafka-guide.md)
- [docs/examples_reference.md](docs/examples_reference.md)

### 🛠️ 上級開発者
- [docs/dev_guide.md](docs/dev_guide.md)
- [docs/namespaces/](docs/namespaces)

### 🏗️ アーキテクト・運用担当
- [docs/docs_advanced_rules.md](docs/docs_advanced_rules.md)
- [docs/docs_configuration_reference.md](docs/docs_configuration_reference.md)
- [docs/architecture_overview.md](docs/architecture_overview.md)
- [docs/test_guidelines.md](docs/test_guidelines.md)
- [docs/amagiprotocol/README.md](docs/amagiprotocol/README.md)

### assistant — 2025-08-30T07:53:22.775660+00:00

やあ、司令！📚 主要ドキュメントを一通り確認して、README.md を整理するための全体像をまとめました。READMEは「入口ドキュメント」なので、詳細情報は他のドキュメントへリンクしつつ、利用者が迷わず導ける構成にするとよいです。

---

# 🔑 README.md 改訂提案

## 1. プロジェクト概要
- **Kafka.Ksql.Linq** は **C# から Kafka/ksqlDB を LINQ スタイルで操作できる DSL ライブラリ**。  
- Entity Framework に慣れた開発者がストリーミング処理を直感的に記述できるよう設計されている【13†source】。

---

## 2. 特徴
- LINQライクな DSL 構文で Kafka/ksqlDB クエリを定義  
- Avro + Schema Registry を前提とした型安全なシリアライズ【15†source】  
- Window/集約処理・Push/Pull クエリ対応【16†source】  
- DLQ / Retry / Commit を含む高度なエラーハンドリング【18†source】

---

## 3. Quick Start
```bash
git clone <repository-url>
cd rc01
dotnet restore

docker-compose -f tools/docker-compose.kafka.yml up -d

cd examples/hello-world
dotnet run
```
👉 詳細サンプルは [examples_reference.md](docs/examples_reference.md) を参照【14†source】。

---

## 4. ドキュメント体系

### 🚀 はじめての方
- [Getting Started](docs/getting-started.md)【13†source】
- [Examples Reference](docs/examples_reference.md)【14†source】

### ⚙️ API / 設定リファレンス
- [API Reference](docs/api_reference.md)【18†source】
- [Configuration Reference](docs/docs_configuration_reference.md)【17†source】

### 🛠️ 上級者向け
- [Advanced Rules](docs/docs_advanced_rules.md)【16†source】
- [設計統合ドキュメント](docs/oss_design_combined.md)【15†source】

### 📐 アーキテクト・運用者向け
- [Architecture Overview](docs/architecture_overview.md)
- [Amagi Protocol](docs/amagiprotocol/README.md)

---

## 5. サンプル集（examples）
- Hello World  
- Basic Produce & Consume  
- Error Handling（Retry / DLQ）  
- SQL Server vs Kafka 置換  
- Window Finalization など【14†source】

---

## 6. 開発/運用のルール
- **属性優先設計**：POCO属性でスキーマ/トピックを定義し、Fluent API は最小限に【15†source】  
- **Fail Fast**：初期化時にDSL/スキーマを検証し、不整合は即エラー【15†source】  
- **Window Finalization**：複数粒度のウィンドウを1 POCOで集約【16†source】  
- **DLQ運用**：既定トピック `dead-letter-queue` を利用。Retention等は `DlqOptions` で調整【17†source】

---

## 7. ライセンス
- OSSライセンス表記（未定義ならここに追記）

---

# ✅ 提案まとめ
- READMEは「全体像＋ドキュメントポータル」として整理。  
- **詳細情報は各mdへリンク**、利用者がレベル別に読み進められる構成。  
- Examples（入口）→ API/Config（利用者用）→ Advanced/Design（開発者・OSSチーム用）→ Architecture/Protocol（アーキテクト用）の順路を明示。  

---

司令、この整理案をベースに実際の **新README.md原稿** を書き出しましょうか？それとも「目次・構造だけ」でまず合意をとりますか？

### tool — 2025-08-30T07:53:22.813404+00:00

Make sure to include `【message_idx†source】` markers to provide citations based on this file, where [message_idx] is provided at the beginning of this message
# サンプルコードと利用ガイド

## よくある誤用と推奨パターン
- このDSLはKafka/ksqlDB専用であり、Entity Frameworkの`Where`や`GroupBy`チェーンはKSQLには反映されません。集約粒度の指定には`Window(x)`拡張メソッドを使用してください。
- キーに利用できる型は`int`、`long`、`string`、`Guid`のみです。その他の型をキーにする場合はこれらへ変換してください。
- 生成済みのSpecificRecord型は`Confluent.SchemaRegistry.Serdes`の`AvroSerializer`でそのまま送受信できます。

## サンプル一覧
1. **Hello World** — `examples/hello-world`  
   最小構成でメッセージを送受信。`KsqlContextBuilder` と `ForEachAsync` の基礎を確認。
2. **Basic Produce & Consume** — `examples/basic-produce-consume`  
   プロデュース後にコンシュームする基本フロー。`Task.Delay` で送信待ちを挟む。
3. **Configuration** — `examples/configuration`  
   複数環境の `appsettings.json` を読み分ける設定例。
4. **Configuration Mapping** — `examples/configuration-mapping`  
   型付き設定を `KsqlContextBuilder` にマップする。
5. **Manual commit** — `examples/manual-commit`  
   手動コミットで確実に処理を終える。
   ```csharp
   await context.Orders.ForEachAsync((o, h, m) =>
   {
       Console.WriteLine($"Processing {o.OrderId}");
       context.Orders.Commit(o);
       return Task.CompletedTask;
   }, autoCommit: false);
   ```
6. **Kafka headers とメッセージメタデータ**  
   ヘッダーをフィルタに使う。
   ```csharp
   await context.Set<OrderMessage>().ForEachAsync((msg, headers, meta) =>
   {
       if (headers.TryGetValue("is_dummy", out var d) && d == "true")
           return Task.CompletedTask;
       // ...
   });
   ```
7. **Error handling** — `examples/error-handling`  
   `OnError` と `WithRetry` で例外を補足して再試行。
8. **Error handling with DLQ** — `examples/error-handling-dlq`  
   エラー時に `ErrorAction.DLQ` で死信キューへ転送。
9. **SQL Server vs Kafka** — `examples/sqlserver-vs-kafka`  
   SQL Server の書き込みを Kafka に置き換える最小サンプル。
10. **Topic Fluent API Extension** — `samples/topic_fluent_api_extension`  
    トピック設定を Fluent API で拡張するテスト付き例。
11. **Daily comparison** — `examples/daily-comparison`  
    レートを集計し日次比較を行う複合サンプル。
12. **API showcase** — `examples/api-showcase`  
    **コードなし**。`Where`・`GroupBy`・`Select` 等を組み合わせた総合例があると良い。
13. **MappingManager AddAsync** — `examples/naruse/mapping_manager`  
    **コードなし**。`MappingManager` からエンティティを登録し `AddAsync` する例が望まれる。
14. **Window finalization** — `examples/window-finalization`  
    **コードなし**。`Window(...).UseFinalized()` を用いたウィンドウ確定の例が必要。
15. **KSQL offset aggregates** — `samples/ksql_offset_aggregates`  
    **コードなし**。オフセットを基にした集計例があると理解が深まる。

### tool — 2025-08-30T07:53:22.845978+00:00

Make sure to include `【message_idx†source】` markers to provide citations based on this file, where [message_idx] is provided at the beginning of this message
# OSS設計資料：統合ドキュメント

## Overview

本ドキュメントは、Kafka.Ksql.Linq OSSの設計思想、アーキテクチャ、構成ルール、拡張指針を一体的にまとめた設計仕様書です。高度な利用者やOSS開発チーム向けに設計されており、全体像の把握と構成要素の関係理解を支援します。

## 目次 (Table of Contents)

-
  1. 設計原則
-
  2. アーキテクチャ概観
-
  3. POCO属性ベースDSL設計ルール
-
  4. POCO設計
-
  5. プロデュース操作
-
  6. コンシューム操作、（リトライ、エラー、DLQ、commitの誤解）
-
  7. View定義とToQuery DSL
-
  8. ウィンドウ・テーブル操作
-
  9. ロギングとクエリ可視化
-
  10. 代表的な利用パターン

## 1. 設計原則

### 1.1 型安全・Fail Fast

- LINQベースでKSQL構文を表現し、ビルド時に構文誤りを排除、
AVROフォーマットの採用
- Context生成時に検出
- モード切替による型安全性の確保

####  🔍 検証時の強制レベル一覧（Strict / Relaxed モード）
検証項目|Strict|Relaxed|備考
---|---|---|---
Topic属性なし|❌ エラー|⚠️ 警告|クラス名をトピック名に使用
Key属性なし|⚠️ 警告|⚠️ 警告|Streamとして動作
抽象クラス|❌ エラー|❌ エラー|基本要件のため両方エラー
char型プロパティ|⚠️ 警告|⚠️ 警告|KSQL互換性の警告
未サポート型|⚠️ 警告|⚠️ 警告型|変換の警告

### 1.2 宣言的構文による表現力

- POCO + 属性 + LINQ = KSQLクエリ構築
- Entity Framework的な直感性を保つ

### 1.3 OSSとしての拡張性

- Builder、Query、Messaging、Windowなど明確な層構造
- Fluent APIによる構文追加・拡張が容易

## 2. アーキテクチャ概観

本OSSの構造は、Entity Framework の設計哲学に基づいて構築されています。POCO（Plain Old CLR Objects）に属性を付与し、LINQ式を用いて処理ロジックを記述することで、Kafka および ksqlDB の構造を宣言的に表現します。

これにより、Entity Framework に慣れた開発者が直感的にKafkaベースのストリーミング処理を設計・運用できるようになっています。各DSL操作（AddAsync, ForEachAsync, Window, Aggregate など）はEFの文法と類似性を持たせることで、学習コストの削減と記述一貫性を実現しています。

POCO（Plain Old CLR Objects）とは、依存性やフレームワーク固有の継承を持たない純粋なC#クラスを指します。本OSSでは、Kafka/KSQLの設定をこのPOCOに対する属性付与によって表現します。

このアプローチにより、構成情報とデータ定義が1つのクラスに集約され、Entity Frameworkと同様の直感的なコーディングスタイルを可能にしています。また、Fluent APIに頼らず、型安全かつ構文明快なDSLを構築することで、チーム内での可読性と再利用性も向上します。

kafkaへの接続エラーはksqlContextのコンストラクタでthrowされます。

> **POCO設計方針**
> POCO/DTO いずれでも `Key` 属性を使用せず、プロパティ定義順のみで key schema を決定します。
> 詳細は [architecture_overview.md](./architecture_overview.md#poco%E8%A8%AD%E8%A8%88%E3%83%BBpk%E9%81%8B%E7%94%A8%E3%83%BB%E3%82%B7%E3%83%AA%E3%82%A2%E3%83%A9%E3%82%A4%E3%82%BA%E6%96%B9%E9%87%9D) を参照してください。

## 3. POCO属性ベースDSL設計ルール（Fluent APIの排除方針）

本OSSでは、Kafka/KSQLの設定をすべてPOCOクラスの属性で定義する方式を採用する。
これは、Fluent APIを用いたDSL記述の柔軟性と引き換えに、「構成がPOCOに集約されている」という明快さを重視した設計方針である。

### 3.1 型一覧

C#型
- bool
- int
- long
- float
- double
- string
- byte[]
- decimal
- DateTime
- DateTimeOffset
- Nullable型
- Guid
- short ,char ※keyに使用することはできません

### 3.2 プロパティ属性一覧

🧩 プロパティ属性一覧
|属性名	|説明|
|---|---|
[KsqlIgnore]	|スキーマ定義・KSQL変換から除外される
[KsqlDecimal(precision, scale)]	|decimal型の精度指定（例：18,4）
[KsqlDatetimeFormat("format")]	|KSQL上でのDateTimeの文字列フォーマット
[KsqlKey(Order = n)] |複合キー順序の指定
[MaxLength(n)]	|文字列長の制約。Avroスキーマにも反映

💡 サンプル：Orderエンティティの定義
```csharp
[KsqlTable]
[KsqlTopic("orders", PartitionCount = 12, ReplicationFactor = 3)]
public class Order
{
    [KsqlKey(Order = 0)]
    public int OrderId { get; set; }

    [KsqlDatetimeFormat("yyyy-MM-dd")]
    public DateTime OrderDate { get; set; }

    [KsqlDecimal(18, 4)]
    public decimal TotalAmount { get; set; }

    [MaxLength(100)]
    public string? Region { get; set; }

    [KsqlIgnore]
    public string? InternalUseOnly { get; set; }
}
```
### 3.3 クラス属性一覧

🏷️ クラス属性一覧
|属性名	|説明|
|---|---|
[KsqlStream] / [KsqlTable]	|Stream/Table の明示指定（未指定時は自動判定）


パーティション数やレプリケーション係数のFluent APIによる設定をおこなう。
// Fluent API版
public class MyKsqlContext : KsqlContext
{
    protected override void OnModelCreating(IModelBuilder modelBuilder)
    {
        modelBuilder.Entity<Order>();
    }
}

```

🤖 自動判定ロジック
出力用 DTO/POCO の key schema はプロパティ定義順から自動生成されます。`KsqlTable` か `KsqlStream` かの判定は `KsqlTable`/`KsqlStream` 属性などのコンテキスト設定により決定されます。

Fluent APIでも指定可能です。

トピックのpartition, replication設定、Table/Streamの指定
```csharp
public class MyKsqlContext : KsqlContext
{
    protected override void OnModelCreating(IModelBuilder modelBuilder)
    {
        modelBuilder.Entity<Order>()
            .AsStream();    //Tableの場合AsTable()                 
    }
}
```   
ただし、以下のメソッド呼び出しは設計原則違反となる。

🚫 制限事項
メソッド|	理由
|---|---|
.AsStream() / .AsTable()	|属性またはModelBuilderと重複可能。両方指定で一致しない場合はエラー

これらのメソッドは呼び出された場合に NotSupportedException をスローする設計とし、誤用を防止する。

### Push/Pull Query の明示
`ToQuery` DSL では `.AsPush()` / `.AsPull()` を用いて実行モードを指定します。未指定の場合は `Unspecified` となり、Pull クエリ制約違反が検出されると自動的に Push (`EMIT CHANGES` 付き) へ切り替わります。
※その他の詳細設定はdev_guide.md参照

## 4. スキーマ構築と初期化手順

`OnModelCreating` は `CREATE STREAM/TABLE AS SELECT ...` のようなクエリ定義専用のフックです。
クエリを伴わない Stream/Table は KsqlContext 派生クラスの public `EventSet<T>` プロパティとして宣言し、`[KsqlTopic]` や `[KsqlKey]` などの属性を評価したうえで OnModelCreating の完了後に自動的に ksqlDB/Schema Registry へ登録されます。

この初期化処理により、POCO の構造は Kafka/KSQL に対する明確なスキーマとして解釈され、後続の LINQ クエリが正しく処理される基盤となります。

✅ 実装のポイント

- クエリを定義する場合は `OnModelCreating` 内で `modelBuilder.Entity<T>()` を使用します。
- クエリを伴わないエンティティは `EventSet<T>` プロパティを追加するだけで登録されます。
- `KsqlStream` または `KsqlTable` 属性が無い場合でも、プロパティ定義順から生成される key schema を基に自動的に Table/Stream が推定されます。

登録時点で DSL の構文検証が行われ、構文誤りや属性不備はここで Fail Fast となります。

Schema Registry への接続もこの時点で必要となり、未接続・未整備の場合には例外が発生します。

```csharp

[KsqlStream]
[KsqlTopic("orders", PartitionCount = 12, ReplicationFactor = 3)]
public class Order
{
    [KsqlKey(Order = 0)]
    public string OrderId { get; set; }
    public DateTimeOffset Timestamp { get; set; }
    [KsqlDecimal(18, 2)]
    public decimal Amount { get; set; }
}

[KsqlTable]
public class Customer
{
    public string CustomerId { get; set; }
    public string Name { get; set; }
}

// 出力用DTO（定義順で自動的にキー生成）
public class CustomerDto
{
    public string CustomerId { get; set; }
    public string Name { get; set; }
}

public class MyKsqlContext : KsqlContext
{
    protected override void OnModelCreating(KsqlModelBuilder modelBuilder)
    {
        modelBuilder.Entity<Order>();
        modelBuilder.Entity<Customer>()
            .Where(c => c.Name != null)
            .Select(c => new { c.CustomerId, c.Name });
        
    }
}
```   

このように、POCOの登録はアプリケーションの起動時に実施されることで、DSL全体の整合性とスキーマ妥当性を確保します。

### ダミーデータ投入によるスキーマ確定

CREATE TABLE/STREAM を実行してテーブルを登録した直後は、KSQL 側がスキーマ情報を完全に認識するまで時間がかかる場合があります。スキーマ未確定の状態で `SELECT` などの DML を実行すると `column 'REGION' cannot be resolved` といったエラーが発生するため、各テーブルに対応する Kafka トピック（例: `orders`, `customers`）へ **1 件以上のダミーレコード** を **AVRO** 形式で送信してください。全てのカラムを埋めたレコードを投入した後に DML クエリを実行することで、カラムスキーマが正しく取得されます。テストコードではこのダミーデータ送信をセットアップ処理に組み込むことを推奨します。

テスト目的で送信するダミーメッセージには `is_dummy=true` といったヘッダーを付与することで、consumer や KSQL 側で本番データと区別できます。このヘッダー値を利用して、スキーマ確定後のクリーンアップや検証を行ってください。
詳細なテスト手順は `features/dummy_flag_test/instruction.md` も併せて参照してください。

ダミーレコード送信後は、`WaitForEntityReadyAsync<T>()` を呼び出して ksqlDB が対象ストリーム/テーブルを認識するまで待機すると安全です。伝搬遅延による `DESCRIBE` 失敗を回避でき、テストや初期化処理での競合を防止できます。

スキーマ登録済みのエンティティ名やフィールド名は **大文字・小文字を区別** します。`SchemaRegistryException` が発生する場合は、Schema Registry に登録されているスキーマと、テストコードで利用しているモデルの名前が完全に一致しているか確認してください。

## 5. プロデュース操作
Kafka.Ksql.Linq では、AddAsync() メソッドを使用して、POCOベースのデータをKafkaトピックへ送信（プロデュース）することができます。LINQ構文と統合されており、型安全かつ直感的なメッセージ生成を実現します。

### ✅ 実装のポイント
AddAsync() は `[KsqlTopic]` 属性で指定したトピックへメッセージを送信します。

送信処理は非同期（Taskベース）であり、awaitable

Fail Fastにより、スキーマ不整合や未設定項目は実行前に検出されます

送信前にログでメッセージ内容を確認可能（詳細は第8章のロギング参照）

🧪 サンプルコード
```csharp
var order = new Order
{
    OrderId = "ORD-001",
    Timestamp = DateTimeOffset.UtcNow,
    Amount = 1234.56m
};

await context.AddAsync(order);
```
このコードでは、Orderエンティティに基づいてKafkaに1件のメッセージが送信されます。トピックやスキーマ定義はPOCO属性に基づいて自動的に解決されます。
ChatGPT:
了解しました。次の章は以下の 6. コンシューム操作、（リトライ、エラー、DLQ、commitの誤解） です。以下のように表示を開始します：

## 6. コンシューム操作、（リトライ、エラー、DLQ、commitの誤解）
この章では、Kafkaメッセージの コンシューム処理 に関する基本操作と、以下のような誤解されやすいポイントを整理します：

### ✅ 基本的な消費処理の構文
```csharp
await context.Orders
    .ForEachAsync();
```

### 🧠 よくある誤解と実態
誤解されやすい概念	|実際の挙動	|補足説明
|---|---|---|
ForEachAsync にリトライ機能がある|	ない	|エラー処理は .OnError() により明示的に定義が必要
DLQは自動的に処理される|	明示 or .OnError(ErrorAction.DLQ) 必須	|設定がないとDLQ送信されない
処理失敗時もcommitされる|	commitは常に明示または .WithAutoCommit() 指定|	自動ではないため注意
メッセージスキップはデフォルトで行われる|	明示的に .OnError(ErrorAction.Skip) 指定が必要	|スキップ設定なしでは処理停止の可能性

🛠 使用例（リトライ＋DLQ）
```csharp
await context.Orders
    .OnError(ErrorAction.DLQ)
    .WithRetry(3)
    .ForEachAsync((order, headers, meta) => Handle(order));
```

このように、明示的なエラーハンドリング設計が求められます。

DLQ の内容を確認する場合は `ctx.Set<DlqEnvelope>()` を用います。DLQ は履歴ストリームであり `Take()` や `ToListAsync()` などの件数指定取得はできません。すべて `ForEachAsync()` で逐次処理してください。さらに DLQ ストリームでは `.OnError(ErrorAction.DLQ)` は無限ループ防止のため禁止されています。

なお、DLQのデフォルトトピック名は `dead-letter-queue` です。

### commitの制御
Kafkaのコンシューム操作において、メッセージのオフセットコミットは非常に重要です。

デフォルトでは コンシューマ設定 `EnableAutoCommit` が有効となっており、
明示的な指定がない場合でも、処理が成功した時点で commit が行われます。

ただし、エラーハンドリングや再処理設計の都合上、明示的に commit 制御をしたい場合は、
`ForEachAsync(..., autoCommit: false)` を利用します。

なお、`appsettings.json` に `EnableAutoCommit` を指定している場合は、その設定値が `autoCommit` より優先されます。

自動 commit を前提とする場合でも、明示的に .WithAutoCommit() を記述することで、
意図を明確にすることができます：

```csharp
public class MyKsqlContext : KsqlContext
{
    protected override void OnModelCreating(IModelBuilder modelBuilder)
    {
        modelBuilder.Entity<Order>();
    }
    // 手動コミット例
    public async Task ManualCommitExample()
    {
      var orders = context.Set<Order>();

      await orders.ForEachAsync(async order => {
        try
        {
            // メッセージ処理
            await ProcessOrder(order);

            // ✅ 処理成功時にコミット
            orders.Commit(order);

            Console.WriteLine($"Successfully processed and committed order: {order.Id}");
        }
        catch (Exception ex)
        {
            Console.WriteLine($"Failed to process order: {ex.Message}");
            throw;
        }
      }, autoCommit: false);
  }
  // retry例
  public async Task RetryManualCommitExample()
  {
    var orders = context.Set<Order>()
        .OnError(ErrorAction.Retry)  // ✅ リトライ設定
        .WithRetry(maxRetries: 3, retryInterval: TimeSpan.FromSeconds(2));

    await orders.ForEachAsync(async order => {
        try
        {
            await ProcessOrder(order);

            // ✅ 処理成功時にコミット
            orders.Commit(order);

            Console.WriteLine($"[{DateTime.UtcNow:HH:mm:ss}] SUCCESS: Order {order.Id} processed and committed");
        }
        catch (Exception ex)
        {
            // ✅ EventSetのRetry機能が働く（内部的にリトライ実行）
            // 最終的にリトライ失敗した場合のみここに到達
            Console.WriteLine($"[{DateTime.UtcNow:HH:mm:ss}] FINAL_FAILURE: Order processing failed after retries: {ex.Message}");
            throw;
        }
    }, autoCommit: false);
  }
}
```

## 7. View定義とToQuery DSL

`ToQuery` メソッドを用いると LINQ チェーンから `CREATE STREAM/TABLE AS SELECT` 文を生成できます。呼び出し順序は `From` → `Join?` → `Where?` → `Select` に固定され、JOIN は2テーブルまでがサポート対象です。結合条件は `Join` メソッド内で指定し、必要に応じて `Where` で追加のフィルタリングを行えます。構文は `ToQuery(...)` 内で検証されます。

```csharp
modelBuilder.Entity<OrderSummary>().ToQuery(q => q
    .From<Order>()
    .Join<Customer>((o, c) => o.CustomerId == c.Id)
    .Where((o, c) => c.IsActive)
    .Select((o, c) => new OrderSummary { OrderId = o.Id, CustomerName = c.Name }));
```

この `KsqlQueryModel` は `KsqlContext` 初期化時に KSQL の `CREATE STREAM/TABLE` 文として登録されます。

## 8. ウィンドウ・テーブル操作

⏳ Window 機能の設計

### 概要

KSQLにおけるWindow処理は、時間単位での集計や状態管理を行う際に使用されます。本OSSでは、LINQ構文からWindow処理に対応するDSLを提供し、Kafka Streamsによるウィンドウ処理のKSQL変換を自動化しています。

### 対象エンティティ

ウィンドウ処理は Set<T> に対して .Window(x) を指定することで適用され、内部的に WindowConfiguration として扱われます。
```
modelBuilder.Entity<Order>()
    .Window(new[] { 1, 5, 60 });
```

この設定により、1分足、5分足、60分足の3種類のウィンドウが定義され、各ウィンドウに対応する状態管理とKSQLクエリが生成されます。

🚩最重要パターン宣言

本OSSでは「1つのPOCO＋Window属性（例：WindowMinutes）」で1分足・5分足・60分足など“複数ウィンドウ集約”を一元管理する設計が王道です。

サンプルやサードパーティAIもこの設計をまず推奨・実装しています。

### Window Finalization

ウィンドウ処理で生成されたデータは、一定時間経過後に「確定」され、*_window_{minutes}_final 形式のトピックに書き出されます。確定処理は WindowFinalizationManager により管理され、以下の責務を持ちます：

- 複数のPODから送信された同一Windowキーのデータをマージ
- 指定分単位でタイマーを駆動し、該当Windowを確定
- KafkaトピックへFinalメッセージを書き込み

このとき、元のWindowデータとは異なるトピックに送信されるため、事前に _window_final トピックの作成が必要です。また、元のトピックに新しいデータが送られなくても、タイマーによりx分単位でFinalデータが自動生成されます。

初期化時、すべての _window_final トピックは EnsureWindowFinalTopicsExistAsync により事前に作成されます。この処理は OnModelCreating 後のステージで自動的に実行され、各エンティティの .Window(...) 設定に基づいて必要なFinalトピックを準備します。

### AvroTimestamp の利用

Window処理で使用される時間情報は、すべて AvroTimestamp 型で管理されます。これにより：

- Avroシリアライズ時のUTC変換とスキーマ整合性を確保
- WindowStart/End の精度と互換性を保証
- フィールドには [AvroTimestamp] 属性を付与
```

public class WindowedOrderSummary
{
    [AvroTimestamp]
    public DateTime WindowStart { get; set; }

    [AvroTimestamp]
    public DateTime WindowEnd { get; set; }

    public int Count { get; set; }
}
```

### 課題と補足

- .Window(...) で複数の粒度（例: 1, 5, 60分）を定義した場合、それぞれに対応する _
The file is too long and its contents have been truncated.

### tool — 2025-08-30T07:53:22.922449+00:00

Make sure to include `【message_idx†source】` markers to provide citations based on this file, where [message_idx] is provided at the beginning of this message
# Advanced Rules（詳細設計と運用ルール）

## 1. 本ドキュメントの位置付け

本ドキュメントは「getting-started.md」に記載された設計原則および構成ルールを前提とし、Kafka.Ksql.Linq OSSの**実装詳細・高度な設計思想・内部処理の挙動**を明文化するものです。

DSLや属性の基本的な使い方、アーキテクチャの理解を終えた上級開発者・運用担当者が、さらに深く制御や拡張を行うための参照資料として機能します。

---

## 2. クラス設計と可視性ポリシー

### 2.1 internal/public の役割整理

- APIとして外部に公開すべき型・拡張ポイント：`public`
- DSL内部の処理ロジック・変換パイプライン・State管理クラスなど：`internal`
- テストは公開インターフェース経由で実施、具象クラス直アクセス禁止

### 2.2 拡張ポイント

- `.OnError()` `.WithRetry()` は `IQueryable` 拡張で構成
- Window関連のDSLは `.Window(x)` 拡張として `IQueryable<POCO>` に統合
- 実行時のウィンドウ選択は `Set<T>().Window(x)` を使い `WindowMinutes` 直接指定は不要
- Fluent API の基本方針は [api_reference.md の Fluent API ガイドライン](./api_reference.md#fluent-api-guide) を参照してください。
- 主なメソッド一覧は [api_reference.md の Fluent API 一覧](./api_reference.md#fluent-api-list) にまとめています。

---

## 3. 型変換とスキーマ登録戦略（Avro連携）

-### 3.1 POCO → Avro スキーマ変換

- POCOに付与された属性（[KsqlDecimal], [KsqlDatetimeFormat] など）を読み取り、Avroスキーマを動的生成する。
- キー情報は DTO/POCO のプロパティ定義順から自動的に生成され、`Key` 属性は利用しない（詳細は [architecture_overview.md](./architecture_overview.md#poco%E8%A8%AD%E8%A8%88%E3%83%BBpk%E9%81%8B%E7%94%A8%E3%83%BB%E3%82%B7%E3%83%AA%E3%82%A2%E3%83%A9%E3%82%A4%E3%82%BA%E6%96%B9%E9%87%9D) を参照）。
- `SchemaRegistry.AutoRegisterSchemas = true` の場合、Kafka初回送信時に自動登録

### 3.2 変換時のマッピング規則

| POCO型                          | Avro型                                 | 備考             |
| ------------------------------ | ------------------------------------- | -------------- |
| `decimal` + [KsqlDecimal] | `bytes` + logicalType=decimal         | 精度・スケール付きで定義   |
| `DateTime`, `DateTimeOffset`   | `long` + logicalType=timestamp-millis | UTCに変換         |
| `string`, `Guid`               | `string`                              | Guidは文字列化      |
| `byte[]`                       | `bytes`                               | Avroのbinaryに対応 |

**Key schema に利用できる型は `int` `long` `string` `Guid` のみ。その他の型で GroupBy
を行う場合は、必ずこれらの型へ変換してから指定すること。**

### 3.3 スキーマレジストリの運用

- CI/CDパイプラインに統合し、スキーマ互換チェックをビルド時に実行
- `FORWARD` / `BACKWARD` / `FULL` の互換モードは明示指定
- 登録失敗時のフィードバックは詳細ログ出力（--verbose）で確認可能

### 3.4 Avroスキーマ命名規則と Namespace 管理

- スキーマの `Name` は **エンティティのクラス名** に対応させます。
- `Namespace` にはエンティティの名前空間を反映し、スキーマの一意性を担保します。
- トピック名を `Name` に含める設計は推奨されません。同一クラス名を複数トピックで使用する場合、Schema Registry 上で名前衝突が発生する可能性が高まります。
- 名前空間管理が不十分な場合は、トピック名などの接頭辞を `Namespace` 側に取り込む運用も検討してください。
- ユーザーは同一クラス名を再利用する際の衝突リスクを理解し、スキーマ管理体制を整備する必要があります。

### 3.5 NUL区切り文字列キー

`KeyValueTypeMapping.FormatKeyForPrefix` は Avro キーの `KeyProperties` を NUL (`\u0000`) で連結した文字列に変換し、`CombineFromStringKeyAndAvroValue` がこのキーと Avro value から POCO を復元します。`DateTime` は UTC の `yyyyMMdd'T'HHmmssfff'Z'` 形式でソート性を保ちます。

---

## 4. Finalトピック生成とWindow処理のタイマー駆動
### 4.1 Window処理

  🚩【最重要パターン宣言】
  本OSSのウィンドウ集約設計は「1つのPOCO＋Window属性で多足集約を一元管理」が基本方針です。
  型設計・APIサンプル・高度な応用もまずこの方式を優先してください。

複数時間足を扱う際は専用のPOCOを分ける必要はありません。以下のように `Window()` 拡張と
`WindowMinutes` プロパティを組み合わせることで、1つのエンティティで任意の足を処理できます。

```csharp
modelBuilder.Entity<RateCandle>()
    .ToQuery(q => q
        .From<Rate>()
        .Window(new[] { 1, 5, 15, 60 })
        .GroupBy(r => r.Symbol)
        .Select(g => new RateCandle { /* 集約ロジック */ }));
```

`ToQuery` DSL は JOIN を最大 2 テーブルまでサポートし、結合条件は `Join` メソッド内で指定します。必要に応じて追加のフィルタリングを `Where` で行えます。

実行時に特定の足だけを処理したい場合は `Set<T>().Window(5)` のように分岐させます。


### 4.2 Finalトピックの命名と作成およびRocksDBとの関係

- `{EntityName}_{Window}min_final` を基本命名規則とする

- 各Windowごとに1つのStateStore（RocksDBインスタンス）が構築され、ウィンドウ確定タイミングでその内容がFinalトピックに出力される

- StateStoreはアプリ内の状態保持に使われ、集計済みの結果は `WindowFinalizationManager` によりローカル→Kafkaへ出力される

- Final用のRocksDBは `rocksdb/final/{Entity}_{Window}min_Store/` に作成される（通常のStateStoreとは別ディレクトリ）

- キャッシュ（EnableCache）がONの場合、最新状態をメモリ保持するためファイルサイズは減少傾向にあるが、OFFの場合は全状態を永続化するためファイルサイズが大きくなる傾向がある

- アプリ起動時に `EnsureWindowFinalTopicsExistAsync` により全トピック事前作成

- `{EntityName}_{Window}min_final` を基本命名規則とする

- 各Windowごとに1つのStateStore（RocksDBインスタンス）が構築され、ウィンドウ確定タイミングでその内容がFinalトピックに出力される

- StateStoreはアプリ内の状態保持に使われ、集計済みの結果は `WindowFinalizationManager` によりローカル→Kafkaへ出力される

- アプリ起動時に `EnsureWindowFinalTopicsExistAsync` により全トピック事前作成

### 4.3 Final出力の特徴とGap対応

- TickがなくてもWindow終了時刻に自動出力されることで、“Gap”（空白期間）を補完し、時系列の連続性を保つ
- Gapとは、トピックにイベントが流れない時間帯においてもウィンドウ処理が時間軸上で欠損しないようにするための、明示的な“空の足”データを指します
- Finalデータは `WindowedResult` POCOをAvro化し、別トピックに出力
- 例：`orders_5min_final` トピックに `OrderCandle` 出力

---

## 5. DLQ設計とエラーハンドリング

### 5.1 DLQの設計思想

- すべてのエラーは `ErrorAction.DLQ` により集約的にDLQトピックへ送信可能
- DLQトピックは1系統（例：`dead-letter-queue`）を共通で使用
- メッセージには `sourceTopic`, `errorCode`, `exception` などのメタ情報付与

### 5.2 DLQ構成例

```json
"DlqOptions": {
  "RetentionMs": 5000,
  "NumPartitions": 1,
  "ReplicationFactor": 1,
  "EnableAutoCreation": true
}
```

> ※ RetentionMs のデフォルト値は 5000（5秒）です。これでは短すぎるケースも多いため、必要に応じて明示的に設定を行ってください。

---
## 6. 可観測性・メトリック運用指針 / Observability & Metrics

### 6.1 メトリック設計方針

本OSSでは、Kafkaやストリーム処理に関連するメトリック収集は**Confluent公式クライアントパッケージ（Confluent.Kafka）**側の機能を利用する方針とします。  
OSS本体はアプリケーション側の運用情報・エラー通知等を**ILogger等の標準ロギング機構**で出力します。
ログメッセージの表記ルールは [logging_guidelines.md](logging_guidelines.md) を参照してください。

- Kafkaパフォーマンス・レイテンシ・メッセージ数などの詳細メトリックは、Confluent.Kafkaが標準で提供する監視API・メトリック機能を活用してください。
- OSS本体で追加するのは「運用ログ（状態・エラー・イベント）」のみです。
- 独自メトリック追加が必要な場合は、ILoggerのログ集約または外部監視ツールと連携する拡張で対応します。

**参考：Confluent.Kafkaの公式メトリック／監視ガイドを参照のこと**

## 7. ストリーム/テーブルの自動判定と明示オーバーライド

- `GroupBy`, `Aggregate`, `Window` を含むLINQ式はテーブルと判定
- `AsStream()`, `AsTable()` は判定ロジックを上書き
- `AsPush()`, `AsPull()` でクエリの実行モードを強制（未指定時は `Unspecified` として扱い、Pull クエリ制約違反検知時に自動で Push へ切り替え）
- 判定結果は `.Explain()` や `ILogger` に出力可能（開発支援）

---

## 8. CI/CDおよび検証モード

- `ValidationMode: Strict` によりDSL構文とPOCO定義を初期化時に厳格チェック
- `GroupBy`/`Join` のキー順と DTO/POCO の定義順を照合し、相違があれば
  `InvalidOperationException` を発生させる。メッセージは
  "GroupByキーの順序と出力DTOの定義順が一致していません。必ず同じ順序にしてください。"
- CI環境では構文検証モードを利用し、Kafka未接続状態でDSL整合性確認
- 初期化失敗はビルド失敗とみなす

---

## 9. デフォルト構成と運用ルール

### 9.1 RocksDBの配置と構成

- StateStoreはローカルファイルとして `rocksdb/{Entity}_{Window}min_Store/` に配置される
- アプリケーション実行ディレクトリ内に階層構造で保存（実体はleveldb/rocksdbによる）
- コンパクションポリシー：デフォルトで `compact` モードが有効

### 9.2 Kafka関連のデフォルト設定

- パーティション数：設定がなければ `1`
- ReplicationFactor：設定がなければ `1`
- GroupId：`KsqlDsl_{EntityName}` が自動割当（手動設定可能）
- AutoOffsetReset：`Latest` がデフォルト

---

## 10. 用語定義と今後の拡張予定

- `WindowFinalizationManager`: Window終了時刻に自動出力を行う内部クラス
- `EventSet<T>.Commit(T entity)`: 手動コミット用メソッド
- `WithRetry`, `OnError`: DSLの拡張ポイント

今後追加予定：

- RetryBackoff, DeadLetterRetry, Topic間リレーション設計
- クエリのExplain
The file is too long and its contents have been truncated.

### tool — 2025-08-30T07:53:22.932116+00:00

Make sure to include `【message_idx†source】` markers to provide citations based on this file, where [message_idx] is provided at the beginning of this message
## ⚙️ Kafka.Ksql.Linq appsettings.json 構成仕様

Kafka.Ksql.Linq では、`appsettings.json` を通じて柔軟なDSL設定が可能です。以下はその構成要素と意味です。
標準的なデフォルト値は `examples/configuration/appsettings.json` にまとめられています。

---

### 1 📐 基本構造

```json
{
  "KsqlDsl": {
    "ValidationMode": "Strict|Relaxed",
    "Common": { /* 共通設定 */ },
    "Topics": { /* トピック別設定 */ },
    "SchemaRegistry": { /* スキーマレジストリ設定 */ },
    "TableCache": [ /* エンティティ／キャッシュ設定 */ ],
    "DlqTopicName": "dead-letter-queue",
    "DlqOptions": { /* DLQ トピック設定 */ },
    "DeserializationErrorPolicy": "Skip|Retry|DLQ",
    "ReadFromFinalTopicByDefault": false,
    "DecimalPrecision": 38,
    "DecimalScale": 9
  }
}
```

---

### 🧱 1.1 Common（共通Kafka設定）

| 項目 | 説明 |
|------|------|
| `BootstrapServers` | Kafkaブローカーの接続先 |
| `ClientId` | 接続クライアント識別子 |
| `RequestTimeoutMs` | Kafka操作タイムアウト（ms） |
| `MetadataMaxAgeMs` | メタデータの最大有効期間（ms） |
| `SecurityProtocol` | `Plaintext` / `SaslPlaintext` など |
| `SaslMechanism` | 認証方式（例：`Plain`, `ScramSha256`） |
| `SaslUsername`, `SaslPassword` | SASL認証情報 |
| `SslCaLocation` | CA証明書ファイルパス |
| `SslCertificateLocation` | クライアント証明書ファイルパス |
| `SslKeyLocation` | 秘密鍵ファイルパス |
| `SslKeyPassword` | 秘密鍵パスワード |
| `AdditionalProperties` | 追加Kafka設定（key-value） |

```json
"Common": {
  "BootstrapServers": "localhost:9092",
  "ClientId": "ksql-dsl-client",
  "RequestTimeoutMs": 30000,
  "MetadataMaxAgeMs": [[REDACTED_PHONE]],
  "SecurityProtocol": "Plaintext",
  "SaslMechanism": "Plain",
  "SaslUsername": "user",
  "SaslPassword": "pass",
  "SslCaLocation": "/path/ca.pem",
  "SslCertificateLocation": "/path/cert.pem",
  "SslKeyLocation": "/path/key.pem",
  "SslKeyPassword": "secret",
  "AdditionalProperties": {}
}
```

---

### 📦 1.2 Topics（トピックごとの詳細設定）

Producer の設定は `Kafka.Ksql.Linq.Configuration.Messaging.ProducerSection`、
Consumer の設定は `ConsumerSection` クラスにそれぞれマッピングされます。
アプリ設定ファイルの項目名とクラスプロパティが 1 対 1 で対応するため、
カスタム設定を追加する際はこれらのクラスを拡張してください。

```json
"Topics": {
  "my-topic": {
    "Producer": {
      "Acks": "All",
      "CompressionType": "Snappy",
      "EnableIdempotence": true,
      "MaxInFlightRequestsPerConnection": 1,
      "LingerMs": 5,
      "BatchSize": 16384,
      "DeliveryTimeoutMs": [[REDACTED_PHONE]],
      "RetryBackoffMs": 100,
      "Retries": [[REDACTED_PHONE]],
      "BufferMemory": [[REDACTED_PHONE]],
      "Partitioner": null
    },
    "Consumer": {
      "GroupId": "my-group",
      "AutoOffsetReset": "Latest",
      "EnableAutoCommit": true,
      "AutoCommitIntervalMs": 5000,
      "SessionTimeoutMs": 30000,
      "HeartbeatIntervalMs": 3000,
      "MaxPollIntervalMs": [[REDACTED_PHONE]],
      "MaxPollRecords": 500,
      "FetchMinBytes": 1,
      "FetchMaxWaitMs": 500,
      "FetchMaxBytes": [[REDACTED_PHONE]],
      "PartitionAssignmentStrategy": null,
      "IsolationLevel": "ReadUncommitted"
    },
    "Creation": {
      "NumPartitions": 1,
      "ReplicationFactor": 1,
      "Configs": {},
      "EnableAutoCreation": false
    }
  }
}
```

| Producer設定 | 説明 |
|------------------|------|
| `Acks` | 書き込み応答の強度設定（例：`All`, `1`） |
| `CompressionType` | 圧縮方式（`Snappy`, `Gzip`, `Lz4`など） |
| `EnableIdempotence` | 冪等性設定（重複防止） |
| `MaxInFlightRequestsPerConnection` | 同時送信要求上限 |
| `LingerMs` | バッチ送信待機時間（ms） |
| `BatchSize` | バッチ書き込み単位（byte） |
| `DeliveryTimeoutMs` | 配信タイムアウト（ms） |
| `RetryBackoffMs` | リトライ待機時間（ms） |
| `Retries` | 最大リトライ回数 |
| `BufferMemory` | 送信バッファサイズ（byte） |
| `Partitioner` | パーティショナー指定 |
| `AdditionalProperties` | 追加Producer設定 |

| Consumer設定 | 説明 |
|------------------|------|
| `GroupId` | コンシューマーグループID |
| `AutoOffsetReset` | `Latest` or `Earliest` |
| `EnableAutoCommit` | 自動コミット可否。`ForEachAsync` の `autoCommit` より優先 |
| `AutoCommitIntervalMs` | 自動コミット間隔(ms) |
| `SessionTimeoutMs` | セッションタイムアウト(ms) |
| `HeartbeatIntervalMs` | ハートビート送信間隔(ms) |
| `MaxPollIntervalMs` | 最大ポーリング間隔(ms) |
| `MaxPollRecords` | 最大ポーリングレコード数 |
| `FetchMinBytes` | フェッチ最小バイト数 |
| `FetchMaxWaitMs` | フェッチ最大待機(ms) |
| `FetchMaxBytes` | フェッチ最大バイト数 |
| `PartitionAssignmentStrategy` | パーティション割当戦略 |
| `IsolationLevel` | アイソレーションレベル |
| `AdditionalProperties` | 追加Consumer設定 |

---

### 🧬 1.3 SchemaRegistry（スキーマレジストリ設定）

```json
"SchemaRegistry": {
  "Url": "http://localhost:8081",
  "MaxCachedSchemas": 1000,
  "RequestTimeoutMs": 30000,
  "BasicAuthUserInfo": "user:pass",
  "BasicAuthCredentialsSource": "UserInfo",
  "AutoRegisterSchemas": true,
  "LatestCacheTtlSecs": 300,
  "SslCaLocation": "/path/ca.pem",
  "SslKeystoreLocation": "/path/keystore.p12",
  "SslKeystorePassword": "secret",
  "SslKeyPassword": "secret",
  "AdditionalProperties": {}
}
```

| 項目 | 説明 |
|------|------|
| `Url` | スキーマレジストリURL |
| `MaxCachedSchemas` | クライアント側でキャッシュする最大スキーマ数 |
| `RequestTimeoutMs` | リクエストタイムアウト(ms) |
| `BasicAuthUserInfo` | Basic認証用クレデンシャル（形式：`user:pass`） |
| `BasicAuthCredentialsSource` | `UserInfo` or `SaslInherit` |
| `AutoRegisterSchemas` | スキーマを自動登録するかどうか |
| `LatestCacheTtlSecs` | 最新スキーマキャッシュTTL(sec) |
| `SslCaLocation` | CA証明書パス |
| `SslKeystoreLocation` | キーストア(PKCS#12)パス |
| `SslKeystorePassword` | キーストアパスワード |
| `SslKeyPassword` | 秘密鍵パスワード |
| `AdditionalProperties` | 追加設定 |

---

### 🏪 1.4 TableCache（テーブルキャッシュ設定）

```json
"TableCache": [
  {
    "Entity": "OrderEntity",
    "SourceTopic": "orders",
    "EnableCache": true,
    "Windows": [5, 15, 60],
    "StoreName": "orders_store",
    "BaseDirectory": "/var/lib/ksql_cache"
  }
]
```

| 項目 | 説明 |
|------|------|
| `Entity` | 対象POCOクラス名 |
| `SourceTopic` | 入力元となるKafkaトピック名 |
| `EnableCache` | キャッシュ有効化（bool） |
| `Windows` | タンブリングウィンドウサイズ（整数：分単位） |
| `StoreName` | キャッシュ名（省略時はトピック名を基に自動生成） |
| `BaseDirectory` | RocksDBディレクトリのルートパス |

---

### 🛡️ 1.5 ValidationMode

| 値 | 説明 |
|-----|------|
| `Strict` | 起動時に全構成値を検証。欠落や不整合があるとエラー（推奨） |
| `Relaxed` | 柔軟に読み込む。テスト・一時構成に使用可 |

```json
"ValidationMode": "Strict"
```

---

### 💌 1.6 DLQ 設定

```json
"DlqTopicName": "dead-letter-queue",
"DlqOptions": {
  "RetentionMs": 5000,
  "NumPartitions": 1,
  "ReplicationFactor": 1,
  "EnableAutoCreation": true,
  "AdditionalConfigs": {
    "cleanup.policy": "delete"
  }
}
```

未指定の場合、`DlqTopicName` は `dead-letter-queue` が使用されます。

| 項目 | 説明 |
|------|------|
| `DlqTopicName` | DLQ用トピック名 |
| `RetentionMs` | メッセージ保持時間(ms) |
| `NumPartitions` | パーティション数 |
| `ReplicationFactor` | レプリケーション係数 |
| `EnableAutoCreation` | 自動作成を行うか |
| `AdditionalConfigs` | 追加トピック設定 |

---

### ⚙️ 1.7 その他オプション

| 項目 | 説明 |
|------|------|
| `DeserializationErrorPolicy` | `Skip` / `Retry` / `DLQ` のエラーハンドリング方針 |
| `ReadFromFinalTopicByDefault` | Finalトピックを既定で参照するか |
| `DecimalPrecision` | decimal型のprecisionを一括設定 |
| `DecimalScale` | decimal型のscaleを一括設定 |

### 🧩 DSL記述とappsettingsの対応関係

| Kafka設定項目             | DSLでの指定                          | appsettings.jsonキー                         | 補足説明 |
|----------------------------|--------------------------------------|---------------------------------------------|--------|
| Bootstrap Servers          | なし                                 | `Kafka:BootstrapServers`                   | Kafka接続先クラスタ |
| Schema Registry URL       | なし                                 | `KsqlDsl:SchemaRegistry:Url`              | POCOスキーマ自動登録時に使用 |
| ksqlDB URL                | なし                                 | `KsqlDsl:KsqlDbUrl`                       | ksqlDB RESTエンドポイント |
| Auto Offset Reset | `.WithAutoOffsetReset(...)` | `Kafka:Consumers.<name>.AutoOffsetReset` | トピックごとの既読位置制御（複数可） | 通常は `earliest` or `latest` |
| GroupId | `.WithGroupId(...)` | `Kafka:Consumers.<name>.GroupId` | コンシューマグループID（複数可） | コンシューマグループID |
| トピック名                 | `[KsqlTopic("orders")]`             | `KsqlDsl:Topics.orders` で上書き可         | 属性またはFluent APIで指定 |
| パーティション数           | `[KsqlTopic("orders", PartitionCount = 12)]` | `KsqlDsl:Topics.orders.NumPartitions` 等    | DSLと設定の併用可能 |
| Replication Factor        | なし（構成ファイルで指定）          | `KsqlDsl:Topics.orders.ReplicationFactor`  | Kafkaクラスタ構成に依存 |
| DLQ構成                    | `.OnError(ErrorAction.DLQ)`          | `KsqlDsl:DlqTopicName`, `DlqOptions` | DLQの有効化、保持期間指定など |
| Windowサイズ               | `.Window(new[] { 5, 15, 60 })`       | `KsqlDsl:Entities[].Windows`              | DSL/設定どちらでも指定可（整合性が必要） |

---

### 📦 2. 実装例との対応（MyKsqlContext & Order & OrderCount）

```csharp
public class Order
{ 
    public string ProductId { get; set; }
    public decimal Amount { get; set; }
}

public class MyKsqlContext : KsqlContext
{
    protected override void OnModelCreating(KsqlModelBuilder modelBuilder)
{
    modelBuilder.Entity<Order>()
        .WithGroupId("orders-consumer")
        .WithAutoOffsetReset(AutoOffsetReset.Earliest)
        .Window(new[] { 5 });

    modelBuilder.Entity<OrderCount>()
        .WithGroupId("order-counts-consumer")
        .WithAutoOffsetReset(AutoOffsetReset.Latest)
        .UseFinalTopic();
});
    }
}
```

```json
{
  "Kafka": {
    "BootstrapServers": "localhost:9092",
    "Consumers": {
      "orders-consumer": {
        "GroupId": "orders-consumer",
        "AutoOffsetReset": "earliest"
      },
      "order-counts-consumer": {
        "GroupId": "order-counts-consumer",
        "AutoOffsetReset": "latest"
      }
    }
  },
  "KsqlDsl": {
    "SchemaRegistry": {
      "Url": "http://localhost:8081"
    },
    "KsqlDbUrl": "http://localhost:8088",
    "Topics":
The file is too long and its contents have been truncated.

### tool — 2025-08-30T07:53:22.939665+00:00

Make sure to include `【message_idx†source】` markers to provide citations based on this file, where [message_idx] is provided at the beginning of this message
# API Reference

`Kafka.Ksql.Linq` の公開 DSL/API を使用頻度の高い順にまとめたリファレンスです。

## 目次
- [属性 (Attributes)](#%E5%B1%9E%E6%80%A7-attributes)
- [Fluent API](#fluent-api)
  - [ToQuery チェーン](#toquery-%E3%83%81%E3%82%A7%E3%83%BC%E3%83%B3)
- [LINQ 風 DSL](#linq-%E9%A2%A8-dsl)
- [エラーハンドリング](#%E3%82%A8%E3%83%A9%E3%83%BC%E3%83%8F%E3%83%B3%E3%83%89%E3%83%AA%E3%83%B3%E3%82%B0)
- [コアインタフェース](#%E3%82%B3%E3%82%A2%E3%82%A4%E3%83%B3%E3%82%BF%E3%83%95%E3%82%A7%E3%83%BC%E3%82%B9)
- [構成オプションとビルダー](#%E6%A7%8B%E6%88%90%E3%82%AA%E3%83%97%E3%82%B7%E3%83%A7%E3%83%B3%E3%81%A8%E3%83%93%E3%83%AB%E3%83%80%E3%83%BC)
- [既定値の参照](#%E6%97%A2%E5%AE%9A%E5%80%A4%E3%81%AE%E5%8F%82%E7%85%A7)

## 属性 (Attributes)

POCO モデルで最も利用される属性です。

| 属性 | 役割 | 主な引数 | 備考 |
|------|------|----------|------|
| `KsqlTopicAttribute` | トピック名・パーティション・レプリケーション指定 | `name`, `PartitionCount`, `ReplicationFactor` | モデルのトピックを構成し、設定より優先されます。 |
| `KsqlKeyAttribute` | 複合キー順序の定義 | `order` | 小さい順にキーが並びます。 |
| `KsqlDecimalAttribute` | `decimal` 型の精度とスケール指定 | `precision`, `scale` | Avro の `bytes` (logicalType: decimal) として生成。 |
| `KsqlDatetimeFormatAttribute` | 日時文字列の解析フォーマット | `format` | `DateTime.ParseExact` 互換。 |
| `KsqlTimestampAttribute` | イベントタイムとなるプロパティを指定 | - | `ROWTIME` の代替に利用。 |
| `KsqlStreamAttribute` | クラスを Stream として扱う | - | 明示指定が必要な場合のみ使用。 |
| `KsqlIgnoreAttribute` | スキーマから除外 | - | 無視するプロパティに付与。 |
| `MaxLengthAttribute` | 文字列長制限 | `length` | 超過時は例外。 |
| `ScheduleRangeAttribute` | 開始・終了プロパティ名の対指定 | `openPropertyName`, `closePropertyName` | 取引時間帯などの範囲指定。 |


## Fluent API

エンティティの登録やクエリ構築を行うための API です。

| メソッド | 説明 | 主なパラメータ |
|----------|------|----------------|
| `Entity<T>(readOnly = false, writeOnly = false)` | エンティティを登録しアクセスモードを指定 | `readOnly`, `writeOnly` |
| `.AsStream()` | ストリームとして登録 | - |
| `.AsTable(topicName = null, useCache = true)` | テーブルとして登録 | `topicName`, `useCache` |
| `.ToQuery(build)` | 新 DSL でビュー定義 | `build`: `From`/`Join`/`Where`/`Select` を連鎖 |

### Fluent API ガイドライン

1. `[KsqlTopic]` や `[KsqlKey]` などの属性でスキーマ情報を宣言。
2. Fluent API はクエリ構築やモード指定に限定し、スキーマ設定は属性へ集約。
3. エンティティ登録時は `readOnly`/`writeOnly`/`readwrite` の 3 種類。未指定は `readwrite`。

#### 推奨記述例

```csharp
[KsqlTopic("orders")]
public class Order
{
    ...
    builder.Entity<Order>(writeOnly: true);
}
```

#### 既存 POCO → Fluent API 移行フロー

1. POCO へ `[KsqlTopic]` と `[KsqlKey]` を付与。
2. `OnModelCreating` では `Entity<T>()` の登録のみ行う。
3. テストでキー順序やトピック設定を確認。

### ToQuery チェーン

View 定義専用の Fluent API です。

| メソッド | 説明 | 主なパラメータ | 注意点 |
|----------|------|----------------|--------|
| `.From<T>()` | ビュー定義の開始 | - | - |
| `.Join<T2>(condition)` | 2 テーブルまでの内部結合 | `(left, right) => bool` | 後続に `.Where` 必須 |
| `.Where(predicate)` | 結合条件やフィルタ | `predicate`: bool 条件式 | `.Join` 使用時は必須 |
| `.Select(selector)` | 投影 | `selector`: 出力構造 | 呼び出し順序は `From`→`Join?`→`Where`→`Select` |

```csharp
modelBuilder.Entity<OrderSummary>().ToQuery(q => q
    .From<Order>()
    .Join<Customer>((o, c) => o.CustomerId == c.Id)
    .Where((o, c) => c.IsActive)
    .Select((o, c) => new OrderSummary { OrderId = o.Id, CustomerName = c.Name }));
```

`.ToQuery(...)` で得られた `KsqlQueryModel` は `CREATE STREAM/TABLE AS SELECT` 文として利用されます。

## LINQ 風 DSL

ストリーム/テーブル共通のクエリ操作を提供します。

| DSL メソッド | 説明 | 戻り値型 | 対象レイヤ | 主なパラメータ | 実装状態 |
|--------------|------|----------|------------|----------------|---------|
| `.Where(predicate)` | 条件フィルタ | `IEventSet<T>` | Stream/Table | `predicate`: bool 式 | ✅ |
| `.GroupBy(keySelector)` | グループ化と集約 | `IEventSet<IGrouping<TKey,T>>` | Stream/Table | `keySelector` | ✅ |
| `.OnError(action)` | エラー処理方針 | `EventSet<T>` | Stream | `Skip`/`Retry`/`DLQ` | ✅ |
| `.WithRetry(count)` | リトライ設定 | `EventSet<T>` | Stream | `count`: 最大回数 | ✅ |
| `.StartErrorHandling()` | エラーチェーン開始 | `IErrorHandlingChain<T>` | Stream | - | ✅ |
| `.Limit(count)` | **保持件数制限** | `IEntitySet<T>` | Table | `count`: 上限件数 | ✅ |

- `ToList`/`ToListAsync` は Pull Query として実行されます。
- `ForEachAsync(..., autoCommit: false)` では `Commit(entity)` による手動コミットが必要です。
- `autoCommit` 既定値は `true` で、`ConsumerConfig.EnableAutoCommit` により自動コミットされます。
- `ctx.Set<DlqEnvelope>()` で DLQ ストリーム取得。`Take()` や `ToListAsync()` は利用不可。

### ForEachAsync の dummy メッセージ扱い（仕様差分）

- 非ヘッダ版 `ForEachAsync(Func<T, Task>)`：`is_dummy=true` のメッセージはスキップします。
- ヘッダ版 `ForEachAsync(Func<T, Dictionary<string,string>, MessageMeta, Task>)`：`is_dummy=true` も処理に渡されます（ヘッダ参照用途）。
- 互換性: 既存コードの挙動は非ヘッダ版のまま維持されます。

## エラーハンドリング

| API / Enum | 説明 | 実装状態 |
|------------|------|---------|
| `ErrorAction` (`Skip`/`Retry`/`DLQ`) | 基本アクション | ✅ |
| `ErrorHandlingPolicy` | リトライ回数やカスタムハンドラ設定 | ✅ |
| `ErrorHandlingExtensions` | `.OnError()` `.WithRetryWhen()` など | ✅ |
| `DlqProducer` / `DlqEnvelope` | DLQ 送信処理 | ✅ |
| `DlqOptions` | DLQ トピックの保持期間等 | ✅ |

### DLQ Read API（Avro 固定）

```csharp
public interface IKsqlContext
{
    IDlqClient Dlq { get; }
}

public interface IDlqClient
{
    IAsyncEnumerable<DlqRecord> ReadAsync(
        DlqReadOptions? options = null,
        CancellationToken ct = default);
}
```

**使い方サンプル**

```csharp
await foreach (var rec in ctx.Dlq.ReadAsync())
{
    Console.WriteLine(rec.RawText);
}
```

**仕様**

- `FromBeginning=true` で earliest へシーク。
- `CommitOnRead=true` で 1 件ごとにコミット。
- Avro ワイヤフォーマットから RawText を可読化。

**既知の制約**

- `PayloadFormat` は常に `"avro"`。
- 再投函は非対応（読むだけ）。

## コアインタフェース

| インタフェース | 説明 | 主な実装 |
|----------------|------|----------|
| `IKsqlContext` | KSQL 操作の起点となるコンテキスト。エンティティ登録やクエリ実行を司る。 | `KsqlContext`, `KafkaContextCore` |
| `IEventSet<T>` | ストリーム/テーブル共通のクエリ操作を定義。 | `EventSet<T>` |
| `IErrorHandlingChain<T>` | エラー処理を段階的に構築するチェーン。 | `ErrorHandlingChain<T>` |
| `IDlqClient` | DLQ からレコードを非同期で読み取るクライアント。 | `DlqClient` |
| `ITableCache<T>` | キー前方一致によるキャッシュ参照を提供。 | `TableCache<T>` |

## 構成オプションとビルダー

| API | 説明 | 実装状態 |
|-----|------|---------|
| `KsqlDslOptions` | DLQ 設定や ValidationMode など DSL 全体の構成を保持 | ✅ |
| `ModelBuilder` | POCO から `EntityModel` を構築するビルダー | ✅ |
| `KafkaAdminService` | DLQ トピック作成などの管理操作 | ✅ |
| `AvroOperationRetrySettings` | Avro 操作ごとのリトライ設定 | ✅ |
| `AvroRetryPolicy` | リトライ回数や遅延などのポリシー | ✅ |

`KsqlDslOptions.DlqTopicName` は既定で `"dead-letter
The file is too long and its contents have been truncated.

### tool — 2025-08-30T07:53:22.946983+00:00

Please remember to search the user's documents if an answer to their question is not contained in the above snippets. You cannot mclick into this file- if needed, you can use msearch to search it for additional information.
