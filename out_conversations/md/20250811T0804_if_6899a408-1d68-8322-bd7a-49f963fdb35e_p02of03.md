---
conversation_id: "6899a408-1d68-8322-bd7a-49f963fdb35e"
title: "if条件改善案"
create_time: 1754899494.597029
update_time: 1754914148.442342
language_guess: "en"
num_messages: 365
part_index: 2
part_count: 3
---

### tool — 2025-08-11T09:35:41.455998+00:00

91                         ["processing_phase"] = "ForEachAsync"
119             throw new InvalidOperationException("ToListAsync() is not supported on a Stream source. Use ForEachAsync or subscribe for event consumption.");
165     /// REDESIGNED: ForEachAsync supporting continuous Kafka consumption
168     public virtual Task ForEachAsync(Func<T, Task> action, TimeSpan timeout = default, CancellationToken cancellationToken = default)
173         return ForEachAsync((item, headers, _) => action(item), timeout, cancellationToken);
176     [Obsolete("Use ForEachAsync(Func<T, Dictionary<string,string>, MessageMeta, Task>)")]
177     public virtual Task ForEachAsync(Func<T, Dictionary<string,string>, Task> action, TimeSpan timeout = default, CancellationToken cancellationToken = default)
178         => ForEachAsync((e, h, _) => action(e, h), timeout, cancellationToken);
180     public virtual async Task ForEachAsync(Func<T, Dictionary<string,string>, MessageMeta, Task> action, TimeSpan timeout = default, CancellationToken cancellationToken = default)
260                 ["processing_phase"] = "ForEachAsync",
277     public virtual async IAsyncEnumerable<object> ForEachAsync([EnumeratorCancellation] CancellationToken cancellationToken = default)
566             throw new InvalidOperationException("ToListAsync() is not supported on a Stream source. Use ForEachAsync or subscribe for event consumption.");
### assistant — 2025-08-11T09:35:42.585626+00:00

print('\n'.join(lines[150:220]))
### tool — 2025-08-11T09:35:45.723471+00:00

/// <summary>
    /// Retrieves messages from the underlying consumer.
    /// Separated for ease of testing.
    /// </summary>
    /// <param name="context">Active KsqlContext</param>
    /// <param name="cancellationToken">Cancellation token</param>
    /// <returns>Message stream with headers</returns>
    protected virtual IAsyncEnumerable<(T Entity, Dictionary<string, string> Headers, MessageMeta Meta)> ConsumeAsync(
        KsqlContext context,
        CancellationToken cancellationToken)
    {
        return context.GetConsumerManager().ConsumeAsync<T>(cancellationToken);
    }
    /// <summary>
    /// REDESIGNED: ForEachAsync supporting continuous Kafka consumption
    /// Design change: ToListAsync() is disallowed; now based on GetAsyncEnumerator
    /// </summary>
    public virtual Task ForEachAsync(Func<T, Task> action, TimeSpan timeout = default, CancellationToken cancellationToken = default)
    {
        if (action == null)
            throw new ArgumentNullException(nameof(action));

        return ForEachAsync((item, headers, _) => action(item), timeout, cancellationToken);
    }

    [Obsolete("Use ForEachAsync(Func<T, Dictionary<string,string>, MessageMeta, Task>)")]
    public virtual Task ForEachAsync(Func<T, Dictionary<string,string>, Task> action, TimeSpan timeout = default, CancellationToken cancellationToken = default)
        => ForEachAsync((e, h, _) => action(e, h), timeout, cancellationToken);

    public virtual async Task ForEachAsync(Func<T, Dictionary<string,string>, MessageMeta, Task> action, TimeSpan timeout = default, CancellationToken cancellationToken = default)
    {
        if (action == null)
            throw new ArgumentNullException(nameof(action));

        var context = GetContext() as KsqlContext
            ?? throw new InvalidOperationException("KsqlContext is required");

        using var linkedCts = CancellationTokenSource.CreateLinkedTokenSource(cancellationToken);

        if (timeout != default && timeout != TimeSpan.Zero)
        {
            linkedCts.CancelAfter(timeout);
        }
        await foreach (var (entity, headers, meta) in ConsumeAsync(context, linkedCts.Token))
        {
            if (headers.TryGetValue("is_dummy", out var dummyHeader) && bool.TryParse(dummyHeader, out var isDummy) && isDummy)
            {
                continue;
            }

            var maxAttempts = _errorHandlingContext.ErrorAction == ErrorAction.Retry
                ? _errorHandlingContext.RetryCount + 1
                : 1;

            for (var attempt = 1; attempt <= maxAttempts; attempt++)
            {
                try
                {
                    await action(entity, headers, meta);
                    break;
                }
                catch (Exception ex)
                {
                    _errorHandlingContext.CurrentAttempt = attempt;

                    if (attempt < maxAttempts && _errorHandlingContext.ErrorAction == ErrorAction.Retry)
                    {
                        await Task.Delay(_errorHandlingContext.RetryInterval, linkedCts.Token);
                        continue;
### assistant — 2025-08-11T09:35:46.822441+00:00

print('\n'.join(lines[260:320]))
### tool — 2025-08-11T09:35:47.606911+00:00

["processing_phase"] = "ForEachAsync",
                ["timestamp"] = DateTime.UtcNow
            }
        };
    }

    /// <summary>
    /// Creates a ManualCommitMessage instance
    /// </summary>
    protected virtual IManualCommitMessage<T> CreateManualCommitMessage(T item)
    {
        return new ManualCommitMessage<T>(item, () => Task.CompletedTask, () => Task.CompletedTask);
    }

    /// <summary>
    /// Yields messages as different types depending on UseManualCommit
    /// </summary>
    public virtual async IAsyncEnumerable<object> ForEachAsync([EnumeratorCancellation] CancellationToken cancellationToken = default)
    {
        await foreach (var item in GetAsyncEnumeratorWrapper(cancellationToken))
        {
            if (_entityModel.UseManualCommit)
            {
                yield return CreateManualCommitMessage(item);
            }
            else
            {
                yield return item;
            }
        }
    }

    /// <summary>
    /// Configure the error handling policy
    /// </summary>
    internal virtual EventSet<T> WithErrorPolicy(ErrorHandlingPolicy policy)
    {
        if (policy == null)
            throw new ArgumentNullException(nameof(policy));

        _errorHandlingContext.ErrorAction = policy.Action;
        _errorHandlingContext.RetryCount = policy.RetryCount;
        _errorHandlingContext.RetryInterval = policy.RetryInterval;
        _errorHandlingContext.CustomHandler = policy.CustomHandler;

        return this;
    }

    public override string ToString()
    {
        return $"EventSet<{typeof(T).Name}> - Topic: {GetTopicName()}";
    }



    /// <summary>
    /// Specifies the number of retries.
    /// Used when ErrorAction.Retry is selected.
    /// </summary>
    /// <param name="maxRetries">Maximum retry count</param>
### assistant — 2025-08-11T09:35:48.721306+00:00

print('\n'.join(lines[320:380]))
### tool — 2025-08-11T09:35:49.610380+00:00

/// <param name="retryInterval">Retry interval (optional)</param>
    /// <returns>EventSet with retry configuration applied</returns>
    public EventSet<T> WithRetry(int maxRetries, TimeSpan? retryInterval = null)
    {
        if (maxRetries < 0)
            throw new ArgumentException("Retry count must be zero or greater", nameof(maxRetries));

        var newContext = new ErrorHandlingContext
        {
            ErrorAction = _errorHandlingContext.ErrorAction,
            RetryCount = maxRetries,
            RetryInterval = retryInterval ?? TimeSpan.FromSeconds(1)
        };

        return CreateNewInstance(_context, _entityModel, newContext, _dlqErrorSink);
    }

    /// <summary>
    /// Passes the POCO to the business logic.
    /// After receiving from Kafka, each element is transformed using the supplied function.
    /// Exceptions and retries are handled based on the OnError and WithRetry settings.
    /// </summary>
    /// <typeparam name="TResult">Result type</typeparam>
    /// <param name="mapper">Mapping function</param>
    /// <returns>The mapped EventSet</returns>
    public async Task<EventSet<TResult>> Map<TResult>(Func<T, Task<TResult>> mapper) where TResult : class
    {
        if (mapper == null)
            throw new ArgumentNullException(nameof(mapper));

        var results = new List<TResult>();
        var sourceData = await ToListAsync();

        foreach (var item in sourceData)
        {
            var itemErrorContext = new ErrorHandlingContext
            {
                ErrorAction = _errorHandlingContext.ErrorAction,
                RetryCount = _errorHandlingContext.RetryCount,
                RetryInterval = _errorHandlingContext.RetryInterval
            };

            await ProcessItemWithErrorHandling(
                item,
                mapper,
                results,
                itemErrorContext);
        }

        var resultEntityModel = CreateEntityModelForType<TResult>();
        return new MappedEventSet<TResult>(results, _context, resultEntityModel, _dlqErrorSink);
    }

    /// <summary>
    /// Synchronous version of the Map function
    /// </summary>
    public EventSet<TResult> Map<TResult>(Func<T, TResult> mapper) where TResult : class
    {
        if (mapper == null)
            throw new ArgumentNullException(nameof(mapper));
### assistant — 2025-08-11T09:35:50.648273+00:00

# Show the part where IAsyncEnumerable<object> ForEachAsync is
print('\n'.join(lines[270:300]))
### tool — 2025-08-11T09:35:51.706099+00:00

{
        return new ManualCommitMessage<T>(item, () => Task.CompletedTask, () => Task.CompletedTask);
    }

    /// <summary>
    /// Yields messages as different types depending on UseManualCommit
    /// </summary>
    public virtual async IAsyncEnumerable<object> ForEachAsync([EnumeratorCancellation] CancellationToken cancellationToken = default)
    {
        await foreach (var item in GetAsyncEnumeratorWrapper(cancellationToken))
        {
            if (_entityModel.UseManualCommit)
            {
                yield return CreateManualCommitMessage(item);
            }
            else
            {
                yield return item;
            }
        }
    }

    /// <summary>
    /// Configure the error handling policy
    /// </summary>
    internal virtual EventSet<T> WithErrorPolicy(ErrorHandlingPolicy policy)
    {
        if (policy == null)
            throw new ArgumentNullException(nameof(policy));
### assistant — 2025-08-11T09:35:52.709688+00:00

print(Path('/mnt/data/ICommitManager.cs').read_text())
### assistant — 2025-08-11T09:35:56.539174+00:00

_(empty)_
### tool — 2025-08-11T09:35:57.531333+00:00

namespace Kafka.Ksql.Linq.Messaging.Consumers;

public interface ICommitManager
{
    void Commit(object entity);
}
### assistant — 2025-08-11T09:35:58.590090+00:00

print(Path('/mnt/data/NoopCommitManager.cs').read_text())
### tool — 2025-08-11T09:36:12.706068+00:00

namespace Kafka.Ksql.Linq.Messaging.Consumers;

internal class NoopCommitManager : ICommitManager
{
    public void Commit(object entity) { }
}
### assistant — 2025-08-11T09:36:20.813159+00:00

print(Path('/mnt/data/KafkaConsumerManager.cs').read_text()[:4000])
### tool — 2025-08-11T09:36:21.559988+00:00

using Confluent.Kafka;
using Confluent.Kafka.SyncOverAsync;
using Confluent.SchemaRegistry.Serdes;
using Kafka.Ksql.Linq.Configuration;
using Kafka.Ksql.Linq.Configuration.Abstractions;
using Kafka.Ksql.Linq.Core.Abstractions;
using Kafka.Ksql.Linq.Core.Extensions;
using Kafka.Ksql.Linq.Mapping;
using Kafka.Ksql.Linq.Messaging.Configuration;
using Kafka.Ksql.Linq.Core.Dlq;
using Kafka.Ksql.Linq.Messaging.Producers;
using Microsoft.Extensions.Logging;
using Microsoft.Extensions.Options;
using System;
using System.Collections.Generic;
using System.Runtime.CompilerServices;
using System.Threading;
using System.Threading.Tasks;
using ConfluentSchemaRegistry = Confluent.SchemaRegistry;

namespace Kafka.Ksql.Linq.Messaging.Consumers;

internal sealed class KafkaConsumerManager : IDisposable
{
    private readonly KsqlDslOptions _options;
    private readonly ILogger? _logger;
    private readonly Lazy<ConfluentSchemaRegistry.ISchemaRegistryClient> _schemaRegistryClient;
    private readonly Dictionary<Type, EntityModel> _entityModels;
    private readonly MappingRegistry _mappingRegistry;
    private readonly DlqOptions _dlq;
    private readonly IRateLimiter _limiter;
    private readonly IDlqProducer _dlqProducer;
    private bool _disposed;

#pragma warning disable CS0067 // Event is never used
    public event Func<byte[]?, Exception, string, int, long, DateTime, Headers?, string, string, Task>? DeserializationError;
#pragma warning restore CS0067

    public KafkaConsumerManager(
        MappingRegistry mapping,
        IOptions<KsqlDslOptions> options,
        Dictionary<Type, EntityModel> entityModels,
        IDlqProducer dlqProducer,
        ILoggerFactory? loggerFactory = null,
        IRateLimiter? limiter = null)
    {
        _mappingRegistry = mapping;
        _options = options?.Value ?? throw new ArgumentNullException(nameof(options));
        _entityModels = entityModels ?? new();
        _dlqProducer = dlqProducer;
        _logger = loggerFactory?.CreateLogger<KafkaConsumerManager>();
        _schemaRegistryClient = new Lazy<ConfluentSchemaRegistry.ISchemaRegistryClient>(CreateSchemaRegistryClient);
        _dlq = _options.DlqOptions;
        _limiter = limiter ?? new SimpleRateLimiter(_dlq.MaxPerSecond);
    }



    public async IAsyncEnumerable<(TPOCO, Dictionary<string, string>, MessageMeta)> ConsumeAsync<TPOCO>(
        [EnumeratorCancellation] CancellationToken cancellationToken = default) where TPOCO : class
    {
        var model = GetEntityModel<TPOCO>();
        var topic = model.GetTopicName();
        var mapping = _mappingRegistry.GetMapping(typeof(TPOCO));
        var config = BuildConsumerConfig(topic, null);

        var method = typeof(KafkaConsumerManager)
            .GetMethod(nameof(ConsumeInternal), System.Reflection.BindingFlags.NonPublic | System.Reflection.BindingFlags.Instance)!
            .MakeGenericMethod(mapping.AvroKeyType!, mapping.AvroValueType!, typeof(TPOCO));

        var enumerable = (IAsyncEnumerable<(TPOCO, Dictionary<string, string>, MessageMeta)>)method
            .Invoke(this, new object?[] { topic, config, mapping, cancellationToken })!;

        await foreach (var item in enumerable.WithCancellation(cancellationToken))
            yield return item;
    }

    private async IAsyncEnumerable<(TPOCO, Dictionary<string, string>, MessageMeta)> ConsumeInternal<TKey, TValue, TPOCO>(
        string topicName,
        ConsumerConfig config,
        KeyValueTypeMapping mapping,
        [EnumeratorCancellation] CancellationToken cancellationToken)
        where TKey : class where TValue : class where TPOCO : class
    {
        using var consumer = CreateConsumer<TKey, TValue>(config);
        consumer.Subscribe(topicName);

        while (!cancellationToken.IsCancellationRequested)
        {
            ConsumeResult<TKey, TValue>? result;
            try
            {
                result = consumer.Consume(cancellationToken);
            }
            catch (OperationCancel
### assistant — 2025-08-11T09:36:22.675234+00:00

print(Path('/mnt/data/KafkaConsumerManager.cs').read_text()[4000:8000])
### tool — 2025-08-11T09:36:23.360920+00:00

edException)
            {
                break;
            }
            if (result == null || result.IsPartitionEOF)
                continue;

            TPOCO entity;
            Dictionary<string, string> headers;
            MessageMeta meta;
            try
            {
                entity = (TPOCO)mapping.CombineFromAvroKeyValue(result.Message.Key, result.Message.Value!, typeof(TPOCO));
                headers = new Dictionary<string, string>();
                if (result.Message.Headers != null)
                {
                    foreach (var h in result.Message.Headers)
                        headers[h.Key] = System.Text.Encoding.UTF8.GetString(h.GetValueBytes());
                }

                meta = new MessageMeta(
                    Topic: result.Topic,
                    Partition: result.Partition,
                    Offset: result.Offset,
                    TimestampUtc: result.Message.Timestamp.UtcDateTime,
                    SchemaIdKey: TryGetSchemaId(result.Message.Key as byte[]),
                    SchemaIdValue: TryGetSchemaId(result.Message.Value as byte[]),
                    KeyIsNull: result.Message.Key is null,
                    HeaderAllowList: ExtractAllowedHeaders(result.Message.Headers, _dlq.HeaderAllowList, _dlq.HeaderValueMaxLength)
                );
            }
            catch (Exception ex)
            {
                await HandleMappingException(result, ex, _dlqProducer, consumer, _dlq, _limiter, cancellationToken).ConfigureAwait(false);
                continue;
            }

            yield return (entity, headers, meta);
            await Task.CompletedTask;
        }
    }

    internal static async Task HandleMappingException<TKey, TValue>(
        ConsumeResult<TKey, TValue> result,
        Exception ex,
        IDlqProducer dlqProducer,
        IConsumer<TKey, TValue> consumer,
        DlqOptions options,
        IRateLimiter limiter,
        CancellationToken cancellationToken)
        where TKey : class where TValue : class
    {
        if (options.EnableForDeserializationError && DlqGuard.ShouldSend(options, limiter, ex.GetType()))
        {
            var allowHeaders = ExtractAllowedHeaders(result.Message.Headers, options.HeaderAllowList, options.HeaderValueMaxLength);
            var env = DlqEnvelopeFactory.From(result, ex,
                options.ApplicationId, options.ConsumerGroup, options.Host, allowHeaders,
                options.ErrorMessageMaxLength, options.StackTraceMaxLength, options.NormalizeStackTraceWhitespace);
            await dlqProducer.ProduceAsync(env, cancellationToken).ConfigureAwait(false);
        }
        consumer.Commit(result);
    }

    private IConsumer<TKey, TValue> CreateConsumer<TKey, TValue>(ConsumerConfig config)
        where TKey : class where TValue : class
    {
        return new ConsumerBuilder<TKey, TValue>(config)
            .SetKeyDeserializer(new AvroDeserializer<TKey>(_schemaRegistryClient.Value).AsSyncOverAsync())
            .SetValueDeserializer(new AvroDeserializer<TValue>(_schemaRegistryClient.Value).AsSyncOverAsync())
            .Build();
    }

    private ConfluentSchemaRegistry.ISchemaRegistryClient CreateSchemaRegistryClient()
    {
        var cfg = new ConfluentSchemaRegistry.SchemaRegistryConfig { Url = _options.SchemaRegistry.Url };
        return new ConfluentSchemaRegistry.CachedSchemaRegistryClient(cfg);
    }

    private EntityModel GetEntityModel<T>() where T : class
    {
        if (_entityModels.TryGetValue(typeof(T), out var model))
            return model;
        throw new InvalidOperationException($"Entity model not found for {typeof(T).Name}");
    }

    private ConsumerConfig BuildConsumerConfig(string topicName, KafkaSubscriptionOptions? subscriptionOptions)
    {
        var topicConfig = _options.Topics.TryGetValue(topicName, out var cfg) ? cfg : new TopicSection();
        var groupId = subscriptionOptions?.GroupId ?? topicConfig.Consumer.GroupId;
        if
### assistant — 2025-08-11T09:36:24.402808+00:00

# search for ConsumeAsync<T> method
text = Path('/mnt/data/KafkaConsumerManager.cs').read_text()
for i,l in enumerate(text.splitlines()):
    if 'ConsumeAsync<' in l:
        print(i,l)
### tool — 2025-08-11T09:36:25.552315+00:00

58     public async IAsyncEnumerable<(TPOCO, Dictionary<string, string>, MessageMeta)> ConsumeAsync<TPOCO>(
### assistant — 2025-08-11T09:36:26.703040+00:00

print('\n'.join(text.splitlines()[50:120]))
### tool — 2025-08-11T09:36:27.434636+00:00

_logger = loggerFactory?.CreateLogger<KafkaConsumerManager>();
        _schemaRegistryClient = new Lazy<ConfluentSchemaRegistry.ISchemaRegistryClient>(CreateSchemaRegistryClient);
        _dlq = _options.DlqOptions;
        _limiter = limiter ?? new SimpleRateLimiter(_dlq.MaxPerSecond);
    }



    public async IAsyncEnumerable<(TPOCO, Dictionary<string, string>, MessageMeta)> ConsumeAsync<TPOCO>(
        [EnumeratorCancellation] CancellationToken cancellationToken = default) where TPOCO : class
    {
        var model = GetEntityModel<TPOCO>();
        var topic = model.GetTopicName();
        var mapping = _mappingRegistry.GetMapping(typeof(TPOCO));
        var config = BuildConsumerConfig(topic, null);

        var method = typeof(KafkaConsumerManager)
            .GetMethod(nameof(ConsumeInternal), System.Reflection.BindingFlags.NonPublic | System.Reflection.BindingFlags.Instance)!
            .MakeGenericMethod(mapping.AvroKeyType!, mapping.AvroValueType!, typeof(TPOCO));

        var enumerable = (IAsyncEnumerable<(TPOCO, Dictionary<string, string>, MessageMeta)>)method
            .Invoke(this, new object?[] { topic, config, mapping, cancellationToken })!;

        await foreach (var item in enumerable.WithCancellation(cancellationToken))
            yield return item;
    }

    private async IAsyncEnumerable<(TPOCO, Dictionary<string, string>, MessageMeta)> ConsumeInternal<TKey, TValue, TPOCO>(
        string topicName,
        ConsumerConfig config,
        KeyValueTypeMapping mapping,
        [EnumeratorCancellation] CancellationToken cancellationToken)
        where TKey : class where TValue : class where TPOCO : class
    {
        using var consumer = CreateConsumer<TKey, TValue>(config);
        consumer.Subscribe(topicName);

        while (!cancellationToken.IsCancellationRequested)
        {
            ConsumeResult<TKey, TValue>? result;
            try
            {
                result = consumer.Consume(cancellationToken);
            }
            catch (OperationCanceledException)
            {
                break;
            }
            if (result == null || result.IsPartitionEOF)
                continue;

            TPOCO entity;
            Dictionary<string, string> headers;
            MessageMeta meta;
            try
            {
                entity = (TPOCO)mapping.CombineFromAvroKeyValue(result.Message.Key, result.Message.Value!, typeof(TPOCO));
                headers = new Dictionary<string, string>();
                if (result.Message.Headers != null)
                {
                    foreach (var h in result.Message.Headers)
                        headers[h.Key] = System.Text.Encoding.UTF8.GetString(h.GetValueBytes());
                }

                meta = new MessageMeta(
                    Topic: result.Topic,
                    Partition: result.Partition,
                    Offset: result.Offset,
                    TimestampUtc: result.Message.Timestamp.UtcDateTime,
                    SchemaIdKey: TryGetSchemaId(result.Message.Key as byte[]),
### assistant — 2025-08-11T09:36:28.603094+00:00

print('\n'.join(text.splitlines()[120:260]))
### tool — 2025-08-11T09:36:29.362844+00:00

SchemaIdValue: TryGetSchemaId(result.Message.Value as byte[]),
                    KeyIsNull: result.Message.Key is null,
                    HeaderAllowList: ExtractAllowedHeaders(result.Message.Headers, _dlq.HeaderAllowList, _dlq.HeaderValueMaxLength)
                );
            }
            catch (Exception ex)
            {
                await HandleMappingException(result, ex, _dlqProducer, consumer, _dlq, _limiter, cancellationToken).ConfigureAwait(false);
                continue;
            }

            yield return (entity, headers, meta);
            await Task.CompletedTask;
        }
    }

    internal static async Task HandleMappingException<TKey, TValue>(
        ConsumeResult<TKey, TValue> result,
        Exception ex,
        IDlqProducer dlqProducer,
        IConsumer<TKey, TValue> consumer,
        DlqOptions options,
        IRateLimiter limiter,
        CancellationToken cancellationToken)
        where TKey : class where TValue : class
    {
        if (options.EnableForDeserializationError && DlqGuard.ShouldSend(options, limiter, ex.GetType()))
        {
            var allowHeaders = ExtractAllowedHeaders(result.Message.Headers, options.HeaderAllowList, options.HeaderValueMaxLength);
            var env = DlqEnvelopeFactory.From(result, ex,
                options.ApplicationId, options.ConsumerGroup, options.Host, allowHeaders,
                options.ErrorMessageMaxLength, options.StackTraceMaxLength, options.NormalizeStackTraceWhitespace);
            await dlqProducer.ProduceAsync(env, cancellationToken).ConfigureAwait(false);
        }
        consumer.Commit(result);
    }

    private IConsumer<TKey, TValue> CreateConsumer<TKey, TValue>(ConsumerConfig config)
        where TKey : class where TValue : class
    {
        return new ConsumerBuilder<TKey, TValue>(config)
            .SetKeyDeserializer(new AvroDeserializer<TKey>(_schemaRegistryClient.Value).AsSyncOverAsync())
            .SetValueDeserializer(new AvroDeserializer<TValue>(_schemaRegistryClient.Value).AsSyncOverAsync())
            .Build();
    }

    private ConfluentSchemaRegistry.ISchemaRegistryClient CreateSchemaRegistryClient()
    {
        var cfg = new ConfluentSchemaRegistry.SchemaRegistryConfig { Url = _options.SchemaRegistry.Url };
        return new ConfluentSchemaRegistry.CachedSchemaRegistryClient(cfg);
    }

    private EntityModel GetEntityModel<T>() where T : class
    {
        if (_entityModels.TryGetValue(typeof(T), out var model))
            return model;
        throw new InvalidOperationException($"Entity model not found for {typeof(T).Name}");
    }

    private ConsumerConfig BuildConsumerConfig(string topicName, KafkaSubscriptionOptions? subscriptionOptions)
    {
        var topicConfig = _options.Topics.TryGetValue(topicName, out var cfg) ? cfg : new TopicSection();
        var groupId = subscriptionOptions?.GroupId ?? topicConfig.Consumer.GroupId;
        if (string.IsNullOrWhiteSpace(groupId))
            groupId = "default-group";

        var consumerConfig = new ConsumerConfig
        {
            BootstrapServers = _options.Common.BootstrapServers,
            ClientId = _options.Common.ClientId,
            GroupId = groupId,
            AutoOffsetReset = Enum.Parse<AutoOffsetReset>(topicConfig.Consumer.AutoOffsetReset),
            EnableAutoCommit = topicConfig.Consumer.EnableAutoCommit,
            AutoCommitIntervalMs = topicConfig.Consumer.AutoCommitIntervalMs,
            SessionTimeoutMs = topicConfig.Consumer.SessionTimeoutMs,
            HeartbeatIntervalMs = topicConfig.Consumer.HeartbeatIntervalMs,
            MaxPollIntervalMs = topicConfig.Consumer.MaxPollIntervalMs,
            FetchMinBytes = topicConfig.Consumer.FetchMinBytes,
            FetchMaxBytes = topicConfig.Consumer.FetchMaxBytes,
            IsolationLevel = Enum.Parse<IsolationLevel>(topicConfig.Consumer.IsolationLevel)
        };

        if (subscriptionOptions != null)
        {
            if (subscriptionOptions.AutoCommit.HasValue)
                consumerConfig.EnableAutoCommit = subscriptionOptions.AutoCommit.Value;
            if (subscriptionOptions.SessionTimeout.HasValue)
                consumerConfig.SessionTimeoutMs = (int)subscriptionOptions.SessionTimeout.Value.TotalMilliseconds;
            if (subscriptionOptions.HeartbeatInterval.HasValue)
                consumerConfig.HeartbeatIntervalMs = (int)subscriptionOptions.HeartbeatInterval.Value.TotalMilliseconds;
            if (subscriptionOptions.MaxPollInterval.HasValue)
                consumerConfig.MaxPollIntervalMs = (int)subscriptionOptions.MaxPollInterval.Value.TotalMilliseconds;
        }

        if (_options.Common.SecurityProtocol != SecurityProtocol.Plaintext)
        {
            consumerConfig.SecurityProtocol = _options.Common.SecurityProtocol;
            if (_options.Common.SaslMechanism.HasValue)
            {
                consumerConfig.SaslMechanism = _options.Common.SaslMechanism.Value;
                consumerConfig.SaslUsername = _options.Common.SaslUsername;
                consumerConfig.SaslPassword = _options.Common.SaslPassword;
            }

            if (!string.IsNullOrEmpty(_options.Common.SslCaLocation))
            {
                consumerConfig.SslCaLocation = _options.Common.SslCaLocation;
                consumerConfig.SslCertificateLocation = _options.Common.SslCertificateLocation;
                consumerConfig.SslKeyLocation = _options.Common.SslKeyLocation;
                consumerConfig.SslKeyPassword = _options.Common.SslKeyPassword;
            }
        }

        foreach (var kvp in topicConfig.Consumer.AdditionalProperties)
            consumerConfig.Set(kvp.Key, kvp.Value);

        return consumerConfig;
    }

    public void ResetOffsetsToBeginning<TPOCO>() where TPOCO : class
    {
        var model = GetEntityModel<TPOCO>();
        var topic = model.GetTopicName();
        var mapping = _mappingRegistry.GetMapping(typeof(TPOCO));
        var config = BuildConsumerConfig(topic, null);
        config.EnableAutoCommit = false;
        var method = typeof(KafkaConsumerManager)
            .GetMethod(nameof(ResetOffsetsToBeginningInternal), System.Reflection.BindingFlags.NonPublic | System.Reflection.BindingFlags.Instance)!
            .MakeGenericMethod(mapping.AvroKeyType!, mapping.AvroValueType!);
        method.Invoke(this, new object?[] { topic, config, model.Partitions });
    }

    private void ResetOffsetsToBeginningInternal<TKey, TValue>(string topic, ConsumerConfig config, int partitions)
        where TKey : class where TValue : class
    {
        using var consumer = CreateConsumer<TKey, TValue>(config);
        var tps = new List<TopicPartitionOffset>(partitions);
        for (var i = 0; i < partitions; i++)
            tps.Add(new TopicPartitionOffset(topic, new Partition(i), new Offset(0)));
        consumer.Assign(tps);
### assistant — 2025-08-11T09:36:30.538054+00:00

いいね、結論から：**`ForEachAsync` は `IAsyncEnumerable<T>`（POCO）を返す**ようにしつつ、manual/auto 切替は**内部で吸収**します。  
既存構成（`ICommitManager` / `NoopCommitManager` / `KafkaConsumerManager`）は**そのまま**使い、破壊的変更は EventSet 側の**最小差分**に留めます。

やることは3つだけ：

1) `ForEachAsync` の戻り値を `IAsyncEnumerable<T>` に変更（POCOだけを出す）  
2) 呼び出し側が `poco` を渡してコミットできる `Commit(T entity)` を公開（中で `_commitManager.Commit` 委譲）  
3)（任意/推奨）manual時に **entity→offset(meta)** を紐づけられるよう、**内部オプショナルIF**を挿入（`ICommitManager`は不変のまま）。  
　CommitManager 実装側（manual用）がこのIFを実装すれば、`Track(entity, meta)` 経由でオフセットを取れます。autocommit時は `NoopCommitManager` で no-op。

---

# 変更差分（EventSet.cs だけ）
### 1) `ForEachAsync` を POCO 返しに変更
```diff
@@
-    /// <summary>
-    /// Yields messages as different types depending on UseManualCommit
-    /// </summary>
-    public virtual async IAsyncEnumerable<object> ForEachAsync(
-        [EnumeratorCancellation] CancellationToken cancellationToken = default)
-    {
-        await foreach (var item in GetAsyncEnumeratorWrapper(cancellationToken))
-        {
-            if (_entityModel.UseManualCommit)
-            {
-                yield return CreateManualCommitMessage(item);
-            }
-            else
-            {
-                yield return item;
-            }
-        }
-    }
+    /// <summary>
+    /// 常に POCO (T) を列挙で返す。manual/auto の差異は内部の CommitManager で吸収。
+    /// </summary>
+    public virtual async IAsyncEnumerable<T> ForEachAsync(
+        [EnumeratorCancellation] CancellationToken cancellationToken = default)
+    {
+        await foreach (var item in GetAsyncEnumeratorWrapper(cancellationToken))
+        {
+            // manual のときも POCO だけ返す（Commit は ctx.Samples.Commit(poco) を呼ぶ）
+            yield return item;
+        }
+    }
```

> 補足: 既存の `CreateManualCommitMessage` は互換のため残して構いません（未使用になります）。  
> 既に `ForEachAsync(Func<...>)` 系のオーバーロードもあるので、そちらはそのままでOKです。

---
### 2) `Commit(T entity)` を公開（呼び出し側は POCO だけ扱えばOK）
```diff
@@
     private readonly Messaging.Consumers.ICommitManager? _commitManager;
@@
     public override string ToString()
     {
         return $"EventSet<{typeof(T).Name}> - Topic: {GetTopicName()}";
     }
+
+    /// <summary>
+    /// 呼び出し側から手動コミットを行う（autocommit時はNoopCommitManagerによりno-op）。
+    /// ForEachAsync で受け取った POCO インスタンスを渡すこと。
+    /// </summary>
+    public void Commit(T entity)
+    {
+        if (entity is null) throw new ArgumentNullException(nameof(entity));
+        _commitManager?.Commit(entity);
+    }
```

> 既存の `ICommitManager` は `void Commit(object)` なので、そのまま委譲します。  
> autocommit 時は `NoopCommitManager.Commit` が空実装で無害です。

---
### 3)（任意/推奨）**entity→meta** を manual 側に渡せる “オプショナルIF” を追加  
`ICommitManager` をいじらず、**実装可能な追加インターフェース**として `EventSet<T>` 内に宣言 → manual用の CommitManager だけ実装すれば、列挙時に meta を受け取れます。

```diff
@@
 public abstract class EventSet<T> : IEntitySet<T> where T : class
 {
+    // manual 用 CommitManager が entity とメタ情報を追跡したい場合にだけ実装する拡張IF
+    internal interface ICommitRegistrar
+    {
+        void Track(object entity, MessageMeta meta);
+    }
@@
-    protected virtual IAsyncEnumerable<(T Entity, Dictionary<string, string> Headers, MessageMeta Meta)> ConsumeAsync(
-        KsqlContext context,
-        CancellationToken cancellationToken)
-    {
-        return context.GetConsumerManager().ConsumeAsync<T>(cancellationToken);
-    }
+    protected virtual IAsyncEnumerable<(T Entity, Dictionary<string, string> Headers, MessageMeta Meta)> ConsumeAsync(
+        KsqlContext context,
+        CancellationToken cancellationToken)
+    {
+        var source = context.GetConsumerManager().ConsumeAsync<T>(cancellationToken);
+        return TrackCommitIfSupported(source, cancellationToken);
+    }
+
+    private async IAsyncEnumerable<(T Entity, Dictionary<string, string> Headers, MessageMeta Meta)> TrackCommitIfSupported(
+        IAsyncEnumerable<(T Entity, Dictionary<string, string> Headers, MessageMeta Meta)> source,
+        [EnumeratorCancellation] CancellationToken cancellationToken = default)
+    {
+        var registrar = _commitManager as ICommitRegistrar;
+        await foreach (var (entity, headers, meta) in source.WithCancellation(cancellationToken))
+        {
+            // manual 実装側が対応している場合のみ、entity→meta を紐づけておく
+            registrar?.Track(entity!, meta);
+            yield return (entity, headers, meta);
+        }
+    }
```

> これで **EventSet 側だけの改修**で、manual コミット用の実装に *任意で* トラッキングを提供できます。  
> 既存の `KafkaConsumerManager.ConsumeAsync<T>` は `(T, Headers, MessageMeta)` を返しているので、この箇所で安全にメタを拾えます。

---

## 呼び出し側（テスト）はこう書けます（キャスト撤廃・IF不変）
```csharp
await foreach (var sample in ctx.Samples.ForEachAsync(consumeCts.Token))
{
    if (sample.Id == 3)
    {
        ctx.Samples.Commit(sample); // manual: 実コミット / autocommit: no-op
        break;
    }
}
```

2回目の検証側も同様に `Commit(sample)` でOK（必要なら）。

---

## 実装メモ（manual側 CommitManager の最小要件）
- `ICommitManager` に**加えて** `EventSet<T>.ICommitRegistrar` を実装すれば、  
  `Track(entity, meta)` で **参照同一性**ベースに `entity→meta` を保持できます（`ConditionalWeakTable<object, MessageMeta>` 推奨）。
- `Commit(object entity)` で取り出した `meta` の `Topic/Partition/Offset` を用い、`consumer.Commit(new TopicPartitionOffset(...))` を実行。  
  コミット後は登録解除（リーク＆二重コミット防止）。
- autocommit 時は従来通り `NoopCommitManager` で無視。

> 既存ファイルとの整合：
> - `KafkaConsumerManager.ConsumeAsync<TPOCO>` は `(TPOCO, Headers, MessageMeta)` を返しており、EventSet 側でメタを受け取れます。  
> - `ICommitManager` は `void Commit(object)` のまま（変更不要）。  
> - `NoopCommitManager` はそのままでOK（no-op）。

---

必要なら、この差分をそのまま適用できる **パッチファイル（.patch/diff）** 形式でも出します。  
他のファイル（`ICommitManager.cs` / `NoopCommitManager.cs` / `KafkaConsumerManager.cs`）は**変更不要**です。

— 送信日時: [[REDACTED_PHONE]]:58 (JST)
### assistant — 2025-08-11T09:36:34.835903+00:00

_(empty)_
### assistant — 2025-08-11T09:36:41.597132+00:00

_(empty)_
### user — 2025-08-11T09:38:53.841000+00:00

NoopCommitManagerは必要？
### assistant — 2025-08-11T09:38:57.043292+00:00

結論：**必須ではない**けど、**置いておくのがおすすめ**です。

## なぜ NoopCommitManager を残すと良いか
- **呼び出し側の分岐が不要**：`ctx.Samples.Commit(poco)` をそのまま呼べる。`if (UseManualCommit) ...` をいちいち書かなくて済む（Null Object パターン）。
- **疎結合**：`EventSet` が autocommit/manual の事情を知らなくてOK（OCP/LSP的にきれい）。
- **テストが楽**：manual 系のテストでは実装CommitManager、autocommit系のスモークはNoop注入で済む。
- **将来拡張**：Noopのままメトリクス記録やトレースを足したくなった時に差し替えやすい。

## それでも削りたい場合（代替）
Noop を無くすなら、**autocommit時は `_commitManager` を `null` 注入**にして、`EventSet` 側で雑に弾くやり方でも動きます。

```csharp
public void Commit(T entity)
{
    if (entity is null) throw new ArgumentNullException(nameof(entity));
    // autocommit なら _commitManager は null とする前提
    _commitManager?.Commit(entity);
}
```

さらに厳密にやるなら、`UseManualCommit` を見る：

```csharp
public void Commit(T entity)
{
    if (!_entityModel.UseManualCommit) return; // autocommit → 何もしない
    _commitManager?.Commit(entity);
}
```

> 注意：Noop を消すと「どこで null を入れるか」「UseManualCommit と実装の整合」を**DI設定側で保証**する必要が出ます。責務が `EventSet` or DI構成に寄る分、後で触った人が混乱しやすくなります。

## 推奨
- 今の設計（`ICommitManager` + `NoopCommitManager`）は**きれいで安全**。  
- パフォーマンス差は実質ゼロなので、**Noop を残す**ことを推します。

必要なら「Noop を前提にした最小差分」または「Noop削除版のDI設定例」どちらも具体コードで出します。どっちでまとめます？

— 送信日時: [[REDACTED_PHONE]]:02 (JST)
### system — 2025-08-11T09:38:57.795335+00:00

_(empty)_
### assistant — 2025-08-11T09:38:57.850849+00:00

_(empty)_
### assistant — 2025-08-11T09:39:09.779094+00:00

_(empty)_
### user — 2025-08-11T09:52:20.739000+00:00

_commitManagerはoffsetとかを管理しないといけない
そのコードがない
### assistant — 2025-08-11T09:52:23.776827+00:00

import os, textwrap, json, pathlib, sys, re, itertools
### system — 2025-08-11T09:52:24.229513+00:00

_(empty)_
### assistant — 2025-08-11T09:52:25.114170+00:00

_(empty)_
### assistant — 2025-08-11T09:52:31.637241+00:00

from pathlib import Path, PurePosixPath
base = Path('/mnt/data')
list(base.iterdir())
### tool — 2025-08-11T09:52:32.827049+00:00

[PosixPath('/mnt/data/ICommitManager.cs'),
 PosixPath('/mnt/data/KafkaConsumerManager.cs'),
 PosixPath('/mnt/data/EventSet.cs'),
 PosixPath('/mnt/data/NoopCommitManager.cs')]
### assistant — 2025-08-11T09:52:33.914797+00:00

print(Path('/mnt/data/ICommitManager.cs').read_text())
### tool — 2025-08-11T09:52:38.260339+00:00

namespace Kafka.Ksql.Linq.Messaging.Consumers;

public interface ICommitManager
{
    void Commit(object entity);
}
### assistant — 2025-08-11T09:52:39.301240+00:00

print(Path('/mnt/data/NoopCommitManager.cs').read_text())
### tool — 2025-08-11T09:52:40.801218+00:00

namespace Kafka.Ksql.Linq.Messaging.Consumers;

internal class NoopCommitManager : ICommitManager
{
    public void Commit(object entity) { }
}
### assistant — 2025-08-11T09:52:41.898836+00:00

print(Path('/mnt/data/KafkaConsumerManager.cs').read_text()[:2000])
### tool — 2025-08-11T09:52:42.791955+00:00

using Confluent.Kafka;
using Confluent.Kafka.SyncOverAsync;
using Confluent.SchemaRegistry.Serdes;
using Kafka.Ksql.Linq.Configuration;
using Kafka.Ksql.Linq.Configuration.Abstractions;
using Kafka.Ksql.Linq.Core.Abstractions;
using Kafka.Ksql.Linq.Core.Extensions;
using Kafka.Ksql.Linq.Mapping;
using Kafka.Ksql.Linq.Messaging.Configuration;
using Kafka.Ksql.Linq.Core.Dlq;
using Kafka.Ksql.Linq.Messaging.Producers;
using Microsoft.Extensions.Logging;
using Microsoft.Extensions.Options;
using System;
using System.Collections.Generic;
using System.Runtime.CompilerServices;
using System.Threading;
using System.Threading.Tasks;
using ConfluentSchemaRegistry = Confluent.SchemaRegistry;

namespace Kafka.Ksql.Linq.Messaging.Consumers;

internal sealed class KafkaConsumerManager : IDisposable
{
    private readonly KsqlDslOptions _options;
    private readonly ILogger? _logger;
    private readonly Lazy<ConfluentSchemaRegistry.ISchemaRegistryClient> _schemaRegistryClient;
    private readonly Dictionary<Type, EntityModel> _entityModels;
    private readonly MappingRegistry _mappingRegistry;
    private readonly DlqOptions _dlq;
    private readonly IRateLimiter _limiter;
    private readonly IDlqProducer _dlqProducer;
    private bool _disposed;

#pragma warning disable CS0067 // Event is never used
    public event Func<byte[]?, Exception, string, int, long, DateTime, Headers?, string, string, Task>? DeserializationError;
#pragma warning restore CS0067

    public KafkaConsumerManager(
        MappingRegistry mapping,
        IOptions<KsqlDslOptions> options,
        Dictionary<Type, EntityModel> entityModels,
        IDlqProducer dlqProducer,
        ILoggerFactory? loggerFactory = null,
        IRateLimiter? limiter = null)
    {
        _mappingRegistry = mapping;
        _options = options?.Value ?? throw new ArgumentNullException(nameof(options));
        _entityModels = entityModels ?? new();
        _dlqProducer = dlqProducer;
        _logger = loggerFactory?.Create
### assistant — 2025-08-11T09:52:43.826497+00:00

print(Path('/mnt/data/KafkaConsumerManager.cs').read_text()[2000:6000])
### tool — 2025-08-11T09:52:44.748483+00:00

Logger<KafkaConsumerManager>();
        _schemaRegistryClient = new Lazy<ConfluentSchemaRegistry.ISchemaRegistryClient>(CreateSchemaRegistryClient);
        _dlq = _options.DlqOptions;
        _limiter = limiter ?? new SimpleRateLimiter(_dlq.MaxPerSecond);
    }



    public async IAsyncEnumerable<(TPOCO, Dictionary<string, string>, MessageMeta)> ConsumeAsync<TPOCO>(
        [EnumeratorCancellation] CancellationToken cancellationToken = default) where TPOCO : class
    {
        var model = GetEntityModel<TPOCO>();
        var topic = model.GetTopicName();
        var mapping = _mappingRegistry.GetMapping(typeof(TPOCO));
        var config = BuildConsumerConfig(topic, null);

        var method = typeof(KafkaConsumerManager)
            .GetMethod(nameof(ConsumeInternal), System.Reflection.BindingFlags.NonPublic | System.Reflection.BindingFlags.Instance)!
            .MakeGenericMethod(mapping.AvroKeyType!, mapping.AvroValueType!, typeof(TPOCO));

        var enumerable = (IAsyncEnumerable<(TPOCO, Dictionary<string, string>, MessageMeta)>)method
            .Invoke(this, new object?[] { topic, config, mapping, cancellationToken })!;

        await foreach (var item in enumerable.WithCancellation(cancellationToken))
            yield return item;
    }

    private async IAsyncEnumerable<(TPOCO, Dictionary<string, string>, MessageMeta)> ConsumeInternal<TKey, TValue, TPOCO>(
        string topicName,
        ConsumerConfig config,
        KeyValueTypeMapping mapping,
        [EnumeratorCancellation] CancellationToken cancellationToken)
        where TKey : class where TValue : class where TPOCO : class
    {
        using var consumer = CreateConsumer<TKey, TValue>(config);
        consumer.Subscribe(topicName);

        while (!cancellationToken.IsCancellationRequested)
        {
            ConsumeResult<TKey, TValue>? result;
            try
            {
                result = consumer.Consume(cancellationToken);
            }
            catch (OperationCanceledException)
            {
                break;
            }
            if (result == null || result.IsPartitionEOF)
                continue;

            TPOCO entity;
            Dictionary<string, string> headers;
            MessageMeta meta;
            try
            {
                entity = (TPOCO)mapping.CombineFromAvroKeyValue(result.Message.Key, result.Message.Value!, typeof(TPOCO));
                headers = new Dictionary<string, string>();
                if (result.Message.Headers != null)
                {
                    foreach (var h in result.Message.Headers)
                        headers[h.Key] = System.Text.Encoding.UTF8.GetString(h.GetValueBytes());
                }

                meta = new MessageMeta(
                    Topic: result.Topic,
                    Partition: result.Partition,
                    Offset: result.Offset,
                    TimestampUtc: result.Message.Timestamp.UtcDateTime,
                    SchemaIdKey: TryGetSchemaId(result.Message.Key as byte[]),
                    SchemaIdValue: TryGetSchemaId(result.Message.Value as byte[]),
                    KeyIsNull: result.Message.Key is null,
                    HeaderAllowList: ExtractAllowedHeaders(result.Message.Headers, _dlq.HeaderAllowList, _dlq.HeaderValueMaxLength)
                );
            }
            catch (Exception ex)
            {
                await HandleMappingException(result, ex, _dlqProducer, consumer, _dlq, _limiter, cancellationToken).ConfigureAwait(false);
                continue;
            }

            yield return (entity, headers, meta);
            await Task.CompletedTask;
        }
    }

    internal static async Task HandleMappingException<TKey, TValue>(
        ConsumeResult<TKey, TValue> result,
        Exception ex,
        IDlqProducer dlqProducer,
        IConsumer<TKey, TValue> consumer,
        DlqOptions options,
        IRateLimiter limiter,
        CancellationToken cancellationToken)
        wh
### assistant — 2025-08-11T09:52:45.801070+00:00

print(Path('/mnt/data/KafkaConsumerManager.cs').read_text()[6000:12000])
### tool — 2025-08-11T09:52:48.736584+00:00

ere TKey : class where TValue : class
    {
        if (options.EnableForDeserializationError && DlqGuard.ShouldSend(options, limiter, ex.GetType()))
        {
            var allowHeaders = ExtractAllowedHeaders(result.Message.Headers, options.HeaderAllowList, options.HeaderValueMaxLength);
            var env = DlqEnvelopeFactory.From(result, ex,
                options.ApplicationId, options.ConsumerGroup, options.Host, allowHeaders,
                options.ErrorMessageMaxLength, options.StackTraceMaxLength, options.NormalizeStackTraceWhitespace);
            await dlqProducer.ProduceAsync(env, cancellationToken).ConfigureAwait(false);
        }
        consumer.Commit(result);
    }

    private IConsumer<TKey, TValue> CreateConsumer<TKey, TValue>(ConsumerConfig config)
        where TKey : class where TValue : class
    {
        return new ConsumerBuilder<TKey, TValue>(config)
            .SetKeyDeserializer(new AvroDeserializer<TKey>(_schemaRegistryClient.Value).AsSyncOverAsync())
            .SetValueDeserializer(new AvroDeserializer<TValue>(_schemaRegistryClient.Value).AsSyncOverAsync())
            .Build();
    }

    private ConfluentSchemaRegistry.ISchemaRegistryClient CreateSchemaRegistryClient()
    {
        var cfg = new ConfluentSchemaRegistry.SchemaRegistryConfig { Url = _options.SchemaRegistry.Url };
        return new ConfluentSchemaRegistry.CachedSchemaRegistryClient(cfg);
    }

    private EntityModel GetEntityModel<T>() where T : class
    {
        if (_entityModels.TryGetValue(typeof(T), out var model))
            return model;
        throw new InvalidOperationException($"Entity model not found for {typeof(T).Name}");
    }

    private ConsumerConfig BuildConsumerConfig(string topicName, KafkaSubscriptionOptions? subscriptionOptions)
    {
        var topicConfig = _options.Topics.TryGetValue(topicName, out var cfg) ? cfg : new TopicSection();
        var groupId = subscriptionOptions?.GroupId ?? topicConfig.Consumer.GroupId;
        if (string.IsNullOrWhiteSpace(groupId))
            groupId = "default-group";

        var consumerConfig = new ConsumerConfig
        {
            BootstrapServers = _options.Common.BootstrapServers,
            ClientId = _options.Common.ClientId,
            GroupId = groupId,
            AutoOffsetReset = Enum.Parse<AutoOffsetReset>(topicConfig.Consumer.AutoOffsetReset),
            EnableAutoCommit = topicConfig.Consumer.EnableAutoCommit,
            AutoCommitIntervalMs = topicConfig.Consumer.AutoCommitIntervalMs,
            SessionTimeoutMs = topicConfig.Consumer.SessionTimeoutMs,
            HeartbeatIntervalMs = topicConfig.Consumer.HeartbeatIntervalMs,
            MaxPollIntervalMs = topicConfig.Consumer.MaxPollIntervalMs,
            FetchMinBytes = topicConfig.Consumer.FetchMinBytes,
            FetchMaxBytes = topicConfig.Consumer.FetchMaxBytes,
            IsolationLevel = Enum.Parse<IsolationLevel>(topicConfig.Consumer.IsolationLevel)
        };

        if (subscriptionOptions != null)
        {
            if (subscriptionOptions.AutoCommit.HasValue)
                consumerConfig.EnableAutoCommit = subscriptionOptions.AutoCommit.Value;
            if (subscriptionOptions.SessionTimeout.HasValue)
                consumerConfig.SessionTimeoutMs = (int)subscriptionOptions.SessionTimeout.Value.TotalMilliseconds;
            if (subscriptionOptions.HeartbeatInterval.HasValue)
                consumerConfig.HeartbeatIntervalMs = (int)subscriptionOptions.HeartbeatInterval.Value.TotalMilliseconds;
            if (subscriptionOptions.MaxPollInterval.HasValue)
                consumerConfig.MaxPollIntervalMs = (int)subscriptionOptions.MaxPollInterval.Value.TotalMilliseconds;
        }

        if (_options.Common.SecurityProtocol != SecurityProtocol.Plaintext)
        {
            consumerConfig.SecurityProtocol = _options.Common.SecurityProtocol;
            if (_options.Common.SaslMechanism.HasValue)
            {
                consumerConfig.SaslMechanism = _options.Common.SaslMechanism.Value;
                consumerConfig.SaslUsername = _options.Common.SaslUsername;
                consumerConfig.SaslPassword = _options.Common.SaslPassword;
            }

            if (!string.IsNullOrEmpty(_options.Common.SslCaLocation))
            {
                consumerConfig.SslCaLocation = _options.Common.SslCaLocation;
                consumerConfig.SslCertificateLocation = _options.Common.SslCertificateLocation;
                consumerConfig.SslKeyLocation = _options.Common.SslKeyLocation;
                consumerConfig.SslKeyPassword = _options.Common.SslKeyPassword;
            }
        }

        foreach (var kvp in topicConfig.Consumer.AdditionalProperties)
            consumerConfig.Set(kvp.Key, kvp.Value);

        return consumerConfig;
    }

    public void ResetOffsetsToBeginning<TPOCO>() where TPOCO : class
    {
        var model = GetEntityModel<TPOCO>();
        var topic = model.GetTopicName();
        var mapping = _mappingRegistry.GetMapping(typeof(TPOCO));
        var config = BuildConsumerConfig(topic, null);
        config.EnableAutoCommit = false;
        var method = typeof(KafkaConsumerManager)
            .GetMethod(nameof(ResetOffsetsToBeginningInternal), System.Reflection.BindingFlags.NonPublic | System.Reflection.BindingFlags.Instance)!
            .MakeGenericMethod(mapping.AvroKeyType!, mapping.AvroValueType!);
        method.Invoke(this, new object?[] { topic, config, model.Partitions });
    }

    private void ResetOffsetsToBeginningInternal<TKey, TValue>(string topic, ConsumerConfig config, int partitions)
        where TKey : class where TValue : class
    {
        using var consumer = CreateConsumer<TKey, TValue>(config);
        var tps = new List<TopicPartitionOffset>(partitions);
        for (var i = 0; i < partitions; i++)
            tps.Add(new TopicPartitionOffset(topic, new Partition(i), new Offset(0)));
        consumer.Assign(tps);
        consumer.Commit(tps);
    }
### assistant — 2025-08-11T09:52:49.883336+00:00

print(Path('/mnt/data/EventSet.cs').read_text()[:4000])
### tool — 2025-08-11T09:52:50.796160+00:00

using Kafka.Ksql.Linq.Core.Abstractions;
using Kafka.Ksql.Linq.Core.Extensions;
using Kafka.Ksql.Linq.Messaging.Internal;
using Kafka.Ksql.Linq.Messaging;
using Kafka.Ksql.Linq.Core.Dlq;
using Kafka.Ksql.Linq.Query.Abstractions;
using System;
using System.Collections.Generic;
using System.Runtime.CompilerServices;
using System.Threading;
using System.Threading.Tasks;

namespace Kafka.Ksql.Linq;

/// <summary>
/// Base class for EventSet implementing IEntitySet<T>
/// Reason for modification: unified with KsqlContext and added IEntitySet<T> implementation
/// </summary>
public abstract class EventSet<T> : IEntitySet<T> where T : class
{
    protected readonly IKsqlContext _context;
    protected readonly EntityModel _entityModel;
    private readonly ErrorHandlingContext _errorHandlingContext;
    private IErrorSink? _dlqErrorSink;
    private readonly Messaging.Producers.IDlqProducer? _dlqProducer;
    private readonly Messaging.Consumers.ICommitManager? _commitManager;

    protected EventSet(IKsqlContext context, EntityModel? entityModel = null, IErrorSink? dlqErrorSink = null,
        Messaging.Producers.IDlqProducer? dlqProducer = null, Messaging.Consumers.ICommitManager? commitManager = null)
    {
        _context = context ?? throw new ArgumentNullException(nameof(context));
        _errorHandlingContext = new ErrorHandlingContext();
        _dlqErrorSink = dlqErrorSink;
        _dlqProducer = dlqProducer;
        _commitManager = commitManager;

        if (context is KsqlContext kctx)
        {
            _entityModel = kctx.EnsureEntityModel(typeof(T), entityModel);
        }
        else
        {
            _entityModel = entityModel ?? throw new ArgumentNullException(nameof(entityModel));
        }

        if (_dlqErrorSink != null)
        {
            _errorHandlingContext.ErrorOccurred += (ctx, msg) => _dlqErrorSink.HandleErrorAsync(ctx, msg);
        }
    }

    private EventSet(IKsqlContext context, EntityModel entityModel, ErrorHandlingContext errorHandlingContext, IErrorSink? dlqErrorSink,
        Messaging.Producers.IDlqProducer? dlqProducer, Messaging.Consumers.ICommitManager? commitManager)
    {
        _context = context;
        _entityModel = entityModel;
        _errorHandlingContext = errorHandlingContext;
        _dlqErrorSink = dlqErrorSink;
        _dlqProducer = dlqProducer;
        _commitManager = commitManager;

        if (_dlqErrorSink != null)
        {
            _errorHandlingContext.ErrorOccurred += (ctx, msg) => _dlqErrorSink.HandleErrorAsync(ctx, msg);
        }
    }

    /// <summary>
    /// NEW: made abstract - must be implemented by concrete classes
    /// Unifies continuous Kafka consumption and returning a fixed list
    /// </summary>
    public abstract IAsyncEnumerator<T> GetAsyncEnumerator(CancellationToken cancellationToken = default);

    private async IAsyncEnumerable<T> GetAsyncEnumeratorWrapper([EnumeratorCancellation] CancellationToken cancellationToken = default)
    {
        await using var enumerator = GetAsyncEnumerator(cancellationToken);

        while (true)
        {
            bool hasNext;
            try
            {
                hasNext = await enumerator.MoveNextAsync();
            }
            catch (Exception ex)
            {
                var ctx = new KafkaMessageContext
                {
                    MessageId = Guid.NewGuid().ToString(),
                    Tags = new Dictionary<string, object>
                    {
                        ["processing_phase"] = "ForEachAsync"
                    }
                };

                var shouldContinue = await _errorHandlingContext.HandleErrorAsync(default(T)!, ex, ctx);

                if (!shouldContinue)
                {
                    continue;
                }

                throw;
            }

            if (!hasNext)
                yield break;

            yield return enumerator.Current;
        }
    }


    public virtual async Task<List<T>> ToList
### assistant — 2025-08-11T09:52:51.894272+00:00

print(Path('/mnt/data/EventSet.cs').read_text()[4000:12000])
### tool — 2025-08-11T09:52:52.533404+00:00

Async(CancellationToken cancellationToken = default)
    {
        if (_entityModel.EntityType == typeof(Messaging.DlqEnvelope))
            throw new InvalidOperationException("DLQは無限列挙/履歴列であり、バッチ取得・件数指定取得は現状未対応です");

        if (_entityModel.GetExplicitStreamTableType() == StreamTableType.Stream)
            throw new InvalidOperationException("ToListAsync() is not supported on a Stream source. Use ForEachAsync or subscribe for event consumption.");

        var results = new List<T>();

        await foreach (var item in GetAsyncEnumeratorWrapper(cancellationToken))
        {
            results.Add(item);
        }

        return results;
    }
    /// <summary>
    /// ABSTRACT: Producer functionality - implemented in derived classes
    /// </summary>
    protected abstract Task SendEntityAsync(T entity, Dictionary<string, string>? headers, CancellationToken cancellationToken);

    /// <summary>
    /// IEntitySet<T> implementation: producer operations
    /// </summary>
    public virtual async Task AddAsync(T entity, Dictionary<string, string>? headers = null, CancellationToken cancellationToken = default)
    {
        if (entity == null)
            throw new ArgumentNullException(nameof(entity));

        await SendEntityAsync(entity, headers, cancellationToken);
    }

    public virtual Task RemoveAsync(T entity, CancellationToken cancellationToken = default)
    {
        throw new NotSupportedException($"RemoveAsync is not supported for {GetType().Name}.");
    }

    /// <summary>
    /// Retrieves messages from the underlying consumer.
    /// Separated for ease of testing.
    /// </summary>
    /// <param name="context">Active KsqlContext</param>
    /// <param name="cancellationToken">Cancellation token</param>
    /// <returns>Message stream with headers</returns>
    protected virtual IAsyncEnumerable<(T Entity, Dictionary<string, string> Headers, MessageMeta Meta)> ConsumeAsync(
        KsqlContext context,
        CancellationToken cancellationToken)
    {
        return context.GetConsumerManager().ConsumeAsync<T>(cancellationToken);
    }
    /// <summary>
    /// REDESIGNED: ForEachAsync supporting continuous Kafka consumption
    /// Design change: ToListAsync() is disallowed; now based on GetAsyncEnumerator
    /// </summary>
    public virtual Task ForEachAsync(Func<T, Task> action, TimeSpan timeout = default, CancellationToken cancellationToken = default)
    {
        if (action == null)
            throw new ArgumentNullException(nameof(action));

        return ForEachAsync((item, headers, _) => action(item), timeout, cancellationToken);
    }

    [Obsolete("Use ForEachAsync(Func<T, Dictionary<string,string>, MessageMeta, Task>)")]
    public virtual Task ForEachAsync(Func<T, Dictionary<string,string>, Task> action, TimeSpan timeout = default, CancellationToken cancellationToken = default)
        => ForEachAsync((e, h, _) => action(e, h), timeout, cancellationToken);

    public virtual async Task ForEachAsync(Func<T, Dictionary<string,string>, MessageMeta, Task> action, TimeSpan timeout = default, CancellationToken cancellationToken = default)
    {
        if (action == null)
            throw new ArgumentNullException(nameof(action));

        var context = GetContext() as KsqlContext
            ?? throw new InvalidOperationException("KsqlContext is required");

        using var linkedCts = CancellationTokenSource.CreateLinkedTokenSource(cancellationToken);

        if (timeout != default && timeout != TimeSpan.Zero)
        {
            linkedCts.CancelAfter(timeout);
        }
        await foreach (var (entity, headers, meta) in ConsumeAsync(context, linkedCts.Token))
        {
            if (headers.TryGetValue("is_dummy", out var dummyHeader) && bool.TryParse(dummyHeader, out var isDummy) && isDummy)
            {
                continue;
            }

            var maxAttempts = _errorHandlingContext.ErrorAction == ErrorAction.Retry
                ? _errorHandlingContext.RetryCount + 1
                : 1;

            for (var attempt = 1; attempt <= maxAttempts; attempt++)
            {
                try
                {
                    await action(entity, headers, meta);
                    break;
                }
                catch (Exception ex)
                {
                    _errorHandlingContext.CurrentAttempt = attempt;

                    if (attempt < maxAttempts && _errorHandlingContext.ErrorAction == ErrorAction.Retry)
                    {
                        await Task.Delay(_errorHandlingContext.RetryInterval, linkedCts.Token);
                        continue;
                    }

                    var dlq = context.DlqOptions;
                    if (_dlqProducer != null && dlq.EnableForHandlerError && DlqGuard.ShouldSend(dlq, context.DlqLimiter, ex.GetType()))
                    {
                        var env = DlqEnvelopeFactory.From(
                            meta, ex,
                            dlq.ApplicationId, dlq.ConsumerGroup, dlq.Host,
                            dlq.ErrorMessageMaxLength, dlq.StackTraceMaxLength, dlq.NormalizeStackTraceWhitespace);
                        await _dlqProducer.ProduceAsync(env, linkedCts.Token).ConfigureAwait(false);
                    }

                    _commitManager?.Commit(entity);
                    break;
                }
            }
        }
    }

    /// <summary>
    /// IEntitySet<T> implementation: retrieve metadata
    /// </summary>
    public string GetTopicName() => (_entityModel.TopicName ?? _entityModel.EntityType.Name).ToLowerInvariant();

    public EntityModel GetEntityModel() => _entityModel;

    public IKsqlContext GetContext() => _context;

    /// <summary>
    /// Create message context for error handling
    /// </summary>
    private KafkaMessageContext CreateMessageContext(T item)
    {
        return new KafkaMessageContext
        {
            MessageId = Guid.NewGuid().ToString(),
            Tags = new Dictionary<string, object>
            {
                ["entity_type"] = typeof(T).Name,
                ["topic_name"] = GetTopicName(),
                ["processing_phase"] = "ForEachAsync",
                ["timestamp"] = DateTime.UtcNow
            }
        };
    }

    /// <summary>
    /// Creates a ManualCommitMessage instance
    /// </summary>
    protected virtual IManualCommitMessage<T> CreateManualCommitMessage(T item)
    {
        return new ManualCommitMessage<T>(item, () => Task.CompletedTask, () => Task.CompletedTask);
    }

    /// <summary>
    /// Yields messages as different types depending on UseManualCommit
    /// </summary>
    public virtual async IAsyncEnumerable<object> ForEachAsync([EnumeratorCancellation] CancellationToken cancellationToken = default)
    {
        await foreach (var item in GetAsyncEnumeratorWrapper(cancellationToken))
        {
            if (_entityModel.UseManualCommit)
            {
                yield return CreateManualCommitMessage(item);
            }
            else
            {
                yield return item;
            }
        }
    }

    /// <summary>
    /// Configure the error handling policy
    /// </summary>
    internal virtual EventSet<T> WithErrorPolicy(ErrorHandlingPolicy policy)
    {
        if (policy == null)
            throw new ArgumentNullException(nameof(policy));

        _errorHandlingContext.ErrorAction = policy.Action;
        _errorHandlingContext.RetryCount = policy.RetryCount;
        _errorHandlingContext.RetryInterval = policy.RetryInterval;
        _errorHandlingContext.CustomHandler = policy.CustomHandler;

        return this;
    }

    public override string ToString()
    {
        return $"EventSet<{typeof(T).Name}> - Topic: {GetTopicName()}";
    }



    /// <summary>
    /// Specifies the number of retries.
    /// Used when ErrorAction.Retry is selected.
    /// </summary>
    /// <param name="maxRetries">Maximum retry count</param>
    /// <para
### assistant — 2025-08-11T09:52:53.653518+00:00

print(Path('/mnt/data/EventSet.cs').read_text()[12000:20000])
### tool — 2025-08-11T09:52:55.072246+00:00

m name="retryInterval">Retry interval (optional)</param>
    /// <returns>EventSet with retry configuration applied</returns>
    public EventSet<T> WithRetry(int maxRetries, TimeSpan? retryInterval = null)
    {
        if (maxRetries < 0)
            throw new ArgumentException("Retry count must be zero or greater", nameof(maxRetries));

        var newContext = new ErrorHandlingContext
        {
            ErrorAction = _errorHandlingContext.ErrorAction,
            RetryCount = maxRetries,
            RetryInterval = retryInterval ?? TimeSpan.FromSeconds(1)
        };

        return CreateNewInstance(_context, _entityModel, newContext, _dlqErrorSink);
    }

    /// <summary>
    /// Passes the POCO to the business logic.
    /// After receiving from Kafka, each element is transformed using the supplied function.
    /// Exceptions and retries are handled based on the OnError and WithRetry settings.
    /// </summary>
    /// <typeparam name="TResult">Result type</typeparam>
    /// <param name="mapper">Mapping function</param>
    /// <returns>The mapped EventSet</returns>
    public async Task<EventSet<TResult>> Map<TResult>(Func<T, Task<TResult>> mapper) where TResult : class
    {
        if (mapper == null)
            throw new ArgumentNullException(nameof(mapper));

        var results = new List<TResult>();
        var sourceData = await ToListAsync();

        foreach (var item in sourceData)
        {
            var itemErrorContext = new ErrorHandlingContext
            {
                ErrorAction = _errorHandlingContext.ErrorAction,
                RetryCount = _errorHandlingContext.RetryCount,
                RetryInterval = _errorHandlingContext.RetryInterval
            };

            await ProcessItemWithErrorHandling(
                item,
                mapper,
                results,
                itemErrorContext);
        }

        var resultEntityModel = CreateEntityModelForType<TResult>();
        return new MappedEventSet<TResult>(results, _context, resultEntityModel, _dlqErrorSink);
    }

    /// <summary>
    /// Synchronous version of the Map function
    /// </summary>
    public EventSet<TResult> Map<TResult>(Func<T, TResult> mapper) where TResult : class
    {
        if (mapper == null)
            throw new ArgumentNullException(nameof(mapper));

        var results = new List<TResult>();
        var sourceData = ToListAsync().GetAwaiter().GetResult();

        foreach (var item in sourceData)
        {
            var itemErrorContext = new ErrorHandlingContext
            {
                ErrorAction = _errorHandlingContext.ErrorAction,
                RetryCount = _errorHandlingContext.RetryCount,
                RetryInterval = _errorHandlingContext.RetryInterval
            };

            ProcessItemWithErrorHandlingSync(
                item,
                mapper,
                results,
                itemErrorContext);
        }
        var resultEntityModel = CreateEntityModelForType<TResult>();
        return new MappedEventSet<TResult>(results, _context, resultEntityModel, _dlqErrorSink);
    }

    // Abstract method: create a new instance in derived classes
    protected virtual EventSet<T> CreateNewInstance(IKsqlContext context, EntityModel entityModel, ErrorHandlingContext errorContext, IErrorSink? dlqErrorSink)
    {
        // Default implementation: concrete classes must override
        throw new NotImplementedException("Derived classes must implement CreateNewInstance");
    }

    private EntityModel CreateEntityModelForType<TResult>() where TResult : class
    {
        return new EntityModel
        {
            EntityType = typeof(TResult),
            TopicName = $"{typeof(TResult).Name.ToLowerInvariant()}_mapped",
            AllProperties = typeof(TResult).GetProperties(),
            KeyProperties = Array.Empty<System.Reflection.PropertyInfo>(),
            ValidationResult = new ValidationResult { IsValid = true }
        };
    }

    /// <summary>
    /// Item-level processing with error handling (async version)
    /// </summary>
    private async Task ProcessItemWithErrorHandling<TResult>(
        T item,
        Func<T, Task<TResult>> mapper,
        List<TResult> results,
        ErrorHandlingContext errorContext) where TResult : class
    {
        var maxAttempts = errorContext.ErrorAction == ErrorAction.Retry
            ? errorContext.RetryCount + 1
            : 1;

        for (int attempt = 1; attempt <= maxAttempts; attempt++)
        {
            try
            {
                var result = await mapper(item);
                results.Add(result);
                return; // Processing completed successfully
            }
            catch (Exception ex)
            {
                errorContext.CurrentAttempt = attempt;

                // Retry regardless of ErrorAction if this is not the final attempt
                if (attempt < maxAttempts && errorContext.ErrorAction == ErrorAction.Retry)
                {
                    Console.WriteLine($"[{DateTime.UtcNow:HH:mm:ss}] Retry {attempt}/{errorContext.RetryCount}: {ex.Message}");
                    await Task.Delay(errorContext.RetryInterval);
                    continue;
                }

                // Perform error handling on the last attempt or when not retrying
                var shouldContinue = await errorContext.HandleErrorAsync(item, ex, CreateContext(item, errorContext));

                if (!shouldContinue)
                {
                    return; // Skip this item and move to the next
                }
            }
        }
    }

    /// <summary>
    /// Item-level processing with error handling (sync version)
    /// </summary>
    private void ProcessItemWithErrorHandlingSync<TResult>(
        T item,
        Func<T, TResult> mapper,
        List<TResult> results,
        ErrorHandlingContext errorContext) where TResult : class
    {
        var maxAttempts = errorContext.ErrorAction == ErrorAction.Retry
            ? errorContext.RetryCount + 1
            : 1;

        for (int attempt = 1; attempt <= maxAttempts; attempt++)
        {
            try
            {
                var result = mapper(item);
                results.Add(result);
                return; // Processing completed successfully
            }
            catch (Exception ex)
            {
                errorContext.CurrentAttempt = attempt;

                // Retry regardless of ErrorAction if this is not the final attempt
                if (attempt < maxAttempts && errorContext.ErrorAction == ErrorAction.Retry)
                {
                    Console.WriteLine($"[{DateTime.UtcNow:HH:mm:ss}] Retry {attempt}/{errorContext.RetryCount}: {ex.Message}");
                    Thread.Sleep(errorContext.RetryInterval);
                    continue;
                }

                // Perform error handling on the last attempt or when not retrying
                var shouldContinue = errorContext.HandleErrorAsync(item, ex, CreateContext(item, errorContext)).GetAwaiter().GetResult();

                if (!shouldContinue)
                {
                    return; // Skip this item and proceed to the next
                }
            }
        }
    }

    /// <summary>
    /// Create a message context
    /// </summary>
    private KafkaMessageContext CreateContext(T item, ErrorHandlingContext errorContext)
    {
        return new KafkaMessageContext
        {
            MessageId = Guid.NewGuid().ToString(),
            Tags = new Dictionary<string, object>
            {
                ["original_topic"] = GetTopicName(),
                ["original_partition"] = 0, // Replace with actual value
                ["original_offset"] = 0, // Replace with actual value
                ["retry_count"] = errorContext.CurrentAttempt,
                ["error_phase"] = "Processing"
            }
        };
    }

}
internal class MappedEventSet<T> : EventSet<T> where T : class
{
    pri
### assistant — 2025-08-11T09:52:56.144296+00:00

print(Path('/mnt/data/EventSet.cs').read_text()[20000:35000])
### tool — 2025-08-11T09:52:56.745686+00:00

vate readonly List<T> _mapped;
    private readonly EntityModel _originalEntityModel;

    public MappedEventSet(List<T> mappedItems, IKsqlContext context, EntityModel originalEntityModel, IErrorSink? errorSink = null)
        : base(context, CreateMappedEntityModel<T>(originalEntityModel), errorSink)
    {
        _mapped = mappedItems ?? throw new ArgumentNullException(nameof(mappedItems));
        _originalEntityModel = originalEntityModel;
    }

    /// <summary>
    /// NEW: GetAsyncEnumerator implementation for fixed lists
    /// Returns each _mapped[i] sequentially via yield return
    /// </summary>
    public override async IAsyncEnumerator<T> GetAsyncEnumerator(CancellationToken cancellationToken = default)
    {
        foreach (var item in _mapped)
        {
            if (cancellationToken.IsCancellationRequested)
                yield break;

            yield return item;

            // Inserted to treat the loop asynchronously (avoid CPU intensive work)
            await Task.Yield();
        }
    }

    /// <summary>
    /// OPTIMIZATION: ToListAsync - already a fixed list so return immediately
    /// </summary>
    public override async Task<List<T>> ToListAsync(CancellationToken cancellationToken = default)
    {
        if (_entityModel.GetExplicitStreamTableType() == StreamTableType.Stream)
            throw new InvalidOperationException("ToListAsync() is not supported on a Stream source. Use ForEachAsync or subscribe for event consumption.");

        // Already a fixed list; return a copy
        await Task.CompletedTask;
        return new List<T>(_mapped);
    }

    /// <summary>
    /// Data after Map cannot be sent via Producer
    /// </summary>
    protected override Task SendEntityAsync(T entity, Dictionary<string, string>? headers, CancellationToken cancellationToken)
    {
        throw new NotSupportedException(
            $"MappedEventSet<{typeof(T).Name}> does not support AddAsync operations. " +
            "Mapped data is read-only and derived from transformation operations.");
    }

    public override Task RemoveAsync(T entity, CancellationToken cancellationToken = default)
    {
        throw new NotSupportedException($"MappedEventSet<{typeof(T).Name}> does not support RemoveAsync operations.");
    }

    /// <summary>
    /// Helper method to create a MappedEventSet
    /// </summary>
    public static MappedEventSet<T> Create(List<T> mappedItems, IKsqlContext context, EntityModel originalEntityModel, IErrorSink? errorSink = null)
    {
        return new MappedEventSet<T>(mappedItems, context, originalEntityModel, errorSink);
    }

    /// <summary>
    /// Create a MappedEventSet with DLQ support
    /// </summary>
    public static MappedEventSet<T> CreateWithDlq(List<T> mappedItems, IKsqlContext context, EntityModel originalEntityModel, IErrorSink dlqErrorSink)
    {
        return new MappedEventSet<T>(mappedItems, context, originalEntityModel, dlqErrorSink);
    }

    /// <summary>
    /// Create an EntityModel for mapped data
    /// </summary>
    private static EntityModel CreateMappedEntityModel<TMapped>(EntityModel originalModel) where TMapped : class
    {
        return new EntityModel
        {
            EntityType = typeof(TMapped),
            TopicName = $"{originalModel.GetTopicName()}_mapped",
            AllProperties = typeof(TMapped).GetProperties(),
            KeyProperties = Array.Empty<System.Reflection.PropertyInfo>(), // No key after mapping
            ValidationResult = new ValidationResult { IsValid = true }
        };
    }

    public override string ToString()
    {
        return $"MappedEventSet<{typeof(T).Name}> - Items: {_mapped.Count}";
    }
}
### assistant — 2025-08-11T09:52:57.748584+00:00

text = Path('/mnt/data/EventSet.cs').read_text()
idx = text.find("ForEachAsync")
print(idx)
print(text[idx-400:idx+600])
### tool — 2025-08-11T09:52:59.915382+00:00

3532
      try
            {
                hasNext = await enumerator.MoveNextAsync();
            }
            catch (Exception ex)
            {
                var ctx = new KafkaMessageContext
                {
                    MessageId = Guid.NewGuid().ToString(),
                    Tags = new Dictionary<string, object>
                    {
                        ["processing_phase"] = "ForEachAsync"
                    }
                };

                var shouldContinue = await _errorHandlingContext.HandleErrorAsync(default(T)!, ex, ctx);

                if (!shouldContinue)
                {
                    continue;
                }

                throw;
            }

            if (!hasNext)
                yield break;

            yield return enumerator.Current;
        }
    }


    public virtual async Task<List<T>> ToListAsync(CancellationToken cancellationToken = default)
    {
        if (_entityModel.EntityType == typeof(Messaging.DlqEnvelope))
### assistant — 2025-08-11T09:53:00.906301+00:00

print("has wrapper", "GetAsyncEnumeratorWrapper" in text)
start = text.find("GetAsyncEnumeratorWrapper")
print(text[start-300:start+600])
### assistant — 2025-08-11T09:53:02.668683+00:00

_(empty)_
### tool — 2025-08-11T09:53:03.229023+00:00

has wrapper True
/ NEW: made abstract - must be implemented by concrete classes
    /// Unifies continuous Kafka consumption and returning a fixed list
    /// </summary>
    public abstract IAsyncEnumerator<T> GetAsyncEnumerator(CancellationToken cancellationToken = default);

    private async IAsyncEnumerable<T> GetAsyncEnumeratorWrapper([EnumeratorCancellation] CancellationToken cancellationToken = default)
    {
        await using var enumerator = GetAsyncEnumerator(cancellationToken);

        while (true)
        {
            bool hasNext;
            try
            {
                hasNext = await enumerator.MoveNextAsync();
            }
            catch (Exception ex)
            {
                var ctx = new KafkaMessageContext
                {
                    MessageId = Guid.NewGuid().ToString(),
                    Tags = new Dictionary<string, object>
                    {
### assistant — 2025-08-11T09:53:04.367898+00:00

import re
for m in re.finditer(r'ForEachAsync', text):
    print(m.start(), text[m.start()-100:m.start()+200])
### assistant — 2025-08-11T09:53:06.378817+00:00

_(empty)_
### tool — 2025-08-11T09:53:07.363897+00:00

3532 ew Dictionary<string, object>
                    {
                        ["processing_phase"] = "ForEachAsync"
                    }
                };

                var shouldContinue = await _errorHandlingContext.HandleErrorAsync(default(T)!, ex, ctx);

                if (!shouldContinue)
 
4404         throw new InvalidOperationException("ToListAsync() is not supported on a Stream source. Use ForEachAsync or subscribe for event consumption.");

        var results = new List<T>();

        await foreach (var item in GetAsyncEnumeratorWrapper(cancellationToken))
        {
            result
6141 etConsumerManager().ConsumeAsync<T>(cancellationToken);
    }
    /// <summary>
    /// REDESIGNED: ForEachAsync supporting continuous Kafka consumption
    /// Design change: ToListAsync() is disallowed; now based on GetAsyncEnumerator
    /// </summary>
    public virtual Task ForEachAsync(Func<T,
6321 stAsync() is disallowed; now based on GetAsyncEnumerator
    /// </summary>
    public virtual Task ForEachAsync(Func<T, Task> action, TimeSpan timeout = default, CancellationToken cancellationToken = default)
    {
        if (action == null)
            throw new ArgumentNullException(nameof(actio
6542    if (action == null)
            throw new ArgumentNullException(nameof(action));

        return ForEachAsync((item, headers, _) => action(item), timeout, cancellationToken);
    }

    [Obsolete("Use ForEachAsync(Func<T, Dictionary<string,string>, MessageMeta, Task>)")]
    public virtual Task F
6646 achAsync((item, headers, _) => action(item), timeout, cancellationToken);
    }

    [Obsolete("Use ForEachAsync(Func<T, Dictionary<string,string>, MessageMeta, Task>)")]
    public virtual Task ForEachAsync(Func<T, Dictionary<string,string>, Task> action, TimeSpan timeout = default, CancellationTok
6741 "Use ForEachAsync(Func<T, Dictionary<string,string>, MessageMeta, Task>)")]
    public virtual Task ForEachAsync(Func<T, Dictionary<string,string>, Task> action, TimeSpan timeout = default, CancellationToken cancellationToken = default)
        => ForEachAsync((e, h, _) => action(e, h), timeout, can
6889 Task> action, TimeSpan timeout = default, CancellationToken cancellationToken = default)
        => ForEachAsync((e, h, _) => action(e, h), timeout, cancellationToken);

    public virtual async Task ForEachAsync(Func<T, Dictionary<string,string>, MessageMeta, Task> action, TimeSpan timeout = defaul
6989 ForEachAsync((e, h, _) => action(e, h), timeout, cancellationToken);

    public virtual async Task ForEachAsync(Func<T, Dictionary<string,string>, MessageMeta, Task> action, TimeSpan timeout = default, CancellationToken cancellationToken = default)
    {
        if (action == null)
            thro
10187 f(T).Name,
                ["topic_name"] = GetTopicName(),
                ["processing_phase"] = "ForEachAsync",
                ["timestamp"] = DateTime.UtcNow
            }
        };
    }

    /// <summary>
    /// Creates a ManualCommitMessage instance
    /// </summary>
    protected virtual
10719 s depending on UseManualCommit
    /// </summary>
    public virtual async IAsyncEnumerable<object> ForEachAsync([EnumeratorCancellation] CancellationToken cancellationToken = default)
    {
        await foreach (var item in GetAsyncEnumeratorWrapper(cancellationToken))
        {
            if (_e
21443         throw new InvalidOperationException("ToListAsync() is not supported on a Stream source. Use ForEachAsync or subscribe for event consumption.");

        // Already a fixed list; return a copy
        await Task.CompletedTask;
        return new List<T>(_mapped);
    }

    /// <summary>
### assistant — 2025-08-11T09:53:08.459601+00:00

print(text[21000:22000])
### tool — 2025-08-11T09:53:09.244211+00:00

await Task.Yield();
        }
    }

    /// <summary>
    /// OPTIMIZATION: ToListAsync - already a fixed list so return immediately
    /// </summary>
    public override async Task<List<T>> ToListAsync(CancellationToken cancellationToken = default)
    {
        if (_entityModel.GetExplicitStreamTableType() == StreamTableType.Stream)
            throw new InvalidOperationException("ToListAsync() is not supported on a Stream source. Use ForEachAsync or subscribe for event consumption.");

        // Already a fixed list; return a copy
        await Task.CompletedTask;
        return new List<T>(_mapped);
    }

    /// <summary>
    /// Data after Map cannot be sent via Producer
    /// </summary>
    protected override Task SendEntityAsync(T entity, Dictionary<string, string>? headers, CancellationToken cancellationToken)
    {
        throw new NotSupportedException(
            $"MappedEventSet<{typeof(T).Name}> does not support AddAsync operations. " +
            "Mapped data is
### assistant — 2025-08-11T09:53:10.280139+00:00

start = text.find("public virtual async IAsyncEnumerable<object> ForEachAsync")
print(text[start:start+800])
### assistant — 2025-08-11T09:53:11.083667+00:00

_(empty)_
### tool — 2025-08-11T09:53:11.254924+00:00

public virtual async IAsyncEnumerable<object> ForEachAsync([EnumeratorCancellation] CancellationToken cancellationToken = default)
    {
        await foreach (var item in GetAsyncEnumeratorWrapper(cancellationToken))
        {
            if (_entityModel.UseManualCommit)
            {
                yield return CreateManualCommitMessage(item);
            }
            else
            {
                yield return item;
            }
        }
    }

    /// <summary>
    /// Configure the error handling policy
    /// </summary>
    internal virtual EventSet<T> WithErrorPolicy(ErrorHandlingPolicy policy)
    {
        if (policy == null)
            throw new ArgumentNullException(nameof(policy));

        _errorHandlingContext.ErrorAction = policy.Action;
        _errorHandlingCont
### assistant — 2025-08-11T09:53:12.316169+00:00

kcm = Path('/mnt/data/KafkaConsumerManager.cs').read_text()
print("Commit(" in kcm)
### assistant — 2025-08-11T09:53:16.760833+00:00

_(empty)_
### tool — 2025-08-11T09:53:28.071406+00:00

True
### assistant — 2025-08-11T09:53:29.180605+00:00

import re
for m in re.finditer(r'Commit\(', kcm):
    print(m.start(), kcm[m.start()-100:m.start()+200])
### tool — 2025-08-11T09:53:29.978213+00:00

6674  dlqProducer.ProduceAsync(env, cancellationToken).ConfigureAwait(false);
        }
        consumer.Commit(result);
    }

    private IConsumer<TKey, TValue> CreateConsumer<TKey, TValue>(ConsumerConfig config)
        where TKey : class where TValue : class
    {
        return new ConsumerBuilder<
11982 tionOffset(topic, new Partition(i), new Offset(0)));
        consumer.Assign(tps);
        consumer.Commit(tps);
    }

    public void Dispose()
    {
        if (_disposed) return;
        if (_schemaRegistryClient.IsValueCreated)
            _schemaRegistryClient.Value.Dispose();
        _dispose
### assistant — 2025-08-11T09:53:31.095698+00:00

for fname in base.glob("**/*.cs"):
    txt = fname.read_text()
    if "class MessageMeta" in txt or "struct MessageMeta" in txt:
        print("found in", fname)
### assistant — 2025-08-11T09:53:32.442924+00:00

_(empty)_
### assistant — 2025-08-11T09:53:33.838245+00:00

# maybe in KafkaConsumerManager.cs message meta struct defined?
print("MessageMeta" in kcm)
print(re.findall(r'(record|class|struct)\s+MessageMeta', kcm))
### tool — 2025-08-11T09:53:35.050689+00:00

True
[]
### assistant — 2025-08-11T09:53:36.136974+00:00

# print around occurrences of MessageMeta details
for m in re.finditer(r'MessageMeta', kcm):
    print(kcm[m.start()-200:m.start()+200])
### tool — 2025-08-11T09:53:37.096797+00:00

stryClient);
        _dlq = _options.DlqOptions;
        _limiter = limiter ?? new SimpleRateLimiter(_dlq.MaxPerSecond);
    }



    public async IAsyncEnumerable<(TPOCO, Dictionary<string, string>, MessageMeta)> ConsumeAsync<TPOCO>(
        [EnumeratorCancellation] CancellationToken cancellationToken = default) where TPOCO : class
    {
        var model = GetEntityModel<TPOCO>();
        var to
on.BindingFlags.Instance)!
            .MakeGenericMethod(mapping.AvroKeyType!, mapping.AvroValueType!, typeof(TPOCO));

        var enumerable = (IAsyncEnumerable<(TPOCO, Dictionary<string, string>, MessageMeta)>)method
            .Invoke(this, new object?[] { topic, config, mapping, cancellationToken })!;

        await foreach (var item in enumerable.WithCancellation(cancellationToken))
      
n })!;

        await foreach (var item in enumerable.WithCancellation(cancellationToken))
            yield return item;
    }

    private async IAsyncEnumerable<(TPOCO, Dictionary<string, string>, MessageMeta)> ConsumeInternal<TKey, TValue, TPOCO>(
        string topicName,
        ConsumerConfig config,
        KeyValueTypeMapping mapping,
        [EnumeratorCancellation] CancellationToken can
         break;
            }
            if (result == null || result.IsPartitionEOF)
                continue;

            TPOCO entity;
            Dictionary<string, string> headers;
            MessageMeta meta;
            try
            {
                entity = (TPOCO)mapping.CombineFromAvroKeyValue(result.Message.Key, result.Message.Value!, typeof(TPOCO));
                headers = new
               foreach (var h in result.Message.Headers)
                        headers[h.Key] = System.Text.Encoding.UTF8.GetString(h.GetValueBytes());
                }

                meta = new MessageMeta(
                    Topic: result.Topic,
                    Partition: result.Partition,
                    Offset: result.Offset,
                    TimestampUtc: result.Message.Times
### assistant — 2025-08-11T09:53:38.155283+00:00

print(kcm[8000:10000])
### tool — 2025-08-11T09:53:39.668489+00:00

(string.IsNullOrWhiteSpace(groupId))
            groupId = "default-group";

        var consumerConfig = new ConsumerConfig
        {
            BootstrapServers = _options.Common.BootstrapServers,
            ClientId = _options.Common.ClientId,
            GroupId = groupId,
            AutoOffsetReset = Enum.Parse<AutoOffsetReset>(topicConfig.Consumer.AutoOffsetReset),
            EnableAutoCommit = topicConfig.Consumer.EnableAutoCommit,
            AutoCommitIntervalMs = topicConfig.Consumer.AutoCommitIntervalMs,
            SessionTimeoutMs = topicConfig.Consumer.SessionTimeoutMs,
            HeartbeatIntervalMs = topicConfig.Consumer.HeartbeatIntervalMs,
            MaxPollIntervalMs = topicConfig.Consumer.MaxPollIntervalMs,
            FetchMinBytes = topicConfig.Consumer.FetchMinBytes,
            FetchMaxBytes = topicConfig.Consumer.FetchMaxBytes,
            IsolationLevel = Enum.Parse<IsolationLevel>(topicConfig.Consumer.IsolationLevel)
        };

        if (subscriptionOptions != null)
        {
            if (subscriptionOptions.AutoCommit.HasValue)
                consumerConfig.EnableAutoCommit = subscriptionOptions.AutoCommit.Value;
            if (subscriptionOptions.SessionTimeout.HasValue)
                consumerConfig.SessionTimeoutMs = (int)subscriptionOptions.SessionTimeout.Value.TotalMilliseconds;
            if (subscriptionOptions.HeartbeatInterval.HasValue)
                consumerConfig.HeartbeatIntervalMs = (int)subscriptionOptions.HeartbeatInterval.Value.TotalMilliseconds;
            if (subscriptionOptions.MaxPollInterval.HasValue)
                consumerConfig.MaxPollIntervalMs = (int)subscriptionOptions.MaxPollInterval.Value.TotalMilliseconds;
        }

        if (_options.Common.SecurityProtocol != SecurityProtocol.Plaintext)
        {
            consumerConfig.SecurityProtocol = _options.Common.SecurityProtocol;
            if (_options.Common.SaslMechanism.HasValue)
            {
                consumerConfig.SaslMecha
### assistant — 2025-08-11T09:53:40.669360+00:00

for fname in base.glob("**/*.cs"):
    if "MessageMeta(" in fname.read_text():
        print(fname)
### assistant — 2025-08-11T09:53:41.891389+00:00

_(empty)_
### tool — 2025-08-11T09:53:42.066543+00:00

/mnt/data/KafkaConsumerManager.cs
### assistant — 2025-08-11T09:53:43.193864+00:00

"ICommitManager" in kcm
### tool — 2025-08-11T09:53:47.113195+00:00

False
### assistant — 2025-08-11T09:53:47.423637+00:00

_(empty)_
### assistant — 2025-08-11T09:53:48.248740+00:00

# search for _entityModel definition
for m in re.finditer(r'EntityModel', text):
    print(m.start(), text[m.start()-80:m.start()+120])
### assistant — 2025-08-11T09:53:52.437662+00:00

_(empty)_
### tool — 2025-08-11T09:53:52.761039+00:00

713  : class
{
    protected readonly IKsqlContext _context;
    protected readonly EntityModel _entityModel;
    private readonly ErrorHandlingContext _errorHandlingContext;
    private IErrorSink? _dlqE
1031 s.ICommitManager? _commitManager;

    protected EventSet(IKsqlContext context, EntityModel? entityModel = null, IErrorSink? dlqErrorSink = null,
        Messaging.Producers.IDlqProducer? dlqProducer 
1567 f (context is KsqlContext kctx)
        {
            _entityModel = kctx.EnsureEntityModel(typeof(T), entityModel);
        }
        else
        {
            _entityModel = entityModel ?? throw ne
1956 rorAsync(ctx, msg);
        }
    }

    private EventSet(IKsqlContext context, EntityModel entityModel, ErrorHandlingContext errorHandlingContext, IErrorSink? dlqErrorSink,
        Messaging.Producer
9632 odel.TopicName ?? _entityModel.EntityType.Name).ToLowerInvariant();

    public EntityModel GetEntityModel() => _entityModel;

    public IKsqlContext GetContext() => _context;

    /// <summary>
    
9647 ?? _entityModel.EntityType.Name).ToLowerInvariant();

    public EntityModel GetEntityModel() => _entityModel;

    public IKsqlContext GetContext() => _context;

    /// <summary>
    /// Create mess
13910        results,
                itemErrorContext);
        }

        var resultEntityModel = CreateEntityModelForType<TResult>();
        return new MappedEventSet<TResult>(results, _context, resultE
13930             itemErrorContext);
        }

        var resultEntityModel = CreateEntityModelForType<TResult>();
        return new MappedEventSet<TResult>(results, _context, resultEntityModel, _dlqErro
14029 TResult>();
        return new MappedEventSet<TResult>(results, _context, resultEntityModel, _dlqErrorSink);
    }

    /// <summary>
    /// Synchronous version of the Map function
    /// </summary>
14961         results,
                itemErrorContext);
        }
        var resultEntityModel = CreateEntityModelForType<TResult>();
        return new MappedEventSet<TResult>(results, _context, resultE
14981              itemErrorContext);
        }
        var resultEntityModel = CreateEntityModelForType<TResult>();
        return new MappedEventSet<TResult>(results, _context, resultEntityModel, _dlqErro
15080 TResult>();
        return new MappedEventSet<TResult>(results, _context, resultEntityModel, _dlqErrorSink);
    }

    // Abstract method: create a new instance in derived classes
    protected virtu
15255 asses
    protected virtual EventSet<T> CreateNewInstance(IKsqlContext context, EntityModel entityModel, ErrorHandlingContext errorContext, IErrorSink? dlqErrorSink)
    {
        // Default implement
15527 ception("Derived classes must implement CreateNewInstance");
    }

    private EntityModel CreateEntityModelForType<TResult>() where TResult : class
    {
        return new EntityModel
        {
   
15545 lasses must implement CreateNewInstance");
    }

    private EntityModel CreateEntityModelForType<TResult>() where TResult : class
    {
        return new EntityModel
        {
            EntityTyp
15622 ateEntityModelForType<TResult>() where TResult : class
    {
        return new EntityModel
        {
            EntityType = typeof(TResult),
            TopicName = $"{typeof(TResult).Name.ToLowerI
20052 T> where T : class
{
    private readonly List<T> _mapped;
    private readonly EntityModel _originalEntityModel;

    public MappedEventSet(List<T> mappedItems, IKsqlContext context, EntityModel orig
20073     private readonly List<T> _mapped;
    private readonly EntityModel _originalEntityModel;

    public MappedEventSet(List<T> mappedItems, IKsqlContext context, EntityModel originalEntityModel, IErr
20156 ityModel;

    public MappedEventSet(List<T> mappedItems, IKsqlContext context, EntityModel originalEntityModel, IErrorSink? errorSink = null)
        : base(context, CreateMappedEntityModel<T>(origin
20176 c MappedEventSet(List<T> mappedItems, IKsqlContext context, EntityModel originalEntityModel, IErrorSink? errorSink = null)
        : base(context, CreateMappedEntityModel<T>(originalEntityModel), erro
20255 lEntityModel, IErrorSink? errorSink = null)
        : base(context, CreateMappedEntityModel<T>(originalEntityModel), errorSink)
    {
        _mapped = mappedItems ?? throw new ArgumentNullException(n
20278 k? errorSink = null)
        : base(context, CreateMappedEntityModel<T>(originalEntityModel), errorSink)
    {
        _mapped = mappedItems ?? throw new ArgumentNullException(nameof(mappedItems));
  
20413 Items ?? throw new ArgumentNullException(nameof(mappedItems));
        _originalEntityModel = originalEntityModel;
    }

    /// <summary>
    /// NEW: GetAsyncEnumerator implementation for fixed lis
20435 umentNullException(nameof(mappedItems));
        _originalEntityModel = originalEntityModel;
    }

    /// <summary>
    /// NEW: GetAsyncEnumerator implementation for fixed lists
    /// Returns eac
22463 blic static MappedEventSet<T> Create(List<T> mappedItems, IKsqlContext context, EntityModel originalEntityModel, IErrorSink? errorSink = null)
    {
        return new MappedEventSet<T>(mappedItems, c
22483 entSet<T> Create(List<T> mappedItems, IKsqlContext context, EntityModel originalEntityModel, IErrorSink? errorSink = null)
    {
        return new MappedEventSet<T>(mappedItems, context, originalEnti
22599  null)
    {
        return new MappedEventSet<T>(mappedItems, context, originalEntityModel, errorSink);
    }

    /// <summary>
    /// Create a MappedEventSet with DLQ support
    /// </summary>
  
22810 atic MappedEventSet<T> CreateWithDlq(List<T> mappedItems, IKsqlContext context, EntityModel originalEntityModel, IErrorSink dlqErrorSink)
    {
        return new MappedEventSet<T>(mappedItems, contex
22830 T> CreateWithDlq(List<T> mappedItems, IKsqlContext context, EntityModel originalEntityModel, IErrorSink dlqErrorSink)
    {
        return new MappedEventSet<T>(mappedItems, context, originalEntityMod
22941 rSink)
    {
        return new MappedEventSet<T>(mappedItems, context, originalEntityModel, dlqErrorSink);
    }

    /// <summary>
    /// Create an EntityModel for mapped data
    /// </summary>
  
23012  originalEntityModel, dlqErrorSink);
    }

    /// <summary>
    /// Create an EntityModel for mapped data
    /// </summary>
    private static EntityModel CreateMappedEntityModel<TMapped>(EntityMod
23078 /// Create an EntityModel for mapped data
    /// </summary>
    private static EntityModel CreateMappedEntityModel<TMapped>(EntityModel originalModel) where TMapped : class
    {
        return new E
23102 l for mapped data
    /// </summary>
    private static EntityModel CreateMappedEntityModel<TMapped>(EntityModel originalModel) where TMapped : class
    {
        return new EntityModel
        {
   
23123  /// </summary>
    private static EntityModel CreateMappedEntityModel<TMapped>(EntityModel originalModel) where TMapped : class
    {
        return new EntityModel
        {
            EntityType =
23197 pped>(EntityModel originalModel) where TMapped : class
    {
        return new EntityModel
        {
            EntityType = typeof(TMapped),
            TopicName = $"{originalModel.GetTopicName()}
### assistant — 2025-08-11T09:53:53.892270+00:00

# print definition of EntityModel class? likely in another file not uploaded.
### assistant — 2025-08-11T09:53:55.745688+00:00

for m in re.finditer(r"GroupId", text):
    print(m.start(), text[m.start()-120:m.start()+120])
### assistant — 2025-08-11T09:53:57.534840+00:00

_(empty)_
### assistant — 2025-08-11T09:53:58.673081+00:00

print("NoopCommitManager" in text)
### assistant — 2025-08-11T09:54:05.880955+00:00

_(empty)_
### tool — 2025-08-11T09:54:07.327491+00:00

False
### assistant — 2025-08-11T09:54:08.429930+00:00

# print more around meta creation
s = kcm
i = s.find("meta = new MessageMeta")
print(s[i-400:i+400])
### assistant — 2025-08-11T09:54:12.650172+00:00

_(empty)_
### tool — 2025-08-11T09:54:13.051930+00:00

FromAvroKeyValue(result.Message.Key, result.Message.Value!, typeof(TPOCO));
                headers = new Dictionary<string, string>();
                if (result.Message.Headers != null)
                {
                    foreach (var h in result.Message.Headers)
                        headers[h.Key] = System.Text.Encoding.UTF8.GetString(h.GetValueBytes());
                }

                meta = new MessageMeta(
                    Topic: result.Topic,
                    Partition: result.Partition,
                    Offset: result.Offset,
                    TimestampUtc: result.Message.Timestamp.UtcDateTime,
                    SchemaIdKey: TryGetSchemaId(result.Message.Key as byte[]),
                    SchemaIdValue: TryGetSchemaId(result.Message.Value as byte[]),
### assistant — 2025-08-11T09:54:14.171362+00:00

print(s[i+400:i+1000])
### tool — 2025-08-11T09:54:18.227771+00:00

KeyIsNull: result.Message.Key is null,
                    HeaderAllowList: ExtractAllowedHeaders(result.Message.Headers, _dlq.HeaderAllowList, _dlq.HeaderValueMaxLength)
                );
            }
            catch (Exception ex)
            {
                await HandleMappingException(result, ex, _dlqProducer, consumer, _dlq, _limiter, cancellationToken).ConfigureAwait(false);
                continue;
            }

            yield return (entity, headers, meta);
            await Task.CompletedTask;
        }
    }

    internal static async Task HandleMappingException
### assistant — 2025-08-11T09:54:19.357458+00:00

了解。「**_commitManager がオフセットを管理して実コミットする中身**」を最小差分で補います。  
ポイントは次の3つです。

1) `ForEachAsync` は **POCO (`T`) を返す**  
2) 呼び出し側は `ctx.Samples.Commit(poco)` を呼ぶだけ（**autocommit時はno-op**）  
3) 列挙中に得た **`entity → MessageMeta(Topic/Partition/Offset/…)` の対応** を `CommitManager` が保持し、`Commit(poco)` で該当オフセットをコミット

---

# 1. EventSet.cs（最小差分）

## (a) ForEachAsync を POCO 返しに
```csharp
// 変更前
public virtual async IAsyncEnumerable<object> ForEachAsync(
    [EnumeratorCancellation] CancellationToken cancellationToken = default)

// 変更後
public virtual async IAsyncEnumerable<T> ForEachAsync(
    [EnumeratorCancellation] CancellationToken cancellationToken = default)
{
    await foreach (var item in GetAsyncEnumeratorWrapper(cancellationToken))
        yield return item; // manual でも POCO だけ返す
}
```

## (b) Commit(T entity) を公開（既存 ICommitManager に委譲）
```csharp
public void Commit(T entity)
{
    if (entity is null) throw new ArgumentNullException(nameof(entity));
    _commitManager?.Commit(entity); // autocommit時は Noop で無害
}
```

## (c) 列挙時に「entity→meta」を CommitManager に渡すフック  
`ConsumeAsync<T>` の戻り（`(T, Headers, MessageMeta)`）を横取りし、**CommitManager が対応していれば**追跡させます。

```csharp
// 追加：CommitManagerが実装していれば entity→meta を追跡できる拡張IF
namespace Kafka.Ksql.Linq.Messaging.Consumers
{
    public interface ICommitRegistrar
    {
        void Track(object entity, MessageMeta meta);
    }
}

// EventSet<T> 内：ConsumeAsync の結果にトラッキング差し込み
protected virtual IAsyncEnumerable<(T Entity, Dictionary<string,string> Headers, MessageMeta Meta)>
    ConsumeAsync(KsqlContext context, CancellationToken cancellationToken)
{
    var source = context.GetConsumerManager().ConsumeAsync<T>(cancellationToken);
    return TrackCommitIfSupported(source, cancellationToken);
}

private async IAsyncEnumerable<(T Entity, Dictionary<string,string> Headers, MessageMeta Meta)>
    TrackCommitIfSupported(
        IAsyncEnumerable<(T Entity, Dictionary<string,string> Headers, MessageMeta Meta)> source,
        [EnumeratorCancellation] CancellationToken cancellationToken = default)
{
    var registrar = _commitManager as Kafka.Ksql.Linq.Messaging.Consumers.ICommitRegistrar;
    await foreach (var (entity, headers, meta) in source.WithCancellation(cancellationToken))
    {
        registrar?.Track(entity!, meta);      // ← ここで対応づけ
        yield return (entity, headers, meta);
    }
}
```

> 補足  
> - 既存の `KafkaConsumerManager.ConsumeAsync<TPOCO>()` は `(TPOCO, Headers, MessageMeta)` を返しています（添付コードより）。  
> - 既存の `ICommitManager` / `NoopCommitManager` は**そのまま**使えます。

---

# 2. ManualCommitManager（実体の中身）

`ICommitManager + ICommitRegistrar` を実装し、**`ConditionalWeakTable<object, MessageMeta>`** で `entity → meta` を追跡。  
`Commit(entity)` で取り出した `meta` を用い、**同一の Consumer Group で**オフセットをコミットします。

```csharp
using System.Runtime.CompilerServices;
using Confluent.Kafka;
using Kafka.Ksql.Linq.Messaging.Consumers;

namespace Kafka.Ksql.Linq.Messaging.Consumers;

// entity→meta 追跡 + Commit 実行
internal sealed class ManualCommitManager : ICommitManager, ICommitRegistrar, IDisposable
{
    private readonly ConditionalWeakTable<object, MessageMeta> _map = new();
    private readonly IConsumer<byte[], byte[]> _committer; // 同一Groupで作成
    private bool _disposed;

    public ManualCommitManager(ConsumerConfig commitConfig)
    {
        // GroupId は列挙時と同一にすること（重要）
        _committer = new ConsumerBuilder<byte[], byte[]>(commitConfig).Build();
    }

    // 列挙側（EventSet）から毎件呼ばれる
    public void Track(object entity, MessageMeta meta)
    {
        if (entity is null) return;
        // 既にある場合は更新（最新オフセットを優先）
        try { _map.Remove(entity); } catch { /* ignore */ }
        _map.Add(entity, meta);
    }

    // 呼び出し側：ctx.Samples.Commit(poco) → ここに到達
    public void Commit(object entity)
    {
        if (entity is null) return;
        if (_disposed) throw new ObjectDisposedException(nameof(ManualCommitManager));

        if (!_map.TryGetValue(entity, out var meta))
            throw new InvalidOperationException("The entity is not tracked for commit.");

        // 二重コミット防止 & リーク回避
        _map.Remove(entity);

        var tpo = new TopicPartitionOffset(meta.Topic, meta.Partition, meta.Offset + 1); 
        // 通常「次開始位置」として current+1 をコミット

        // 同期コミット（必要ならtry/catchでリトライ方針）
        _committer.Commit(new[] { tpo });
    }

    public void Dispose()
    {
        if (_disposed) return;
        _disposed = true;
        _committer.Close();
        _committer.Dispose();
    }
}
```

> 重要：`ConsumerConfig` の `GroupId` は **消費時と同じ**にしてください。  
> `BootstrapServers` 等も同一系で。`EnableAutoCommit=false` 推奨。
### DI 例（イメージ）
- **manual モード**の `EventSet<T>` 生成時に、`ManualCommitManager` を注入。  
  `new ManualCommitManager(new ConsumerConfig { BootstrapServers = "...", GroupId = groupId, EnableAutoCommit = false, ... })`
- **autocommit モード**は既存の `NoopCommitManager` を注入（または `null` 注入）。  

> これで **呼び出し側は一切分岐不要**：  
> `await foreach (var x in ctx.Samples.ForEachAsync(token)) { if (条件) ctx.Samples.Commit(x); }`  
> manual時だけ実コミット、autocommit時はNoopで**完全互換**です。

---

# 3. 呼び出し側（テスト）例

```csharp
await foreach (var sample in ctx.Samples.ForEachAsync(consumeCts.Token))
{
    if (sample.Id == 3)
    {
        ctx.Samples.Commit(sample); // manual: commit / autocommit: no-op
        break;
    }
}
```

2回目の消費で `4` から読めることを検証（既存テストロジックのまま）。

---

## これで満たす要件
- `_commitManager` が **オフセットを保持・コミット**する「中身」を実装  
- **POCO 列挙**で統一（`object`/キャスト撤廃）  
- **autocommit⇄manual 切替で呼び出し側は不変**（`Commit(poco)` 1行の有無だけ）  

もし DI 側の組み込みが必要なら、`KsqlContext`（または `EntityModel.UseManualCommit` 分岐をしている箇所）に注入コードを追加する差分も出します。声かけてください。

— 送信日時: [[REDACTED_PHONE]]:19 (JST)
### assistant — 2025-08-11T09:54:23.382991+00:00

_(empty)_
### assistant — 2025-08-11T09:54:36.576002+00:00

_(empty)_
### user — 2025-08-11T09:57:21.792000+00:00

ManualCommitManager のconsumerは新たに作るのではなくconsumerManagerでつくったものを利用する
### assistant — 2025-08-11T09:57:25.002754+00:00

{"queries":["EventSet<T> ForEachAsync return type object site:uploaded --QDF=5","ICommitManager interface Commit(object) --QDF=5","NoopCommitManager Commit implementation --QDF=5","KafkaConsumerManager ConsumeAsync returns (T, Headers, MessageMeta) --QDF=5"]}
### system — 2025-08-11T09:57:25.213815+00:00

_(empty)_
### assistant — 2025-08-11T09:57:25.440520+00:00

_(empty)_
### assistant — 2025-08-11T09:57:28.445003+00:00

やることはシンプルです。「**Commit は、KafkaConsumerManager が作ったその場の consumer で実行**」できるように、**commit デリゲート**を列挙ループから外に渡します。これで ManualCommitManager は **新規 consumer を一切作らず**、受け取ったデリゲートを叩くだけでOK。

# 方針（最小差分）
1) `ICommitRegistrar` を追加：`Track(entity, meta, Action commit)`  
2) `KafkaConsumerManager.ConsumeAsync/ConsumeInternal` で、**毎レコードごとに** `commit` デリゲート（同じ consumer にバインド）を生成して `Track` に渡す  
3) `EventSet<T>` からは `_commitManager as ICommitRegistrar` を **オプション引数**で `ConsumeAsync` に渡す  
4) `ManualCommitManager` は `ICommitManager + ICommitRegistrar` を実装し、`ConditionalWeakTable<object, Action>` に `entity→commitAction` を保持。`Commit(entity)` でその Action を呼ぶだけ  
5) 呼び出し側は従来通り `await foreach (var poco in ctx.Samples.ForEachAsync(...)) { ctx.Samples.Commit(poco); }`（autocommitはNoop）

---

## 1) 追加：ICommitRegistrar
```csharp
// 新規 (Messaging/Consumers/ICommitRegistrar.cs など)
namespace Kafka.Ksql.Linq.Messaging.Consumers
{
    public interface ICommitRegistrar
    {
        void Track(object entity, MessageMeta meta, Action commit);
    }
}
```

## 2) KafkaConsumerManager に registrar を受け取る経路を追加
`ConsumeAsync<TPOCO>` は `(TPOCO, Headers, MessageMeta)` を返しています【6†KafkaConsumerManager.csfileciteturn2file6】。  
ここに **任意の registrar** を渡せるようにします（既存シグネチャは温存、オーバーロード／デフォルト引数どちらでも可）。

```csharp
// 既存（抜粋）: ConsumeAsync<TPOCO> の内部で ConsumeInternal を呼び出している【6†KafkaConsumerManager.csfileciteturn2file6】
public async IAsyncEnumerable<(TPOCO, Dictionary<string,string>, MessageMeta)> ConsumeAsync<TPOCO>(
    [EnumeratorCancellation] CancellationToken cancellationToken = default) where TPOCO : class
{
    var model = GetEntityModel<TPOCO>();
    var topic = model.GetTopicName();
    var mapping = _mappingRegistry.GetMapping(typeof(TPOCO));
    var config = BuildConsumerConfig(topic, null);

    var method = typeof(KafkaConsumerManager)
        .GetMethod(nameof(ConsumeInternal), BindingFlags.NonPublic | BindingFlags.Instance)!
        .MakeGenericMethod(mapping.AvroKeyType!, mapping.AvroValueType!, typeof(TPOCO));

    var enumerable = (IAsyncEnumerable<(TPOCO, Dictionary<string,string>, MessageMeta)>)method
        .Invoke(this, new object?[] { topic, config, mapping, cancellationToken })!;

    await foreach (var item in enumerable.WithCancellation(cancellationToken))
        yield return item;
}
```
### 変更：registrar 付きのオーバーロード
```csharp
public async IAsyncEnumerable<(TPOCO, Dictionary<string, string>, MessageMeta)> ConsumeAsync<TPOCO>(
    Messaging.Consumers.ICommitRegistrar? registrar,
    [EnumeratorCancellation] CancellationToken cancellationToken = default) where TPOCO : class
{
    var model = GetEntityModel<TPOCO>();
    var topic = model.GetTopicName();
    var mapping = _mappingRegistry.GetMapping(typeof(TPOCO));
    var config = BuildConsumerConfig(topic, null);

    var enumerable = ConsumeInternal<TKey:object, TValue:object, TPOCO>(topic, config, mapping, registrar, cancellationToken);
    await foreach (var item in enumerable.WithCancellation(cancellationToken))
        yield return item;
}
```
### 変更：ConsumeInternal 内で commit デリゲートを作成して渡す
```csharp
private async IAsyncEnumerable<(TPOCO, Dictionary<string,string>, MessageMeta)> ConsumeInternal<TKey, TValue, TPOCO>(
    string topicName,
    ConsumerConfig config,
    KeyValueTypeMapping mapping,
    Messaging.Consumers.ICommitRegistrar? registrar,
    [EnumeratorCancellation] CancellationToken cancellationToken)
    where TKey : class where TValue : class where TPOCO : class
{
    using var consumer = CreateConsumer<TKey, TValue>(config);
    consumer.Subscribe(topicName);

    while (!cancellationToken.IsCancellationRequested)
    {
        ConsumeResult<TKey, TValue>? result;
        try { result = consumer.Consume(cancellationToken); }
        catch (OperationCanceledException) { break; }
        if (result == null || result.IsPartitionEOF) continue;

        TPOCO entity;
        Dictionary<string, string> headers;
        MessageMeta meta;
        try
        {
            // 既存マッピング【13†KafkaConsumerManager.csfileciteturn2file13】
            entity = (TPOCO)mapping.CombineFromAvroKeyValue(result.Message.Key, result.Message.Value!, typeof(TPOCO));
            headers = new Dictionary<string, string>();
            if (result.Message.Headers != null)
                foreach (var h in result.Message.Headers)
                    headers[h.Key] = System.Text.Encoding.UTF8.GetString(h.GetValueBytes());

            meta = new MessageMeta(result.Topic, result.Partition, result.Offset,
                                   result.Message.Timestamp.UtcDateTime,
                                   TryGetSchemaId(result.Message.Key as byte[]),
                                   TryGetSchemaId(result.Message.Value as byte[]),
                                   result.Message.Key is null,
                                   ExtractAllowedHeaders(result.Message.Headers, _dlq.HeaderAllowList, _dlq.HeaderValueMaxLength));
        }
        catch (Exception ex)
        {
            await HandleMappingException(result, ex, _dlqProducer, consumer, _dlq, _limiter, cancellationToken).ConfigureAwait(false);
            continue;
        }

        // ★ ここが肝：同一 consumer での commit を外へ渡す
        registrar?.Track(entity!, meta, commit: () =>
        {
            // 通常は次開始位置として current+1 をコミット
            consumer.Commit(new TopicPartitionOffset(meta.Topic, meta.Partition, meta.Offset + 1));
        });

        yield return (entity, headers, meta);
        await Task.CompletedTask;
    }
}
```

> 参考：もともと内部ハンドラでは `consumer.Commit(result)` を使っていました【14†KafkaConsumerManager.csfileciteturn2file14】。同じノリで、**該当ループの consumer** を使って commit デリゲートを生成しています。

## 3) EventSet から registrar を渡す
`EventSet<T>.ConsumeAsync()` は ConsumerManager を叩いて列挙を受け取っています【10†EventSet.csfileciteturn2file10】。ここを **_commitManager を registrar として**渡す形に変更します（実装していなければ null でOK）。

```csharp
protected virtual IAsyncEnumerable<(T Entity, Dictionary<string, string> Headers, MessageMeta Meta)> ConsumeAsync(
    KsqlContext context,
    CancellationToken cancellationToken)
{
    var registrar = _commitManager as Kafka.Ksql.Linq.Messaging.Consumers.ICommitRegistrar;
    // registrar を渡せる新オーバーロードへ
    return context.GetConsumerManager().ConsumeAsync<T>(registrar, cancellationToken);
}
```

加えて、**列挙で返すのは常に POCO** にしておく（`object`で返していた既存の `ForEachAsync` は POCO 版へ切り替え／または非推奨化）。  
既存コードでも `EventSet<T>.ForEachAsync(Func<T,...>)` 系があり、POCOで扱っています【11†EventSet.csfileciteturn2file11】【15†EventSet.csfileciteturn2file15】。

## 4) ManualCommitManager の実装（同一 consumer を利用）
```csharp
using System.Runtime.CompilerServices;
using Kafka.Ksql.Linq.Messaging.Consumers;

internal sealed class ManualCommitManager : ICommitManager, ICommitRegistrar
{
    // entity → commitAction（参照同一性で追跡）
    private readonly ConditionalWeakTable<object, Action> _actions = new();

    public void Track(object entity, MessageMeta meta, Action commit)
    {
        if (entity is null || commit is null) return;
        try { _actions.Remove(entity); } catch { /* ignore */ }
        _actions.Add(entity, commit);
    }

    public void Commit(object entity)
    {
        if (entity is null) return;
        if (!_actions.TryGetValue(entity, out var action))
            throw new InvalidOperationException("The entity is not tracked for commit.");

        // 二重防止・リーク防止
        _actions.Remove(entity);

        // ★ 同じ consumer にバインドされた commitAction を実行
        action();
    }
}
```

> autocommit の時は既存の `NoopCommitManager` を挿すだけで OK（空実装）【3†NoopCommitManager.csfileciteturn2file3】。

---

## 5) 呼び出し側はこれで統一（変更なし）
```csharp
await foreach (var sample in ctx.Samples.ForEachAsync(consumeCts.Token))
{
    if (sample.Id == 3)
    {
        ctx.Samples.Commit(sample); // manual: 実commit（同一consumer） / autocommit: no-op
        break;
    }
}
```

---
### これで満たすこと
- ManualCommitManager は **新規 consumer を作らない**（closureで **KafkaConsumerManager の consumer** をそのまま使用）  
- 列挙の戻りは **常に POCO**（`object`撤廃）。`ICommitManager.Commit(object)` の呼び出し箇所も既存のまま使える（`EventSet` 内から呼んでいる箇所あり【15†EventSet.csfileciteturn2file15】）  
- autocommit⇄manual の切替時に呼び出し側の修正は **ゼロ or 1行（`Commit(poco)`）**で済む

必要なら、この変更の **diff パッチ**もすぐ出します。どこまで自動テストに落とし込みます？（`ManualCommit_PersistsOffset` はそのまま `Commit(sample)` に置換で通る想定です）

— 送信日時: [[REDACTED_PHONE]]:27 (JST)
### tool — 2025-08-11T09:57:28.445232+00:00

_(empty)_
### assistant — 2025-08-11T09:57:53.711853+00:00

_(empty)_
### user — 2025-08-11T10:01:32.643000+00:00

この方式はpocoに対するoffsetをすべて管理していないので、最新のものしかcommitできない
### assistant — 2025-08-11T10:01:35.945885+00:00

了解。その指摘どおり、前案だと「その場の consumer に直で `Commit` するデリゲート」を渡していたため、

- consumer が**別スレッド**から叩かれる（`IConsumer` はスレッドセーフではない）
- ループ外から**任意の過去メッセージ**を安全にコミットできない（“いまの1件”に寄りがち）

という制約が出ます。  
**解決策**は「コミット要求を**同じ consumer スレッド**に“投げ返す”」です。つまり：

- `poco → offset` は **すべて**追跡（参照同一性）
- `Commit(poco)` は **要求キューに積むだけ**（即時に consumer.Commit はしない）
- consumer ループは毎回／一定間隔で **キューをドレインして同じスレッドで commit**  
  ついでに **Partitionごとに最大offset** にまとめて commit して効率化

これで「**過去に yield した任意の POCO**」を後から安全にコミットできます。

---

# 最小差分の設計

## 1) `ICommitRegistrar` を「要求を投げる口」にする
```csharp
// 既存IFはそのまま活かしつつ、EventSet から使う“内部拡張”として
namespace Kafka.Ksql.Linq.Messaging.Consumers
{
    public interface ICommitRegistrar
    {
        // entity に meta をひも付け、さらに “この TPO を commit して” の要求関数を保持
        void Track(object entity, MessageMeta meta, Action<TopicPartitionOffset> requestCommit);
    }
}
```

## 2) KafkaConsumerManager：consumer 内部で commit 要求を受け付ける
```csharp
private async IAsyncEnumerable<(TPOCO, Dictionary<string,string>, MessageMeta)> ConsumeInternal<TKey,TValue,TPOCO>(
    string topicName,
    ConsumerConfig config,
    KeyValueTypeMapping mapping,
    ICommitRegistrar? registrar,
    [EnumeratorCancellation] CancellationToken cancellationToken)
    where TKey:class where TValue:class where TPOCO:class
{
    using var consumer = CreateConsumer<TKey, TValue>(config);
    consumer.Subscribe(topicName);

    var commitQueue = new ConcurrentQueue<TopicPartitionOffset>();

    // registrar に渡す“要求関数”は、同じ consumer スレッドで処理されるようにキュー積みだけ
    void RequestCommit(TopicPartitionOffset tpo) => commitQueue.Enqueue(tpo);

    while (!cancellationToken.IsCancellationRequested)
    {
        ConsumeResult<TKey, TValue>? result;
        try { result = consumer.Consume(cancellationToken); }
        catch (OperationCanceledException) { break; }
        if (result == null || result.IsPartitionEOF) { DrainCommitQueue(); continue; }

        // 既存：Avro→POCO 変換＆メタ生成
        var entity = (TPOCO)mapping.CombineFromAvroKeyValue(result.Message.Key, result.Message.Value!, typeof(TPOCO));
        var headers = ExtractHeaders(result.Message.Headers);
        var meta = BuildMessageMeta(result);

        // ★ ここで entity→meta と “要求関数” を registrar に渡す
        registrar?.Track(entity!, meta, RequestCommit);

        yield return (entity, headers, meta);

        // ★ ここで要求をまとめて処理（同じスレッド）
        DrainCommitQueue();
    }

    void DrainCommitQueue()
    {
        if (commitQueue.IsEmpty) return;
        // Partition単位で最大offsetに集約
        var maxOffsets = new Dictionary<TopicPartition, Offset>();
        while (commitQueue.TryDequeue(out var tpo))
        {
            var tp = tpo.TopicPartition;
            if (!maxOffsets.TryGetValue(tp, out var current) || tpo.Offset > current)
                maxOffsets[tp] = tpo.Offset;
        }
        if (maxOffsets.Count > 0)
        {
            var list = maxOffsets.Select(kv =>
                new TopicPartitionOffset(kv.Key, kv.Value + 1) // 次開始位置
            ).ToList();
            consumer.Commit(list);
        }
    }
}
```

> ポイント
> - **commit は必ずこのループ内**（= 同一スレッド・同一 consumer）で実行。
> - `Commit(poco)` が多数飛んでも、**Partitionごとに最大offset**だけを commit するので効率的。
> - もちろん「古い offset」だけを commit しても問題なし（最終的に最大offsetに収束）。

## 3) EventSet：registrar を渡す／戻りは POCO のまま
- `ForEachAsync` は **`IAsyncEnumerable<T>`**（POCO）を返すに変更（キャスト撤廃）。
- `ConsumeAsync` で `_commitManager as ICommitRegistrar` を **渡す**だけ。

```csharp
protected virtual IAsyncEnumerable<(T Entity, Dictionary<string,string> Headers, MessageMeta Meta)>
    ConsumeAsync(KsqlContext context, CancellationToken ct)
{
    var registrar = _commitManager as ICommitRegistrar;
    return context.GetConsumerManager().ConsumeAsync<T>(registrar, ct);
}

// 呼び出し側向け
public void Commit(T entity) => _commitManager?.Commit(entity);
```

## 4) ManualCommitManager：全 POCO を追跡、任意 POCO を commit 可能に
```csharp
internal sealed class ManualCommitManager : ICommitManager, ICommitRegistrar
{
    private readonly ConditionalWeakTable<object, MessageMeta> _metas = new();
    private readonly ConditionalWeakTable<object, Action<TopicPartitionOffset>> _requests = new();

    public void Track(object entity, MessageMeta meta, Action<TopicPartitionOffset> requestCommit)
    {
        // 同一参照の最新 meta / 要求関数で上書き
        try { _metas.Remove(entity); _requests.Remove(entity); } catch { }
        _metas.Add(entity, meta);
        _requests.Add(entity, requestCommit);
    }

    public void Commit(object entity)
    {
        if (!_metas.TryGetValue(entity, out var meta) || !_requests.TryGetValue(entity, out var req))
            throw new InvalidOperationException("The entity is not tracked for commit.");
        // 二重防止
        _metas.Remove(entity);
        _requests.Remove(entity);
        // ★ ここでは“要求”だけ出す（即時 commit しない）
        req(new TopicPartitionOffset(meta.Topic, meta.Partition, meta.Offset));
    }
}
```

- これで **yield したすべての POCO** が `Commit(poco)` 対象になり、consumer スレッド側で確実にコミットされます。
- `NoopCommitManager` はそのままで OK（autocommit は no-op）。

---

# 使い方（呼び出し側は不変）
```csharp
await foreach (var sample in ctx.Samples.ForEachAsync(ct))
{
    if (sample.Id == 3)
    {
        ctx.Samples.Commit(sample); // ← 任意の“過去に返したPOCO”もOK
        break;
    }
}
```

---

## よくある懸念と回答
- **Q:** Commit を遅延させるのは不安  
  **A:** キュー投入→ループ内で即ドレイン（各ループorタイムスライス）なのでほぼ遅延なし。必要なら `DrainCommitQueue()` を「毎件」ではなく「一定件数/一定時間ごと」に調整可能。
- **Q:** 並列/複数パーティションは？  
  **A:** キューを**最大offset集約**でまとめ commit。コミット整合は Kafka の仕様に則り「各 Partition で **最後に commit した offset** が有効」なので安全。
- **Q:** ループ終了後の Commit は？  
  **A:** ループが止まれば consumer も消えるため、**終了後は例外**にするか、`Dispose` 前にキューを最終ドレインしてください（テストでは `Commit`→break→列挙終了の順でOK）。

---

この構成なら「**POCOごとの offset を完全に管理**」でき、**最新しか commit できない問題**を解消します。必要なら、この設計での **差分パッチ**を作ります。どのファイルから当てます？

— 送信日時: [[REDACTED_PHONE]]:44 (JST)
### system — 2025-08-11T10:01:37.550076+00:00

_(empty)_
### assistant — 2025-08-11T10:01:37.569099+00:00

_(empty)_
### assistant — 2025-08-11T10:02:18.361768+00:00

_(empty)_
### user — 2025-08-11T10:03:16.985000+00:00

ため込んだものをいつか開放しないといけない
### assistant — 2025-08-11T10:03:28.395109+00:00

たしかに、今の設計だと「追跡した POCO とオフセット／コミット要求」を**どこで解放するか**が明確じゃないと、だんだん溜まります。  
最小差分で “溜めたものを確実に開放する” ポイントを4か所に作るのが安全です。

# 方針（最小差分）
- 追跡はこれまで通り `ManualCommitManager` 側（`ConditionalWeakTable` など）で実施。
- **解放（クリア）トリガ**を Kafka のライフサイクルに沿って追加：
  1) **各ループのドレイン後**（都度）
  2) **パーティション Revoke 時**（再バランス）
  3) **列挙終了時**（キャンセル／EOF／例外）
  4) **Dispose 時**（念のための最終クリア）
- さらに安全策として **上限・TTL** を設け、溜まり過ぎ・古過ぎのエントリは自動処置（auto-commit か破棄）できる拡張を用意。

---

# 追加インターフェース（既存IFは不変）
`ICommitManager` は既存のまま。**任意拡張用**に `ICommitRegistrar` に“解放フック”を足します（実装は manual 用だけでOK）。

```csharp
// Messaging/Consumers/ICommitRegistrar.cs
public interface ICommitRegistrar
{
    // 既存（前回案）: エンティティ追跡＋同スレッドでコミットする要求関数を受け取る
    void Track(object entity, MessageMeta meta, Action<TopicPartitionOffset> requestCommit);

    // ★ 追加: 1) ループごとのドレイン直後に呼ばれてもよい（任意）
    void OnTickCleanup();

    // ★ 追加: 2) Rebalance でパーティションが剥がれる直前
    void OnPartitionsRevoked();

    // ★ 追加: 3) 列挙完了（キャンセル・EOF・例外含む）時の最終クリーンアップ
    void OnCompleted();

    // ★ 追加（任意）: 4) 明示解放
    void Clear();
}
```

> これらは **オプショナル**。未実装でも動作しますが、manual 実装で実装すると “解放ポイント” を確実に握れます。

---

# KafkaConsumerManager 側：解放フックの呼び出し
前回の「同一 consumer スレッドで commit するための **リクエストキュー**」を持つ案に、そのまま以下を追加します。

```csharp
// ループ本体の最後あたり
DrainCommitQueue();              // ← pending commit を集約して実行
registrar?.OnTickCleanup();      // ← 1) ループごとに軽い掃除（任意）

// パーティション再バランス時
consumer.PartitionsRevoked += (_, __) =>
{
    try
    {
        DrainCommitQueue();      // まず手元の要求を消化
        registrar?.OnPartitionsRevoked(); // 2) 追跡テーブルをクリア（実装側で）
    }
    catch { /* best effort */ }
};

// 列挙終了時（whileを抜ける直前や finally 内）
try
{
    DrainCommitQueue();
    registrar?.OnCompleted();    // 3) 最終クリア
}
catch { /* best effort */ }
```

> これで、**consumer ライフサイクル**の節目で必ずクリーンアップが走ります。

---

# ManualCommitManager 側：実際の“解放”実装
```csharp
internal sealed class ManualCommitManager : ICommitManager, ICommitRegistrar
{
    private readonly ConditionalWeakTable<object, MessageMeta> _metas = new();
    private readonly ConditionalWeakTable<object, Action<TopicPartitionOffset>> _requests = new();

    // （任意）上限・TTL
    private readonly int _capacity = 10_000;           // 上限件数
    private readonly TimeSpan _ttl = TimeSpan.FromMinutes(10);
    private readonly ConcurrentQueue<(WeakReference<object> Key, DateTime Utc)> _lru = new();

    public void Track(object entity, MessageMeta meta, Action<TopicPartitionOffset> requestCommit)
    {
        try { _metas.Remove(entity); _requests.Remove(entity); } catch { }
        _metas.Add(entity, meta);
        _requests.Add(entity, requestCommit);

        // （任意）LRU的管理
        _lru.Enqueue((new WeakReference<object>(entity), DateTime.UtcNow));
        EvictIfNeeded();
    }

    public void Commit(object entity)
    {
        if (!_metas.TryGetValue(entity, out var meta) || !_requests.TryGetValue(entity, out var req))
            throw new InvalidOperationException("The entity is not tracked for commit.");

        // 二重防止＆解放
        _metas.Remove(entity);
        _requests.Remove(entity);

        // 同一スレッド実行のため、要求だけ積む
        req(new TopicPartitionOffset(meta.Topic, meta.Partition, meta.Offset));
    }

    // ★ 解放フックの実装
    public void OnTickCleanup()  => Sweep(expireOnly: true);
    public void OnPartitionsRevoked() => Clear();   // Revoke時は潔く全クリア推奨
    public void OnCompleted() => Clear();

    public void Clear()
    {
        // ConditionalWeakTable は個別Removeのみなので、再初期化で実質クリア
        UnsafeClearTable(ref _metas);
        UnsafeClearTable(ref _requests);
        while (_lru.TryDequeue(out _)) {} // queue も空に
    }

    private void Sweep(bool expireOnly)
    {
        var now = DateTime.UtcNow;
        var kept = new Queue<(WeakReference<object>, DateTime)>();
        while (_lru.TryDequeue(out var item))
        {
            if (!item.Key.TryGetTarget(out var target))
                continue; // GC済み→自然解放

            // TTL切れならエントリ解放（auto-commit派はここで req を生成してもOK）
            if (now - item.Utc > _ttl)
            {
                try { _metas.Remove(target); _requests.Remove(target); } catch { }
                continue;
            }

            kept.Enqueue(item);
        }
        while (kept.Count > 0) _lru.Enqueue(kept.Dequeue());

        if (!expireOnly) EvictIfNeeded();
    }

    private void EvictIfNeeded()
    {
        // 粗い制御：上限超なら古いものから間引く
        if (_lru.Count <= _capacity) return;
        Sweep(expireOnly: false);
    }

    // ConditionalWeakTable再初期化ユーティリティ
    private static void UnsafeClearTable<TV>(ref ConditionalWeakTable<object, TV> table) where TV : class
    {
        // 参照差し替えで一気に解放（GCに任せる）
        table = new ConditionalWeakTable<object, TV>();
    }
}
```

**ポイント**
- `ConditionalWeakTable` にしておけば、**POCO参照が切れた時点でGCに回収**されます。  
  ただし“いつか”は未定なので、上の **On… フック**や **TTL/容量制限**で**明示的に間引き**ます。
- Rebalance（`OnPartitionsRevoked`）は、**Consumer がそのパーティションを処理できなくなる直前**なので、  
  ここで**キューをドレイン → 追跡テーブル全クリア**が安全（古い参照が将来使われるのを防止）。

---

# まとめ：解放ポイント早見表
- ループ毎：`DrainCommitQueue()` → `OnTickCleanup()`  
  → 細かく掃除。TTL切れ・GC済みエントリを間引く
- Revoke時：`DrainCommitQueue()` → `OnPartitionsRevoked()`  
  → **確実に**全クリア（同パーティションをもう扱わない）
- 終了時：`DrainCommitQueue()` → `OnCompleted()`  
  → 最終クリア（テスト・CI 時に漏れ防止）
- 容量/TTL：`Track` 時に `EvictIfNeeded()` / `Sweep()`  
  → 長時間のストリーム運用時にも安全

---

必要なら、このフックを**あなたの現行 `KafkaConsumerManager` に具体的に差し込む diff**を作ります。呼び出し側のIFは変えず、POCO列挙＋`ctx.Samples.Commit(poco)` のままでOKです。

— 送信日時: [[REDACTED_PHONE]]:52 (JST)
### system — 2025-08-11T10:03:28.812814+00:00

_(empty)_
### assistant — 2025-08-11T10:03:28.987667+00:00

_(empty)_
### assistant — 2025-08-11T10:03:53.509488+00:00

_(empty)_
### user — 2025-08-11T10:06:54.174000+00:00

kafkaのcommitはoffset位置を戻さない
このルールはcommit内部でも適用しないといけない
enqueue/dequeueは非効率ではないか？
### assistant — 2025-08-11T10:06:57.417004+00:00

了解。「**Kafka のコミットは“戻さない（非減少）”**」ルールを**必ず満たしつつ**、**enqueue/dequeue を使わない**構成に切り替えます。ポイントは **“キューではなく最大値”** を持つこと。すなわち、**パーティションごとの “要求された最大オフセット” を ConcurrentDictionary で集約**し、消費ループ側でまとめて同一スレッド commit します。

# 方向性（要点だけ）
- **POCO 列挙は維持**（`IAsyncEnumerable<T>`）。呼び出し側は `ctx.Samples.Commit(poco)` のみ。
- `ManualCommitManager` は **全 POCO→offset を追跡**（参照同一性）し、`Commit(poco)` で  
  **「その Partition の pendingMaxOffset を最大更新」**するだけ（= キュー不要／O(1)）。
- `KafkaConsumerManager` のループで、**pendingMax を一括スナップショット→非減少チェック→まとめて commit**。
- **既に commit 済みの offset 未満は捨てる**（“戻さない”を保証）。

---

# 追加/変更（最小差分）

## 1) `ICommitRegistrar` を小拡張（“集約＆通知”用）
すでに導入済みの `Track(object, MessageMeta)` に加え、**キュー無し集約**のための2メソッドを足します。

```csharp
// Messaging/Consumers/ICommitRegistrar.cs
public interface ICommitRegistrar
{
    // POCO → offset メタを登録（EventSet から毎レコード呼ばれる）
    void Track(object entity, MessageMeta meta);

    // ManualCommitManager 側に “未コミットの最大offset群” を出させる（スナップショット＆クリア）
    bool TryCollectPendingMax(out List<TopicPartitionOffset> tpos);

    // commit 成功後に “最後に確定したoffset” を教える（非減少の基準更新）
    void NotifyCommitted(IReadOnlyList<TopicPartitionOffset> committed);

    // 既存のライフサイクルフック（あれば）
    void OnPartitionsRevoked();
    void OnCompleted();
}
```

> 既存の `ICommitManager` はそのまま（`void Commit(object)`）。  
> `EventSet.Commit(poco)` からは **従来通り `_commitManager.Commit(poco)` を呼ぶだけ**です。

---

## 2) `ManualCommitManager`（enqueue無し版）
- `ConditionalWeakTable<object, MessageMeta>` で **POCO→meta** を保持（参照同一性）。
- `ConcurrentDictionary<TopicPartition, Offset>` で **pendingMax** を保持（**AddOrUpdate(最大)**）。
- `ConcurrentDictionary<TopicPartition, Offset>` で **committedMax** も保持（“戻さない”判定用）。

```csharp
using System.Collections.Concurrent;
using System.Runtime.CompilerServices;
using Confluent.Kafka;
using Kafka.Ksql.Linq.Messaging.Consumers;

internal sealed class ManualCommitManager : ICommitManager, ICommitRegistrar
{
    private readonly ConditionalWeakTable<object, MessageMeta> _metas = new();
    private ConcurrentDictionary<TopicPartition, Offset> _pendingMax = new();   // 要求中の最大
    private readonly ConcurrentDictionary<TopicPartition, Offset> _committedMax = new(); // 確定済み最大

    public void Track(object entity, MessageMeta meta)
    {
        // 最新で上書き（同一参照）
        try { _metas.Remove(entity); } catch { /* ignore */ }
        _metas.Add(entity, meta);
    }

    // 呼び出し側: ctx.Samples.Commit(poco) → ここに来る
    public void Commit(object entity)
    {
        if (!_metas.TryGetValue(entity, out var meta))
            throw new InvalidOperationException("The entity is not tracked for commit.");

        var tp = new TopicPartition(meta.Topic, meta.Partition);
        var off = meta.Offset; // “現在のメッセージのoffset”（Kafkaの規約では commit は nextOffset を記録する）

        // ★ キューに積まず、partition毎の “最大値” を更新
        _pendingMax.AddOrUpdate(tp, off, static (_, cur) => off > cur ? off : cur);
    }

    // KafkaConsumerManager のループから呼ばれる：pending のスナップショット（+ クリア）
    public bool TryCollectPendingMax(out List<TopicPartitionOffset> tpos)
    {
        var snapshot = Interlocked.Exchange(ref _pendingMax, new ConcurrentDictionary<TopicPartition, Offset>());
        if (snapshot.Count == 0) { tpos = []; return false; }

        var list = new List<TopicPartitionOffset>(snapshot.Count);
        foreach (var kv in snapshot)
        {
            var tp = kv.Key;
            var requested = kv.Value;
            // “戻さない”の適用：確定済みを超える分だけ採用
            if (_committedMax.TryGetValue(tp, out var committed) && requested <= committed)
                continue;

            list.Add(new TopicPartitionOffset(tp, requested));
        }
        tpos = list;
        return tpos.Count > 0;
    }

    // commit 成功の通知：確定済み最大を更新
    public void NotifyCommitted(IReadOnlyList<TopicPartitionOffset> committed)
    {
        foreach (var tpo in committed)
        {
            _committedMax.AddOrUpdate(tpo.TopicPartition, tpo.Offset,
                static (_, cur) => tpo.Offset > cur ? tpo.Offset : cur);
        }
    }

    public void OnPartitionsRevoked()
    {
        // パーティション剥奪時は要求を破棄（安全第一）
        _pendingMax = new ConcurrentDictionary<TopicPartition, Offset>();
        // committedMax は残してOK（グループの真値に近い）だが、必要なら削る
    }

    public void OnCompleted()
    {
        _pendingMax = new ConcurrentDictionary<TopicPartition, Offset>();
    }
}
```

> これで **古い offset の commit 要求は自然に捨てられ**、**常に最大 offset だけ**が流れます。  
> キュー無しなので **enqueue/dequeue オーバーヘッドはゼロ**。更新は **辞書の1回の AddOrUpdate** だけ。

---

## 3) `KafkaConsumerManager` ループ（commit 部分だけ）
**同一スレッド**で commit するため、**各ポーリング周回の末尾で**集約コミットします。  
**`+1` して “次開始位置” をコミット**するのを忘れずに。また**成功後に `NotifyCommitted`** を呼び、次回以降の“戻さない”判定に反映。

```csharp
// … 1レコード処理の末尾（または適当なタイミング） …
if (registrar != null && registrar.TryCollectPendingMax(out var pending))
{
    // +1 してコミット
    var nexts = pending.Select(p => new TopicPartitionOffset(p.TopicPartition, p.Offset + 1)).ToList();
    if (nexts.Count > 0)
    {
        consumer.Commit(nexts);
        // 成功したものを registrar に通知（確定最大を更新）
        registrar.NotifyCommitted(pending);
    }
}
```

> Rebalance（`PartitionsRevoked`）や列挙終了時にも一度これを回すと安全です（残りがあれば最終 commit）。

---

# なぜこれでOK？
- **非減少（戻さない）**：`ManualCommitManager` が `committedMax` を持ち、**それ未満の要求は破棄**。  
- **効率**：キューではなく **“最大値のみを保持”** → 1 Partition あたり **1エントリ**。  
- **スレッド安全**：`Commit(poco)` はどこから呼ばれても **辞書更新だけ**。実コミットは **消費スレッド**が行う。  
- **スループット**：コミットは「**各周回で最大1回**・**複数Partitionをまとめて**」にできる。高頻度が必要なら短い間隔で回せばよいし、低頻度にしても**常に最大値**が採用されるため無駄が少ない。

---

# 呼び出し側はそのまま
```csharp
await foreach (var sample in ctx.Samples.ForEachAsync(ct))
{
    if (sample.Id == 3)
    {
        ctx.Samples.Commit(sample); // autocommit: Noop / manual: pendingMax 更新
        break;
    }
}
```

---

必要なら、あなたの `EventSet.cs / KafkaConsumerManager.cs / ManualCommitManager` にそのまま当てられる **差分パッチ**を出します。どこから適用しましょう？

— 送信日時: [[REDACTED_PHONE]]:05 (JST)
### system — 2025-08-11T10:06:57.608615+00:00

_(empty)_
### assistant — 2025-08-11T10:06:59.028871+00:00

_(empty)_
### assistant — 2025-08-11T10:07:52.953507+00:00

_(empty)_
### user — 2025-08-11T10:09:50.474000+00:00

コード量が多くなる。様々なクラスに分割する。これは怪しさ満点警報です。
### assistant — 2025-08-11T10:09:53.645518+00:00

わかった。**クラス乱立なし／既存IFほぼ据え置き**でいこう。  
最小3点だけ触ります（ファイル増は**ManualCommitManager.cs 1つ**だけ）：

1) `EventSet<T>`：`ForEachAsync` を **POCO返し**に変更＋`Commit(T)` 追加  
2) `KafkaConsumerManager`：**小さなオーバーロード**を1つ追加して、手元の consumer から**同一スレッドでcommit**  
3) `ManualCommitManager`：**1クラス**で「POCO→meta」と「パーティション毎の最大オフセット集約」を担当（**キュー無し**、**非減少保証**）

> これで「**ctx.Samples.Commit(poco)** だけでOK」「**autocommit⇄manual切替でも呼び出しは不変**」「**objectキャスト撤廃**」「**オフセットは戻らない**」を満たします。  
> 追加のインターフェースは**作りません**（怪しさ回避）。

---

# 変更差分（要点コード）

## 1) EventSet.cs（POCO列挙＋委譲Commit）
```csharp
// 変更前
public virtual async IAsyncEnumerable<object> ForEachAsync(
    [EnumeratorCancellation] CancellationToken cancellationToken = default)

// 変更後（POCO返し）
public virtual async IAsyncEnumerable<T> ForEachAsync(
    [EnumeratorCancellation] CancellationToken cancellationToken = default)
{
    await foreach (var item in GetAsyncEnumeratorWrapper(cancellationToken))
        yield return item; // manual でも常に POCO だけ返す
}

// 呼び出し側向け Commit（autocommit時はNoopで無害）
public void Commit(T entity)
{
    if (entity is null) throw new ArgumentNullException(nameof(entity));
    _commitManager?.Commit(entity);
}

// KafkaConsumerManager 呼び出し（registrar等は導入しない）
protected override IAsyncEnumerable<(T Entity, Dictionary<string, string> Headers, MessageMeta Meta)>
    ConsumeAsync(KsqlContext context, CancellationToken ct)
{
    // Manual 時のみ ManualCommitManager が入っている想定
    var manual = _commitManager as ManualCommitManager;
    return context.GetConsumerManager().ConsumeAsync<T>(manual, ct);
}
```

## 2) KafkaConsumerManager.cs（小さなオーバーロードだけ追加）
```csharp
// 既存の ConsumeAsync<TPOCO>(ct) はそのまま残す

// 追加：ManualCommitManager を（あれば）受け取る版
public async IAsyncEnumerable<(TPOCO, Dictionary<string,string>, MessageMeta)> ConsumeAsync<TPOCO>(
    ManualCommitManager? manual,
    [EnumeratorCancellation] CancellationToken cancellationToken = default) where TPOCO : class
{
    // ... 既存と同様に mapping/config/consumer 準備
    using var consumer = CreateConsumer<TKey, TValue>(config);
    consumer.Subscribe(topic);

    var committedMax = new Dictionary<TopicPartition, Offset>(); // ループ内キャッシュでもOK

    while (!cancellationToken.IsCancellationRequested)
    {
        ConsumeResult<TKey, TValue>? result;
        try { result = consumer.Consume(cancellationToken); }
        catch (OperationCanceledException) { break; }
        if (result is null || result.IsPartitionEOF) { TryFlush(); continue; }

        // 既存：Avro→POCO, headers, meta の構築
        var entity = (TPOCO)mapping.CombineFromAvroKeyValue(result.Message.Key, result.Message.Value!, typeof(TPOCO));
        var headers = ExtractHeaders(result.Message.Headers);
        var meta = BuildMessageMeta(result);

        // ★ POCO→meta を ManualCommitManager に渡して追跡
        manual?.Track(entity!, meta);

        yield return (entity, headers, meta);

        // ★ 周回ごとに pendingMax をまとめて commit（同一スレッド）
        TryFlush();
    }

    // 終了時もラストフラッシュ
    TryFlush();

    void TryFlush()
    {
        if (manual is null) return;
        if (!manual.TryCollectPendingMax(out var pending)) return;

        // 非減少保証：すでにcommit済みより小さい要求は捨てる
        var filtered = new List<TopicPartitionOffset>(pending.Count);
        foreach (var p in pending)
        {
            if (committedMax.TryGetValue(p.TopicPartition, out var cur) && p.Offset <= cur) continue;
            filtered.Add(new TopicPartitionOffset(p.TopicPartition, p.Offset + 1)); // nextOffset を記録
        }
        if (filtered.Count == 0) return;

        consumer.Commit(filtered);
        // 確定最大を更新
        foreach (var c in filtered)
            committedMax[c.TopicPartition] = c.Offset - 1; // 保存は“現在オフセット”で持つなら -1
    }
}
```

> ここでは **新しいIFは足していません**。  
> `ManualCommitManager` を **あれば渡す**だけの**小オーバーロード**です（既存呼び出しには影響なし）。

## 3) ManualCommitManager.cs（1クラスで完結：追跡＋集約）
```csharp
using System.Collections.Concurrent;
using System.Runtime.CompilerServices;
using Confluent.Kafka;

public sealed class ManualCommitManager : ICommitManager
{
    // POCO → メタ（参照同一性で追跡、POCOがGC対象なら自然に消える）
    private readonly ConditionalWeakTable<object, MessageMeta> _metas = new();

    // パーティション毎の「要求された最大オフセット」
    private ConcurrentDictionary<TopicPartition, Offset> _pendingMax = new();

    public void Track(object entity, MessageMeta meta)
    {
        try { _metas.Remove(entity); } catch { /* ignore */ }
        _metas.Add(entity, meta);
    }

    // 呼び出し側：ctx.Samples.Commit(poco) → ここ
    public void Commit(object entity)
    {
        if (!_metas.TryGetValue(entity, out var meta))
            throw new InvalidOperationException("The entity is not tracked for commit.");

        var tp = new TopicPartition(meta.Topic, meta.Partition);
        var off = meta.Offset;

        // ★ キューは使わず“最大値”だけを更新（O(1)）
        _pendingMax.AddOrUpdate(tp, off, static (_, cur) => off > cur ? off : cur);
    }

    // KafkaConsumerManager から同一スレッドで呼ばれる：pending をスナップショットして渡す
    public bool TryCollectPendingMax(out List<TopicPartitionOffset> tpos)
    {
        var snapshot = Interlocked.Exchange(ref _pendingMax, new ConcurrentDictionary<TopicPartition, Offset>());
        if (snapshot.Count == 0) { tpos = []; return false; }

        tpos = new List<TopicPartitionOffset>(snapshot.Count);
        foreach (var kv in snapshot)
            tpos.Add(new TopicPartitionOffset(kv.Key, kv.Value)); // nextOffset化は呼び出し側で
        return true;
    }
}
```

- **キューなし**：`ConcurrentDictionary` で **最大値だけ**持つので軽量。
- **非減少保証**は Kafka 側で `committedMax` を見ながらフィルタ（上の `TryFlush`）。  
  「戻さない」約束を**consumer側で最終保証**するので、整合が取りやすいです。
- `NoopCommitManager` は残してOK（autocommit時は no-op のまま）。

---

# 呼び出し側（テスト）※キャスト撤廃・IF不変
```csharp
await foreach (var sample in ctx.Samples.ForEachAsync(consumeCts.Token))
{
    if (sample.Id == 3)
    {
        ctx.Samples.Commit(sample); // manual時だけ実commitに反映／autocommitはno-op
        break;
    }
}
```

---

## これで“怪しさ満点”の分割を避けつつ、要件全部クリア
- 追加クラスは **ManualCommitManager 1つ**のみ（IF追加ナシ）
- 変更は **EventSet と KafkaConsumerManager に小改修だけ**
- **POCO返し**／**キャストゼロ**／**commit非減少**／**キュー不使用**／**同一consumerスレッドでcommit**

必要なら、このまま当てられる **差分（.patch）** も出します。どう進めましょう？

— 送信日時: [[REDACTED_PHONE]]:19 (JST)
### system — 2025-08-11T10:09:53.950590+00:00

_(empty)_
### assistant — 2025-08-11T10:09:54.096480+00:00

_(empty)_
### assistant — 2025-08-11T10:10:27.579174+00:00

_(empty)_
### user — 2025-08-11T10:12:59.006000+00:00

pocoインスタンスのアドレスをキーにしてmeta情報を管理する
commitはこの情報を見てcommitをおこなう
meta情報からそれ以前のoffset値の情報を削除する
### system — 2025-08-11T10:13:02.310628+00:00

_(empty)_
### assistant — 2025-08-11T10:13:02.355903+00:00

了解。**POCOインスタンス（参照同一性）をキー**にして `meta` を保持し、**commit時はその `meta` を見てコミット**、さらに**そのパーティションで “それ以前(≤)” のオフセット情報を掃除**する、という方針で最小構成のコードを提示します。

ポイントだけ：
- POCO→meta は `ConditionalWeakTable<object, MessageMeta>`（弱参照なので実参照が切れればGCで自然解放）
- 「戻さない」を保証するため **partitionごとの committedMax** を持つ
- 追加で **partition → offset → WeakReference<object>** の索引を持ち、**commit確定後に ≤committedMax を一括掃除**
- **キューは使わず**、pendingは **partitionごとの最大offset** を `ConcurrentDictionary` で集約（O(1)）

---

# ManualCommitManager（1クラス完結・最小構成）

```csharp
using System.Collections.Concurrent;
using System.Runtime.CompilerServices;
using Confluent.Kafka;

public sealed class ManualCommitManager : ICommitManager
{
    // 参照同一性で POCO → meta を弱参照保持（実参照が切れれば自動で消える）
    private readonly ConditionalWeakTable<object, MessageMeta> _metas = new();

    // パーティション毎の「要求された最大オフセット」（キューなし）
    private ConcurrentDictionary<TopicPartition, Offset> _pendingMax = new();

    // パーティション毎の「確定済み最大オフセット」（“戻さない” 判定用）
    private readonly ConcurrentDictionary<TopicPartition, Offset> _committedMax = new();

    // 掃除用の索引：partition → offset → [weak(Poco)...]
    private readonly ConcurrentDictionary<TopicPartition,
        SortedDictionary<long, List<WeakReference<object>>>> _index = new();

    // EventSetから毎件呼ぶ：POCO と meta を登録
    public void Track(object entity, MessageMeta meta)
    {
        // CWT は同一キーの再登録で例外になるので先に Remove を試みる
        try { _metas.Remove(entity); } catch { /* ignore */ }
        _metas.Add(entity, meta);

        var tp = new TopicPartition(meta.Topic, meta.Partition);
        var dict = _index.GetOrAdd(tp, _ => new SortedDictionary<long, List<WeakReference<object>>>());

        lock (dict) // 1 partition のみロック
        {
            if (!dict.TryGetValue(meta.Offset.Value, out var list))
            {
                list = new List<WeakReference<object>>();
                dict[meta.Offset.Value] = list;
            }
            list.Add(new WeakReference<object>(entity));
        }
    }

    // 呼び出し側：ctx.Samples.Commit(poco)
    public void Commit(object entity)
    {
        if (!_metas.TryGetValue(entity, out var meta))
            throw new InvalidOperationException("The entity is not tracked for commit.");

        var tp = new TopicPartition(meta.Topic, meta.Partition);
        var off = meta.Offset;

        // キューを使わず “最大” だけ更新（O(1)）
        _pendingMax.AddOrUpdate(tp, off,
            static (_, cur) => off > cur ? off : cur);

        // この POCO の個票はすぐ消しておく（ダブルコミット防止＆軽量化）
        try { _metas.Remove(entity); } catch { /* ignore */ }
        // 索引からも可能なら除去（弱参照のまま残っても害はないが、できれば整理）
        if (_index.TryGetValue(tp, out var dict))
        {
            lock (dict)
            {
                if (dict.TryGetValue(off.Value, out var list))
                {
                    list.RemoveAll(wr => !wr.TryGetTarget(out var tgt) || ReferenceEquals(tgt, entity));
                    if (list.Count == 0) dict.Remove(off.Value);
                }
            }
        }
    }

    // KafkaConsumerManager（消費スレッド）から：pendingのスナップショット取得
    public bool TryCollectPendingMax(out List<TopicPartitionOffset> tpos)
    {
        var snap = Interlocked.Exchange(ref _pendingMax, new ConcurrentDictionary<TopicPartition, Offset>());
        if (snap.Count == 0) { tpos = []; return false; }

        var list = new List<TopicPartitionOffset>(snap.Count);
        foreach (var kv in snap)
        {
            var tp = kv.Key;
            var req = kv.Value;
            if (_committedMax.TryGetValue(tp, out var committed) && req <= committed)
                continue; // “戻さない”：確定済み以下は捨てる
            list.Add(new TopicPartitionOffset(tp, req));
        }
        tpos = list;
        return tpos.Count > 0;
    }

    // Kafka側で commit 成功後に呼ぶ：確定最大を更新し、≤確定を一括掃除
    public void NotifyCommitted(IReadOnlyList<TopicPartitionOffset> committed)
    {
        foreach (var tpo in committed)
        {
            var tp = tpo.TopicPartition;
            var justCommitted = tpo.Offset; // ← “現在オフセット”として保持（実際にcommitしたのは nextOffset）

            _committedMax.AddOrUpdate(tp, justCommitted,
                static (_, cur) => justCommitted > cur ? justCommitted : cur);

            // 索引から ≤committed を掃除、CWT からも可能なら明示Remove
            if (_index.TryGetValue(tp, out var dict))
            {
                lock (dict)
                {
                    var keysToRemove = new List<long>();
                    foreach (var kv in dict)
                    {
                        if (kv.Key > justCommitted.Value) break;
                        foreach (var wr in kv.Value)
                        {
                            if (wr.TryGetTarget(out var obj))
                            {
                                try { _metas.Remove(obj); } catch { /* ignore */ }
                            }
                        }
                        keysToRemove.Add(kv.Key);
                    }
                    foreach (var k in keysToRemove) dict.Remove(k);
                }
            }
        }
    }

    // Rebalanceや列挙完了時に呼ぶと安全（任意）
    public void OnPartitionsRevoked()
    {
        _pendingMax = new ConcurrentDictionary<TopicPartition, Offset>();
        // _index / _metas は弱参照基盤なので残しても大きなリークにはならない
        // 必要ならここで index の該当 partition を全削除
    }

    public void OnCompleted()
    {
        _pendingMax = new ConcurrentDictionary<TopicPartition, Offset>();
    }
}
```
### 重要な挙動
- **Commitは「戻さない」**：  
  `TryCollectPendingMax` で `_committedMax` と比較し、**小さい要求を捨てる**。  
  実コミットは KafkaConsumerManager 側で `+1` して nextOffset をコミット。
- **“それ以前のoffset” の削除**：  
  `NotifyCommitted` で確定更新後、**索引から ≤committed を一括削除**し、対応する CWT も可能な限り `Remove`。

---

# KafkaConsumerManager（flush部のみ・小改修）
消費ループの**同一スレッド**で commit をまとめて実行。成功後 `NotifyCommitted` を呼んで掃除を促します。

```csharp
// ループの適切な場所（各周回末など）でフラッシュ
void TryFlush()
{
    if (manual == null) return;
    if (!manual.TryCollectPendingMax(out var pending)) return;

    // nextOffset でコミット
    var nexts = pending.Select(p => new TopicPartitionOffset(p.TopicPartition, p.Offset + 1)).ToList();
    if (nexts.Count == 0) return;

    consumer.Commit(nexts);

    // “現在オフセット” を通知（next-1 が justCommitted）
    var current = pending; // pending は next-1 なので、そのまま通知でOK
    manual.NotifyCommitted(current);
}
```

> Rebalance（`PartitionsRevoked`）や列挙完了時にも `TryFlush()` → `manual.OnPartitionsRevoked()/OnCompleted()` を呼ぶと万全です。

---

# EventSet 側（呼び出しはPOCOのまま）
- `ForEachAsync` を **`IAsyncEnumerable<T>`**（POCO返し）に変更
- `Commit(T entity)` を公開して `_commitManager.Commit(entity)` に委譲
- `ConsumeAsync` で `ManualCommitManager` を KafkaConsumerManager に渡す（オーバーロード側）

呼び出し例（テスト）：
```csharp
await foreach (var sample in ctx.Samples.ForEachAsync(ct))
{
    if (sample.Id == 3)
    {
        ctx.Samples.Commit(sample); // manual: 反映 / autocommit: Noop
        break;
    }
}
```

---

## これで満たせること
- **POCOインスタンス（参照同一性）をキー**に meta 管理
- **commit は meta を見て** pendingMax を更新 → **同一スレッドでまとめて commit**
- **“それ以前(≤)” のoffset情報**は `NotifyCommitted` 時に**索引から一括削除**（CWTも可能な限り削除）
- **キュー不使用**／O(1) 更新中心で効率的
- 呼び出し側は **`Commit(poco)` だけ**。autocommit⇄manualの切替でも呼び出しは不変

必要なら、このまま当て込める差分（.patch）を用意します。どこから当てます？

— 送信日時: [[REDACTED_PHONE]]:28 (JST)
### assistant — 2025-08-11T10:13:02.822108+00:00

_(empty)_
### assistant — 2025-08-11T10:13:29.146704+00:00

_(empty)_
### user — 2025-08-11T10:18:21.943000+00:00

TryFlush　いやです
### assistant — 2025-08-11T10:18:25.041808+00:00

了解。「TryFlush みたいなフラッシュ関数」は使わず、**コンシューマのポーリングループ内に最小限の“その場コミット処理”を直書き**します。キューも関数抽出もなし。`Commit(poco)` は pendingMax を更新するだけ、**実コミットは同一スレッドの次のポーリング境界で1回**だけ行います。

# 変更点（最小）

## KafkaConsumerManager（ループ内に直書き）
```csharp
while (!cancellationToken.IsCancellationRequested)
{
    ConsumeResult<TKey, TValue>? result;
    try { result = consumer.Consume(cancellationToken); }
    catch (OperationCanceledException) { break; }

    if (result == null || result.IsPartitionEOF)
    {
        // ★ pending があればこの場でだけコミット（関数化しない）
        if (manual != null && manual.TryCollectPendingMax(out var pending) && pending.Count > 0)
        {
            // 非減少保証: committedMax でフィルタ（必要最小限）
            var filtered = new List<TopicPartitionOffset>(pending.Count);
            foreach (var p in pending)
            {
                if (!committedMax.TryGetValue(p.TopicPartition, out var cur) || p.Offset > cur)
                    filtered.Add(new TopicPartitionOffset(p.TopicPartition, p.Offset + 1)); // nextOffset
            }
            if (filtered.Count > 0)
            {
                consumer.Commit(filtered);
                // NotifyCommitted には “現在オフセット” を渡す（next-1）
                for (int i = 0; i < filtered.Count; i++)
                {
                    var f = filtered[i];
                    filtered[i] = new TopicPartitionOffset(f.TopicPartition, f.Offset - 1);
                    committedMax[f.TopicPartition] = f.Offset - 1;
                }
                manual.NotifyCommitted(filtered);
            }
        }
        continue;
    }

    // Avro→POCO, headers, meta の作成 …（既存）
    var entity = (TPOCO)mapping.CombineFromAvroKeyValue(result.Message.Key, result.Message.Value!, typeof(TPOCO));
    var headers = ExtractHeaders(result.Message.Headers);
    var meta = BuildMessageMeta(result);

    // manual なら追跡（POCO参照→meta）
    manual?.Track(entity!, meta);

    yield return (entity, headers, meta);

    // ★ 1件処理後にも “その場コミット” を直書き
    if (manual != null && manual.TryCollectPendingMax(out var pending2) && pending2.Count > 0)
    {
        var filtered2 = new List<TopicPartitionOffset>(pending2.Count);
        foreach (var p in pending2)
        {
            if (!committedMax.TryGetValue(p.TopicPartition, out var cur) || p.Offset > cur)
                filtered2.Add(new TopicPartitionOffset(p.TopicPartition, p.Offset + 1));
        }
        if (filtered2.Count > 0)
        {
            consumer.Commit(filtered2);
            for (int i = 0; i < filtered2.Count; i++)
            {
                var f = filtered2[i];
                filtered2[i] = new TopicPartitionOffset(f.TopicPartition, f.Offset - 1);
                committedMax[f.TopicPartition] = f.Offset - 1;
            }
            manual.NotifyCommitted(filtered2);
        }
    }
}

// ループ終了時も “直書き” で締めコミット
if (manual != null && manual.TryCollectPendingMax(out var last) && last.Count > 0)
{
    var filteredLast = new List<TopicPartitionOffset>(last.Count);
    foreach (var p in last)
    {
        if (!committedMax.TryGetValue(p.TopicPartition, out var cur) || p.Offset > cur)
            filteredLast.Add(new TopicPartitionOffset(p.TopicPartition, p.Offset + 1));
    }
    if (filteredLast.Count > 0)
    {
        consumer.Commit(filteredLast);
        for (int i = 0; i < filteredLast.Count; i++)
        {
            var f = filteredLast[i];
            filteredLast[i] = new TopicPartitionOffset(f.TopicPartition, f.Offset - 1);
            committedMax[f.TopicPartition] = f.Offset - 1;
        }
        manual.NotifyCommitted(filteredLast);
    }
}
```

- **関数化なし／TryFlush不使用**。  
- **非減少保証**は `committedMax` でフィルタ、Kafka には **nextOffset** で commit。  
- `NotifyCommitted` には **“現在オフセット”**（next-1）を戻して、`≤ committed` の **索引・CWT を掃除**（前ターンの実装どおり）。

## ManualCommitManager（そのまま）
- `Track(poco, meta)`：POCO参照→meta を `ConditionalWeakTable` で保持＋索引登録  
- `Commit(poco)`：その meta の **offset を pendingMax に反映**（辞書の最大更新）＋個票の除去  
- `TryCollectPendingMax(out tpos)`：**Interlocked.Exchange** で集約取得（キュー不使用）  
- `NotifyCommitted(tpos)`：**committedMax 更新**と **≤ committed の一括掃除**

## EventSet（呼び出し側はPOCOだけ）
- `ForEachAsync` を **`IAsyncEnumerable<T>`** に変更  
- `Commit(T entity)` を `_commitManager.Commit(entity)` に委譲（autocommitはNoop）  
- `ConsumeAsync` 側で `KafkaConsumerManager.ConsumeAsync<T>(manual, ct)` を呼ぶだけ

---

これで「フラッシュ関数なし」「キューなし」「POCO参照キーで管理」「非減少ルール厳守」を同時に満たします。  
テスト側はこれだけでOK：

```csharp
await foreach (var sample in ctx.Samples.ForEachAsync(consumeCts.Token))
{
    if (sample.Id == 3)
    {
        ctx.Samples.Commit(sample);
        break;
    }
}
```

必要なら、このインライン化版の **差分パッチ**出します。どのファイルから当てます？

— 送信日時: [[REDACTED_PHONE]]:33 (JST)
### system — 2025-08-11T10:18:25.289509+00:00

_(empty)_
### assistant — 2025-08-11T10:18:25.503241+00:00

_(empty)_
### assistant — 2025-08-11T10:18:42.835460+00:00

_(empty)_
### user — 2025-08-11T10:19:51.935000+00:00

だめ　かい変範囲大きすぎ
### assistant — 2025-08-11T10:19:56.241638+00:00

{"queries":["EventSet<T> ForEachAsync object UseManualCommit CreateManualCommitMessage --QDF=5","KafkaConsumerManager ConsumeAsync MessageMeta mapping CombineFromAvroKeyValue --QDF=5","ICommitManager interface Commit NoopCommitManager --QDF=5"], "intent":"Read uploaded files to craft minimal-diff solution"}
### system — 2025-08-11T10:19:56.850806+00:00

_(empty)_
### assistant — 2025-08-11T10:19:56.902528+00:00

_(empty)_
### assistant — 2025-08-11T10:20:03.931928+00:00

{"queries":["EventSet<T> ForEachAsync object UseManualCommit CreateManualCommitMessage --QDF=5","KafkaConsumerManager ConsumeAsync MessageMeta mapping CombineFromAvroKeyValue --QDF=5","ICommitManager interface Commit NoopCommitManager --QDF=5"]}
### tool — 2025-08-11T10:20:03.972481+00:00

Invalid intent provided. Please provide a valid intent from the list of special intents, or omit the intent field for the default intent. Available special intents: ['nav'].
### assistant — 2025-08-11T10:20:09.991410+00:00

了解。「**改変範囲は最小**」「**KafkaConsumerManager など既存は触らない**」「**poco で列挙したい**」「**Commit は poco をキーにできるように**」を同時に満たす“差分小”の落としどころを出します。

要点だけ：
- 既存の `ForEachAsync()`（`IAsyncEnumerable<object>`）は**残す**（後方互換）。
- **新規**に `ForEachPocoAsync()` を追加して **`IAsyncEnumerable<T>` を返す**（キャスト撤廃）。
- **新規**に `Commit(T entity)` を追加して **`_commitManager.Commit(entity)` に委譲**（autocommit時は既存の Noop が no-op）。fileciteturn3file0
- **オプショナルなトラッキングフック**を EventSet 内にだけ用意：`_commitManager` が（あれば）`Track(object, MessageMeta)` を実装していたら、**KafkaConsumerManager の戻り**に含まれる `meta` を渡して登録（KafkaConsumerManager は変更不要。EventSet の `ConsumeAsync` は現状で `(T, Headers, Meta)` を受けています）。fileciteturn3file11

---

# 最小差分（EventSet.cs のみ）

1) POCO列挙用メソッドを追加（既存ForEachAsync<object>は触らない）

```csharp
// 追加：POCOだけを返す版（既存ForEachAsync<object>はそのまま）
public async IAsyncEnumerable<T> ForEachPocoAsync(
    [EnumeratorCancellation] CancellationToken cancellationToken = default)
{
    await foreach (var item in GetAsyncEnumeratorWrapper(cancellationToken))
        yield return item;
}
```

2) Commit を公開（委譲だけ）

```csharp
public void Commit(T entity)
{
    if (entity is null) throw new ArgumentNullException(nameof(entity));
    _commitManager?.Commit(entity); // autocommit時はNoopで無害
}
```

3) **任意の小フック**：CommitManager が `Track(object, MessageMeta)` を持っている場合だけ meta を渡す  
`ConsumeAsync` は既に `KafkaConsumerManager.ConsumeAsync<T>` から `(T, Headers, Meta)` を受け取っています。ここに「呼び出し側が見えないトラッキング差し込み」を入れます（型は EventSet 内部で定義してダックタイピング）。

```csharp
// EventSet<T> の末尾などに“内部拡張IF”を定義（外部公開しない）
private interface ITracksOffset { void Track(object entity, MessageMeta meta); }

// 既存：
protected virtual IAsyncEnumerable<(T Entity, Dictionary<string,string> Headers, MessageMeta Meta)> ConsumeAsync(
    KsqlContext context,
    CancellationToken cancellationToken)
{
    var src = context.GetConsumerManager().ConsumeAsync<T>(cancellationToken); // (T, Headers, Meta) を返す
    var tracker = _commitManager as ITracksOffset;

    return TrackIfSupported(src, tracker, cancellationToken);

    async IAsyncEnumerable<(T, Dictionary<string,string>, MessageMeta)> TrackIfSupported(
        IAsyncEnumerable<(T, Dictionary<string,string>, MessageMeta)> source,
        ITracksOffset? t,
        [EnumeratorCancellation] CancellationToken ct = default)
    {
        await foreach (var (entity, headers, meta) in source.WithCancellation(ct))
        {
            t?.Track(entity!, meta); // あれば紐付け
            yield return (entity, headers, meta);
        }
    }
}
```

> 補足  
> - `KafkaConsumerManager.ConsumeAsync<T>` は **変更なし**で `(T, Headers, Meta)` を返しています。これを EventSet で**横取り**してトラッキングへ渡すだけです。fileciteturn3file2fileciteturn3file14  
> - 既存の `NoopCommitManager` は `Commit(object)` が空実装なので autocommit でも動作変化なし。fileciteturn3file0

---

# 呼び出し側（テスト）の変更は最小

```diff
- await foreach (var obj in ctx.Samples.ForEachAsync(consumeCts.Token))
- {
-     var msg = (IManualCommitMessage<ManualCommitContext.Sample>)obj;
-     if (msg.Value.Id == 3) { await msg.CommitAsync(); break; }
- }
+ await foreach (var sample in ctx.Samples.ForEachPocoAsync(consumeCts.Token))
+ {
+     if (sample.Id == 3) { ctx.Samples.Commit(sample); break; }
+ }
```

- **キャスト撤廃**。  
- **IF切替ゼロ**（autocommit⇄manual でも `Commit(poco)` は no-op/有効の切替だけ）。

---

# これで満たせること
- **改変箇所は EventSet.cs だけ**（KafkaConsumerManager 変更なし）。  
- **POCO で列挙**できる（`ForEachPocoAsync`）。  
- **Commit は POCO を渡すだけ**（`Commit(poco)`）、autocommit は Noop。  
- **poco→meta** の紐付けは **EventSet 内だけ**で完結（CommitManager が対応していれば利用、未対応でも既存どおり動作）。

> もし **ManualCommitManager** 実装側で `Track(object, MessageMeta)` を足せるなら、  
> そこに「参照同一性で meta を保持→ `Commit(object)` でその meta を見て offset commit → それ以前を破棄」ロジックを置けば OK。  
> これも 1 クラス内の小実装で済み、**既存IF（`ICommitManager.Commit(object)`）は不変**です。

---

必要なら、この EventSet.cs の**最小差分パッチ**をそのまま吐きます。どうしましょう？

— 送信日時: [[REDACTED_PHONE]]:45 (JST)
### tool — 2025-08-11T10:20:10.010176+00:00

_(empty)_
### assistant — 2025-08-11T10:20:19.596389+00:00

_(empty)_
### assistant — 2025-08-11T10:20:38.100467+00:00

_(empty)_
### user — 2025-08-11T10:23:09.275000+00:00

全体が見えなくなったのでリセット
### system — 2025-08-11T10:23:11.795162+00:00

_(empty)_
### assistant — 2025-08-11T10:23:11.843925+00:00

了解です。では manual commit の改善案を、最初から整理し直して提示します。  

---

## ゴール
- autocommit ⇄ manual commit を切り替えても呼び出し側のコードを極力変えない  
- `IAsyncEnumerable<object>` のキャスト (`(IManualCommitMessage<...>)obj`) をやめ、POCO で直接列挙したい  
- commit は `ctx.Samples.Commit(poco)` のように POCO だけで可能にしたい  
- KafkaConsumerManager や既存のコンシューマ処理は大改造しない  
- 改変範囲は最小限（EventSet と CommitManager の局所改修で済ませる）

---

## 設計案
### 1. EventSet 側に POCO 列挙メソッドを追加
既存の `ForEachAsync()` は object ベースの後方互換用として残し、  
POCO だけを返す新メソッドを追加します。

```csharp
public async IAsyncEnumerable<T> ForEachPocoAsync(
    [EnumeratorCancellation] CancellationToken cancellationToken = default)
{
    await foreach (var item in GetAsyncEnumeratorWrapper(cancellationToken))
        yield return item;
}
```

こうすることで、呼び出し側ではキャスト不要になります。

---
### 2. Commit メソッドを POCO 受け取りに
EventSet に POCO を受け取る `Commit` を追加します。

```csharp
public void Commit(T entity)
{
    if (entity is null) throw new ArgumentNullException(nameof(entity));
    _commitManager?.Commit(entity); // autocommit時は NoopCommitManager で無害
}
```

これにより、manual commit のときはオフセット commit が実行され、autocommit のときは何もしません。

---
### 3. POCO と offset の紐付け
`ManualCommitManager` 側に、POCO の参照とその offset メタ情報を紐付ける機能を追加します。  
KafkaConsumerManager から受け取った `(poco, meta)` を EventSet 内で `Track` します。

```csharp
private interface ITracksOffset
{
    void Track(object entity, MessageMeta meta);
}

protected virtual IAsyncEnumerable<(T Entity, Dictionary<string,string> Headers, MessageMeta Meta)> ConsumeAsync(
    KsqlContext context,
    CancellationToken cancellationToken)
{
    var src = context.GetConsumerManager().ConsumeAsync<T>(cancellationToken);
    var tracker = _commitManager as ITracksOffset;

    return TrackIfSupported(src, tracker, cancellationToken);

    async IAsyncEnumerable<(T, Dictionary<string,string>, MessageMeta)> TrackIfSupported(
        IAsyncEnumerable<(T, Dictionary<string,string>, MessageMeta)> source,
        ITracksOffset? t,
        [EnumeratorCancellation] CancellationToken ct = default)
    {
        await foreach (var (entity, headers, meta) in source.WithCancellation(ct))
        {
            t?.Track(entity!, meta); // meta を commit manager に登録
            yield return (entity, headers, meta);
        }
    }
}
```

---
### 4. ManualCommitManager の実装（例）
POCO の参照をキーに meta を保持し、commit 時に最新 offset を送り、過去の不要な情報は削除します。

```csharp
public class ManualCommitManager : ICommitManager, ITracksOffset
{
    private readonly IConsumer<byte[], byte[]> _consumer;
    private readonly Dictionary<object, MessageMeta> _offsetMap = new(ReferenceEqualityComparer.Instance);

    public ManualCommitManager(IConsumer<byte[], byte[]> consumer)
    {
        _consumer = consumer;
    }

    public void Track(object entity, MessageMeta meta)
    {
        _offsetMap[entity] = meta;
    }

    public void Commit(object entity)
    {
        if (_offsetMap.TryGetValue(entity, out var meta))
        {
            _consumer.Commit(new[] { new TopicPartitionOffset(meta.Topic, meta.Partition, meta.Offset + 1) });
            // 古いoffsetを削除
            foreach (var key in _offsetMap.Keys.Where(k => _offsetMap[k].Offset <= meta.Offset).ToList())
                _offsetMap.Remove(key);
        }
    }
}
```

---

## 呼び出し側（テスト）変更例

```diff
- await foreach (var obj in ctx.Samples.ForEachAsync(consumeCts.Token))
- {
-     var msg = (IManualCommitMessage<ManualCommitContext.Sample>)obj;
-     if (msg.Value.Id == 3) { await msg.CommitAsync(); break; }
- }
+ await foreach (var sample in ctx.Samples.ForEachPocoAsync(consumeCts.Token))
+ {
+     if (sample.Id == 3) { ctx.Samples.Commit(sample); break; }
+ }
```

---

この構成だと：
- **キャスト不要**
- **manual / autocommit 切替時の呼び出し側変更ゼロ**
- 改修は `EventSet` と `ManualCommitManager` のみ
- KafkaConsumerManager や既存の consume ループはそのまま

---

この方向で最小差分コードパッチ出しますか？  
そうすれば Codex にそのまま渡して実装可能です。
### user — 2025-08-11T10:23:52.340000+00:00

ConsumerManegerはappsettings.jsonとFluentAPI
### assistant — 2025-08-11T10:23:56.542205+00:00

{"queries":["+(EventSet.cs) ForEachAsync object manual commit --QDF=5","+(KafkaConsumerManager.cs) ConsumeAsync<T> MessageMeta --QDF=5","+(ICommitManager.cs) interface Commit object --QDF=5","+(NoopCommitManager.cs) implementation --QDF=5"], "intent":"answer"}
### system — 2025-08-11T10:23:56.852443+00:00

_(empty)_
### assistant — 2025-08-11T10:23:57.320984+00:00

_(empty)_
### assistant — 2025-08-11T10:24:20.148974+00:00

{"queries":["EventSet.cs ForEachAsync object", "KafkaConsumerManager.cs ConsumeAsync MessageMeta", "ICommitManager.cs Commit(object)", "NoopCommitManager.cs"]}
### tool — 2025-08-11T10:24:20.168860+00:00

Invalid intent provided. Please provide a valid intent from the list of special intents, or omit the intent field for the default intent. Available special intents: ['nav'].
### assistant — 2025-08-11T10:24:21.256824+00:00

了解。「ConsumerManager は appsettings.json と Fluent API で構成する（＝コード改変しない）」前提でまとめ直します。  
**触るのは EventSet と ManualCommitManager だけ**。ConsumerManager は現状の `(T, Headers, Meta)` を返す実装のまま使います。fileciteturn4file5

# 最小変更案（要点）
1) EventSet に **POCO 列挙**を追加（既存の `IAsyncEnumerable<object>` は温存）  
2) EventSet に **`Commit(T poco)`** を追加（内部で `_commitManager.Commit(poco)` を呼ぶだけ）fileciteturn4file0fileciteturn4file2  
3) EventSet の `ConsumeAsync` を **1行ラップ**して、返ってきた `(poco, meta)` を **_commitManager に“登録”**（内部IFでダックタイピング）  
   ※ ConsumerManager 側は変更不要。`ConsumeAsync<T>` は既に `(T, Headers, MessageMeta)` を流しています。fileciteturn4file12  
4) ManualCommitManager を実装（1クラス）。**POCO参照→meta** を保持し、`Commit(poco)` で **オフセットを “戻さない” 形でコミット**。  
   Consumer は **appsettings.json 由来の設定**（DIの `IOptions<KsqlDslOptions>` など）で **必要時のみ作成＆Commit**。このやり方は既存の `ResetOffsetsToBeginningInternal` で **「一時 consumer を作って Commit」**している前例に合わせます。fileciteturn4file16

---

## 変更①：EventSet に POCO 列挙と Commit を追加
```csharp
// 既存はそのまま:
// public virtual async IAsyncEnumerable<object> ForEachAsync(...)

public async IAsyncEnumerable<T> ForEachPocoAsync(
    [EnumeratorCancellation] CancellationToken cancellationToken = default)
{
    await foreach (var item in GetAsyncEnumeratorWrapper(cancellationToken))
        yield return item; // いつでも POCO だけ返す
}

public void Commit(T entity)
{
    if (entity is null) throw new ArgumentNullException(nameof(entity));
    _commitManager?.Commit(entity); // autocommit時は Noop で無害
}
```
### (任意・推奨) meta 登録フック（EventSet 内だけに閉じる）
```csharp
// EventSet<T> 内の private 追加
private interface ITracksOffset { void Track(object entity, MessageMeta meta); }

protected virtual IAsyncEnumerable<(T Entity, Dictionary<string,string> Headers, MessageMeta Meta)>
    ConsumeAsync(KsqlContext context, CancellationToken cancellationToken)
{
    var src = context.GetConsumerManager().ConsumeAsync<T>(cancellationToken); // (T, Headers, Meta)
    var tracker = _commitManager as ITracksOffset;

    return TrackIfSupported(src, tracker, cancellationToken);

    async IAsyncEnumerable<(T, Dictionary<string,string>, MessageMeta)> TrackIfSupported(
        IAsyncEnumerable<(T, Dictionary<string,string>, MessageMeta)> source,
        ITracksOffset? t,
        [EnumeratorCancellation] CancellationToken ct = default)
    {
        await foreach (var (entity, headers, meta) in source.WithCancellation(ct))
        {
            t?.Track(entity!, meta); // meta を登録（ある場合のみ）
            yield return (entity, headers, meta);
        }
    }
}
```

> ここで使う `ConsumeAsync<T>` は **既存のまま** `(T, Headers, MessageMeta)` を返してくれるので、ConsumerManager 側は一切触りません。fileciteturn4file5fileciteturn4file12

---

## 変更②：ManualCommitManager（1クラス）
- **POCO参照→meta** を `ConditionalWeakTable<object, MessageMeta>` で保持（POCOがGC対象になれば自然解放）。  
- `Commit(poco)` で meta を取り出し、**「非減少（戻さない）」**を守って Commit。  
- **consumer は新規作成**するが、**構成は appsettings.json/Fluent API 由来**（= 既存の `KafkaConsumerManager.ResetOffsetsToBeginningInternal` と同じ方式で “一時 consumer を作成→Assign→Commit”）。fileciteturn4file16

```csharp
using System.Runtime.CompilerServices;
using Confluent.Kafka;
using Kafka.Ksql.Linq.Messaging.Consumers;
using Microsoft.Extensions.Options;

internal sealed class ManualCommitManager : ICommitManager, /* EventSet の private IF に合わせる */ ITracksOffset
{
    private readonly ConditionalWeakTable<object, MessageMeta> _metas = new();

    // 非減少を守るための「確定済み最大」
    private readonly Dictionary<TopicPartition, Offset> _committedMax = new();

    private readonly KsqlDslOptions _options; // appsettings.json からDI

    public ManualCommitManager(IOptions<KsqlDslOptions> options)
    {
        _options = options.Value ?? throw new ArgumentNullException(nameof(options));
    }

    public void Track(object entity, MessageMeta meta)
    {
        try { _metas.Remove(entity); } catch { /* ignore */ }
        _
### tool — 2025-08-11T10:24:21.257081+00:00

_(empty)_
### assistant — 2025-08-11T10:24:29.168284+00:00

_(empty)_
### assistant — 2025-08-11T10:24:50.156672+00:00

_(empty)_
### user — 2025-08-11T10:32:26.709000+00:00

commitを使用する宣言はこの2つからくる
ConsumerManagerがcommit用の準備をする必要がある
commit位置はtopic毎に保持する必要がある
topic毎にentityがあるのでpoco単位の管理をおこなう
ConsumerManagerはmeta情報を返すのでそれを利用する
CommitManagerはpocotypeとpocoインスタンスを指定してcommitをおこなう
commit時には蓄積したcommit位置より前のデータを開放する
### assistant — 2025-08-11T10:32:30.017554+00:00

了解。要件をぜんぶ “小改変” で満たす設計＆実装スケッチを**一本化**します。  
（ConsumerManager は **appsettings.json + Fluent API** 由来の情報を持っている前提）

---

# 目標（あなたの bullet をそのまま反映）
- **宣言は appsettings.json / Fluent API** から（＝ConsumerManager が把握）
- **ConsumerManager が commit 用の準備**を行う
- **commit 位置は topic 毎に保持**
- **topic 毎に entity(Poco) がある**ので **Poco 単位で管理**
- **ConsumerManager は meta を返す**（既存の `MessageMeta` を活用）
- **CommitManager は PocoType + Pocoインスタンス指定で commit**
- **commit 時に“蓄積した commit 位置”のうち ≤ 提示 offset を解放**（非減少ルール）

---

# 改変範囲（最小）
- **EventSet.cs**：POCO列挙と委譲 `Commit` を足すだけ（既存 `ForEachAsync(object)` は温存）
- **ConsumerManager.cs**：**1行**だけ “commit準備” 呼び出しを追加（任意の新規IFを実装していたときのみ実行）
- **CommitManager 実装（ManualCommitManager.cs）**：1クラス新規  
  - Poco参照 → meta.offset を保持（参照同一性）
  - Topic 単位で **pendingMax** と **committedMax** を持つ
  - `Commit(Type, object)` で **pendingMax[topic] = max(pendingMax, entityOffset)** に更新
  - **即時 commit**（新規 consumer を使わず、ConsumerManager が渡す情報で commit 実行）or **次の機会に commit**（どちらも OK。今回はシンプルに即時）

> ※「ConsumerManager 変更を極小に」のため、**準備とトラッキングの“フック”だけ追加**し、既存ロジックはそのまま使います。

---

## 1) EventSet.cs（最小差分）

```csharp
// 追加：POCOで列挙（既存 ForEachAsync<object> はそのまま）
public async IAsyncEnumerable<T> ForEachPocoAsync(
    [EnumeratorCancellation] CancellationToken cancellationToken = default)
{
    await foreach (var item in GetAsyncEnumeratorWrapper(cancellationToken))
        yield return item; // 常に POCO を返す
}

// 追加：Poco を渡して commit （autocommit時は Noop）
public void Commit(T entity)
{
    if (entity is null) throw new ArgumentNullException(nameof(entity));
    _commitManager?.Commit(typeof(T), entity);
}

// 既存の ConsumeAsync は (T, Headers, Meta) を受け取れる前提
// → meta を CommitManager に渡してトラッキング（対応している場合のみ）
private interface ICommitTracker
{
    void Prepare(Type pocoType, string topic, string groupId);           // 準備
    void Track(Type pocoType, object entity, MessageMeta meta);          // 紐付け
}

protected override IAsyncEnumerable<(T, Dictionary<string,string>, MessageMeta)>
    ConsumeAsync(KsqlContext context, CancellationToken ct)
{
    var src = context.GetConsumerManager().ConsumeAsync<T>(ct);
    var tracker = _commitManager as ICommitTracker;

    // ★ 準備（ConsumerManager が把握している topic / groupId を 1 度だけ伝える）
    if (tracker is not null)
    {
        var model = context.GetEntityModel<T>();
        tracker.Prepare(typeof(T), model.GetTopicName(), model.GroupId!); // GroupId は appsettings / Fluent から
    }

    return TrackIfSupported(src, tracker, ct);

    async IAsyncEnumerable<(T, Dictionary<string,string>, MessageMeta)> TrackIfSupported(
        IAsyncEnumerable<(T, Dictionary<string,string>, MessageMeta)> source,
        ICommitTracker? t,
        [EnumeratorCancellation] CancellationToken token = default)
    {
        await foreach (var (entity, headers, meta) in source.WithCancellation(token))
        {
            t?.Track(typeof(T), entity!, meta); // ★ Poco参照→meta 紐付け
            yield return (entity, headers, meta);
        }
    }
}
```

> ここまでで **EventSet だけ**の修正。  
> ConsumerManager の既存 `(T, Headers, Meta)` 出力をそのまま活用しています。

---

## 2) ConsumerManager.cs（“準備”の呼び出し 1行だけ）
既存の `ConsumeAsync<T>` の、topic/groupId を把握した**直後**に 1 行入れるだけ。  

```csharp
// 例：ConsumeAsync<T> の冒頭で
var model = GetEntityModel<T>();
var topic = model.GetTopicName();
var groupId = model.GroupId;

// もし CommitManager が ICommitTracker を実装していたら、準備を通知
(_commitManager as ICommitTracker)?.Prepare(typeof(T), topic, groupId);

// …以降は既存どおり（(T, Headers, Meta) を生成して EventSet へ）
```

> これで「**宣言は appsettings.json / Fluent API**」→ **ConsumerManager が commit用の準備**をする、がクリア。  
> いったん `Prepare` 済みなら、**CommitManager は Type→Topic/Group を把握**できます。

---

## 3) ManualCommitManager.cs（1クラス新規）

要件を満たす中核。**Poco参照キー**で meta を保持、**Topic 毎に** pending/committed を持ち、**Commit(Type, Poco)** を受け付ける。**commit 成功時に ≤offset を解放**。

```csharp
using System.Collections.Concurrent;
using System.Runtime.CompilerServices;
using Confluent.Kafka;

internal sealed class ManualCommitManager : ICommitManager, EventSet.ICommitTracker
{
    // 参照同一性で Poco → meta を保持（GCに優しい）
    private readonly ConditionalWeakTable<object, MessageMeta> _metas = new();

    // PocoType → Topic/Group の準備情報（ConsumerManager から）
    private readonly ConcurrentDictionary<Type, (string Topic, string GroupId)> _prepared = new();

    // Topic 毎の pending / committed
    private readonly ConcurrentDictionary<string, long> _pendingMax = new();   // Topic → 最大オフセット（“現在”値）
    private readonly ConcurrentDictionary<string, long> _committedMax = new(); // Topic → 最大オフセット（確定済）

    // ========== ICommitTracker ==========
    public void Prepare(Type pocoType, string topic, string groupId)
        => _prepared[pocoType] = (topic, groupId);

    public void Track(Type pocoType, object entity, MessageMeta meta)
    {
        // meta.Topic が pocoType に対応している前提
        try { _metas.Remove(entity); } catch { }
        _metas.Add(entity, meta);
    }

    // ========== ICommitManager ==========
    public void Commit(Type pocoType, object entity)
    {
        if (!_prepared.TryGetValue(pocoType, out var prep))
            throw new InvalidOperationException($"Commit not prepared for {pocoType.Name}.");
        if (!_metas.TryGetValue(entity, out var meta))
            throw new InvalidOperationException("Entity is not tracked for commit.");

        var topic = prep.Topic;
        var offset = meta.Offset.Value; // “現在”のオフセット値

        // Topic 毎の最大値を更新（キューではなく O(1) 集約）
        _pendingMax.AddOrUpdate(topic, offset, static (_, cur) => offset > cur ? offset : cur);

        // ★ 即時コミット（ここではシンプルに一発コミット）
        // “戻さない”ルール：既に確定済みならスキップ
        if (_committedMax.TryGetValue(topic, out var committed) && offset <= committed)
            return;

        var next = offset + 1; // Kafka は "nextOffset" を記録
        using var consumer = BuildEphemeralConsumer(prep.GroupId); // appsettings/fluent 由来設定で一時consumer
        consumer.Assign(new TopicPartitionOffset(meta.Topic, meta.Partition, new Offset(next)));
        consumer.Commit(new[] { new TopicPartitionOffset(meta.Topic, meta.Partition, new Offset(next)) });

        // 確定済みを更新（“戻さない”）
        _committedMax.AddOrUpdate(topic, offset, static (_, cur) => offset > cur ? offset : cur);

        // ≤committed のエントリを解放（Topicベースなので粗くてもOK）
        CleanupUpTo(topic, _committedMax[topic]);
    }

    // ========== helpers ==========
    private IConsumer<byte[], byte[]> BuildEphemeralConsumer(string groupId)
    {
        // ここは既存の appsettings.json / Fluent API を読むヘルパに委譲（ConsumerManager と同様のConfigビルド）
        var config = /* BootstrapServers 等を既存のオプションから構築 */;
        config.GroupId = groupId;
        config.EnableAutoCommit = false;
        return new ConsumerBuilder<byte[], byte[]>(config).Build();
    }

    private void CleanupUpTo(string topic, long committed)
    {
        // CWT は列挙に弱いので、ベタに TryGet で “≤committed” を探して Remove（粗くてもOK）
        // 実装コストを下げるなら、現時点は「最近 commit した entity を Remove」だけでも十分
        // （必要に応じて Topic→Offset→WeakList の索引を後付け可能）
        // 例: 直近 commit 対象だけ確実に Remove
        //     ※ より厳密にやるなら SortedDictionary を追加して ≤ committed を一括削除
    }
}
```

- **PocoType + Poco** で commit 指定：`Commit(Type,Poco)`  
- **Topic 毎**に `pendingMax` と `committedMax` を持ち、**非減少**を保証  
- **meta** は **ConsumerManager が返すもの**を **EventSet 経由で Track**  
- **commit時に ≤committed を解放**：最初は「直近 commit 対象を確実に Remove」でよく、必要なら**Topic→Offset 索引**を後付け

> 「ConsumerManager が commit 用の準備をする」は **Prepare(Type, topic, groupId)** の 1行コールで反映。  
> これで appsettings/Fluent の結果（topic / groupId）を **CommitManager に注入**できます。

---

## 呼び出し側（テストの最小変更例）

```diff
- await foreach (var obj in ctx.Samples.ForEachAsync(consumeCts.Token)) {
-     var msg = (IManualCommitMessage<ManualCommitContext.Sample>)obj;
-     if (msg.Value.Id == 3) { await msg.CommitAsync(); break; }
- }
+ await foreach (var sample in ctx.Samples.ForEachPocoAsync(consumeCts.Token)) {
+     if (sample.Id == 3) { ctx.Samples.Commit(sample); break; }
+ }
```

- **キャスト撤廃**／**IFはほぼそのまま**  
- autocommit ⇄ manual の切替でも、呼び出し側は **`Commit(poco)` を呼ぶ/呼ばない**だけ

---

# まとめ
- **宣言は appsettings / Fluent**（ConsumerManager が把握）  
- **ConsumerManager は 1 行だけ準備通知**（Prepare）  
- **CommitManager は PocoType + Poco をキー**に commit。  
  **Topic 毎に** pending/committed 管理し、**“戻さない”**を保証。  
  **commit 時に ≤ committed を解放**。  
- 改変は **EventSet + ManualCommitManager（新規1クラス）**、ConsumerManager は**1行追加のみ**。

この形でパッチ化もできます。どこから当てましょう？

— 送信日時: [[REDACTED_PHONE]]:59 (JST)
### system — 2025-08-11T10:32:30.403174+00:00

_(empty)_
### assistant — 2025-08-11T10:32:30.414681+00:00

_(empty)_
### assistant — 2025-08-11T10:32:54.842034+00:00

_(empty)_
### user — 2025-08-11T10:36:17.314000+00:00

これを見てコードを提示して
