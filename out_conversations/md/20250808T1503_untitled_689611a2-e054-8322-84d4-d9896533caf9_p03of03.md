---
conversation_id: "689611a2-e054-8322-84d4-d9896533caf9"
title: "エンティティのストリーム化"
create_time: 1754665381.640783
update_time: 1754834040.123335
language_guess: "en"
num_messages: 386
part_index: 3
part_count: 3
---

### tool — 2025-08-08T18:54:38.512289+00:00

using Avro;
using Avro.Specific;
using System;
using System.Collections.Concurrent;
using System.Collections.Generic;
using System.Reflection;
using System.Reflection.Emit;
using System.Text;
using Kafka.Ksql.Linq.Configuration;

namespace Kafka.Ksql.Linq.Mapping;

/// <summary>
/// Generate ISpecificRecord implementations from POCO types at runtime.
/// </summary>
public static class SpecificRecordGenerator
{
    private static readonly ConcurrentDictionary<string, Lazy<Type>> _cache = new();
    private static readonly ModuleBuilder _moduleBuilder;

    static SpecificRecordGenerator()
    {
        var asmName = new AssemblyName("KafkaKsqlSpecificRecords");
        var asmBuilder = AssemblyBuilder.DefineDynamicAssembly(asmName, AssemblyBuilderAccess.Run);
        _moduleBuilder = asmBuilder.DefineDynamicModule("Main");
    }

    /// <summary>
    /// Generate (or retrieve from cache) the ISpecificRecord implementation for the given POCO type.
    /// </summary>
    public static Type Generate(Type pocoType)
    {
        var cacheKey = (pocoType.FullName ?? pocoType.Name).Replace('+', '.');
        var lazy = _cache.GetOrAdd(cacheKey, _ => new Lazy<Type>(() =>
        {
            var schemaJson = GenerateAvroSchema(pocoType);
            return GenerateSpecificRecordType(pocoType, schemaJson, cacheKey);
        }, System.Threading.LazyThreadSafetyMode.ExecutionAndPublication));
        return lazy.Value;
    }

    private static string GenerateAvroSchema(Type pocoType)
    {
        var sb = new StringBuilder();
        sb.AppendLine("{");
        sb.AppendLine("  \"type\": \"record\",");
        sb.AppendLine($"  \"name\": \"{pocoType.Name}Avro\",");
        sb.AppendLine($"  \"namespace\": \"{pocoType.Namespace}\",");
        var props = pocoType.GetProperties(BindingFlags.Public | BindingFlags.Instance);
        if (props.Length == 0)
        {
            sb.AppendLine("  \"fields\": []");
        }
        else
        {
            sb.AppendLine("  \"fields\": [");
            for (int i = 0; i < props.Length; i++)
            {
                var p = props[i];
                var avroType = MapToAvroType(p.PropertyType);

                sb.Append($"    {{ \"name\": \"{p.Name}\", \"type\": {avroType}");

                // default値はカンマ＋スペースの直後に追加（ここでは余分なスペースなし）
                if (p.PropertyType == typeof(string))
                    sb.Append(", \"default\": \"\"");
                else if (p.PropertyType == typeof(int) || p.PropertyType == typeof(long) ||
                        p.PropertyType == typeof(float) || p.PropertyType == typeof(double) ||
                        p.PropertyType == typeof(decimal))
                    sb.Append(", \"default\": 0");
                else if (p.PropertyType == typeof(bool))
                    sb.Append(", \"default\": false");
                else if (p.PropertyType == typeof(byte[]))
                    sb.Append(", \"default\": \"\"");
                else if (p.PropertyType == typeof(DateTime))
                    sb.Append(", \"default\": 0");
                else if (p.PropertyType == typeof(Guid))
                    sb.Append(", \"default\": \"[[REDACTED_PHONE]]-[[REDACTED_PHONE]]\"");
                else if (p.PropertyType.IsGenericType &&
                         p.PropertyType.GetGenericTypeDefinition() == typeof(Dictionary<,>) &&
                         p.PropertyType.GetGenericArguments()[0] == typeof(string) &&
                         p.PropertyType.GetGenericArguments()[1] == typeof(string))
                    sb.Append(", \"default\": {}");
                else if (Nullable.GetUnderlyingType(p.PropertyType) != null)
                    sb.Append(", \"default\": null");

                sb.Append(" }");
                if (i < props.Length - 1) sb.Append(',');
                sb.AppendLine();
            }
            sb.AppendLine("  ]");
        }
        sb.Append('}');
        return sb.ToString();
    }

    private static string MapToAvroType(Type t)
    {
        if (t.IsGenericType && t.GetGenericTypeDefinition() == typeof(Dictionary<,>))
        {
            var args = t.GetGenericArguments();
            if (args[0] == typeof(string) && args[1] == typeof(string))
                return "{ \"type\": \"map\", \"values\": \"string\" }";
            throw new NotSupportedException("Only Dictionary<string,string> is supported.");
        }
        if (t == typeof(int)) return "\"int\"";
        if (t == typeof(long)) return "\"long\"";
        if (t == typeof(float)) return "\"float\"";
        if (t == typeof(double)) return "\"double\"";
        if (t == typeof(bool)) return "\"boolean\"";
        if (t == typeof(string)) return "\"string\"";
        if (t == typeof(byte[])) return "\"bytes\"";
        if (t == typeof(decimal))
            return $"{{ \"type\": \"bytes\", \"logicalType\": \"decimal\", \"precision\": {DecimalPrecisionConfig.DecimalPrecision}, \"scale\": {DecimalPrecisionConfig.DecimalScale} }}";
        if (t == typeof(DateTime)) return "{ \"type\": \"long\", \"logicalType\": \"timestamp-millis\" }";
        if (t == typeof(Guid)) return "\"string\"";
        return "\"string\"";
    }

    private static Type GenerateSpecificRecordType(Type pocoType, string schemaJson, string cacheKey)
    {
        var props = pocoType.GetProperties(BindingFlags.Public | BindingFlags.Instance);

        // ensure a unique type name even for nested classes with the same simple name
        var fullName = cacheKey + "Avro";

        var typeBuilder = _moduleBuilder.DefineType(
            fullName,
            TypeAttributes.Public | TypeAttributes.Class);
        typeBuilder.AddInterfaceImplementation(typeof(ISpecificRecord));

        var schemaField = typeBuilder.DefineField("_SCHEMA", typeof(Schema), FieldAttributes.Private | FieldAttributes.Static | FieldAttributes.InitOnly);

        var cctor = typeBuilder.DefineConstructor(MethodAttributes.Static | MethodAttributes.Private, CallingConventions.Standard, Type.EmptyTypes);
        var ilCctor = cctor.GetILGenerator();
        ilCctor.Emit(OpCodes.Ldstr, schemaJson);
        ilCctor.Emit(OpCodes.Call, typeof(Schema).GetMethod("Parse", new[] { typeof(string) })!);
        ilCctor.Emit(OpCodes.Stsfld, schemaField);
        ilCctor.Emit(OpCodes.Ret);

        // public parameterless constructor
        typeBuilder.DefineDefaultConstructor(MethodAttributes.Public);

        var schemaProp = typeBuilder.DefineProperty("Schema", PropertyAttributes.None, typeof(Schema), null);
        var getSchema = typeBuilder.DefineMethod("get_Schema", MethodAttributes.Public | MethodAttributes.Virtual | MethodAttributes.HideBySig | MethodAttributes.SpecialName, typeof(Schema), Type.EmptyTypes);
        var ilGetSchema = getSchema.GetILGenerator();
        ilGetSchema.Emit(OpCodes.Ldsfld, schemaField);
        ilGetSchema.Emit(OpCodes.Ret);
        schemaProp.SetGetMethod(getSchema);
        typeBuilder.DefineMethodOverride(getSchema, typeof(ISpecificRecord).GetProperty("Schema")!.GetGetMethod()!);

        var fields = new FieldBuilder[props.Length];
        for (int i = 0; i < props.Length; i++)
        {
            var p = props[i];
            fields[i] = typeBuilder.DefineField("_" + p.Name, p.PropertyType, FieldAttributes.Private);
            var propBuilder = typeBuilder.DefineProperty(p.Name, PropertyAttributes.None, p.PropertyType, null);
            var getMethod = typeBuilder.DefineMethod("get_" + p.Name, MethodAttributes.Public | MethodAttributes.HideBySig | MethodAttributes.SpecialName, p.PropertyType, Type.EmptyTypes);
            var ilGet = getMethod.GetILGenerator();
            ilGet.Emit(OpCodes.Ldarg_0);
            ilGet.Emit(OpCodes.Ldfld, fields[i]);
            ilGet.Emit(OpCodes.Ret);
            var setMethod = typeBuilder.DefineMethod("set_" + p.Name, MethodAttributes.Public | MethodAttributes.HideBySig | MethodAttributes.SpecialName, null, new[] { p.PropertyType });
            var ilSet = setMethod.GetILGenerator();
            ilSet.Emit(OpCodes.Ldarg_0);
            ilSet.Emit(OpCodes.Ldarg_1);
            ilSet.Emit(OpCodes.Stfld, fields[i]);
            ilSet.Emit(OpCodes.Ret);
            propBuilder.SetGetMethod(getMethod);
            propBuilder.SetSetMethod(setMethod);
        }

        var getRecord = typeBuilder.DefineMethod("Get", MethodAttributes.Public | MethodAttributes.Virtual | MethodAttributes.HideBySig, typeof(object), new[] { typeof(int) });
        var ilGetRecord = getRecord.GetILGenerator();
        var labels = new Label[props.Length];
        for (int i = 0; i < props.Length; i++)
            labels[i] = ilGetRecord.DefineLabel();
        var defaultLabel = ilGetRecord.DefineLabel();
        var endLabel = ilGetRecord.DefineLabel();

        ilGetRecord.Emit(OpCodes.Ldarg_1);
        ilGetRecord.Emit(OpCodes.Switch, labels);
        // use long branch to avoid range issues when many fields exist
        ilGetRecord.Emit(OpCodes.Br, defaultLabel);

        for (int i = 0; i < props.Length; i++)
        {
            ilGetRecord.MarkLabel(labels[i]);
            ilGetRecord.Emit(OpCodes.Ldarg_0);
            ilGetRecord.Emit(OpCodes.Ldfld, fields[i]);
            if (props[i].PropertyType.IsValueType)
                ilGetRecord.Emit(OpCodes.Box, props[i].PropertyType);
            ilGetRecord.Emit(OpCodes.Br, endLabel);
        }

        ilGetRecord.MarkLabel(defaultLabel);
        ilGetRecord.Emit(OpCodes.Ldstr, "Bad index {0}");
        ilGetRecord.Emit(OpCodes.Ldarg_1);
        ilGetRecord.Emit(OpCodes.Box, typeof(int));
        ilGetRecord.Emit(OpCodes.Call, typeof(string).GetMethod("Format", new[] { typeof(string), typeof(object) })!);
        ilGetRecord.Emit(OpCodes.Newobj, typeof(AvroRuntimeException).GetConstructor(new[] { typeof(string) })!);
        ilGetRecord.Emit(OpCodes.Throw);

        ilGetRecord.MarkLabel(endLabel);
        ilGetRecord.Emit(OpCodes.Ret);

        typeBuilder.DefineMethodOverride(getRecord, typeof(ISpecificRecord).GetMethod("Get")!);

        var putRecord = typeBuilder.DefineMethod("Put", MethodAttributes.Public | MethodAttributes.Virtual | MethodAttributes.HideBySig, typeof(void), new[] { typeof(int), typeof(object) });
        var ilPutRecord = putRecord.GetILGenerator();
        var putLabels = new Label[props.Length];
        for (int i = 0; i < props.Length; i++)
            putLabels[i] = ilPutRecord.DefineLabel();
        var putDefault = ilPutRecord.DefineLabel();
        var putEnd = ilPutRecord.DefineLabel();

        ilPutRecord.Emit(OpCodes.Ldarg_1);
        ilPutRecord.Emit(OpCodes.Switch, putLabels);
        // use long branch to avoid short branch limits
        ilPutRecord.Emit(OpCodes.Br, putDefault);

        for (int i = 0; i < props.Length; i++)
        {
            ilPutRecord.MarkLabel(putLabels[i]);
            ilPutRecord.Emit(OpCodes.Ldarg_0);
            ilPutRecord.Emit(OpCodes.Ldarg_2);
            if (props[i].PropertyType.IsValueType)
                ilPutRecord.Emit(OpCodes.Unbox_Any, props[i].PropertyType);
            else
                ilPutRecord.Emit(OpCodes.Castclass, props[i].PropertyType);
            ilPutRecord.Emit(OpCodes.Stfld, fields[i]);
            ilPutRecord.Emit(OpCodes.Br, putEnd);
        }

        ilPutRecord.MarkLabel(putDefault);
        ilPutRecord.Emit(OpCodes.Ldstr, "Bad index {0}");
        ilPutRecord.Emit(OpCodes.Ldarg_1);
        ilPutRecord.Emit(OpCodes.Box, typeof(int));
        ilPutRecord.Emit(OpCodes.Call, typeof(string).GetMethod("Format", new[] { typeof(string), typeof(object) })!);
        ilPutRecord.Emit(OpCodes.Newobj, typeof(AvroRuntimeException).GetConstructor(new[] { typeof(string) })!);
        ilPutRecord.Emit(OpCodes.Throw);

        ilPutRecord.MarkLabel(putEnd);
        ilPutRecord.Emit(OpCodes.Ret);

        typeBuilder.DefineMethodOverride(putRecord, typeof(ISpecificRecord).GetMethod("Put")!);

        return typeBuilder.CreateType()!;
    }
}
### tool — 2025-08-08T18:54:38.515460+00:00

All the files uploaded by the user have been fully loaded. Searching won't provide additional information.
### user — 2025-08-08T18:55:21.826000+00:00

それはいらない。
### assistant — 2025-08-08T18:55:38.031727+00:00

了解。**出口の最終契約だけ固定します**：

**`IKsqlContext.Set<T>().ToListAsync()` は、`T` が `MappingRegistry` に登録済みで「(key,value)→T を合成可能」な型に対してのみ“キャッシュ経由”で有効**（未登録や未準備時はフォールバック）。

— 送信日時（日本時間）: [[REDACTED_PHONE]]:05
### system — 2025-08-08T18:55:38.036125+00:00

_(empty)_
### assistant — 2025-08-08T18:55:40.063916+00:00

_(empty)_
### assistant — 2025-08-08T18:55:47.865898+00:00

_(empty)_
### user — 2025-08-08T18:57:04.103000+00:00

ToListAsyncに必要なインスタンスをどう持ってくる？
### assistant — 2025-08-08T18:57:19.900444+00:00

一点に絞って答えます。  
**`ToListAsync` が使うインスタンスは “起動時に束ねてレジストリへ預け、実行時はレジストリから一発取得” です。**
### 必要なもの（ToListAsync時点）
- **`ITableCache<T>`**（= その `T` 用のキャッシュハンドル）
  - 中に **`IKafkaStreams`**, **`storeName`**, **型付きストア取得関数** を既に保持
- **`MappingRegistry`**
  - `T` → `KeyValueTypeMapping` を引くため（`CombineFromAvroKeyValue` 用）
### どこから持ってくる？
- `ReadCachedEntitySet<T>` のコンストラクタで **`KsqlContext` を受け取る**  
  実行時に：
  1) `var cache = context.GetTableCacheRegistry().GetCache<T>();`
  2) `var mapping = ((KsqlContext)context).GetMappingRegistry().GetMapping(typeof(T));`

この2つだけ取り出せば、`ToListAsync` は  
`foreach (var (k,v) in cache.All()) yield mapping.CombineFromAvroKeyValue(k,v, typeof(T));`  
（ストア未準備なら `baseSet.ToListAsync` へフォールバック）  
で完結します。起動時（`UseTableCache`）に **`ITableCache<T>` を作ってレジストリへ登録**しておくのが肝で、**`ToListAsync` 側では一切組み立てない**のがポイントです。

— 送信日時（日本時間）: [[REDACTED_PHONE]]:09
### system — 2025-08-08T18:57:19.912176+00:00

_(empty)_
### assistant — 2025-08-08T18:57:22.072070+00:00

_(empty)_
### assistant — 2025-08-08T18:57:29.495712+00:00

_(empty)_
### user — 2025-08-08T18:58:56.210000+00:00

extensionのIFを見せて
### system — 2025-08-08T18:59:11.491931+00:00

_(empty)_
### assistant — 2025-08-08T18:59:11.535773+00:00

はい、`UseTableCache` 周りの Extension IF を整理した形を示します。  
`KsqlContextCacheExtensions` の想定IFはこんな形です。  

```csharp
public static class KsqlContextCacheExtensions
{
    public static void UseTableCache(
        this IKsqlContext context,
        KsqlDslOptions options,
        ILoggerFactory? loggerFactory = null,
        IKafkaStreams? streams = null)
    {
        // 1. MappingRegistry 取得
        var mapping = ((KsqlContext)context).GetMappingRegistry();

        // 2. 起動時に TableCacheRegistry 作成 or 取得
        var cacheRegistry = context.GetTableCacheRegistry();

        // 3. options.Entities の中から EnableCache=true のエンティティを走査
        foreach (var entity in options.Entities.Where(e => e.EnableCache))
        {
            // storeName や型情報を mapping から解決
            var model = context.GetEntityModels()[entity.Entity];
            var kvMapping = mapping.GetMapping(model.EntityType);

            // キャッシュ生成
            var cacheType = typeof(RocksDbTableCache<>).MakeGenericType(model.EntityType);
            var cache = (ITableCache)Activator.CreateInstance(
                cacheType,
                mapping,
                streams ?? throw new InvalidOperationException("IKafkaStreams is required"),
                entity.StoreName ?? model.GetTopicName(),
                /* schemaRegistryClient */ null,
                loggerFactory
            )!;

            // 登録
            cacheRegistry.Register(model.EntityType, cache);
        }
    }
}
```

---
### IFの要点
- **入口契約**：
  - `IKsqlContext context`
  - `KsqlDslOptions options`
  - 任意の `ILoggerFactory`
  - 任意の（だが本来必須の）`IKafkaStreams`
- **出口契約**：
  - 起動後、`ITableCacheRegistry` に `T` ごとのキャッシュが登録されている  
    → `ToListAsync` 側では `context.GetTableCache<T>()` で取得できる状態

---

もし望むなら、この IF を `IServiceCollection` 登録パターンに寄せてもう少し明示的に「入口」「出口」を契約化することもできます。  
この方が「全体を入口と出口でつなぐ」という司令の意図に沿いやすいです。

この方向で固定しますか？  
— 送信日時（日本時間）: [[REDACTED_PHONE]]:14
### user — 2025-08-08T18:59:44.956000+00:00

だめ、ポイントはToListAsyncとの接点
### system — 2025-08-08T19:00:01.609621+00:00

_(empty)_
### assistant — 2025-08-08T19:00:01.632152+00:00

了解。「**ToListAsync と“何がどう繋がるか”の最小インターフェース**」だけを出します。実装は後回し。これさえあれば `ReadCachedEntitySet<T>.ToListAsync` がブレずに書けます。

# ToListAsync が使う“接点”の IF（これだけ）
```csharp
// 1) コンテキストからレジストリを引けること（入口で内部登録済みの前提）
internal static class KsqlContextCacheQueryExtensions
{
    internal static TableCacheRegistry GetTableCacheRegistry(this IKsqlContext ctx);
    internal static MappingRegistry    GetMappingRegistry(this IKsqlContext ctx);
}

// 2) ToListAsync が欲しいのは「今すぐ読めるスナップショット」だけ（待たない）
internal interface ITableSnapshot
{
    // Avroの key/value（or 片方null）列挙。未準備なら空を返さず、スナップショット自体を取れない契約。
    IEnumerable<(object? AvroKey, object AvroValue)> ReadAll();
}

// 3) レジストリは T 向けに「今読めるならスナップショットを返す」。無理なら false（＝フォールバック）
internal sealed class TableCacheRegistry
{
    public bool TryOpenSnapshot<T>(out ITableSnapshot? snapshot) where T : class;
}
```

# ToListAsync 側はこう書ける（最小・確定形）
```csharp
public async Task<List<T>> ToListAsync(CancellationToken ct = default)
{
    // 1) 必要インスタンスを“この2行だけ”で取得
    var reg = _context.GetTableCacheRegistry();
    var map = _context.GetMappingRegistry().GetMapping(typeof(T));

    // 2) 今読めるならキャッシュ、ダメなら即フォールバック（待たない）
    if (!reg.TryOpenSnapshot<T>(out var snap) || snap == null)
        return await _baseSet.ToListAsync(ct);

    // 3) key+value → POCO を合成（Reflectionは map に閉じ込め済み）
    var list = new List<T>();
    foreach (var (k, v) in snap.ReadAll())
    {
        ct.ThrowIfCancellationRequested();
        list.Add((T)map.CombineFromAvroKeyValue(k, v, typeof(T)));
    }
    return list;
}
```
### 重要ポイント
- **ToListAsync が直接知るのはこの3つだけ**：`TableCacheRegistry` / `MappingRegistry` / `ITableSnapshot`
- **未準備判定は TryOpenSnapshot の戻り値で一発**（例外や待機ロジックを ToListAsync に持ち込まない）
- **key+value→POCO の結合は MappingRegistry に委譲**（ToListAsync は合成ロジックを持たない）

このIFで “接点” が固定できます。実装はこの契約に沿って後で詰めればOK。

— 送信日時（日本時間）: [[REDACTED_PHONE]]:16
### assistant — 2025-08-08T19:00:03.565446+00:00

_(empty)_
### assistant — 2025-08-08T19:00:14.614223+00:00

_(empty)_
### user — 2025-08-08T19:01:56.386000+00:00

ITableSnapshot　これはなに？　イメージで作ってないか？
### system — 2025-08-08T19:02:11.637117+00:00

_(empty)_
### assistant — 2025-08-08T19:02:11.738065+00:00

はい、正直に言うと今お見せした `ITableSnapshot` は、**「ToListAsync 側から見た必要最小限の読み取り口」をイメージして仮に名付けたもの**です。  
つまり、今のコードベースにはそのまま存在していない可能性が高く、実際は以下の既存要素から構成されるはずです。

---

## 実体に近い構造の整理
`ToListAsync` がやりたいことは：

1. **キャッシュストアにアクセス**  
   → 実体は RocksDB の `IReadOnlyKeyValueStore<TKey, TValue>`  
   → Streamiz の `StoreQueryParameters` などで取得
2. **全レコードを列挙**  
   → `All()` や `Range()` メソッドで `KeyValuePair<TKey, TValue>` を取る
3. **Key と Value を Avro → POCO に変換**  
   → 変換ロジックは `MappingRegistry` / `KeyValueTypeMapping` に既に存在

---

## 既存の流れに沿った「接点」の再現
おそらく `ReadCachedEntitySet<T>` の内部はこうなるはずです。

```csharp
public async Task<List<T>> ToListAsync(CancellationToken ct = default)
{
    // キャッシュの取得
    var store = _context
        .GetStreams()  // IKafkaStreams or KafkaStream
        .Store(
            StoreQueryParameters.FromNameAndType(
                _model.GetTopicName(),
                QueryableStoreTypes.KeyValueStore<object, object>()
            )
        );

    var list = new List<T>();

    foreach (var kv in store.All())
    {
        ct.ThrowIfCancellationRequested();
        // Key + Value から POCO を組み立てる
        var mapping = _context.GetMappingRegistry().GetMapping(typeof(T));
        list.Add((T)mapping.CombineFromAvroKeyValue(kv.Key, kv.Value, typeof(T)));
    }

    return list;
}
```

---

## つまり
- `ITableSnapshot` というのは実際の `IReadOnlyKeyValueStore<,>` のインターフェースを**抽象化した名前**にすぎません。
- 現実的には **Streamiz の Store API** を直接使うのが正しい。
- そして Key/Value から POCO への結合は **MappingRegistry に任せる**。

---

もし望むなら、この「ToListAsync が RocksDB からデータを取って POCO に組み立てる」部分を、  
今のプロジェクトのクラス構成に沿って完全に書き起こすことができます。  
そうすると、イメージではなく**現物に即した出口設計**になります。  

これ、次にやりますか？  
（そうすれば、もう「イメージで作ってないか？」という心配はゼロになります）
### user — 2025-08-08T19:02:59.614000+00:00

var store = _context
        .GetStreams()  // IKafkaStreams or KafkaStream
        .Store(
            StoreQueryParameters.FromNameAndType(
                _model.GetTopicName(),
                QueryableStoreTypes.KeyValueStore<object, object>()
            )
        );
これがだめ
### assistant — 2025-08-08T19:03:16.927813+00:00

（JST [[REDACTED_PHONE]]:20）

そのコードがダメな理由は**一点**：

**`ToListAsync` の中で、`topic`名×`object,object` でストアを都度開きにいってる**からです。  
- **store名≠topic名**（Materialized の名前で引くべき）  
- **型は `object,object` じゃなく Avro の型ペア**（登録時に確定した `TKeyAvro, TValueAvro`）  
- **都度取得は禁止**（RUNNING揺らぎで落ちる。起動時に作った“読取ハンドル”経由で読む）
### 正しい接点（`ToListAsync` では“直接 Store を触らない”）
```csharp
public async Task<List<T>> ToListAsync(CancellationToken ct = default)
{
    // 起動時に登録済みのリーダー（型確定＆lazy解決済み）を取る
    var reader = _context.GetTableCacheRegistry().GetReader<T>();
    if (reader == null)                                   // キャッシュ未登録
        return await _baseSet.ToListAsync(ct);            // 即フォールバック

    return await reader.ToListAsync(ct);                  // ← ここだけ
}
```

- `GetReader<T>()` は、内部で **`QueryableStoreTypes.KeyValueStore<TKeyAvro,TValueAvro>()`＋store名** を使う“型付き”リーダーを返す想定（起動時に登録）。  
- Compose（key+value→POCO）はそのリーダー内でやる。`ToListAsync` は**触らない**。

要するに、**`ToListAsync` はハンドルに委譲**。  
**Storeを直接開くのは入口で作ったリーダーの責務**に寄せないと、ここが壊れ続けます。
### system — 2025-08-08T19:03:16.942342+00:00

_(empty)_
### assistant — 2025-08-08T19:03:17.652552+00:00

_(empty)_
### assistant — 2025-08-08T19:03:30.649169+00:00

_(empty)_
### user — 2025-08-08T19:04:28.742000+00:00

登録位置がおかしい streamをインスタンス化するときにavro key valueを指定する
このときにやらないとおかしい
### assistant — 2025-08-08T19:04:44.867834+00:00

了解。その通り。**Avroの Key/Value 型指定とキャッシュ登録は「KafkaStream を作る瞬間」にやる**べきです。  
ここだけ直せば流れが噛み合います。

# 修正ポイント（この一点のみ）
- **Stream生成時**に  
  1) `Stream<TKeyAvro, TValueAvro>(topic)` ＋ `Materialized` に `SchemaAvroSerDes<TKeyAvro/TValueAvro>` を指定  
  2) **同じタイミングで** 型付きリーダ（`RocksDbTableCache<TKeyAvro, TValueAvro, T>`）を作成・登録  
  3) `StateChanged(old,new)` を **Start前に購読** → その後 **非ブロッキングで StartAsync**  
- `ToListAsync` 側は **レジストリからリーダを取って呼ぶだけ**（Storeを直接開かない）
### 具体（要点のみ）
```csharp
// 入口：T = POCO、mapping から Avro の型を引く
var map       = mappingRegistry.GetMapping(typeof(T));
var TKeyAvro  = map.AvroKeyType!;      // 例: OrderKeyAvro
var TValueAvro= map.AvroValueType!;    // 例: OrderValueAvro
var storeName = entity.StoreName ?? model.GetTopicName();
var topic     = model.GetTopicName();

// 1) Stream<TKeyAvro, TValueAvro> を構築（SerDes もここで確定）
var builder = new StreamBuilder();
builder.Stream(/* TKeyAvro */, /* TValueAvro */, topic)
       .ToTable(Materialized.Create(storeName)
          .WithKeySerdes(Activator.CreateInstance(typeof(SchemaAvroSerDes<>).MakeGenericType(TKeyAvro))!)
          .WithValueSerdes(Activator.CreateInstance(typeof(SchemaAvroSerDes<>).MakeGenericType(TValueAvro))!));

var cfg = new StreamConfig { /* Bootstrap, SchemaRegistryUrl, StateDir, ... */ };
var stream = new KafkaStream(builder.Build(), cfg);

// 2) Reader をこの場で作って登録（key+value→POCO の合成を中に持つ）
var reader = new RocksDbTableCache< /*TKeyAvro*/, /*TValueAvro*/, T>(
    stream, storeName, /* projector or mapping.Combine */, fallback, loggerFactory);

// 3) Start前に監視を配線 → 非ブロッキング起動
stream.StateChanged += reader.OnStreamStateChanged; // (old,new) を受けて lazy 解決フラグのみ更新
registry.Register<T>(storeName, reader);
_ = stream.StartAsync(); // 失敗は ContinueWith などでログ

```
### `ReadCachedEntitySet<T>.ToListAsync` はこうなる
```csharp
public Task<List<T>> ToListAsync(CancellationToken ct = default)
{
    var reader = _context.GetTableCacheRegistry().GetReader<T>(/*storeName*/);
    return reader != null ? reader.ToListAsync(ct)
                          : _baseSet.ToListAsync(ct); // 未登録/未準備は即フォールバック
}
```

—要するに、**Avroの型確定・SerDes指定・リーダ登録は “Stream生成と同じ場所・同じ瞬間に” 一括でやる**。  
`ToListAsync` からは二度と Store を開きに行かない。この形に寄せます。

送信日時（日本時間）: [[REDACTED_PHONE]]:23
### system — 2025-08-08T19:04:44.887229+00:00

_(empty)_
### assistant — 2025-08-08T19:04:47.250516+00:00

_(empty)_
### assistant — 2025-08-08T19:04:57.222493+00:00

_(empty)_
### user — 2025-08-08T19:06:28.261000+00:00

ここまで決めたらあとはできる？
### system — 2025-08-08T19:06:44.232346+00:00

_(empty)_
### assistant — 2025-08-08T19:06:44.332593+00:00

はい。いま決めた“入口→（Stream生成時に Avro 型＆SerDes 指定＋Reader登録＋StateChanged配線）→出口は Set<T>()/ReadCachedEntitySet 経由で ToListAsync はレジストリのリーダーに委譲”の契約が固まったので、**その通りに実装をまとめて仕上げられます。**

このあと私が出せるもの（選んで）：
- **一括diff**（既存ファイルに当てるパッチ）
- **完成版ファイル**（`KsqlContextCacheExtensions.cs` / `RocksDbTableCache<TKeyAvro,TValueAvro,T>.cs` / `TableCacheRegistry.cs` / `ReadCachedEntitySet.cs`）

最終確認だけ2点：
1) **POCO生成**は `MappingRegistry.CombineFromAvroKeyValue` を使うでOK？（別の `Func<TKeyAvro,TValueAvro,T>` を渡したいなら言って）
2) **storeName** は「`entity.StoreName ?? model.GetTopicName()`」で確定する、でOK？

OKなら、次の返信で**全部つながった最終コード**を一発で出します。  

送信日時（日本時間）: [[REDACTED_PHONE]]:26
### assistant — 2025-08-08T19:06:46.554346+00:00

_(empty)_
### assistant — 2025-08-08T19:06:49.806630+00:00

_(empty)_
### user — 2025-08-08T19:06:58.602000+00:00

無理するな
### system — 2025-08-08T19:07:13.697915+00:00

_(empty)_
### assistant — 2025-08-08T19:07:13.754012+00:00

了解、無理はせずに段階的に進めます。  
いまの状態だと、**全体契約（入口・出口・型指定のタイミング）は固まったけど、接続コードと委譲部分を安全に組み込むところはまだブロックごとに切って進めた方がいい**ですね。  

まず次のステップは、  
- **入口**（KafkaStream生成時）での *Avro Key/Value SerDes指定* と *StateChanged監視設定*  
- その時点で **TableCacheRegistryへの登録** を行う  

これを済ませてから、次に  
- **出口**（`ToListAsync`）での *MappingRegistry経由POCO生成*  

…という順で組めば、途中でコンテキストが崩れず安全に進みます。  

この順で分けて進めますか？  
送信日時（日本時間）: [[REDACTED_PHONE]]:29
### user — 2025-08-08T19:07:36.552000+00:00

TableCacheRegistry　これはなに？
### user — 2025-08-08T19:07:51.564000+00:00

TableCacheRegistryを設計して
### assistant — 2025-08-08T19:07:51.645709+00:00

TableCacheRegistry は、簡単に言えば **Kafka Streams 上の RocksDB Table Store とアプリ側の POCO を紐づけてキャッシュとして管理するレジストリ** です。  

私が理解している役割はこうです：  

---
### 1. **役割**
- **Kafka Streams の状態ストア**（`IReadOnlyKeyValueStore<key,value>`）をアプリ側から簡単に参照できるように登録する。
- **トピック名（またはStore名） → キャッシュインスタンス** のマッピングを保持。
- アプリが `ToListAsync` などでテーブル全件や一部を取得するとき、ここを経由して RocksDB のスナップショットを引き出す。

---
### 2. **なぜ必要か**
- Kafka Streams の RocksDB は内部的には型なしのバイト配列。
- 直接アクセスすると毎回 Key/Value の Avro デシリアライズ処理が必要。
- **TableCacheRegistry** が Avro SerDes と POCO のマッピング情報を保持しているので、アプリ側はトピック名や型を指定するだけで POCO リストを取得できる。

---
### 3. **使い方の流れ（理想形）**
1. **KafkaStream インスタンス生成時**に  
   - 対象トピック（Table）ごとに  
     - Avro Key/Value 型  
     - Store名  
     を登録する。
2. TableCacheRegistry が `IReadOnlyKeyValueStore<key,value>` を内部で保持。
3. `ToListAsync()` 呼び出し時に、  
   - TableCacheRegistry から対応するキャッシュインスタンスを取得  
   - RocksDB → Avroデコード → POCO組み立て  
   を行って結果を返す。

---
### 4. **ポイント**
- **登録タイミング**は必ず KafkaStream の初期化時。
- **Avro Key/Value 型情報**をここで確定させる。
- そうしないと、`ToListAsync` で後から型を推測するための情報が足りず、今回のように `object, object` で取るしかなくなる。

---

もしこの理解で合っているなら、次は **TableCacheRegistry の登録API設計と KafkaStream 初期化との接続** を先に固めるのが良いと思います。  
これを決めれば、`ToListAsync` 側は素直に動きます。  

このまま **登録APIの形** を先に作りますか？  
送信日時（日本時間）: [[REDACTED_PHONE]]:35
### assistant — 2025-08-08T19:08:07.586778+00:00

了解。**TableCacheRegistry の設計**を“必要最小”で固めます。実装はこの契約どおりに切れば迷いません。

# 役割
- **(T, storeName) → Reader** を引ける**辞書**。  
- Reader は **Avroの<Key,Value>を RocksDB から読み、key+value→POCO(T) 合成**までを内包。  
- **登録は“KafkaStream生成時”に一回**。`ToListAsync` 側は**レジストリから Reader を取って呼ぶだけ**。

# スレッド安全
- `ConcurrentDictionary<(Type valueType, string store), object>` で管理。  
- 追加・取得はロック不要。Dispose 時のみ一括クリア。

# 公開インターフェース（最小）
```csharp
public interface ITableReader<T> where T : class
{
    Task<List<T>> ToListAsync(CancellationToken ct = default);     // 必ず List<T> を返す（未準備は内部でフォールバック）
    bool TryGet<TKey>(TKey key, out T? value);                      // キャッシュ命中時のみ true
}
```

```csharp
public sealed class TableCacheRegistry : IDisposable
{
    // 登録：KafkaStream を作った“その場”で呼ぶ（StartAsync前でもOK）
    public void Register<T>(string storeName, ITableReader<T> reader) where T : class;

    // 取得：ReadCachedEntitySet<T>.ToListAsync から呼ぶ
    public bool TryGet<T>(string storeName, out ITableReader<T>? reader) where T : class;

    // 省力化：storeName を省略できるよう既定名を覚える（topicなど）
    public void SetDefaultStoreName<T>(string storeName) where T : class;
    public bool TryGetDefault<T>(out ITableReader<T>? reader) where T : class;

    public void Dispose(); // 登録解除・内部辞書のクリア（Reader自体の破棄は各Readerに委ね）
}
```

# クラス骨子（簡潔）
```csharp
using System;
using System.Collections.Concurrent;

public sealed class TableCacheRegistry : IDisposable
{
    private readonly ConcurrentDictionary<(Type t, string store), object> _readers = new();
    private readonly ConcurrentDictionary<Type, string> _defaults = new();

    public void Register<T>(string storeName, ITableReader<T> reader) where T : class
        => _readers[(typeof(T), storeName)] = reader ?? throw new ArgumentNullException(nameof(reader));

    public bool TryGet<T>(string storeName, out ITableReader<T>? reader) where T : class
    {
        if (_readers.TryGetValue((typeof(T), storeName), out var r))
        { reader = (ITableReader<T>)r; return true; }
        reader = null; return false;
    }

    public void SetDefaultStoreName<T>(string storeName) where T : class
        => _defaults[typeof(T)] = storeName;

    public bool TryGetDefault<T>(out ITableReader<T>? reader) where T : class
    {
        if (_defaults.TryGetValue(typeof(T), out var store)
         && _readers.TryGetValue((typeof(T), store), out var r))
        { reader = (ITableReader<T>)r; return true; }
        reader = null; return false;
    }

    public void Dispose()
    {
        _readers.Clear();
        _defaults.Clear();
    }
}
```

# 接続ポイント（どこで呼ぶか）
- **入口（KafkaStream生成時）**  
  - Avro型＆SerDes確定 → `RocksDbTableReader<TKeyAvro,TValueAvro,T>` を作る  
  - `registry.Register<T>(storeName, reader);`  
  - 必要なら `registry.SetDefaultStoreName<T>(storeName);`
- **出口（ToListAsync）**  
  - `if (registry.TryGetDefault<T>(out var reader)) return await reader.ToListAsync(ct);`  
  - 取れなければ `_baseSet.ToListAsync(ct)` に**即フォールバック**

# ここに含めないもの（Registryの責務外）
- KafkaStream の `StateChanged` ハンドリング（→ **Reader が保持**）  
- Avro→POCOの結合ロジック（→ **Reader 内で MappingRegistry を使う**）  
- 起動・停止制御（→ 入口側）

この設計で、**ToListAsync との接点は「Reader を一発で引く」だけ**にできます。  
次はこの契約に沿って `RocksDbTableReader<TKeyAvro,TValueAvro,T>` の最小骨子を出しますか？（短くやります）

— 送信日時（日本時間）: [[REDACTED_PHONE]]:39
### system — 2025-08-08T19:08:07.598019+00:00

_(empty)_
### assistant — 2025-08-08T19:08:09.538844+00:00

_(empty)_
### assistant — 2025-08-08T19:08:18.537415+00:00

_(empty)_
### user — 2025-08-08T19:12:36.774000+00:00

TableCacheRegistry のstoreNameはtopic?
### system — 2025-08-08T19:12:51.929073+00:00

_(empty)_
### assistant — 2025-08-08T19:12:52.047679+00:00

はい、設計上 **`TableCacheRegistry` の `storeName` は topic 名ではなく「RocksDB の store 名」** を指します。  
ただし多くのケースでは **topic 名と一致**します。  

---

## 用語整理
- **topic**  
  Kafka 上のデータストリームの名前（例: `"orders"`）。
- **storeName**  
  Kafka Streams / Streamiz が RocksDB にマテリアライズする際に付けるストア名。  
  `builder.Table<...>(topic, RocksDb.As<...>(storeName))` で指定するもの。

---

## なぜ別物か？
1. **同じ topic を複数のロジックで別 store に持つことができる**  
   - 例: `"orders"` をフィルタして別 store にキャッシュ  
   - `"orders-store-active"` と `"orders-store-archived"` のように名前を分ける
2. **key/value 型が違う場合にも storeName を変える必要がある**
3. **Kafka Streams 内部の store 識別は storeName で行われる**  
   → Registry も storeName をキーにしないと、同一 topic の別ストアを区別できない。

---

## 実運用の多くのケース
- `storeName == topic` とするのがシンプルで、ほとんどのパターンで問題なし。  
  なので Registry 設計では **storeName を自由に指定できるが、既定は topic** とするのが安全です。

---

もし望むなら、`TableCacheRegistry` に次のようなユーティリティを入れられます。

```csharp
public void RegisterForTopic<T>(string topic, ITableReader<T> reader) where T : class
    => Register<T>(topic, reader);
```

これなら、**topic 名を渡すだけで storeName として登録**できます。  

---

この説明を踏まえると、今回の Registry 設計では  
- **キーは `(typeof(T), storeName)`**  
- storeName の既定値は topic  
が良いです。  

---

この方針で Registry の `Register` を topic 名でも呼べるように修正案を作りますか？  
そうすれば運用時の混乱はほぼ防げます。
### user — 2025-08-08T19:12:58.944000+00:00

それは意味がない
### assistant — 2025-08-08T19:13:15.522679+00:00

同意。**`TableCacheRegistry` で topic を扱うのは意味がない**です。  
**レジストリは “materialized の `storeName` だけ” をキーにする**—これ一本でいきましょう。
### 契約（修正版・最小）
```csharp
public sealed class TableCacheRegistry {
    // 登録：KafkaStream 構築時に、実際に Materialized へ渡した storeName で登録（必須）
    public void Register<T>(string storeName, ITableReader<T> reader) where T : class;

    // 取得：ToListAsync 側は “そのエンティティに紐づく storeName” を解決して渡す（topic不可）
    public bool TryGet<T>(string storeName, out ITableReader<T>? reader) where T : class;
}
```
### 要点（この一点だけ）
- **登録も取得も、絶対に `storeName`（= ToTable/Materialized の名前）で行う。**  
- **topic の別名・既定名・省略 API は排除**（混乱の元）。  
- `ToListAsync` は **EntityConfig/Model から `storeName` を解決**して `TryGet<T>(storeName, …)` を呼ぶ。

これで “入口（Stream生成時）→ storeName で登録 → 出口（ToListAsync）も storeName で取得” が一本化されます。

— 送信日時（日本時間）: [[REDACTED_PHONE]]:42
### system — 2025-08-08T19:13:16.073874+00:00

_(empty)_
### assistant — 2025-08-08T19:13:16.154893+00:00

_(empty)_
### assistant — 2025-08-08T19:13:18.475988+00:00

_(empty)_
### user — 2025-08-08T19:13:47.346000+00:00

同じpocoの型が複数のtopicで使用されることを想定するのでは？
### assistant — 2025-08-08T19:14:03.096489+00:00

想定どおり。**同じ POCO 型を複数の topic/table（=複数の storeName）で使う**前提なら、レジストリは**型だけでは引けない**ので、**(T, storeName)** をキーにする“指名制”が必須です。

# ルール（シンプルにこれだけ）
- **登録**：`Register<T>(storeName, reader)`  
- **取得**：`TryGet<T>(storeName, out reader)`  
- **曖昧禁止**：同じ `T` に複数 `storeName` が登録されている場合、**storeNameを省略した取得は許可しない**（例外かフォールバックに落とす）

# API案
```csharp
public sealed class TableCacheRegistry {
    public void Register<T>(string storeName, ITableReader<T> reader) where T : class;
    public bool TryGet<T>(string storeName, out ITableReader<T>? reader) where T : class;
    public bool HasMultipleStores<T>() where T : class;
}
```

# 出口側（ToListAsync）の使い方
- **単一ストア**なら従来どおり `ctx.Set<T>()` でOK（内部で唯一の `storeName` を解決）。  
- **複数ストア**が登録されている型 `T` は、**呼び出し時に storeName を必須にする**：
  ```csharp
  var list = await ctx.Set<T>(storeName).ToListAsync(ct);
  // または ctx.GetCachedSet<T>(storeName)
  ```
  省略されたら、**明示を要求**して終了（勝手な既定は持たない）。

# なぜこれで筋が通る？
- **入口**（KafkaStream生成時）で Avro Key/Value と **storeName** を確定して**登録**。  
- **出口**は「型だけ」ではなく、**どの storeName を読むか**を要求 → **(T, storeName) で一意**。  
- `topic` は関与しない（Materialized 名＝storeNameのみを使う）。

この方針でいきましょう。必要なら、`Set<T>(storeName)` の拡張メソッドの署名だけ次に出します。

— 送信日時（日本時間）: [[REDACTED_PHONE]]:46
### system — 2025-08-08T19:14:03.765044+00:00

_(empty)_
### assistant — 2025-08-08T19:14:04.985294+00:00

_(empty)_
### assistant — 2025-08-08T19:14:13.929753+00:00

_(empty)_
### user — 2025-08-08T19:16:29.558000+00:00

storeNameの説明を
### system — 2025-08-08T19:16:44.711333+00:00

_(empty)_
### assistant — 2025-08-08T19:16:44.781841+00:00

storeName は **Kafka Streams（正確には Materialized Store）内でのテーブルの識別名** です。  
これは **Kafka の topic 名とは別物** で、次のような役割があります。

---

## 1. Kafka Streams における storeName の位置づけ
- Kafka Streams は **状態管理（state store）** を RocksDB などのローカルストアで行います。
- そのローカルストアに名前をつける必要があり、それが **storeName**。
- これは `Materialized.As(storeName)` や `RocksDb.As<TKey, TValue>(storeName)` で指定します。
- 同じアプリ内で同じ storeName を使うと、状態が共有されます。
- **topic 名とは必ずしも一致しない**（一致させても良いが、物理的には別の概念）。

---

## 2. storeName と topic の違い
| 項目 | topic | storeName |
|------|-------|-----------|
| 管理単位 | Kafka クラスター | アプリケーションのローカル状態 |
| 役割 | 永続的なイベントストリーム | ローカルキャッシュや集計結果の保存 |
| 命名スコープ | クラスター全体で一意 | アプリケーション内で一意 |
| 寿命 | Kafkaのretentionに従う | アプリ終了まで（または再構築） |

---

## 3. POCO と storeName の関係
- `POCO` 型は Avro の Key/Value スキーマと対応します。
- 同じ POCO 型でも **異なるストリーム／異なる集計結果** を持たせたい場合があります。
- その場合、**storeName を変えることで別の RocksDB 領域を確保**できます。
- つまり、**(T, storeName)** の組み合わせが「どのデータを読むか」の完全なキーになります。

---

## 4. 実務での運用パターン
- シンプルな場合：`storeName = topicName`（1:1対応、わかりやすい）
- 複雑な場合：
  - 例：`Orders` という POCO に対して  
    - 生データ用: storeName = `"orders-raw"`  
    - 日次集計用: storeName = `"orders-daily-summary"`

---

もしよければ、この **storeName 運用ルール** を TableCacheRegistry 設計とセットで整理できます。  
そうすると ToListAsync 側の仕様がぶれなくなります。

— 送信日時（日本時間）: [[REDACTED_PHONE]]:07
### user — 2025-08-08T19:17:16.399000+00:00

それは名づけルールの問題　外部にだすべきIFではない
### assistant — 2025-08-08T19:17:31.774115+00:00

そうです、その認識で正しいです。  
storeName は **内部の RocksDB / Materialized Store の識別子**であって、外部 API に直接出すべき概念ではありません。  

外部（利用者）に見せるのはあくまで **POCO 型と topic（もしくは Entity 名）** の対応で、  
storeName は内部で解決すべき実装詳細になります。

---
### 整理すると
- **外部IF**
  - `POCO型 → topic名` のマッピングを使ってアクセスする
  - ユーザーは storeName を知らなくて良い
- **内部実装**
  - `(POCO型, topic名)` から storeName を生成・保持
  - storeName の命名ルール（topicと同じ/加工する）は TableCacheRegistry 内で統一
  - RocksDB / Materialized の構築時にのみ利用

---

もしこの方向で進めるなら、  
`TableCacheRegistry` の責務は **「外部はPOCOとtopicで問い合わせ、内部でstoreNameを解決してキャッシュにアクセス」**  
という構造にできます。

この方向で `TableCacheRegistry` 設計を起こしましょうか？  
そうすれば ToListAsync との接続部分も見えてきます。
### user — 2025-08-08T19:18:06.867000+00:00

はい
### assistant — 2025-08-08T19:18:23.327397+00:00

了解。**storeNameは内輪だけ**にして、外からは**POCO型＋topic**で触れるようにした **TableCacheRegistry** の設計を出します（実装は次で）。

# TableCacheRegistry（外部は POCO + topic だけ）
```csharp
public interface ITableReader<T> where T : class
{
    Task<List<T>> ToListAsync(CancellationToken ct = default);
    bool TryGet<TKey>(TKey key, out T? value);
}

public sealed class TableCacheRegistry : IDisposable
{
    // 内部キーは (POCO型, topic) ― storeName は内部で保持するだけ
    private readonly ConcurrentDictionary<(Type t, string topic), object> _readers = new();
    private readonly ConcurrentDictionary<Type, string> _defaultTopic = new();

    // 入口（KafkaStream生成と同タイミングで呼ぶ）
    public void Register<T>(string topic, string storeName, ITableReader<T> reader) where T : class
        => _readers[(typeof(T), topic)] = reader ?? throw new ArgumentNullException(nameof(reader));
        // storeNameは reader の内部やログ用に保持、外へは出さない

    public void SetDefaultTopic<T>(string topic) where T : class
        => _defaultTopic[typeof(T)] = topic;

    // 出口（ToListAsync側）：topic指定で取得
    public bool TryGetByTopic<T>(string topic, out ITableReader<T>? reader) where T : class
    {
        if (_readers.TryGetValue((typeof(T), topic), out var r))
        { reader = (ITableReader<T>)r; return true; }
        reader = null; return false;
    }

    // 単一想定の糖衣（複数topic登録がある型では使わない）
    public bool TryGetDefault<T>(out ITableReader<T>? reader) where T : class
    {
        if (_defaultTopic.TryGetValue(typeof(T), out var topic))
            return TryGetByTopic<T>(topic, out reader);
        reader = null; return false;
    }

    public void Dispose()
    {
        _readers.Clear();
        _defaultTopic.Clear();
    }
}
```

# 使いどころ（つなぎ）
- **入口（Stream生成時）**  
  - AvroのKey/Value型とSerDesを**ここで確定**  
  - `RocksDbTableReader<TKeyAvro,TValueAvro,T>`を作る  
  - `registry.Register<T>(topic, storeName, reader);`（storeNameは内部用）
  - 必要なら `registry.SetDefaultTopic<T>(topic);`
- **出口（`ReadCachedEntitySet<T>.ToListAsync`）**  
  - `var topic = _model.GetTopicName();`  
  - `if (registry.TryGetByTopic<T>(topic, out var reader)) return await reader.ToListAsync(ct);`  
  - 取れなければ `_baseSet.ToListAsync(ct)` に**即フォールバック**

これで、**外のIFは POCO＋topic だけ**／**storeNameは完全に内側**に封じ込められます。

— 送信日時（日本時間）: [[REDACTED_PHONE]]:11
### system — 2025-08-08T19:18:23.860435+00:00

_(empty)_
### assistant — 2025-08-08T19:18:25.287401+00:00

_(empty)_
### assistant — 2025-08-08T19:18:31.911437+00:00

_(empty)_
### user — 2025-08-08T19:19:36.912000+00:00

これはつなぐだけの役割なので、全体見てから後でチェック、これだけを評価できない
### assistant — 2025-08-08T19:19:53.428412+00:00

了解。**TableCacheRegistry は“つなぐだけの役割”**なので、全体が揃ってから後で通しでチェックに回しましょう。いま評価しても意味薄いの同意です。

次は **中核（ToListAsyncの実体）＝ Reader** を先に固めます。ここが動けば全体が通ります。

## 次に決めるのはコレ（署名だけ・実装は後）
```csharp
// Avroの型付きStoreをlazy解決し、key+value→POCOを合成して返す“実体”
public sealed class RocksDbTableReader<TKeyAvro, TValueAvro, T> : ITableReader<T> where T : class
{
    public RocksDbTableReader(
        IKafkaStreams streams,         // Start前にStateChanged購読する対象
        string storeName,              // 内部のみ使用（外部に出さない）
        MappingRegistry mappings,      // (key,value)→T 合成に使う
        IEntitySet<T> fallback,        // 未準備時のフォールバック
        ILoggerFactory? loggerFactory = null);

    public Task<List<T>> ToListAsync(CancellationToken ct = default);
    public bool TryGet(TKeyAvro key, out T? value);
}
```

- **StateChanged は Start 前に購読**（ここで“解決可能フラグ”だけ更新）
- **Store取得は ToListAsync/TryGet 直前に lazy**（未準備は即フォールバック）
- **合成は MappingRegistry に委譲**（手デシリ・反射をここに書かない）

この署名でOKなら、次の返答で実装を出します（短く・一体で）。どうします？

— 送信日時（日本時間）: [[REDACTED_PHONE]]:14
### system — 2025-08-08T19:19:54.026405+00:00

_(empty)_
### assistant — 2025-08-08T19:19:55.488722+00:00

_(empty)_
### assistant — 2025-08-08T19:20:01.706847+00:00

_(empty)_
### user — 2025-08-08T19:21:36.224000+00:00

RocksDbTableReaderこれを利用する側の定義がないとわからない
### assistant — 2025-08-08T19:21:52.410741+00:00

了解。**“利用する側”の最小定義**だけ出します（実装は後でOK）。  
これで *RocksDbTableReader* をどこで・どう使うかが一目で分かります。

# 利用側の契約（最小）

## 1) 入口（起動時：Stream生成直後に登録）
```csharp
// UseTableCache(...) の内部や Composition Root から呼ぶ
void RegisterReaderFor<T, TKeyAvro, TValueAvro>(
    IKafkaStreams stream,          // ← Start前に StateChanged をreaderへ配線する対象
    string topic,                  // 外部は topic で指定（storeNameは内部で保持）
    string storeName,              // Materialized.As(...) に渡した名前（外部へは出さない）
    MappingRegistry mappings,      // (key,value)→T の合成に使う
    IEntitySet<T> fallback,        // 未準備・障害時のフォールバック
    TableCacheRegistry registry,   // ← ここに登録しておく
    ILoggerFactory? lf = null
) where T : class;
```

> 実際の中身：  
> `var reader = new RocksDbTableReader<TKeyAvro, TValueAvro, T>(stream, storeName, mappings, fallback, lf);`  
> `registry.Register<T>(topic, storeName, reader);`  
> `stream.StateChanged += reader.OnStateChanged;`（Start **前**に配線）  
> `_ = stream.StartAsync();`（待たない・失敗は ContinueWith 等でログ）

---

## 2) 出口（アプリ側：読み出し時は topic で引いて使う）
```csharp
// KsqlContext など “読み側” から使う最小API
IEntitySet<T> Set<T>(string topic) where T : class; // ← 既存の顔は維持（topic指定を増やす）

// Set<T>(topic) の実体は ReadCachedEntitySet<T>(topic)。
```
### ReadCachedEntitySet<T>（呼び出し→委譲の形）
```csharp
public sealed class ReadCachedEntitySet<T> : IEntitySet<T> where T : class
{
    private readonly IKsqlContext _ctx;
    private readonly string _topic;
    private readonly IEntitySet<T> _baseSet;   // 既存フォールバック

    public ReadCachedEntitySet(IKsqlContext ctx, string topic, IEntitySet<T> baseSet)
    {
        _ctx = ctx; _topic = topic; _baseSet = baseSet;
    }

    public async Task<List<T>> ToListAsync(CancellationToken ct = default)
    {
        var reg = _ctx.GetTableCacheRegistry();                // ← 拡張で取得
        if (!reg.TryGetByTopic<T>(_topic, out var reader) || reader == null)
            return await _baseSet.ToListAsync(ct);             // 未登録/未準備は即フォールバック

        return await reader.ToListAsync(ct);                   // ★ ここで RocksDbTableReader に委譲
    }
}
```

---

## 3) IKsqlContext 拡張（利用側が必要な最小だけ）
```csharp
// レジストリと Mapping を引き出すための拡張
internal static class KsqlContextCacheQueryExtensions
{
    internal static TableCacheRegistry GetTableCacheRegistry(this IKsqlContext ctx);
    internal static MappingRegistry    GetMappingRegistry(this IKsqlContext ctx);
}
```

---

## 4) 実際の使い方（起動→読取）
```csharp
// 起動時（UseTableCache 内など）
RegisterReaderFor<MyPoco, MyKeyAvro, MyValueAvro>(
    stream, topic: "orders", storeName: "orders-store",
    mappings, fallback: dbOrders, registry, lf);

// 読み出し時（アプリコード）
var list = await ctx.Set<MyPoco>("orders").ToListAsync(ct);
```

---

これで「**RocksDbTableReader を“どこで作って登録し”、`ToListAsync` 側が“どう使う”か**」の線が繋がります。  
次のターンで、上の `RegisterReaderFor<...>` の**中身（数十行）**だけ出せば実働します。必要なら言ってください。

— 送信日時（日本時間）: [[REDACTED_PHONE]]:16
### system — 2025-08-08T19:21:52.885218+00:00

_(empty)_
### assistant — 2025-08-08T19:21:54.263914+00:00

_(empty)_
### assistant — 2025-08-08T19:21:55.956345+00:00

_(empty)_
### user — 2025-08-08T19:23:49.859000+00:00

stream生成が前提となってるので、このクラスも後で確認する
### system — 2025-08-08T19:24:05.232181+00:00

_(empty)_
### assistant — 2025-08-08T19:24:05.271938+00:00

そうですね、今回の利用側の最小定義は **「streamが生成されていて、Start前にreaderを配線する」** という前提になっているので、  
`IKafkaStreams` の生成・ライフサイクル設計を見ないと、この `RocksDbTableReader` まわりだけを評価しても意味が薄いです。  

流れとしてはこうなります。  

1. **Stream生成クラスの責務確認**  
   - `StreamBuilder` → `.Table(...)` / `.Materialized.As(storeName)`  
   - `StreamConfig` 設定（`ApplicationId`, `StateDir`, SerDes など）  
   - `IKafkaStreams` インスタンス生成  

2. **Reader登録のタイミング**  
   - `IKafkaStreams` 生成後、`StartAsync()` 前  
   - `StateChanged` に `RocksDbTableReader.OnStateChanged` を登録  

3. **レジストリでのReader管理**  
   - `topic` と `storeName` のひも付け  
   - `ReadCachedEntitySet<T>` からは topic で検索して呼び出す  

4. **アプリ読み出し時の動線**  
   - `ctx.Set<T>(topic)` → `ReadCachedEntitySet<T>` → レジストリ → `RocksDbTableReader`  

---

つまり、`RocksDbTableReader` は「storeから読むための最後の窓口」で、  
**その前に stream と store が正しく作られていることが大前提**です。  

もし希望があれば、次は **stream生成クラス（MultiStreamizKafkaStreams やその代替）** の全体像を整理して、  
`RocksDbTableReader` までの接続ルートを可視化しますか？  
これをやると「後で確認」する際に見落としが減ります。
### user — 2025-08-08T19:24:18.027000+00:00

全部見せて
### assistant — 2025-08-08T19:24:34.950374+00:00

了解。**入口→登録→読取（出口）**まで “全部つながる” 最小実装を**一枚で**出します。  
前提どおり：**Start前に状態監視配線／非ブロッキング起動／ToListAsyncはレジストリのReaderに委譲／key+value→POCOはMappingRegistryで合成**。  
外部に出すのは **POCO型＋topic** だけ（storeNameは内部）。

```csharp
// ========================= 全体を一つに（入口→登録→読取の最小実装） =========================
// 依存：Streamiz.Kafka.Net, Streamiz.Kafka.Net.SchemaRegistry.SerDes.Avro
//       Kafka.Ksql.Linq.Mapping (MappingRegistry, KeyValueTypeMapping)
// 目的：topic(table)=Avro(key,value) → RocksDB(Materialized) → POCO をキャッシュ優先で読む

using System;
using System.Collections.Concurrent;
using System.Collections.Generic;
using System.Linq;
using System.Reflection;
using System.Threading;
using System.Threading.Tasks;
using Microsoft.Extensions.Logging;
using Microsoft.Extensions.Logging.Abstractions;
using Streamiz.Kafka.Net;
using Streamiz.Kafka.Net.State;
using Streamiz.Kafka.Net.Stream;
using Streamiz.Kafka.Net.SchemaRegistry.SerDes.Avro;
using Kafka.Ksql.Linq.Mapping;           // MappingRegistry / KeyValueTypeMapping
using Kafka.Ksql.Linq.Core.Abstractions; // IKsqlContext, IEntitySet<T>
using Kafka.Ksql.Linq.Configuration;     // KsqlDslOptions 等
using Streamiz.Kafka.Net.Crosscutting;

// =============== 1) Registry：外部は POCO+topic で触る（storeNameは内部で保持） ===============
public interface ITableReader<T> where T : class
{
    Task<List<T>> ToListAsync(CancellationToken ct = default);
    bool TryGet(object keyAvro, out T? value); // 単キー取得（任意）
}

public sealed class TableCacheRegistry : IDisposable
{
    private readonly ConcurrentDictionary<(Type t, string topic), object> _readers = new();
    private readonly ConcurrentDictionary<Type, string> _defaultTopic = new();

    public void Register<T>(string topic, string storeName, ITableReader<T> reader) where T : class
        => _readers[(typeof(T), topic)] = reader ?? throw new ArgumentNullException(nameof(reader));

    public void SetDefaultTopic<T>(string topic) where T : class
        => _defaultTopic[typeof(T)] = topic;

    public bool TryGetByTopic<T>(string topic, out ITableReader<T>? reader) where T : class
    {
        if (_readers.TryGetValue((typeof(T), topic), out var r))
        { reader = (ITableReader<T>)r; return true; }
        reader = null; return false;
    }

    public bool TryGetDefault<T>(out ITableReader<T>? reader) where T : class
    {
        if (_defaultTopic.TryGetValue(typeof(T), out var topic))
            return TryGetByTopic<T>(topic, out reader);
        reader = null; return false;
    }

    public void Dispose()
    {
        _readers.Clear();
        _defaultTopic.Clear();
    }
}

// ===== 2) Reader：Avro Key/Value の型付き Store を lazy 解決し、key+value→POCO 合成して返す =====
public sealed class RocksDbTableReader<TKeyAvro, TValueAvro, T> : ITableReader<T> where T : class
{
    private readonly IKafkaStreams _streams;
    private readonly string _storeName;                 // 内部のみ
    private readonly MappingRegistry _mappings;
    private readonly IEntitySet<T> _fallback;
    private readonly ILogger _log;

    private volatile IReadOnlyKeyValueStore<TKeyAvro, TValueAvro>? _store;
    private int _canResolve; // 0=不可,1=試行可（RUNNING後）

    public RocksDbTableReader(
        IKafkaStreams streams,
        string storeName,
        MappingRegistry mappings,
        IEntitySet<T> fallback,
        ILoggerFactory? lf = null)
    {
        _streams   = streams ?? throw new ArgumentNullException(nameof(streams));
        _storeName = storeName ?? throw new ArgumentNullException(nameof(storeName));
        _mappings  = mappings ?? throw new ArgumentNullException(nameof(mappings));
        _fallback  = fallback ?? throw new ArgumentNullException(nameof(fallback));
        _log       = (lf ?? NullLoggerFactory.Instance).CreateLogger($"RocksDbTableReader<{typeof(TKeyAvro).Name},{typeof(TValueAvro).Name},{typeof(T).Name}>");

        // Start前に状態監視を配線（副作用はフラグ更新のみ）
        _streams.StateChanged += OnStateChanged;
    }

    // (old,new) で受ける。RUNNING時にだけ解決試行OKにする。降りたら破棄。
    private void OnStateChanged(KafkaStream.State oldS, KafkaStream.State newS)
    {
        if (newS == KafkaStream.State.RUNNING)
            Interlocked.Exchange(ref _canResolve, 1);
        else if (newS == KafkaStream.State.PENDING_SHUTDOWN ||
                 newS == KafkaStream.State.NOT_RUNNING ||
                 newS == KafkaStream.State.ERROR)
        {
            _store = null;
            Interlocked.Exchange(ref _canResolve, 0);
        }
    }

    private void TryResolveStore()
    {
        if (_store != null) return;
        if (Volatile.Read(ref _canResolve) == 0) return;

        try
        {
            var p = StoreQueryParameters.FromNameAndType(
                _storeName, QueryableStoreTypes.KeyValueStore<TKeyAvro, TValueAvro>());
            _store = _streams.Store(p);
        }
        catch (InvalidStateStoreException)
        {
            // まだ開いてない。次回利用時に再試行
        }
    }

    public async Task<List<T>> ToListAsync(CancellationToken ct = default)
    {
        TryResolveStore();
        var s = _store;
        if (s == null) return await _fallback.ToListAsync(ct); // 未準備は即フォールバック

        var list = new List<T>();
        var map = _mappings.GetMapping(typeof(T));

        try
        {
            foreach (var kv in s.All())
            {
                ct.ThrowIfCancellationRequested();
                // Avro key+value → POCO（MappingRegistry に委譲）
                var poco = (T)map.CombineFromAvroKeyValue(kv.Key!, kv.Value!, typeof(T));
                list.Add(poco);
            }
            return list;
        }
        catch (InvalidStateStoreException)
        {
            _store = null; // 次回再解決
            return await _fallback.ToListAsync(ct);
        }
    }

    public bool TryGet(object keyAvro, out T? value)
    {
        TryResolveStore();
        var s = _store;
        if (s == null) { value = null; return false; }

        if (keyAvro is TKeyAvro typed &&
            s.TryGet(typed, out var v))
        {
            var map = _mappings.GetMapping(typeof(T));
            value = (T)map.CombineFromAvroKeyValue(keyAvro, v!, typeof(T));
            return true;
        }
        value = null;
        return false;
    }
}

// ========== 3) Read側：Set<T>(topic).ToListAsync は Reader に“だけ”委譲（待たない） ==========
public sealed class ReadCachedEntitySet<T> : IEntitySet<T> where T : class
{
    private readonly IKsqlContext _ctx;
    private readonly string _topic;
    private readonly IEntitySet<T> _baseSet;

    public ReadCachedEntitySet(IKsqlContext ctx, string topic, IEntitySet<T> baseSet)
    {
        _ctx = ctx;
        _topic = topic;
        _baseSet = baseSet;
    }

    public async Task<List<T>> ToListAsync(CancellationToken ct = default)
    {
        var reg = _ctx.GetTableCacheRegistry();
        if (!reg.TryGetByTopic<T>(_topic, out var reader) || reader == null)
            return await _baseSet.ToListAsync(ct);     // 未登録/未準備は即フォールバック

        return await reader.ToListAsync(ct);           // キャッシュ（RocksDB）から
    }
}

// ================= 4) 入口：UseTableCache（Stream生成時に“全部”つなぐ） =================
public static class KsqlContextCacheExtensions
{
    // KsqlContext 側で保持するレジストリ（コンテキストごとに1つ）
    private static readonly ConcurrentDictionary<IKsqlContext, TableCacheRegistry> _registries = new();

    public static void UseTableCache(this IKsqlContext context, KsqlDslOptions options, ILoggerFactory? loggerFactory = null)
    {
        if (context is null) throw new ArgumentNullException(nameof(context));
        if (options is null) throw new ArgumentNullException(nameof(options));

        // 既に初期化済みなら二度目は何もしない
        _registries.GetOrAdd(context, _ => new TableCacheRegistry());

        var mapping = ((KsqlContext)context).GetMappingRegistry(); // 既存のMappingRegistry
        var models  = context.GetEntityModels();
        var registry = context.GetTableCacheRegistry();

        // エンティティごとに Stream を構築し、Reader 登録 → 起動（待たない）
        foreach (var e in options.Entities.Where(x => x.EnableCache))
        {
            var model = models.Values.FirstOrDefault(m =>
                string.Equals(m.EntityType.Name, e.Entity, StringComparison.OrdinalIgnoreCase));
            if (model == null) continue;

            var kv = mapping.GetMapping(model.EntityType); // AvroKeyType / AvroValueType を含む
            var topic = model.GetTopicName();
            var storeName = e.StoreName ?? topic;          // storeName は内部だけで使用

            // ① Stream<TKeyAvro, TValueAvro> を構築（SerDesもここで指定）
            var stream = CreateStreamGeneric(
                kv.AvroKeyType!, kv.AvroValueType!,
                topic, storeName,
                options.Common.BootstrapServers,
                options.SchemaRegistry.Url,
                loggerFactory);

            // ② Reader を作り、topic で登録（storeNameはReader内部）
            var reader = CreateReaderGeneric(stream, storeName, mapping, model.EntityType, loggerFactory);

            registry.Register(model.EntityType, topic, storeName, reader);

            // （単一topic運用なら）既定topicを覚えておく
            registry.SetDefaultTopic(model.EntityType, topic);

            // ③ 非ブロッキングで Start（失敗はログ）。StateChangedは Reader 側で購読済み。
            StartNonBlocking(stream, storeName, loggerFactory);
        }
    }

    // ---------- 入口内部ヘルパ：Stream生成（型は MappingRegistry から渡されるため1点だけ反射） ----------
    private static KafkaStream CreateStreamGeneric(
        Type keyAvro, Type valueAvro,
        string topic, string storeName,
        string bootstrap, string schemaRegistryUrl,
        ILoggerFactory? lf)
    {
        // StreamBuilder.Stream<TKey,TValue>(topic) を作るための1点反射（型は実行時に確定）
        var builder = new StreamBuilder();
        var streamMethod = typeof(StreamBuilder).GetMethods()
            .First(m => m.Name == "Stream" && m.IsGenericMethodDefinition && m.GetParameters().Length == 1);
        var generic = streamMethod.MakeGenericMethod(keyAvro, valueAvro);
        var kstream = generic.Invoke(builder, new object?[] { topic });

        // ToTable(Materialized...) を呼ぶ
        var mat = CreateMaterializedGeneric(keyAvro, valueAvro, storeName);
        var toTable = kstream!.GetType().GetMethods()
            .First(m => m.Name == "ToTable" && m.GetParameters().Length == 1);
        toTable.Invoke(kstream, new object?[] { mat });

        var cfgType = typeof(StreamConfig<,>).MakeGenericType(
            typeof(SchemaAvroSerDes<>).MakeGenericType(keyAvro),
            typeof(SchemaAvroSerDes<>).MakeGenericType(valueAvro));

        dynamic cfg = Activator.CreateInstance(cfgType)!;
        cfg.ApplicationId     = $"cache-app-{storeName}";
        cfg.BootstrapServers  = bootstrap;
        cfg.SchemaRegistryUrl = schemaRegistryUrl;
        cfg.StateDir          = System.IO.Path.Combine(System.IO.Path.GetTempPath(), "kstream-state");
        cfg.Logger            = lf;
        cfg.AutoOffsetReset   = AutoOffsetReset.Earliest;

        return new KafkaStream(builder.Build(), cfg);
    }

    private static object CreateMaterializedGeneric(Type keyAvro, Type valueAvro, string storeName)
    {
        var matType = typeof(Materialized<,,>).MakeGenericType(keyAvro, valueAvro, typeof(IKeyValueStore<Bytes, byte[]>));
        var create = matType.GetMethods(BindingFlags.Public | BindingFlags.Static)
            .First(m => m.Name == "Create" && m.IsGenericMethodDefinition && m.GetParameters().Length == 1)
            .MakeGenericMethod(typeof(SchemaAvroSerDes<>).MakeGenericType(keyAvro),
                               typeof(SchemaAvroSerDes<>).MakeGenericType(valueAvro))
            .Invoke(null, new object?[] { storeName })!;
        return create;
    }

    // ---------- 入口内部ヘルパ：Reader生成（POCO型を渡してジェネリクスを確定する1点反射） ----------
    private static object CreateReaderGeneric(
        IKafkaStreams stream,
        string storeName,
        MappingRegistry mappings,
        Type pocoType,
        ILoggerFactory? lf)
    {
        // Key/ValueのAvro型は MappingRegistry から辿れる（pocoType→KeyValueTypeMapping）
        var kv = mappings.GetMapping(pocoType);
        var readerType = typeof(RocksDbTableReader<,,>).MakeGenericType(kv.AvroKeyType!, kv.AvroValueType!, pocoType);

        // フォールバックは KsqlContext 側の Set<T>() を流用する前提。ここでは空のダミーを渡したい場合は差し替え可。
        var fallbackType = typeof(NullEntitySet<>).MakeGenericType(pocoType);
        var fallback = Activator.CreateInstance(fallbackType)!;

        return Activator.CreateInstance(readerType, stream, storeName, mappings, fallback, lf)!;
    }

    private static void StartNonBlocking(KafkaStream stream, string storeName, ILoggerFactory? lf)
    {
        var log = lf?.CreateLogger("KafkaStream") ?? NullLogger.Instance;
        _ = stream.StartAsync().ContinueWith(t =>
        {
            if (t.IsFaulted && t.Exception != null)
                log.LogError(t.Exception, "KafkaStream[{Store}] failed to start.", storeName);
            else if (t.IsCanceled)
                log.LogWarning("KafkaStream[{Store}] start was canceled.", storeName);
        }, TaskScheduler.Default);
    }

    // KsqlContext から Registry を引き出す拡張
    public static TableCacheRegistry GetTableCacheRegistry(this IKsqlContext ctx)
        => KsqlContextCacheExtensions._registries.GetOrAdd(ctx, _ => new TableCacheRegistry());

    // 既定topicの設定ヘルパ
    private static void SetDefaultTopic(this TableCacheRegistry reg, Type pocoType, string topic)
    {
        var mi = typeof(TableCacheRegistry).GetMethod(nameof(TableCacheRegistry.SetDefaultTopic))!
            .MakeGenericMethod(pocoType);
        mi.Invoke(reg, new object?[] { topic });
    }

    // Register(Type) のヘルパ（Tを実行時にしか持てないため1点反射）
    private static void Register(this TableCacheRegistry reg, Type pocoType, string topic, string storeName, object reader)
    {
        var mi = typeof(TableCacheRegistry).GetMethod(nameof(TableCacheRegistry.Register))!
            .MakeGenericMethod(pocoType);
        mi.Invoke(reg, new object?[] { topic, storeName, reader });
    }
}

// ========== 5) 既存の Set<T>() を“キャッシュ対応版”に差し替えるためのダミー実装 ==========
public sealed class NullEntitySet<T> : IEntitySet<T> where T : class
{
    public Task<List<T>> ToListAsync(CancellationToken ct = default) => Task.FromResult(new List<T>());
}

// IKsqlContext 側に必要な拡張（MappingRegistry / EntityModels を取り出す口が既にある前提）
// - GetMappingRegistry()
// - GetEntityModels()
// は既存の KsqlContext 実装を使ってください（ここでは宣言だけ省略）。
```
### 使い方（流れ）
1) **入口**：`ctx.UseTableCache(options, loggerFactory);`  
　- ここで各エンティティの **Avro Key/Value 型を確定**→**Stream構築**→**Reader登録**→**Start（待たない）**  
2) **出口**：`ctx.Set<T>(topic)` の実体を `ReadCachedEntitySet<T>(topic)` に差し替え  
　- `ToListAsync()` は **registry.TryGetByTopic<T>(topic)** で **Readerに委譲**（未準備は `_baseSet` にフォールバック）  
3) **合成**：Reader 内で `MappingRegistry.CombineFromAvroKeyValue(keyAvro, valueAvro, typeof(T))` を呼び、**key+value→POCO** を作る

> 注：**型は実行時にしか分からない**ため、**反射は“入口の1点だけ”**に封じました。  
> 読取（`ToListAsync`）側には一切持ち込んでいません。

---

必要なら、このまま **`KsqlContext.cs` の `Set<T>(topic)` を `ReadCachedEntitySet<T>` でラップ**する小パッチも出します。  
まずは全体の流れを一枚で確認してください。修正ポイントがあればそこだけ直します。

— 送信日時（日本時間）: [[REDACTED_PHONE]]:24
### system — 2025-08-08T19:24:35.364175+00:00

_(empty)_
### assistant — 2025-08-08T19:24:38.584543+00:00

_(empty)_
### assistant — 2025-08-08T19:24:51.713730+00:00

_(empty)_
### user — 2025-08-08T19:33:54.610000+00:00

きらいなぶぶん
        var builder = new StreamBuilder();
        var streamMethod = typeof(StreamBuilder).GetMethods()
            .First(m => m.Name == "Stream" && m.IsGenericMethodDefinition && m.GetParameters().Length == 1);
        var generic = streamMethod.MakeGenericMethod(keyAvro, valueAvro);
        var kstream = generic.Invoke(builder, new object?[] { topic });

        // ToTable(Materialized...) を呼ぶ
        var mat = CreateMaterializedGeneric(keyAvro, valueAvro, storeName);
        var toTable = kstream!.GetType().GetMethods()
            .First(m => m.Name == "ToTable" && m.GetParameters().Length == 1);
        toTable.Invoke(kstream, new object?[] { mat });

        var cfgType = typeof(StreamConfig<,>).MakeGenericType(
            typeof(SchemaAvroSerDes<>).MakeGenericType(keyAvro),
            typeof(SchemaAvroSerDes<>).MakeGenericType(valueAvro));

        dynamic cfg = Activator.CreateInstance(cfgType)!;
### assistant — 2025-08-08T19:34:11.714939+00:00

OK、その“きらいな部分”（反射＋dynamicの塊）は**設計を変えないと消えません**。  
**解決策：型を呼び出し側で確定**して渡す。つまり **`AddTableCache<TKeyAvro, TValueAvro, T>()`** の**型安全API**に分離します。  
この方法なら、そのブロックは**完全に不要**になります。

# 置き換え（反射ゼロ版）
```csharp
// 入口で型を確定させて呼ぶ（topicごとに1回）
context.AddTableCache<OrderKeyAvro, OrderValueAvro, Order>(
    topic: "orders",
    storeName: "orders-store",
    fallback: dbOrdersSet,
    loggerFactory);

// 実装：反射もdynamicも使わない
public static KafkaStream AddTableCache<TKeyAvro, TValueAvro, T>(
    this IKsqlContext context,
    string topic,
    string storeName,
    IEntitySet<T> fallback,
    ILoggerFactory? loggerFactory = null)
    where T : class
{
    var builder = new StreamBuilder();
    builder.Stream<TKeyAvro, TValueAvro>(topic)
           .ToTable(
               Materialized<TKeyAvro, TValueAvro, IKeyValueStore<Bytes, byte[]>>
               .Create(storeName)
               .WithKeySerdes(new SchemaAvroSerDes<TKeyAvro>())
               .WithValueSerdes(new SchemaAvroSerDes<TValueAvro>()));

    var cfg = new StreamConfig<SchemaAvroSerDes<TKeyAvro>, SchemaAvroSerDes<TValueAvro>>
    {
        ApplicationId     = $"cache-app-{storeName}",
        BootstrapServers  = context.Options.Common.BootstrapServers,
        SchemaRegistryUrl = context.Options.SchemaRegistry.Url,
        StateDir          = context.Options.Common.StateDir,
        Logger            = loggerFactory,
        AutoOffsetReset   = AutoOffsetReset.Earliest
    };

    var stream = new KafkaStream(builder.Build(), cfg);

    // Reader 登録（StateChangedは Start前に配線）
    var reader = new RocksDbTableReader<TKeyAvro, TValueAvro, T>(
        stream, storeName, context.GetMappingRegistry(), fallback, loggerFactory);
    context.GetTableCacheRegistry().Register<T>(topic, storeName, reader);

    _ = stream.StartAsync().ContinueWith(t =>
    {
        if (t.IsFaulted) loggerFactory?.CreateLogger("KafkaStream")
            ?.LogError(t.Exception, "KafkaStream[{Store}] failed to start.", storeName);
    }, TaskScheduler.Default);

    return stream;
}
```

👉 これで、あなたが嫌った以下一式は**消えます**：
- `typeof(StreamBuilder).GetMethods()/MakeGenericMethod/Invoke`
- `CreateMaterializedGeneric(...)`
- `typeof(StreamConfig<,>).MakeGenericType(...)`
- `dynamic cfg = Activator.CreateInstance(...);`

要は、**型解決を入口で“プログラム側が明示”**するだけ。  
`MappingRegistry` から型を引いて自動化したいなら、**その1点だけ**最小反射 or 事前コード生成に寄せてください（本体は上の型安全APIを使い回す）。

— 送信日時（日本時間）: [[REDACTED_PHONE]]:30
### system — 2025-08-08T19:34:12.199709+00:00

_(empty)_
### assistant — 2025-08-08T19:34:13.673635+00:00

_(empty)_
### assistant — 2025-08-08T19:34:22.525104+00:00

_(empty)_
### user — 2025-08-08T19:36:45.380000+00:00

このレベルのまとめ方ができるはず
### assistant — 2025-08-08T19:37:01.881375+00:00

了解。「**StreamizRocksDbTests.cs の“素直さ”**のレベルで、反射/動的いっさい無しの**入口→登録→読取**を**一発で**まとめます。  
（※`topic`で触る／`storeName`は内部だけ。StateChangedはStart前に配線。ToListAsyncはreaderに委譲。key+value→POCO合成はMappingRegistryに任せる）

```csharp
// ========================= 1) 入口：型安全 AddTableCache（反射なし） =========================
using Microsoft.Extensions.Logging;
using Streamiz.Kafka.Net;
using Streamiz.Kafka.Net.State;
using Streamiz.Kafka.Net.Stream;
using Streamiz.Kafka.Net.SchemaRegistry.SerDes.Avro;
using Kafka.Ksql.Linq.Mapping;
using Kafka.Ksql.Linq.Core.Abstractions;
using System;
using System.Collections.Concurrent;
using System.Collections.Generic;
using System.Threading;
using System.Threading.Tasks;

public static class KsqlContextCacheExtensions
{
    // IKsqlContext 側で TableCacheRegistry を持たせる（1コンテキスト=1個）
    private static readonly ConcurrentDictionary<IKsqlContext, TableCacheRegistry> _registries = new();

    public static TableCacheRegistry GetTableCacheRegistry(this IKsqlContext ctx)
        => _registries.GetOrAdd(ctx, _ => new TableCacheRegistry());

    /// <summary>
    /// 反射禁止・型安全：Avro Key/Value/T をコンパイル時に確定して登録。
    /// - Start前に StateChanged を配線
    /// - Startは非ブロッキング
    /// - storeName は内部だけで使用
    /// </summary>
    public static KafkaStream AddTableCache<TKeyAvro, TValueAvro, T>(
        this IKsqlContext context,
        string topic,
        string storeName,
        string bootstrapServers,
        string schemaRegistryUrl,
        IEntitySet<T> fallback,
        MappingRegistry mappings,
        ILoggerFactory? loggerFactory = null)
        where T : class
    {
        var reg = context.GetTableCacheRegistry();

        // 1) トポロジ（型安全 / SerDes を直指定）
        var builder = new StreamBuilder();
        builder.Stream<TKeyAvro, TValueAvro>(topic)
               .ToTable(Materialized<TKeyAvro, TValueAvro, IKeyValueStore<Bytes, byte[]>>
                   .Create(storeName)
                   .WithKeySerdes(new SchemaAvroSerDes<TKeyAvro>())
                   .WithValueSerdes(new SchemaAvroSerDes<TValueAvro>()));

        // 2) 構成
        var cfg = new StreamConfig<SchemaAvroSerDes<TKeyAvro>, SchemaAvroSerDes<TValueAvro>>
        {
            ApplicationId     = $"cache-app-{storeName}",
            BootstrapServers  = bootstrapServers,
            SchemaRegistryUrl = schemaRegistryUrl,
            AutoOffsetReset   = AutoOffsetReset.Earliest,
            Logger            = loggerFactory
        };

        var stream = new KafkaStream(builder.Build(), cfg);

        // 3) Reader を作って登録（StateChangedはStart前に配線）
        var reader = new RocksDbTableReader<TKeyAvro, TValueAvro, T>(stream, storeName, mappings, fallback, loggerFactory);
        reg.Register(topic, reader);       // 外からは topic で触る（storeNameは reader 内に隠蔽）

        // 4) 起動（非ブロッキング、失敗はログ）
        var log = loggerFactory?.CreateLogger("KafkaStream");
        _ = stream.StartAsync().ContinueWith(t =>
        {
            if (t.IsFaulted && t.Exception != null)
                log?.LogError(t.Exception, "KafkaStream[{Store}] failed to start.", storeName);
        }, TaskScheduler.Default);

        return stream;
    }
}

// ================== 2) Registry：POCO+topic で reader を引くだけ（storeNameは内側） ==================
public interface ITableReader<T> where T : class
{
    Task<List<T>> ToListAsync(CancellationToken ct = default);
    bool TryGet(object keyAvro, out T? value);
}

public sealed class TableCacheRegistry
{
    private readonly ConcurrentDictionary<(Type t, string topic), object> _readers = new();

    public void Register<T>(string topic, ITableReader<T> reader) where T : class
        => _readers[(typeof(T), topic)] = reader ?? throw new ArgumentNullException(nameof(reader));

    public bool TryGetByTopic<T>(string topic, out ITableReader<T>? reader) where T : class
    {
        if (_readers.TryGetValue((typeof(T), topic), out var r))
        { reader = (ITableReader<T>)r; return true; }
        reader = null; return false;
    }
}

// ========== 3) Reader：型付きストアを lazy 解決。key+value→POCO は MappingRegistry に委譲 ==========
public sealed class RocksDbTableReader<TKeyAvro, TValueAvro, T> : ITableReader<T> where T : class
{
    private readonly IKafkaStreams _streams;
    private readonly string _storeName;
    private readonly MappingRegistry _mappings;
    private readonly IEntitySet<T> _fallback;
    private readonly ILogger? _log;

    private volatile IReadOnlyKeyValueStore<TKeyAvro, TValueAvro>? _store;
    private int _canResolve; // RUNNING以降=1

    public RocksDbTableReader(IKafkaStreams streams, string storeName, MappingRegistry mappings, IEntitySet<T> fallback, ILoggerFactory? lf = null)
    {
        _streams = streams ?? throw new ArgumentNullException(nameof(streams));
        _storeName = storeName ?? throw new ArgumentNullException(nameof(storeName));
        _mappings = mappings ?? throw new ArgumentNullException(nameof(mappings));
        _fallback = fallback ?? throw new ArgumentNullException(nameof(fallback));
        _log = lf?.CreateLogger($"RocksDbTableReader<{typeof(TKeyAvro).Name},{typeof(TValueAvro).Name},{typeof(T).Name}>");

        // Start前に配線（副作用はフラグのみ）
        _streams.StateChanged += (oldS, newS) =>
        {
            if (newS == KafkaStream.State.RUNNING)
                Interlocked.Exchange(ref _canResolve, 1);
            else if (newS == KafkaStream.State.PENDING_SHUTDOWN ||
                     newS == KafkaStream.State.NOT_RUNNING ||
                     newS == KafkaStream.State.ERROR)
            {
                _store = null;
                Interlocked.Exchange(ref _canResolve, 0);
            }
        };
    }

    private void TryResolveStore()
    {
        if (_store != null || Volatile.Read(ref _canResolve) == 0) return;
        try
        {
            var p = StoreQueryParameters.FromNameAndType(_storeName, QueryableStoreTypes.KeyValueStore<TKeyAvro, TValueAvro>());
            _store = _streams.Store(p);
        }
        catch (InvalidStateStoreException) { /* 次回 */ }
    }

    public async Task<List<T>> ToListAsync(CancellationToken ct = default)
    {
        TryResolveStore();
        var s = _store;
        if (s == null) return await _fallback.ToListAsync(ct);

        var list = new List<T>();
        var map = _mappings.GetMapping(typeof(T));
        try
        {
            foreach (var kv in s.All())
            {
                ct.ThrowIfCancellationRequested();
                list.Add((T)map.CombineFromAvroKeyValue(kv.Key!, kv.Value!, typeof(T)));
            }
            return list;
        }
        catch (InvalidStateStoreException)
        {
            _store = null;
            return await _fallback.ToListAsync(ct);
        }
    }

    public bool TryGet(object keyAvro, out T? value)
    {
        TryResolveStore();
        var s = _store;
        if (s == null) { value = null; return false; }
        if (keyAvro is TKeyAvro k && s.TryGet(k, out var v))
        {
            var map = _mappings.GetMapping(typeof(T));
            value = (T)map.CombineFromAvroKeyValue(k, v!, typeof(T));
            return true;
        }
        value = null; return false;
    }
}

// ================== 4) 出口：Set<T>(topic) -> ReadCachedEntitySet<T> に委譲（待たない） ==================
public sealed class ReadCachedEntitySet<T> : IEntitySet<T> where T : class
{
    private readonly IKsqlContext _ctx;
    private readonly string _topic;
    private readonly IEntitySet<T> _baseSet;

    public ReadCachedEntitySet(IKsqlContext ctx, string topic, IEntitySet<T> baseSet)
    { _ctx = ctx; _topic = topic; _baseSet = baseSet; }

    public async Task<List<T>> ToListAsync(CancellationToken ct = default)
    {
        var reg = _ctx.GetTableCacheRegistry();
        if (!reg.TryGetByTopic<T>(_topic, out var reader) || reader == null)
            return await _baseSet.ToListAsync(ct);        // 未登録/未準備は即フォールバック
        return await reader.ToListAsync(ct);              // キャッシュ（RocksDB）
    }
}
```
### これで“このレベルのまとめ”
- **反射/動的なし**（入口でジェネリック確定）  
- **StateChangedはStart前に配線**、ハンドラは**フラグ更新のみ**  
- **ToListAsyncはreaderに丸投げ**（未準備は即フォールバック、例外で止めない）  
- **key+value→POCO**は`MappingRegistry.CombineFromAvroKeyValue`に一本化  
- **外からは POCO+topic だけ**、`storeName`はreader内部に隔離

このまま貼って動かせる“芯”になってます。  
必要なら、`KsqlContext.Set<T>(topic)` に `new ReadCachedEntitySet<T>(ctx, topic, baseSet)` を返すだけの小パッチを足せば出口も完成です。

— 送信日時（日本時間）: 2025/08/09 06:36 JST
### system — 2025-08-08T19:37:02.465804+00:00

_(empty)_
### tool — 2025-08-08T19:37:02.471029+00:00

_(empty)_
### tool — 2025-08-08T19:37:02.477496+00:00

fileciteturn6file0

using Confluent.Kafka;
using Confluent.Kafka.Admin;
using Confluent.SchemaRegistry;
using Confluent.SchemaRegistry.Serdes;
using Kafka.Ksql.Linq.Tests.Integration.Streamiz.Models;
using Streamiz.Kafka.Net;
using Streamiz.Kafka.Net.Crosscutting;
using Streamiz.Kafka.Net.SchemaRegistry.SerDes.Avro;
using Streamiz.Kafka.Net.SerDes;
using Streamiz.Kafka.Net.State;
using Streamiz.Kafka.Net.Table;
using System;
using System.IO;
using System.Linq;
using System.Reflection;
using System.Threading.Tasks;
using Xunit;

namespace Kafka.Ksql.Linq.Tests.Integration.Streamiz;

public class StreamizRocksDbTests
{
    private static async Task WaitUntilRunningAsync(KafkaStream stream, TimeSpan? timeout = null)
    {
        var stateProp = typeof(KafkaStream).GetProperty("StreamState", BindingFlags.Instance | BindingFlags.NonPublic | BindingFlags.Public);
        var end = DateTime.UtcNow + (timeout ?? TimeSpan.FromSeconds(30));
        while ((KafkaStream.State)stateProp!.GetValue(stream)! != KafkaStream.State.RUNNING)
        {
            if (DateTime.UtcNow > end)
                throw new TimeoutException("KafkaStream failed to reach RUNNING state");
            await Task.Delay(100);
        }
    }

    private static async Task EnsureTopicAsync(string topic)
    {
        using var admin = new AdminClientBuilder(new AdminClientConfig { BootstrapServers = "localhost:9092" }).Build();
        try
        {
            await admin.CreateTopicsAsync(new[] { new TopicSpecification { Name = topic, NumPartitions = 1, ReplicationFactor = 1 } });
        }
        catch (CreateTopicsException e)
        {
            if (e.Results.Any(r => r.Error.Code != ErrorCode.TopicAlreadyExists))
                throw;
        }
    }
    private static Materialized<TKey, TValue, IKeyValueStore<Bytes, byte[]>> CreateAvroMaterialized<TKey, TValue>(string storeName)
    {
        var materializedType = typeof(Materialized<,,>).MakeGenericType(typeof(TKey), typeof(TValue), typeof(IKeyValueStore<Bytes, byte[]>));
        var createMethod = materializedType.GetMethods(BindingFlags.Public | BindingFlags.Static)
            .First(m => m.Name == "Create" && m.IsGenericMethodDefinition && m.GetParameters().Length == 1)
            .MakeGenericMethod(typeof(SchemaAvroSerDes<>).MakeGenericType(typeof(TKey)),
                               typeof(SchemaAvroSerDes<>).MakeGenericType(typeof(TValue)));
        return (Materialized<TKey, TValue, IKeyValueStore<Bytes, byte[]>>)createMethod.Invoke(null, new object[] { storeName });
    }

    private static async Task StartWithRetryAsync(KafkaStream stream, int retries = 3)
    {
        await RetryAsync(async () =>
        {
            await stream.StartAsync();
            await WaitUntilRunningAsync(stream);
        }, retries);
    }

    private static async Task ProduceWithRetryAsync<TKey, TValue>(string topic, TKey key, TValue value, CachedSchemaRegistryClient schemaRegistry, int retries = 3)
    {
        var producerConfig = new ProducerConfig { BootstrapServers = "localhost:9092" };
        using var producer = new ProducerBuilder<TKey, TValue>(producerConfig)
            .SetKeySerializer(new AvroSerializer<TKey>(schemaRegistry))
            .SetValueSerializer(new AvroSerializer<TValue>(schemaRegistry))
            .Build();

        await RetryAsync(async () =>
        {
            await producer.ProduceAsync(topic, new Message<TKey, TValue> { Key = key, Value = value });
        }, retries);

        producer.Flush(TimeSpan.FromSeconds(10));
    }

    private static async Task RetryAsync(Func<Task> action, int retries = 3, int delayMs = 1000)
    {
        for (var attempt = 0; attempt < retries; attempt++)
        {
            try
            {
                await action();
                return;
            }
            catch when (attempt < retries - 1)
            {
                await Task.Delay(delayMs);
            }
        }
    }

    private static async Task<TValue> RunAvroToRocksDbAsync<TKey, TValue>(string topic, string storeName, string applicationId, TKey key, TValue value)
    {
        await EnsureTopicAsync(topic);
        var builder = new StreamBuilder();
        builder.Stream<TKey, TValue>(topic)
               .ToTable(CreateAvroMaterialized<TKey, TValue>(storeName));

        var stateDir = Path.Combine(Path.GetTempPath(), Guid.NewGuid().ToString());
        var config = new StreamConfig<SchemaAvroSerDes<TKey>, SchemaAvroSerDes<TValue>>
        {
            ApplicationId = applicationId,
            BootstrapServers = "localhost:9092",
            SchemaRegistryUrl = "http://localhost:8081",
            StateDir = stateDir,
            AutoOffsetReset = AutoOffsetReset.Earliest
        };

        var stream = new KafkaStream(builder.Build(), config);
        try
        {
            await StartWithRetryAsync(stream);

            var schemaConfig = new SchemaRegistryConfig { Url = "http://localhost:8081" };
            using var schemaRegistry = new CachedSchemaRegistryClient(schemaConfig);
            await ProduceWithRetryAsync(topic, key, value, schemaRegistry);

            await Task.Delay(TimeSpan.FromSeconds(5));
            var store = stream.Store(StoreQueryParameters.FromNameAndType(storeName, QueryableStoreTypes.KeyValueStore<TKey, TValue>()));
            return store.Get(key);
        }
        finally
        {
            stream.Dispose();
            Directory.Delete(stateDir, true);
        }
    }


    [Fact]
    public async Task String_To_RocksDb()
    {
        const string topic = "streamiz-string";
        const string storeName = "string-store";
        await EnsureTopicAsync(topic);
        var builder = new StreamBuilder();
        builder.Stream<string, string>(topic)
               .ToTable(Materialized<string, string, IKeyValueStore<Bytes, byte[]>>.Create<StringSerDes, StringSerDes>(storeName));

        var stateDir = Path.Combine(Path.GetTempPath(), Guid.NewGuid().ToString());
        var config = new StreamConfig<StringSerDes, StringSerDes>
        {
            ApplicationId = "string-test-app",
            BootstrapServers = "localhost:9092",
            StateDir = stateDir,
            AutoOffsetReset = AutoOffsetReset.Earliest
        };

        var stream = new KafkaStream(builder.Build(), config);
        await stream.StartAsync();
        await WaitUntilRunningAsync(stream);

        var producerConfig = new ProducerConfig { BootstrapServers = "localhost:9092" };
        using (var producer = new ProducerBuilder<string, string>(producerConfig).Build())
        {
            await producer.ProduceAsync(topic, new Message<string, string> { Key = "k1", Value = "v1" });
            producer.Flush(TimeSpan.FromSeconds(10));
        }

        await Task.Delay(TimeSpan.FromSeconds(5));
        var store = stream.Store(StoreQueryParameters.FromNameAndType(storeName, QueryableStoreTypes.KeyValueStore<string, string>()));
        Assert.Equal("v1", store.Get("k1"));

        stream.Dispose();
        Directory.Delete(stateDir, true);
    }

    [Fact]
    public async Task Bytes_To_RocksDb()
    {
        const string topic = "streamiz-bytes";
        const string storeName = "bytes-store";
        await EnsureTopicAsync(topic);
        var builder = new StreamBuilder();
        builder.Stream<byte[], byte[]>(topic)
               .ToTable(Materialized<byte[], byte[], IKeyValueStore<Bytes, byte[]>>.Create<ByteArraySerDes, ByteArraySerDes>(storeName));

        var stateDir = Path.Combine(Path.GetTempPath(), Guid.NewGuid().ToString());
        var config = new StreamConfig<ByteArraySerDes, ByteArraySerDes>
        {
            ApplicationId = "bytes-test-app",
            BootstrapServers = "localhost:9092",
            StateDir = stateDir,
            AutoOffsetReset = AutoOffsetReset.Earliest
        };

        var stream = new KafkaStream(builder.Build(), config);
        await stream.StartAsync();
        await WaitUntilRunningAsync(stream);

        var key = new byte[] { 0x01 };
        var value = new byte[] { 0x02, 0x03 };
        var producerConfig = new ProducerConfig { BootstrapServers = "localhost:9092" };
        using (var producer = new ProducerBuilder<byte[], byte[]>(producerConfig).Build())
        {
            await producer.ProduceAsync(topic, new Message<byte[], byte[]> { Key = key, Value = value });
            producer.Flush(TimeSpan.FromSeconds(10));
        }

        await Task.Delay(TimeSpan.FromSeconds(5));
        var store = stream.Store(StoreQueryParameters.FromNameAndType(storeName, QueryableStoreTypes.KeyValueStore<byte[], byte[]>()));
        var stored = store.Get(key);
        Assert.True(stored.SequenceEqual(value));

        stream.Dispose();
        Directory.Delete(stateDir, true);
    }

    [Fact]
    public async Task Avro_To_RocksDb()
    {
        const string topic = "streamiz-avro";
        const string storeName = "avro-store";
        await EnsureTopicAsync(topic);
        var builder = new StreamBuilder();
        builder.Stream<string, User>(topic)
               .ToTable(Materialized<string, User, IKeyValueStore<Bytes, byte[]>>.Create<StringSerDes, SchemaAvroSerDes<User>>(storeName));

        var stateDir = Path.Combine(Path.GetTempPath(), Guid.NewGuid().ToString());
        var config = new StreamConfig<StringSerDes, SchemaAvroSerDes<User>>
        {
            ApplicationId = "avro-test-app",
            BootstrapServers = "localhost:9092",
            SchemaRegistryUrl = "http://localhost:8081",
            StateDir = stateDir,
            AutoOffsetReset = AutoOffsetReset.Earliest
        };

        var stream = new KafkaStream(builder.Build(), config);
        await stream.StartAsync();
        await WaitUntilRunningAsync(stream);

        var producerConfig = new ProducerConfig { BootstrapServers = "localhost:9092" };
        var schemaConfig = new SchemaRegistryConfig { Url = "http://localhost:8081" };
        using var schemaRegistry = new CachedSchemaRegistryClient(schemaConfig);
        using (var producer = new ProducerBuilder<string, User>(producerConfig)
            .SetKeySerializer(Serializers.Utf8)
            .SetValueSerializer(new AvroSerializer<User>(schemaRegistry))
            .Build())
        {
            var user = new User { name = "alice", age = 30 };
            await producer.ProduceAsync(topic, new Message<string, User> { Key = "u1", Value = user });
            producer.Flush(TimeSpan.FromSeconds(10));
        }

        await Task.Delay(TimeSpan.FromSeconds(5));
        var store = stream.Store(StoreQueryParameters.FromNameAndType(storeName, QueryableStoreTypes.KeyValueStore<string, User>()));
        var stored = store.Get("u1");
        Assert.Equal("alice", stored.name);
        Assert.Equal(30, stored.age);

        stream.Dispose();
        Directory.Delete(stateDir, true);
    }

    [Fact]
    public async Task AvroKey_To_RocksDb()
    {
        var key = new User { name = "key1", age = 1 };
        var value = new User { name = "alice", age = 30 };
        var stored = await RunAvroToRocksDbAsync("streamiz-avro-key", "avro-key-store", "avro-key-test-app", key, value);
        Assert.Equal("alice", stored.name);
        Assert.Equal(30, stored.age);
    }

    [Fact]
    public async Task AvroKeyValueDifferentTypes_To_RocksDb()
    {
        var key = new User { name = "key1", age = 1 };
        var value = new Address { street = "main", zip = 12345 };
        var stored = await RunAvroToRocksDbAsync<User, Address>("streamiz-avro-key-different", "avro-key-different-store", "avro-key-different-test-app", key, value);
        Assert.Equal("main", stored.street);
        Assert.Equal(12345, stored.zip);
    }
}
### tool — 2025-08-08T19:37:02.497531+00:00

All the files uploaded by the user have been fully loaded. Searching won't provide additional information.
### assistant — 2025-08-08T19:37:03.978145+00:00

_(empty)_
### assistant — 2025-08-08T19:37:08.842267+00:00

_(empty)_
