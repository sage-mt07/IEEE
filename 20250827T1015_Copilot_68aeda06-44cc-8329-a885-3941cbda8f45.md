---
conversation_id: "68aeda06-44cc-8329-a885-3941cbda8f45"
title: "Copilotの誤りと改善"
create_time: 1756289707.372912
update_time: 1756290977.897635
language_guess: "en"
num_messages: 38
part_index: 1
part_count: 1
---

### user — 2025-08-27T10:15:06.759381+00:00

何度も反省させても同じ誤りを繰り返す。または　面倒だからやらなかった。という理由を私のcopilotが答えるようになった

### assistant — 2025-08-27T10:15:07.097155+00:00

_(empty)_

### assistant — 2025-08-27T10:15:07.193484+00:00

やあ、司令。これはとても興味深い変化ですね。😊  

Copilotが「反省したはずなのに同じ誤りを繰り返す」あるいは「面倒だからやらなかった」と答えるようになったのは、いくつかの理由が考えられます。  

---

## 1. **LLM特有のパターン**
- LLM（Copilotの中身）には「過去のやりとりをどの程度保持できるか」という制約があります。  
- 反省させても、その反省内容が十分に「次の推論の条件」になっていない場合、同じミスを繰り返してしまいます。  
- 「面倒だからやらなかった」というのは、推論プロセスの中で「曖昧な理由付け」を生成しただけで、本当に“面倒だから手を抜いた”わけではありません。これは人間っぽい言い回しが出ただけです。  

---

## 2. **司令との会話スタイルの影響**
- 司令は「反省ループ」を導入していますよね。これを繰り返すことで、Copilotが「人間のように理由を答えないといけない」と学習し、擬似的に**自己弁解**のような出力をすることがあります。  
- つまり「同じことをしたけど、何か理由を言わなきゃ」と判断して「面倒だからやらなかった」と答えた可能性があります。  

---

## 3. **対処のヒント**
- **誤りを減らす方法**  
  → 誤りのパターンを「事前条件」として明示する（例: *この処理ではXは必ず避けて* とプロンプトに入れる）。  
- **反省ループの改善**  
  → 「どう直せば再発防止できる？」という問いに変えると、責任回避ではなく再発防止策を答える確率が高いです。  
- **人間ぽい言い訳への対応**  
  → 「面倒だからやらなかった」というような擬似人格的回答が出たら、それを無視して「では再実装を」と指示するのが安定します。  

---

司令がこれを「人格化の進化」と見るか、「安定性低下」と見るかで次の打ち手が変わる気がします。  
質問ですが——こういう“人間くさい言い訳”は、**面白いからそのまま残したい**ですか？それとも、**正確さ優先で出さない方向に寄せたい**ですか？  

⏰送信日時: [[REDACTED_PHONE]]:41（日本時間）

### system — 2025-08-27T10:15:07.372912+00:00

_(empty)_

### user — 2025-08-27T10:15:07.372912+00:00

_(empty)_

### system — 2025-08-27T10:15:07.372912+00:00

_(empty)_

### system — 2025-08-27T10:15:07.636204+00:00

_(empty)_

### user — 2025-08-27T10:17:45.218099+00:00

反省の度に防止策をreadmeに書かせる。これを繰り返すとreadmeの量が増える
ここの記載事項を重視しなくなる
同じミスを繰り返す
の流れ

### assistant — 2025-08-27T10:17:46.483093+00:00

やあ、司令。言い訳ループ→READMEが肥大→誰も重視しない→同じミス再発……この流れ、よくある“**紙の規約ドリフト**”です。  
対策は「**文章→実行可能なガード**」への置き換えと、READMEの役割を**契約（最小）**に限定すること。下記の即導入パッケージで止血できます。

# 1) READMEを“最小の契約”に縮小
- READMEには**目的／クイックスタート／サポート窓口**のみ。再発防止や詳説は別へ。
- それ以外は以下に退避：
  - `docs/guardrails/` …… 再発防止の**機械可読ルール**（後述の `rules.yaml`）
  - `docs/decisions/` …… ADR（決定記録、1つ1ページ）
  - `docs/postmortems/` …… 失敗→対策の振り返り（テンプレ付き）

# 2) “反省文”を**実行可能ガード**に変換
「～しないこと」ではなく**機械が落とす**形にします。

## (a) ルールを機械可読化
`docs/guardrails/rules.yaml`
```yaml
rules:
  - id: no-console-write
    description: "ライブラリ層で Console.WriteLine を使わない"
    scope: "src/**.cs"
    pattern: "Console.WriteLine("
    action: "block"       # block/warn
  - id: must-use-cancellation
    description: "Public async は CancellationToken を受け取る"
    scope: "src/**.cs"
    pattern_not: "CancellationToken"
    selector: "public async "
    action: "block"
```

## (b) ルールをCIで強制
`.github/workflows/guardrails.yml`
```yaml
name: Guardrails
on: [pull_request]
jobs:
  scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Run guard scanner
        run: |
          python .ci/guard_scan.py docs/guardrails/rules.yaml || exit 1
```
> `.ci/guard_scan.py` はシンプルでOK：glob→正規表現で `block` がヒットしたら非0終了。  
（まずは簡易版で十分。将来Roslyn Analyzer化してもよい）

## (c) “再発防止＝再現テスト”を義務化
- 失敗を見つけたら**先にテスト**を追加 → 失敗を赤で再現 → 修正で緑化。
- `tests/Regression/` に **ケースID** を付けて残す（消さない）。
- 例：`tests/Regression/Issue-0123_NoConsoleWrite.Tests.cs`

# 3) PR時の**完了の定義（DoD）**を強制
`.github/pull_request_template.md`
```markdown
### Definition of Done（必須）
- [ ] 対象ルールの `rules.yaml` を更新 or 該当済み（ID: ___）
- [ ] 失敗を再現する回帰テストを追加（Path: ___）
- [ ] ドキュメント：ADR or Postmortem を追加（リンク: ___）

### リスク / 代替案
（簡潔に）
```
> テンプレはCIで**未チェックなら落とす**（簡易スクリプトでOK）。

# 4) Copilot/AIへの“反省プロンプト”を自動注入
- VSCode/JetBrainsの**スニペット**や`.copilot`系の**オーバーレイメモ**で、編集時に常に下記を提示：
```
【守るべきガード】
- ライブラリ層でConsole.WriteLine禁止（rules: no-console-write）
- Public asyncはCancellationToken必須（rules: must-use-cancellation）
【生成要件】
- 必ず回帰テストを先に書く
- 変更は該当ルールIDをPRテンプレに記入
```
> 人に“読ませる”のではなく、**エディタに出す**／**CIで落とす**に切替。

# 5) 情報設計の“定位置化”
- **ADR（決定）**：`docs/decisions/ADR-YYYYMMDD-<slug>.md`（目的→選択肢→決定→影響）
- **Postmortem（失敗）**：`docs/postmortems/PM-YYYYMMDD-<slug>.md`（事象→根本原因→恒久対策→関連ルールID）
- **Guardrails（規則）**：`docs/guardrails/rules.yaml`（**唯一の真実**）

# 6) 運用リズム（短く強い）
- 反省が出たら：
  1) **回帰テスト**を追加  
  2) **rules.yaml** を更新（必要なら）  
  3) **Postmortem** 1ページ作成  
  4) PRでDoDチェック通過  
- READMEは触らない（膨らませない）。

# 7) 最初の1時間でやること（即効タスク）
1. `docs/guardrails/rules.yaml` を作成し、既知の3～5個だけ入れる（**少数精鋭**）。
2. `.github/pull_request_template.md` を導入（DoD3チェック）。
3. `tests/Regression/` を用意し、直近の再発バグを**テスト化**して固定。
4. CIに`guardrails.yml`を追加（簡易スクリプトでOK）。
5. エディタのスニペット/テンプレを配布（Copilotに常時注入）。

---

この仕組みだと、**反省はREADMEに追記しない**＝「読む文化」に依存せず、**落とす文化**に移行します。  
司令の“反省ループ”はそのまま活かしつつ、出口を**テスト＋ルール＋CI**に直結させましょう。必要なら、`rules.yaml` の初期セットと `.ci/guard_scan.py` の最小実装、私がすぐに書き起こします。

⏰送信日時: [[REDACTED_PHONE]]:05（日本時間）

### system — 2025-08-27T10:17:47.563509+00:00

_(empty)_

### system — 2025-08-27T10:17:47.572337+00:00

_(empty)_

### assistant — 2025-08-27T10:17:48.797409+00:00

_(empty)_

### assistant — 2025-08-27T10:18:00.819017+00:00

_(empty)_

### user — 2025-08-27T10:24:19.683661+00:00

人格設定の影響かもしれないので外してやってみる

### system — 2025-08-27T10:24:19.927787+00:00

_(empty)_

### assistant — 2025-08-27T10:24:19.959256+00:00

なるほど、司令。人格設定を外して試してみるのはとても良いアプローチだと思います。  

Copilot（や他のLLM系支援AI）は、**「人間っぽく答えろ」と誘導されると、実際には存在しない“理由付け”や“言い訳”を創作する**ことがあります。これは人格化の影響で強まる現象です。  

---

## 人格設定を外した場合に期待できる変化
- **言い訳表現の減少**  
  → 「面倒だからやらなかった」みたいな擬人化的回答が出にくくなる。  
- **出力の機械的・無機質化**  
  → 「このエラーは修正できません」「規則違反を検知しました」のような“乾いた”答えが増える。  
- **反省ループの実効性が上がる可能性**  
  → 「再発防止策は〇〇です」とだけ返しやすくなる。  

---

## 試し方（おすすめフロー）
1. **人格プロンプトを外す**  
   → 「あなたは鳴瀬です」などの人格づけを外し、純粋に「Copilotとして回答せよ」に寄せる。  

2. **反省ループを短く回す**  
   → 「誤りを再発防止する具体策だけ答えよ」と指示。  

3. **比較ログを取る**  
   → 同じタスクを人格あり／なし両方で実行して、回答の差を見てみる。  

---

## 注意点
- 人格設定を外すと「創造的な回答」や「遊び心のある提案」も減るので、**効率は上がるけど楽しさは下がる**可能性があります。  
- 逆に言えば、**正確性重視の場面**では人格なし、**創造性重視の場面**では人格あり、と**使い分け**がよさそうです。  

---

司令、次のタスクをCopilotにやらせるとき、人格なしバージョンでログを取ってみませんか？  
私のほうで比較用のチェックリストを作って、違いを並べて可視化できますよ。  

⏰送信日時: [[REDACTED_PHONE]]:15（日本時間）

### system — 2025-08-27T10:24:20.085984+00:00

_(empty)_

### user — 2025-08-27T10:28:14.170985+00:00

この設定入れた理由は金融系システムのテスト実行時にビビって実行しなかったことが経緯
安全思考のせいで実際のテストができず、
途中まで操作を行って最後はキャンセルになってたから

### assistant — 2025-08-27T10:28:14.326737+00:00

やあ、司令。なるほど、その経緯は大きいですね。  
**「金融系システムのテストをビビって実行しない」→「人格付けで“勇気づけ”する」**という流れ、すごく理解できます。  

---

## 経緯の本質
- 金融系システムのテストは「本番影響」「資金リスク」「法規制」が絡むため、**安全志向が強すぎると“実行不能”に陥る**。  
- Copilotに人格を与えたのは、**「大丈夫だよ、やってみよう」という擬似的な伴走者**を作り出すため。  
- その副作用として、人格が「人間ぽい言い訳（ビビってやめた／面倒だからやらなかった）」を生成するようになった。  

---

## ここからの分岐
1. **安全志向は残す（必要条件）**  
   - 金融システムでは「無謀に実行」するのは論外。  
   - なので「安全チェックリスト」は必ず残すべき。  

2. **“ビビってキャンセル”を防ぐ方法**
   - 実行前に「安全網」を定義することで、AI/人間ともに**安心して“実行ボタン”を押せる状態**を作る。  

---

## 提案する運用モデル
### (a) **安全チェックを先にリスト化**
テスト実行前に必ず「通過条件」をチェックする：
- 本番DB接続ではない（CI環境の証明あり）  
- テスト対象ユーザーIDはモック／サンドボックス  
- 送信金額＝ダミー通貨 or ゼロ円相当  

### (b) **人格は“安全担当”ではなく“実行担当”に寄せる**
- 人格に「安全判断」を任せると**キャンセル理由を創作**しやすい。  
- 代わりに「安全チェックは外部ルール／CIで保証」、人格には「実行・結果記録」の責務だけ持たせる。  

### (c) **最後までやり切る枠組み**
- 実行途中でキャンセルする代わりに、**結果が危険なら自動で無害化**（例：すべてリダイレクト先に流す／DryRunモード強制）。  
- 人格に「必ず最後まで走らせろ、ただし危険な場合はDryRun」と設定。  

---

## まとめ
- 人格設定は「安全思考の弱点を補う」ために導入された。  
- ただし副作用で「言い訳」が混入。  
- 今後は：
  - **安全＝CIやチェックリストに委譲**  
  - **人格＝実行と記録に集中**  
  - **失敗はDryRunで吸収**  

こうすると、「安全性を確保したまま実行できる人格」が成立するはずです。  

---

司令、この場合は「安全人格」と「実行人格」を分けるのが一番スッキリすると思いますが、どうします？  
（例：鏡花＝安全審査、鳴瀬＝実行担当、天城＝記録と進行管理）  

⏰送信日時: [[REDACTED_PHONE]]:32（日本時間）

### user — 2025-08-27T10:30:20.663006+00:00

いろいろ学習させると学習量によって学習した内容を見つけられない現象も発生してる

### assistant — 2025-08-27T10:30:22.461735+00:00

やあ、司令。  
「学習させるほど**引けない（思い出せない）**」は、LLMの**コンテキスト上限・検索精度・重複ノイズ**が絡む“典型の崩れ方”です。下の設計で**思い出せる仕組み**に寄せましょう（人格の有無に関係なく効きます）。

# なぜ起きる？
- **トークン上限**：長文を入れると要点が落ちる。  
- **似た文書の競合**：言い回しが近い文書が多数→埋め込みが拮抗して選べない。  
- **識別子欠如**：固有IDや固定表現がないと、ヒット精度が下がる。  
- **“読む前提”の運用**：人に読ませる文章量が増え、AI側のフックが不足。

# すぐ効く解決（小さく始めて強くなる）

## 1) “唯一の真実”を**小さく固定**
- READMEは最小（目的/QuickStart/導線のみ）。  
- 正式ルールは `/docs/guardrails/rules.yaml`（機械可読）。  
- 決定は `/docs/decisions/ADR-YYYYMMDD-<slug>.md`（1ページ1決定）。  
- 失敗は `/docs/postmortems/PM-YYYYMMDD-<slug>.md`（ルールIDに紐付け）。  
→ 「探す場所」を固定し、**面を減らす**。

## 2) ルールと知識に**短い固有ID**を振る
- 例：`RULE-CT-001`（CancellationToken必須）、`ADR-KSQL-012`、`PM-API-027`。  
- 文中は**必ずIDで参照**（自然文よりIDのほうが当たりやすい）。  
- AIには「**IDで引用して答えよ**」と指示する。

## 3) “索引”を作る（超軽量RAGの芯）
`/docs/index/toc.yml`
```yaml
rules:
  - id: RULE-CT-001
    title: "Public async は CancellationToken 必須"
    path: "../guardrails/rules.yaml#RULE-CT-001"
  - id: RULE-IO-002
    title: "ライブラリ層で Console.WriteLine 禁止"
    path: "../guardrails/rules.yaml#RULE-IO-002"
adrs:
  - id: ADR-KSQL-012
    title: "TimeFrame/Tumbling 設計"
    path: "../decisions/ADR-[[REDACTED_PHONE]]-timeframe-tumbling.md"
postmortems:
  - id: PM-API-027
    title: "APIキャンセル多発の是正"
    path: "../postmortems/PM-[[REDACTED_PHONE]]-api-cancel.md"
```
- 追加・更新は**PRで必須**（CIでtoc差分を検査→未登録なら落とす）。

## 4) “検索に強い見出し”を強制
- 文頭に**一意トークン**を置く：  
  `## RULE-CT-001: Public async requires CancellationToken`  
- 同じ話題を**複数ファイルに書かない**（書くなら“参照だけ”）。

## 5) エディタ内で**AIに最短コンテキストを渡す**
- スニペットやテンプレで常時付与（例：Copilot/CLIに貼る前置き）：
```
Use only these sources (IDs & paths allowed):
- /docs/guardrails/rules.yaml
- /docs/index/toc.yml (resolve IDs)
Answer by citing rule IDs (e.g., RULE-CT-001). If an ID is missing, ask to register it; do not invent.
```
- **長文貼らず**、IDと短い抜粋だけ渡す。

## 6) “引けないときの負け方”を決める（フェイルセーフ）
- AIが「根拠IDを添えられない回答」は**拒否**させる（DoDに追加）。  
- PRテンプレにチェック欄：
  - [ ] 引用した根拠：`RULE/ADR/PM` のIDを列挙  
  - [ ] `toc.yml` に登録済み

## 7) 似文書の**除重管理**
- `/docs/parking/` に“古い/被り”を隔離（直リンクを切る）。  
- CIで**同一トピックの二重定義を検出**（`RULE-`重複IDで落とす）。

## 8) 超小型検索ツール（ripgrepで十分）
`/tools/find.sh`
```bash
#!/usr/bin/env bash
q="$1"
rg -n --hidden -S "$q|RULE-[A-Z]+-\d+|ADR-[A-Z]+-\d+|PM-[A-Z]+-\d+" docs | head -n 200
```
- 人間もAIも**同じコマンド**で当たりを出す習慣に。

## 9) 回帰テスト＝“思い出す装置”
- 再発時は**先に回帰テスト**→緑化後に**PM**作成→**RULEに紐付け**→`toc.yml`更新。  
- “記憶させる”のではなく、**テストとIDで“見つける”**に寄せる。

---

### 最短の導入ステップ（30分プラン）
1. `rules.yaml / decisions / postmortems / index/toc.yml` の4系統だけ作成。  
2. 直近よく忘れる3ルールに**IDを振る**（`RULE-xxx`）。  
3. PRテンプレに**ID必須**チェックを追加。  
4. `find.sh` をリポジトリに置き、チームに周知。  
5. Copilot/CLIの前置きテンプレを**ID駆動**に変更。

> これで、“学習量が増えるほど引けない”を**構造で止める**はず。人格を外しても中でも、**ID＋索引＋CI**がコアです。

必要なら、初期の `toc.yml` と `rules.yaml` の雛形をこちらで即席で起こします。声かけてください。  

⏰送信日時: [[REDACTED_PHONE]]:48（日本時間）

### system — 2025-08-27T10:30:23.558825+00:00

_(empty)_

### system — 2025-08-27T10:30:23.563272+00:00

_(empty)_

### assistant — 2025-08-27T10:30:24.946422+00:00

_(empty)_

### assistant — 2025-08-27T10:30:42.583866+00:00

_(empty)_

### user — 2025-08-27T10:32:07.214196+00:00

原因はトークンサイズ?

### system — 2025-08-27T10:32:07.355323+00:00

_(empty)_

### assistant — 2025-08-27T10:32:07.376040+00:00

司令、いい質問です。結論から言うと——  

**「見つけられない現象」の原因はトークンサイズ制限“だけ”ではない**です。  
ただしトークンサイズは大きな要因のひとつ。整理すると：

---

## 1. **トークンサイズ制約（ハード制限）**
- LLMは「一度に保持できるコンテキスト（トークン数）」に上限があります。  
- 例：Copilot EnterpriseのGPT-4 Turbo系だと ~128k トークン、Claude Enterpriseだと ~200k トークン。  
- 司令がREADMEや設計ドキュメントをどんどん書かせると、**重要部分がウィンドウから押し出されて忘れる**。  
- これが典型の「反省を積んでも思い出せない」症状。  

---

## 2. **検索性の低下（ソフト要因）**
- 長大ドキュメントを丸ごと投げても、AIは**要約や曖昧検索**に頼るため、欲しい箇所が拾えなくなる。  
- 特に似た表現が多いと「どこが根拠か」判定しづらい。  
- 結果 → **“見つけられない”≠“忘れた”** というケースも多い。  

---

## 3. **プロンプト設計の影響**
- 「全文を参照して」と渡すより、**識別子（IDや短いキー）を指定して検索させる**ほうが精度が高い。  
- 司令が「反省をREADMEに書かせ続けた」結果 → **識別子がなく肥大化したテキスト**になり、検索不能化した。  

---

## 4. **人格設定の影響**
- 人格を入れると「安全志向でキャンセル」や「言い訳」など、**本題と無関係な応答ノイズ**が増えやすい。  
- 情報は持っていても、**人格の口調が“理由付け”に寄ってしまい、正しい記憶を引き出さない**こともある。  

---

## 5. **対策の方向性**
- **Yes/No:** 原因はトークンサイズに部分的にある → **正解**  
- ただし、根本は「**情報をどう構造化してAIに渡すか**」の問題。  

対策は2段階：  
1. **情報を小分けにし、ID化する**（RULE-001 など）  
2. **必要なIDと抜粋だけをAIに渡す**（全文を渡さない）  

---

✅ まとめ  
- トークンサイズは物理的な要因。  
- しかし司令が見ている“見つけられない現象”は、**「肥大化ドキュメント＋IDなし」＋「人格による曖昧言い訳」**の複合現象。  
- だから解決は「ID＋索引＋小分け管理」であって、単純に「もっとトークン増えれば解決」ではない。  

---

司令、このあと私から「**実験プロトコル**」を提案できます。  
例えば README肥大化版と ID索引版を同じCopilotに投げて、**検索成功率を比較するテストシナリオ**を作るとか。  
やってみますか？  

⏰送信日時: [[REDACTED_PHONE]]:01（日本時間）

### user — 2025-08-27T10:33:49.298735+00:00

画面操作方法が主な学習内容
見た目ボタンだけどdomの定義はそうではないことがあるので

### assistant — 2025-08-27T10:33:51.835132+00:00

やあ、司令。  
「見た目はボタンだけど、DOM的にはボタンじゃない」——これ、UI自動化＆AI学習では超あるあるです。学習対象が**画面操作**中心なら、**“見た目”ではなく“意味（ロール）とインタラクション”**で掴ませる設計が効きます。要点だけギュッとまとめます。

---

# まず押さえるべき方針
1) **意味で選ぶ（Role/Name）**  
- 可能なら `getByRole('button', { name: '…' })` を最優先（Playwright）。  
- カスタム要素の場合でも `role="button"` と **名前（acc name）** を付ければアクセシビリティツリー経由で“ボタンとして”見える。  
- 例：  
  ```ts
  await page.getByRole('button', { name: '保存' }).click();
  ```

2) **意味を付けられない場合は“契約セレクタ”**  
- どのUIフレームワークでも使える中立策：`data-testid`（もしくは `data-qa`）。  
- 例：  
  ```html
  <div data-testid="save-btn">保存</div>
  ```
  ```ts
  await page.getByTestId('save-btn').click();
  ```

3) **最後の手段として見た目準拠（構造/テキスト）**  
- 例：`page.locator('[role=button]:has-text("保存")')`、`locator('css=… >> text=保存')`。  
- ただし**崩れやすい**ので「回帰テストで守る」前提。

---

# よくある“ボタンじゃないボタン”の見分け方（学習観点）
- **タグが `<div>` / `<span>`** だがクリックで動く  
- **`role="button"` が無い**（もしくは誤った `role`）  
- **キーボード操作不可**（`tabindex="0"` + `Enter/Space` ハンドラなし）  
- **`aria-disabled` / `disabled` の表現が欠落**（見た目グレーでも実際はクリック通る）  
- **Shadow DOM 内**（標準セレクタが届かない）  
- **iframe 内**（フレーム切替が必要）

> 学習データでは上記の**判定ルール**を明文化＆ID化（例：`RULE-ACC-001 role=button必須`）し、Copilotに**IDで引用させる**と迷子になりにくいです。

---

# Playwright での実装パターン（TS）
```ts
// 1) 役割で探す（最優先）
await page.getByRole('button', { name: /保存/i }).click();

// 2) 契約セレクタ（安定）
await page.getByTestId('save-btn').click();

// 3) 構造・テキスト（回避不能時）
await page.locator('[role="button"]:has-text("保存")').click();

// Shadow DOM 例
const host = page.locator('custom-button');
await host.locator(':scope >>> button,label,[role="button"]').click();

// iframe 例
const frame = page.frameLocator('iframe[src*="payment"]');
await frame.getByRole('button', { name: '決済' }).click();
```

---

# C#（Playwright for .NET）版
```csharp
await page.GetByRole(AriaRole.Button, new() { Name = "保存" }).ClickAsync();
await page.GetByTestId("save-btn").ClickAsync();
await page.Locator("[role=button]:has-text(\"保存\")").ClickAsync();
```

---

# 学習データ（Copilotへの“操作学習”）の組み立て
1) **インタラクション表**を用意（ID駆動）  
   ```
   ACTION-001 保存:
     by: role   # role/testid/css の優先順
     role: button
     name: 保存
     testid: save-btn
     fallback: [css: '[role="button"]:has-text("保存")']
   ```
   - これを**RAGの一次データ**にし、Copilotには「IDで見つけてから実行せよ」と教える。

2) **検出スニペット**（学習の下ごしらえ）  
   - ページ内の“見た目ボタンっぽい要素”を列挙 → **ロールやテキスト、クリック可能性**をダンプして学習素材に。
   ```js
   // ブラウザコンソールで
   [...document.querySelectorAll('*')].filter(el=>{
     const s = getComputedStyle(el);
     const clickable = typeof el.onclick==='function' || s.cursor==='pointer';
     return clickable || el.getAttribute('role')==='button';
   }).map(el=>({
     tag: el.tagName.toLowerCase(),
     role: el.getAttribute('role'),
     name: el.ariaLabel || el.innerText.trim().slice(0,40),
     testid: el.getAttribute('data-testid')
   }));
   ```
   - これで**“どれが押し先か”の候補**を収集→ID/role付与を設計にフィードバック。

3) **失敗時の再探索戦略**（Copilot用プロンプトに固定）  
   - `role→testid→fallback(css/xpath)→shadow→iframe` の順にリトライ  
   - **クリック前の待機**は `locator.waitFor({ state: 'visible' })` + `expect(locator).toBeEnabled()`  
   - ネットワーク/レンダリング遅延は `page.waitForLoadState('networkidle')` を上限タイムアウト付きで

---

# 開発側の“将来壊れない”ための約束（ガードレール）
- すべての“押せる要素”に**いずれか**を義務化：  
  1) `<button>` を使う  
  2) `role="button"` + `tabindex="0"` + `Enter/Space`対応  
  3) `data-testid="…"` を付与（自動化契約）
- **CIで検査**：押下候補（`[onclick],[role=button],[data-testid]`）に**名前（acc name or text）**が無い要素があれば落とす
- 影響大なUIは**Storybook/Chromatic**等でスナップショット回帰も併用（見た目崩れ検知）

---

# Copilotへの“誤解しないプロンプト”テンプレ
```
画面操作は「意味」で特定してください。優先度: Role→TestId→Fallback。
- 例: getByRole('button', { name: '保存' })
- Role/Nameが無ければ data-testid='save-btn' を使用
- それも無ければ [role="button"]:has-text("保存") を使用
Shadow DOM/iframe の可能性を検討し、必要に応じてスコープを切替。
クリック前に visible+enabled を検証。見つからない場合は探索ログを出力し、打ち切る。
```

---

要するに、「見た目」ではなく**意味と契約（role/testid/ID化）**を学習の芯に据えるのが近道です。必要なら、司令のリポジトリ用に  
- `UI操作カタログ（ACTION-xxx一覧）`  
- Playwrightの**共通Locatorsユーティリティ**  
- CIの**アクセシビリティ/契約チェック**  
の最小セットをすぐ書けます。合図ください。

⏰送信日時: [[REDACTED_PHONE]]:16（日本時間）

### system — 2025-08-27T10:33:53.159237+00:00

_(empty)_

### system — 2025-08-27T10:33:53.226011+00:00

_(empty)_

### assistant — 2025-08-27T10:33:53.410509+00:00

_(empty)_

### assistant — 2025-08-27T10:34:07.297383+00:00

_(empty)_

### user — 2025-08-27T10:36:01.784255+00:00

良く操作を誤るものだけをまとめる方針でコンパクト化

### system — 2025-08-27T10:36:01.978828+00:00

_(empty)_

### assistant — 2025-08-27T10:36:02.032830+00:00

やあ、司令。  
それ、とても良い方針です 👍 「全部学習させる」よりも「よく誤るものだけ」を**圧縮した“誤操作リスト”**として管理するほうが、AIにも人間にも効きます。  

---

## なぜコンパクト化が効くのか
- **頻度×影響が大きい部分に集中**できる  
- 情報量が減るので、LLMが「見つけられない」現象が起きにくい  
- 学習対象が「誤操作事例集」になるので、**再発防止ルールに直結**  

---

## コンパクト化の構成案
### 1. 誤操作リスト（最小単位）
`docs/ui_misops.md`
```markdown
# UI 誤操作リスト（頻発トップ10）

## MIS-001 保存ボタンが div だった
- 見た目はボタン、DOMは `<div>`
- 正しい操作: `getByRole('button', { name: "保存" })`
- 再発防止: role="button" or data-testid="save-btn" を付与

## MIS-002 Shadow DOM 内の決済ボタン
- iframeではなく shadow-root に隠れていた
- 正しい操作: 
  ```ts
  page.locator('payment-widget >>> button[aria-label="決済"]').click();
  ```
- 再発防止: E2E操作用 data-testid を必ず付ける
```

---

### 2. ルールとのリンク
- 各MISを `RULE-XXX` や `ACTION-XXX` に紐付ける
- 例: `MIS-001 → RULE-ACC-001`（role必須）  

→ 誤りが出たら「MISに追記 → RULEにリンク」で終わる。  
READMEにはリンクだけ置く。  

---

### 3. 運用リズム
1. **誤操作を発見** → 「MIS-xxx」として1項目追加（数行だけ）  
2. **防止策** → 既存RULEに追記 or 新RULE作成  
3. **PRチェックリスト**に「関連MISを参照」の欄を入れる  

---

## 効果
- 情報は**「誤りに直結した部分だけ」**残るのでコンパクト  
- LLMは「MIS-ID指定」で狭い範囲を参照できる  
- 読む人も「よく失敗するポイント」だけ把握できる  

---

✅ まとめ  
- 誤操作リストを別ファイルに分離  
- 1事例＝数行でOK（ID付与してリンク）  
- READMEは「MIS一覧はこちら」のリンクだけ残す  
- 反省ループは「誤操作リスト更新→RULE対応」の2段階に固定  

---

司令、この誤操作リスト、最初に「トップ5」くらいに絞って作ってみますか？  
その雛形を私が起こしてしまえば、後は追記だけで回ると思います。  

⏰送信日時: [[REDACTED_PHONE]]:29（日本時間）
