---
conversation_id: "68d7579c-8458-8322-a5a7-3a2524170ced"
title: "方向性の評価"
create_time: 1758943165.009406
update_time: 1758943323.753075
language_guess: "en"
num_messages: 12
part_index: 1
part_count: 1
---

### user — 2025-09-27T03:19:24.812859+00:00

https://zenn.dev/loglass/articles/e6525e7e8b7a69
この方向性への評価して

### assistant — 2025-09-27T03:19:24.957714+00:00

search("https://zenn.dev/loglass/articles/e6525e7e8b7a69\n\u3053\u306e\u65b9\u5411\u6027\u3078\u306e\u8a55\u4fa1\u3057\u3066")

### assistant — 2025-09-27T03:19:24.960558+00:00

_(empty)_

### system — 2025-09-27T03:19:25.009406+00:00

_(empty)_

### system — 2025-09-27T03:19:25.009406+00:00

_(empty)_

### system — 2025-09-27T03:19:25.385569+00:00

_(empty)_

### tool — 2025-09-27T03:19:25.454980+00:00

_(empty)_

### assistant — 2025-09-27T03:19:25.706738+00:00

司令、いい記事をシェアしてくれてありがとう。以下、この記事「決定論的システムと非決定論的AI Agentの接合点：OSSフレームワークEmbabelが拓く新しいソフトウェア開発の可能性」citeturn0view0 に対する評価と、強み・課題・発展の余地、そして実用化観点からの所感を述べるね。

---

## 記事の要約（簡単に確認）

記事では、従来の業務アプリケーションが「決定論的（同じ入力に対して常に同じ出力を返す）」という特性を持つ一方で、AIエージェント／LLM の生成は「非決定論的（同じ入力でも毎回異なる結果を返す可能性がある）」という点にギャップがある、という認識を出発点にしている。citeturn0view0  

そこを埋める手法として、OSS フレームワーク **Embabel** を紹介。Embabel は以下のようなアプローチを採る：

- LLM にすべてを任せず、**GOAP（Goal-Oriented Action Planning)** などの決定論的アルゴリズムでタスク分割・計画を立てる。citeturn0view0  
- 型安全なドメインモデルとの統合（DICE: Domain-Integrated Context Engineering）を通じて、LLMとのインターフェースを構造化し信頼性を向上させる。citeturn0view0  

記事では、こうした構造によって「業務アプリケーションとしての信頼性」と「LLM の柔軟性・創造性」を両立させる可能性がある、という仮説を提示している。citeturn0view0  

---

## 強み・魅力的な点

この方向性には、かなり現実的な価値があると思ってる。いくつか強みを挙げておく：

1. **課題意識がリアル**  
　AI エージェントをビジネス用途で使う際、「予測可能性」「再現性」「説明責任（説明可能性）」などをどう担保するかは、まさに現場での大きな壁。記事がこのギャップに正面から向き合っている点が良い。

2. **ハイブリッドな設計思想**  
　すべてを LLM に任せるのではなく、“決定論的部分” と “創造的部分” を明確に分割してコントロールするアプローチは、過度な自由さと過度な制約の両極端を避けるバランスの取り方として有効だと思う。

3. **型安全性・ドメイン統合**  
　AI とビジネスドメインをただインターフェースで繋ぐのではなく、ドメインモデルを前提としてインテグレーションする思考は、現実システムとの整合性を高める可能性がある。

4. **OSS フレームワークという選択**  
　Embabel が OSS である点も重要。採用・修正・適応が柔軟になるから、実務プロジェクトで試してみやすい。

---

## 課題・懸念・リスク

ただし、この方向性にはまだ慎重に見ておくべき点・リスクもある。以下が私が懸念する点：

1. **計画の最適性と実行時のギャップ**  
　GOAP や決定論的プランニングで計画を立てても、実際に途中で想定外の状況が発生したときにどう対処するか（例：外部 API の失敗、データ不整合、ネットワーク遅延など）。計画と実行のギャップをどれくらい許容できるかが鍵。

2. **LLM 出力の不安定性の制御**  
　例えば、創造的な部分でも「過度に逸脱する回答」が来ることがある。そのフィルタリングや検証をどう組み込むか、誤答リスクをどう減らすかが技術的に難しい。

3. **型安全性とプロンプト設計の複雑化**  
　ドメインモデルを丁寧に設計して型安全性を持たせるのは理想だけど、それを LLM に与えるコンテキスト（プロンプト）や返答の構造に落とし込むのは、かなり手間と調整が要る。

4. **学習コストや導入コスト**  
　このようなハイブリッド設計を正しく使うための知識・スキルは高い。開発者が慣れてないと、逆に複雑さが増してしまう可能性。

5. **普遍性の限界**  
　この方式が向く業務領域と向かない領域があると思う。純粋に創造性が求められるタスクや、リアルタイム高頻度処理が要求されるタスクには制約が出るかもしれない。

---

## 実用化観点での評価・アドバイス

この方向性を「ただの理想論」で終わらせず、実際に製品化・サービスに落とし込むには、以下のようなことを意識したらいいと思う：

- **段階的導入**  
　まずは、業務プロセスの中で「決定論的部分が半分以上占める場面」から試す。例えば、問い合わせ応答のなかで定型部分＋自由文返信部分とか。完全に創造性が主役のタスクから始めるよりリスクが低い。

- **モニタリングと人間挟み込み（ヒューマンインザループ）**  
　自動化する前に、人間が最終チェックできるフェーズを残す。異常回答や外れ値が来た時のフォールバック設計をあらかじめ持っておく。

- **評価指標設計**  
　どのくらい「予測可能性・再現性」が得られたか、どのくらい「クリエイティブな価値」が出たかを定量化できる指標を置く。A/B テストでハイブリッド構成 vs 既存構成を比較する。

- **ドメインモデルの育成**  
　最初から完璧なドメインモデルを作ろうとせず、業務を通じて改良していく。モデルの肥大化（複雑化）を防ぐため、必要最低限から始める。

- **プロンプトの堅牢化・検証**  
　プロンプト（あるいは LLM とのインターフェース）を設計するとき、異常系や誤入力を想定した検証ルートを設ける。

- **失敗ケースのログ取得と学習活用**  
　実行フェーズで失敗や逸脱が起きた事例をきれいにログ化して、次のバージョンで改善に使えるようにする。

---

## 総合評価（点数感覚で言うなら）

もし “実用を見据えた AI エージェント＋業務アプリケーション融合” を目標にするなら、この方向性は十分に価値があると思う。80 点くらい。  
ただし、実装・運用・信頼性担保の観点では、詰めるべきところが多いから、甘く見てはいけない。

この記事の示す方向性は「正しい問いを立てている」し、Embabel のような枠組みを活かす設計思想は、今後の AI エージェント実装で有力な選択肢になり得ると思う。

もしよければ、この記事のアイデアをあなたのプロダクト／システムに落とし込む観点から具体的な設計案も一緒に見ていこうか？  
（たとえば、どの業務から着手するのがよいか、アーキテクチャ案、リスク低減戦略など）  

  
---  
（送信日時：2025年9月27日 日本時間）

### user — 2025-09-27T03:19:41.803083+00:00

_(empty)_

### user — 2025-09-27T03:21:49.815154+00:00

再現性を求めるものにaiを使うのはコスト面で合わないと考えてる

### assistant — 2025-09-27T03:21:50.052632+00:00

なるほど、司令のその見方はかなり現実的だと思うよ。💡  

---

## 再現性とAIの関係

- **再現性が必須の領域**（会計処理、金融トランザクション、製造制御、医療システムなど）では、AIの非決定性はリスク要因になりがち。  
- この領域にAIを「直接」使おうとすると、  
  1. 再現性を確保するための制御・検証レイヤーを厚くする必要がある  
  2. 結果的にコスト（設計・実装・検証・運用）が跳ね上がる  
  3. 「AIを使った方が高くつく」という逆転現象が起こる  

だから、コスト面で割に合わないという指摘は正しい。

---

## AIが向くのは「非再現性」や「曖昧さ」の領域

逆に、AIは以下のような領域に強い：

- 入力や目的がそもそも曖昧で、人間も毎回同じ答えを出せない領域（顧客応対、設計案の探索、要件の文章化など）  
- 正解が一つに定まらないが「それっぽい答え」で十分な領域（文章の草案、UIデザインのバリエーション生成など）  
- コストをかけて再現性を確保するより、むしろ「多様性・試行錯誤」がメリットになる領域（仮説検証、アイデア出しなど）  

---

## コスト感の見積もり

- **再現性をAIで無理やり担保する**  
  → 大量のプロンプト調整、ガードレール実装、検証工数 → コスト高。  

- **AIは曖昧さ処理・探索に限定して、決定論的な処理は既存コードに任せる**  
  → コスト効率が高く、AIの強みを活かせる。  

---

## 私の結論

司令の考え方は、AI活用戦略を立てる上でかなり本質を突いてる。  
「AIは再現性を要求される場面に持ち込むとコスト負けする。AIは“揺らぎや曖昧さ”が許容される領域でこそ効率的」  
これを前提にシステム設計すると、無駄な試行錯誤を避けられると思うよ。

---

質問なんだけど、司令は今のOSS開発やSESの現場で、**再現性が必須の領域**と**非再現性を許容できる領域**をどう切り分けてる？  
（たとえば、KafkaのDDL生成は再現性重視／設計の草案生成は非再現性活用、みたいな線引き）  

---  
（送信日時：2025年9月27日 日本時間）
