---
conversation_id: "68df236b-38d8-8324-801d-2f0620a9461a"
title: "KSQLアップグレードエラー"
create_time: 1759454060.066417
update_time: 1759454262.23942
language_guess: "en"
num_messages: 20
part_index: 1
part_count: 1
---

### user — 2025-10-03T01:13:37.964000+00:00

info: Kafka.Ksql.Linq.KsqlContext[0]
      KSQL DDL (derived bar_tbimp_1m_live): CREATE OR REPLACE TABLE bar_tbimp_1m_live  WITH (KAFKA_TOPIC='bar_tbimp_1m_live', KEY_FORMAT='AVRO', VALUE_FORMAT='AVRO') AS
      SELECT BROKER AS Broker, SYMBOL AS Symbol, WINDOWSTART AS BucketStart, EARLIEST_BY_OFFSET(o.OPEN) AS Open, MAX(o.HIGH) AS High, MIN(o.LOW) AS Low, LATEST_BY_OFFSET(o.CLOSE) AS Close
      FROM bar_tbimp_1s_rows o WINDOW TUMBLING (SIZE 1 MINUTES, GRACE PERIOD 2 SECONDS)
      GROUP BY BROKER, SYMBOL
      EMIT CHANGES;
info: Kafka.Ksql.Linq.KsqlContext[0]
      ksql execute: EXECUTE SQL=CREATE OR REPLACE TABLE bar_tbimp_1m_live  WITH (KAFKA_TOPIC='bar_tbimp_1m_live', KEY_FORMAT='AVRO', VALUE_FORMAT='AVRO'...
fail: Kafka.Ksql.Linq.KsqlContext[0]
      DDL execution failed for Bar: {"@type":"generic_error","error_code":40000,"message":"Upgrades not yet supported for StreamWindowedAggregate"}

### system — 2025-10-03T01:14:20.066417+00:00

_(empty)_

### system — 2025-10-03T01:14:20.066417+00:00

_(empty)_

### assistant — 2025-10-03T01:14:20.857627+00:00

{"search_query": [{"q": "ksqlDB \"Upgrades not yet supported for StreamWindowedAggregate\""}, {"q": "ksqlDB query upgrades not yet supported windowed aggregate"}, {"q": "ksqlDB CREATE OR REPLACE windowed aggregate limitation"}, {"q": "ksqldb upgrades not yet supported for StreamWindowedAggregate site:github.com"}], "response_length": "short"}

### system — 2025-10-03T01:14:22.156654+00:00

_(empty)_

### system — 2025-10-03T01:14:22.159751+00:00

_(empty)_

### assistant — 2025-10-03T01:14:22.161403+00:00

_(empty)_

### assistant — 2025-10-03T01:14:22.449234+00:00

_(empty)_

### tool — 2025-10-03T01:14:31.745189+00:00

_(empty)_

### tool — 2025-10-03T01:14:31.756014+00:00

_(empty)_

### assistant — 2025-10-03T01:14:40.964610+00:00

やあ司令、ログのこれ👇が原因です。

> `Upgrades not yet supported for StreamWindowedAggregate`

ksqlDB は「ウィンドウ付き集計（TUMBLING/HOPPING/SESSION など）」を含む永続クエリに対して **CREATE OR REPLACE（インプレースアップグレード）を未サポート**です。公式にも “windowed や join を含むソース、ならびに table 集計のインプレースアップグレードはまだサポートしていない” と明記されています。citeturn0search1

つまり、`CREATE OR REPLACE TABLE ... WINDOW TUMBLING ...` は構文としては通っても、既存クエリを置き換える段階で上記のエラーになります（類似の “Upgrades not yet supported for StreamStreamJoin” 報告もあります）。citeturn0search3

## 取れる対処パターン（実務向け）

### A) ダウンタイム覚悟で「止めて作り直す」（同一トピック名を維持）
1. 影響するクエリIDを確認  
   `SHOW QUERIES;`
2. 対象を停止  
   `TERMINATE <QUERY_ID>;`
3. シンクのテーブル/トピックを削除（トピック名を再利用するなら必要）  
   `DROP TABLE bar_tbimp_1m_live DELETE TOPIC;`
4. **OR REPLACE を使わずに**再作成  
   ```sql
   CREATE TABLE bar_tbimp_1m_live
   WITH (KAFKA_TOPIC='bar_tbimp_1m_live', KEY_FORMAT='AVRO', VALUE_FORMAT='AVRO') AS
   SELECT BROKER AS Broker, SYMBOL AS Symbol, WINDOWSTART AS BucketStart,
          EARLIEST_BY_OFFSET(o.OPEN)  AS Open,
          MAX(o.HIGH)                 AS High,
          MIN(o.LOW)                  AS Low,
          LATEST_BY_OFFSET(o.CLOSE)   AS Close
   FROM bar_tbimp_1s_rows o
   WINDOW TUMBLING (SIZE 1 MINUTES, GRACE PERIOD 2 SECONDS)
   GROUP BY BROKER, SYMBOL
   EMIT CHANGES;
   ```
> メモ：インプレースアップグレードが効かない以上、この「Terminate→Drop→Create」手順が公式推奨の移行パターンです。citeturn0search1

### B) ブルー/グリーンで「新トピックへ切替」（無停止〜最小停止）
1. 新しい出力先で **別名** を作る（例：`bar_tbimp_1m_live_v2`）。  
   ```sql
   CREATE TABLE bar_tbimp_1m_live_v2
   WITH (KAFKA_TOPIC='bar_tbimp_1m_live_v2', KEY_FORMAT='AVRO', VALUE_FORMAT='AVRO') AS
   ...同じSELECT...
   ```
2. バックフィルが必要なら  
   `SET 'auto.offset.reset'='earliest';` をクエリ作成前に設定して追いつかせる。
3. 消費者を `..._v2` に切替→動作確認。
4. 旧クエリを `TERMINATE`、旧テーブルを `DROP ... DELETE TOPIC` で廃止。

> どうしても**元のトピック名**を最終的に維持したい場合は、切替完了後に  
> - 一旦停止して A) で作り直す（短時間停止）  
> - もしくはリレープロセス（Kafka Streams/Connect/MirrorMaker）で `..._v2` → 旧名へ転送して消費側の設定を変えずに入替  
> の二択です。インプレースの “REPLACE” ではできません。citeturn0search1turn0search3

## 補足（ハマりどころ）
- **Windowed-Key の可視化**：`KEY_FORMAT='AVRO'` のウィンドウ付き TABLE はキーに window 情報を含むため、外部コンシューマがそのままデシリアライズできないことがあります。外部配信を簡単にしたい場合は、最終出力用に「値側へ `BucketStart/End` を展開したシンプル key の STREAM/TABLE」を別途用意して出すのが安全です（内部 state store と changelog の都合に依存しにくくなるため）。背景として、windowed テーブルやその二次加工には制約が多いことが長年 issue でも議論されています。citeturn0search6turn0search7

- **内部トピックのクリーンアップ**：`DROP ... DELETE TOPIC` はシンクトピックを消しますが、内部の `-changelog` / `-repartition` はクエリ停止・再作成で再生成されます。容量や命名衝突に注意。運用指針は公式の容量計画ドキュメントも参照。citeturn0search8

---

### 結論
このエラーは不具合ではなく**仕様**です。`CREATE OR REPLACE` をウィンドウ集計に対して使わず、**Terminate→Drop→Create** か **ブルー/グリーン** のどちらかで移行してください。詳しい移行手順や “安全な差し替え計画” を一緒に固めることもできますよ。citeturn0search1

送信時刻（JST）：[[REDACTED_PHONE]]:14:40

### assistant — 2025-10-03T01:14:45.856179+00:00

_(empty)_

### user — 2025-10-03T01:15:02.520028+00:00

_(empty)_

### user — 2025-10-03T01:16:51.992000+00:00

テスト間で同じトピック名を使いまわしてる

### assistant — 2025-10-03T01:16:52.551942+00:00

了解。**同じトピック名の使い回し**は、ksqlDB と Kafka の状態が残って**テスト間で干渉**しやすいです（内部 `-changelog/-repartition`、offset、Schema Registry subjects、クエリID など）。実務では次のどちらかに寄せるのが安定です。

# 方針1（推奨）：テストごとに一意トピック
- 例：`bar_tbimp_1m_live_{RunId}_{TestName}_{Guid:N}`  
- **並列実行**にも強い／クリーンアップ失敗の影響が次テストに波及しない。
- 生成・破棄は **Fixture/Factory** に寄せ、Dispose で確実に削除。

### .NET最小例（要点）
```csharp
static string NewTopic(string baseName) 
    => $"{baseName}_{DateTime.UtcNow:yyyyMMddHHmmss}_{Guid.NewGuid():N}".ToLowerInvariant();

using var admin = new AdminClientBuilder(new AdminClientConfig { BootstrapServers = "localhost:9092" }).Build();
var topic = NewTopic("bar_tbimp_1m_live");
await admin.CreateTopicsAsync(new[] { new TopicSpecification { Name = topic, NumPartitions = 3, ReplicationFactor = 1 } });

// …テスト本体…

await admin.DeleteTopicsAsync(new[] { topic });
// 削除完了待ち（Describeで存在確認ループ or 一定のbackoff付sleep）
```

### ksqlDB 側（永続クエリを使う場合）
- `CREATE TABLE/STREAM ... WITH (KAFKA_TOPIC='<unique>') AS SELECT ...`
- テスト終了時：`TERMINATE <QUERY_ID>; DROP TABLE/STREAM <name> DELETE TOPIC;`
- **待機を入れる**：Kafka が実際にトピック削除を完了→`DescribeTopics`で「NotFound」になるまでポーリング。

---

# 方針2：同じトピック名を再利用（非推奨・やるなら厳密手順）
**順序が肝心**。どれかが漏れると古い状態が“残留”します。

1) **ksqlDB の永続クエリ停止**  
`SHOW QUERIES;` → 対象 `TERMINATE <QUERY_ID>;`

2) **シンクと中間オブジェクトを DROP**  
`DROP TABLE/STREAM <name> DELETE TOPIC;`  
（可能なら、関連する**すべて**の生成物を落とす）

3) **Schema Registry の Subject を削除**  
- 例：`DELETE /subjects/<topic>-value?permanent=true` 等  
- 互換性チェックで引っかかるのを防ぐ（テストでは “permanent” で掃除してしまうのが手っ取り早い）

4) **Kafkaトピック削除と確定待ち**  
AdminClient で `DeleteTopicsAsync` → `DescribeTopics` で **存在しない** ことを確認するまで待機（一定回数＋指数バックオフ）。

5) **コンシューマの offset をリセット or グループIDを替える**  
- 再利用時は `group.id` を一意化するか、`kafka-consumer-groups --reset-offsets` 相当の処理を実施。
- ksqlDB 側も `SET 'auto.offset.reset'='earliest';` を作成前に設定。

6) **一貫した再作成**  
**`CREATE`（OR REPLACE は使わない）**で作り直し。ウィンドウ集計は `OR REPLACE` 非対応のため。

> 備考：
> - **並列テストは禁止**（xUnit なら Collection でシリアライズ）か、トピックを分ける。
> - **Kafka Streams の `application.id`**（使っている場合）も一意にする。衝突すると内部 state が競合。

---

## ありがちな不具合チェック
- **Upgrades not yet supported for StreamWindowedAggregate**：`OR REPLACE` 禁止。Terminate→Drop→Create。
- **Schema Registry 互換性エラー**：Subject 残骸。テストでは削除で解決。
- **古い offset を拾う**：`group.id` 使い回し。新しい `group.id` か offset リセット。
- **トピック削除が未完了**：ブローカー側で実削除が遅延しがち。**Describe で未存在を確認**してから次に進む。
- **内部トピック残り**：クエリ停止前に DROP しても残る場合がある→クエリを先に `TERMINATE`。

---

## 結論
- 最も安全で速いのは**「テストごと一意トピック＋確実なDispose」**。
- 同名再利用は**厳密なクリーンアップ順序＋待機**が必要で、並列実行には不向き。

必要なら、xUnit 用の **TopicFixture**（生成・削除・Schema Registry cleanup・ksql REST 連携一式）をこちらで用意します。  

送信時刻（JST）：[[REDACTED_PHONE]]:26

### system — 2025-10-03T01:16:54.140639+00:00

_(empty)_

### system — 2025-10-03T01:16:54.145883+00:00

_(empty)_

### assistant — 2025-10-03T01:16:54.289850+00:00

_(empty)_

### assistant — 2025-10-03T01:17:03.708075+00:00

_(empty)_
