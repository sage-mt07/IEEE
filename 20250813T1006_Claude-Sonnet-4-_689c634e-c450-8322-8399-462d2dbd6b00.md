---
conversation_id: "689c634e-c450-8322-8399-462d2dbd6b00"
title: "Claude Sonnet 4 読み込み能力"
create_time: 1755079596.574471
update_time: 1755163551.77174
language_guess: "en"
num_messages: 15
part_index: 1
part_count: 1
---

### user — 2025-08-13T10:06:36.098008+00:00

Claude sonnet 4が100万トークンに対応した
20ｋステップのソース一度に読める?

### assistant — 2025-08-13T10:06:36.233540+00:00

_(empty)_

### assistant — 2025-08-13T10:06:36.248722+00:00

"Claude sonnet 4\u304c100\u4e07\u30c8\u30fc\u30af\u30f3\u306b\u5bfe\u5fdc\u3057\u305f\n20\uff4b\u30b9\u30c6\u30c3\u30d7\u306e\u30bd\u30fc\u30b9\u4e00\u5ea6\u306b\u8aad\u3081\u308b?"

### system — 2025-08-13T10:06:36.433506+00:00

_(empty)_

### system — 2025-08-13T10:06:36.574471+00:00

_(empty)_

### user — 2025-08-13T10:06:36.574471+00:00

_(empty)_

### system — 2025-08-13T10:06:36.574471+00:00

_(empty)_

### tool — 2025-08-13T10:06:38.670542+00:00

_(empty)_

### assistant — 2025-08-13T10:06:39.868689+00:00

2025年8月13日 20:00（日本時間）

---

はい、**Claude Sonnet 4**（2025年5月にリリース）は、**最大で100万トークン（1 Mトークン）**のコンテキストを扱えるようになりました。これはこれまでの5倍の容量となります citeturn0search1turn0news17。

この大規模コンテキスト対応は現在、**Anthropic APIのパブリックベータ**として提供されており、**Tier 4またはカスタムレート制限契約を持つエンタープライズ開発者**向けに先行提供中で、**Amazon Bedrock**でもすでに利用可能です（**Google Cloud Vertex AI**では近日中に対応予定）citeturn0search1turn0search16turn0news17turn0search9。

---

## 「20kステップのソースを一度に読めるか？」について

おそらく、**20kステップ**とは「20,000 行程度のソースコード（コードステップ）」を指しているかと思います。

- 100万トークンで扱えるコード量は、おおよそ**75,000 行以上のコードベース**に相当するとの情報があります citeturn0news17turn0search16。
- 一般的なソースファイルで、1 行が約10～20 トークン程度と仮定しても、**20,000 行**なら余裕で収まります。

したがって、**20kステップのソースを一度に読み込むことは十分可能**です。

---

### まとめ

| 項目 | 内容 |
|------|------|
| **1Mトークン対応** | 5倍拡張により、最大1,000,000トークンのコンテキストが可能。APIおよびBedrockでパブリックベータとして提供中（Vertex AIは準備中） citeturn0search1turn0news17turn0search16turn0search9 |
| **必要な行数** | 20,000行のコード（20kステップ）は、充分に読み込める容量。実際には75,000行以上も余裕あり citeturn0news17turn0search16 |

---

ご質問ありがとうございました。他にもモデルの詳細や使い方について気になることがあれば、いつでもお気軽にどうぞ！

### user — 2025-08-14T09:24:29.948846+00:00

普通のcladeの仕様は変わってなかった

### system — 2025-08-14T09:24:30.069829+00:00

_(empty)_

### assistant — 2025-08-14T09:24:30.091376+00:00

2025年8月13日 20:04（日本時間）  

---

はい、その通りです。  
今回の **1Mトークン対応は「Claude Sonnet 4」のベータ版専用機能**で、  
通常の Claude（例えば Sonnet 3.5、Opus 3.5、Haiku 3.5 など）の仕様は変更されていません。

- **通常版 Claude** の最大コンテキスト長は現状のまま（例えば Sonnet 3.5 は20万トークン）。
- **1Mコンテキスト**は API/Bedrock 上の「Claude Sonnet 4（ベータ）」でのみ利用可能。  
  Vertex AIは近日対応予定。
- 無料プランや標準的なClaude利用では1Mトークンは使えません。

つまり、今までのClaude環境では変化なしで、今回の拡張はあくまで**限定提供**ですね。  

---

もし希望があれば、この **1Mトークン版Sonnet 4** を使って、あなたのOSSの全コードを一括解析する構成案を出すこともできます。  
これは20k行どころか、リポジトリ丸ごと渡しても扱えるレベルです。

### user — 2025-08-14T09:25:42.685346+00:00

これだけのコンテキストサイズがあれば暴走は防げると思う?

### assistant — 2025-08-14T09:25:42.776156+00:00

2025年8月13日 20:08（日本時間）  

---

正直に言うと、**1Mトークンの巨大コンテキストがあっても「暴走」は完全には防げません**。  
ただし、暴走の原因の**一部**は確実に減らせます。

---

## 1Mコンテキストで防げるもの
- **前後関係を忘れて筋がズレる**現象（コンテキスト切れによる誤解）
- 会話やコードの一部しか読めずに**設計方針を誤解する**
- 長いソース解析で、途中から**命名規約や方針が変わってしまう**問題  
  → 全仕様・全コードを1回で読み込めるため、一貫性維持がしやすい

---

## それでも防げない暴走の原因
- **推論の方向性そのものの誤り**  
  例：仕様理解はできていても、論理飛躍や不要な創作をしてしまう
- **曖昧な指示やゴール設定**による迷走  
  → コンテキストに全情報があっても「どこをどう変えるべきか」が曖昧だと暴走
- **確率的生成のブレ**（LLM特有の出力揺れ）
- **モデルの内部バイアスや学習データ由来の癖**  
  → 例えば安全寄りに極端な回避をする、逆に創作過剰になる等

---

## 結論
- **コンテキスト不足由来の暴走は大幅に減る**
- ただし、「推論の方向性」と「指示の明確さ」が残る限り、ゼロにはならない  
- 完全防止には、  
  - ゴールと制約条件を明確化  
  - 中間出力レビュー（人間チェック）  
  - ステップ分割（段階的実行）  
  が依然として必要

---

これ、もし希望があれば  
**「1Mトークンを最大限使っても暴走しないAI指示テンプレ」** を作って渡せます。  
これを使えば、OSS全体レビューでも方向ブレをかなり抑えられます。
