---
conversation_id: "68c20449-b3f8-8332-9ac7-f0578ebf8672"
title: "デッドコード整理方法"
create_time: 1757545659.685319
update_time: 1757548032.927599
language_guess: "en"
num_messages: 22
part_index: 1
part_count: 1
---

### user — 2025-09-10T23:07:39.317048+00:00

足のutが安定した
前の設計から要素をシンプルにした成果と考える
あとはデッドコードの整理
この整理方法教えて

### system — 2025-09-10T23:07:39.685319+00:00

_(empty)_

### system — 2025-09-10T23:07:39.685319+00:00

_(empty)_

### user — 2025-09-10T23:07:39.685319+00:00

_(empty)_

### system — 2025-09-10T23:07:39.685319+00:00

_(empty)_

### system — 2025-09-10T23:07:42.265562+00:00

_(empty)_

### system — 2025-09-10T23:07:42.270188+00:00

_(empty)_

### assistant — 2025-09-10T23:07:42.284672+00:00

_(empty)_

### assistant — 2025-09-10T23:07:43.219537+00:00

_(empty)_

### assistant — 2025-09-10T23:07:54.319649+00:00

やったね司令！UTが安定したのは大きい🎉  
ここからのデッドコード整理は「壊さず・戻らず・増やさず」の三原則でいきましょう。.NET（C#）前提で、実務で回しやすい手順を最短コースに絞って置いておきます。

# デッドコード整理の実務レシピ（安全重視・段階撤去）

## 0) ブランチとスナップショット
- `feat/cleanup-deadcode-YYYYMMDD` を切る  
- 直近の公開API状態を「固定化」：Public APIスナップショットテストを作る（例：PublicApiGeneratorで `*.PublicApi.approved.txt` を置く）。これが“外部互換性の地雷探知機”になります。

## 1) コンパイラ＆アナライザで「消しても平気」候補を出す
- ビルドを厳格化：
  - `Directory.Build.props`（またはcsproj）に入れる  
    ```xml
    <PropertyGroup>
      <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
      <WarningsNotAsErrors>CS1591</WarningsNotAsErrors><!-- ドキュコメント系は除外可 -->
      <AnalysisLevel>latest</AnalysisLevel>
      <EnforceCodeStyleInBuild>true</EnforceCodeStyleInBuild>
    </PropertyGroup>
    ```
- NuGetアナライザ（例）を追加：  
  - `Microsoft.CodeAnalysis.NetAnalyzers`（公式）  
  - `Roslynator.Analyzers`（未使用メンバー/式の検出が強い）
- 重要ルール（代表例）
  - `IDE0051` 未使用のプライベートメンバー  
  - `IDE0052` 書き込まれるが読み取られないプライベートフィールド  
  - `CA1811` 参照されていないプライベートメンバー  
  - `CA1823` 参照されていないプライベートフィールド  
- `dotnet build` で赤くなる “未使用” を**自動修正できるものから**消す（`dotnet format analyzers` も有効）。

## 2) カバレッジで「永遠に触れられていない経路」を洗う
- `dotnet test /p:CollectCoverage=true /p:CoverletOutputFormat=cobertura`
- `reportgenerator` でHTML化して “行単位の死蔵” を見る  
  - **注意**：カバレッジは“死んで見えるけど反射/ソース生成/DIで生きている”ことがある。下の“反射・公開APIチェック”と突き合わせる。

## 3) 参照グラフの目視（プロジェクト/名前空間レベル）
- “使われていないプロジェクト/フォルダ/名前空間”を先に落とすと効果大。  
- `*.Tests` からも参照されていない `Feature/*` などは優先候補。  
- **まず内部（internal/private）から削る**。publicは後回し。

## 4) 反射・ソース生成・外部スクリプトで使われるものを「誤爆防止マーク」
- ksqlDB DSLは**属性や命名規約、リフレクション**が多いはず。以下のどれかに該当するものは“保護”して先に外すのを避ける：
  - ランタイムで `Type.GetType(...)` / `Activator.CreateInstance(...)` / `GetMethod(...)` している対象
  - ソースジェネレーター / T4 / 動的ロードが触る型・メンバー
  - `InternalsVisibleTo` でTestsから叩かれるinternal
- 必要に応じて一時的に `[Obsolete("Remove in vX.Y", error:false)]` を**public APIにだけ**付けて「予告非推奨」→次のマイルストーンで削除。

## 5) 小刻みに削除 → フルテスト → 物理テスト（ksqldb）→ API差分検証
- 単位：
  1. **内部メンバー/内部型**削除 → `dotnet test`（ユニット）  
  2. **物理/統合テスト**（ksqldb環境）を短縮ターンで通す  
  3. **Public APIスナップショット**差分を確認  
- 1PRあたり削除量を絞り、レビュアが「意図」が読みやすい差分にする。

## 6) CIで“再発防止ゲート”を立てる
- `dotnet format analyzers --verify-no-changes` をCIに追加（未使用メンバー再流入をブロック）  
- カバレッジの**最低ライン**を設定（例：`Statement 70%`）。ただし数値に縛られすぎず“死蔵の温床を減らす”目的で。  
- Public APIスナップショットをCIでチェックして**互換性破壊の混入を検知**。

## 7) 目に見える“ごみ”の仕分けルール
- **コメントアウトされた旧実装**：即削除（Gitが履歴を持つので温存不要）  
- `#if UNUSED`/`#if DEBUG_ONLY` の死蔵ブロック：原則撤去  
- 役割を失った`Helper/Utils`の巨大クラス：**分割→残存参照ゼロ部分を撤去**  
- “将来使うかも”コード：Issue化して**コードからは消す**（戻すときはIssue参照で再導入）

## 8) 公開APIを削るときの“やらかし防止”テンプレ
- **段階廃止**（推奨）  
  1. リリースN： `[Obsolete]` + ドキュメントに代替API記載  
  2. リリースN+1： 実体削除／シャイム（`[EditorBrowsable(Never)]` 追加はNでも可）  
- **代替策の提示**：サンプル/ガイドを先に直す（利用者行動の軌道修正を先行）  
- **セマンティックバージョニング**に沿う（breakingはMINORではなくMAJORで）

---

## 具体的な“最初の1時間”タスクリスト（すぐ動ける形）
1. ブランチ作成 & Public APIスナップショット追加  
2. `Microsoft.CodeAnalysis.NetAnalyzers` と `Roslynator.Analyzers` をソリューションに入れる  
3. `TreatWarningsAsErrors=true` を全プロジェクトへ（ドキュコメント等は除外）  
4. `dotnet format analyzers` → 自動修正で削れる未使用を一掃  
5. `dotnet test`（ユニット）→ OKなら“内部専用の死蔵”を手動削除  
6. 物理テスト（短縮シナリオ）→ OKならPR作成（“内部デッドコード第1弾”）  
7. CIで analyzer 検査と Public API チェックを有効化

---

必要なら、司令のリポジトリ構成に合わせた `.editorconfig` / `Directory.Build.props` の最適化テンプレもすぐ出します。  
「まずは内部→次に公開API」という順番を守れば、リスク最小でスッキリできます。進め方で詰まったら、PRリンクを投げてくれればレビュー観点もつけますね。

—  
送信日時（JST）: [[REDACTED_PHONE]]:07:54

### assistant — 2025-09-10T23:07:55.946436+00:00

_(empty)_

### user — 2025-09-10T23:09:07.216500+00:00

Codexに依頼出来る?

### system — 2025-09-10T23:09:07.409659+00:00

_(empty)_

### assistant — 2025-09-10T23:09:07.439732+00:00

もちろんCodexに依頼できますよ😊  

やり方のイメージはこんな流れです：

1. **整理方針を決める**  
   - 「内部専用（private/internal）の未使用コードを削除」  
   - 「Public APIは `[Obsolete]` 化から段階撤去」  
   - 「テストカバレッジ未達部分を候補にする」  
   こういうルールをプロンプトの冒頭で伝えておくとCodexが迷いません。

2. **タスク指示として書く**  
   例：
   ```
   # Task
   デッドコード整理をしてください。

   # 方針
   - 未使用の private/internal メンバーは削除
   - コメントアウトされた旧実装は削除
   - 将来使う予定のものは Issue 化しコードから削除
   - Public API は削除せず [Obsolete] を付与
   - CIで Roslynator/Analyzers に従う

   # 対象
   src/ 以下の全プロジェクト
   ```

3. **Codexにやってもらう単位**  
   - *小さく*: 「まず Builders フォルダのみ」などスコープを区切る  
   - *逐次レビュー*: 生成PRを司令がレビューして、次の範囲に進める  
   - *テスト実行*: 削除後は必ず `dotnet test` が通ることを要求

4. **差分の記録**  
   - PRレビュー運用フロー（79で決めたもの）に沿って、リンクを天城に投げてもらえればレビュー観点を用意できます。

---

Codexへの依頼文は「要件定義書」みたいに短く・はっきり・機械的に書くのがコツです。曖昧に「いらないコードを消して」とすると、反射やDSLで実際に使ってる部分まで削られるリスクがあります⚠️  

もし望むなら、私がCodex向けのプロンプト雛形を整理してお渡しできますけど、どうしますか？  

—  
送信日時（JST）: [[REDACTED_PHONE]]:02:12

### system — 2025-09-10T23:09:07.539138+00:00

_(empty)_

### user — 2025-09-10T23:46:35.823059+00:00

Codex cliのlimitもそろそろ終わるので物理テスト再開

### system — 2025-09-10T23:46:39.505802+00:00

_(empty)_

### system — 2025-09-10T23:46:39.511831+00:00

_(empty)_

### assistant — 2025-09-10T23:46:39.744100+00:00

_(empty)_

### assistant — 2025-09-10T23:46:47.615384+00:00

いいね司令、ちょうど切り替えどき！  
**Codex CLI の制限が明けたら “短時間で再現性を取り戻す” 物理テスト再開プレイブック**を置きます。最小の手数で環境の揺れ（特にトランザクション／フェンシング）を潰しつつ回せる形です。

# 物理テスト再開プレイブック（最短コース）

## 0) 本番前の前準備（1回だけ）
- **単一インスタンス原則**：ksqlDB・Kafka が複数立ち上がっていないことを確認（フェンシング回避）。
- **識別子を固定**：`KSQL_KSQL_SERVICE_ID` を `ksql_svc_1` 等で固定。  
  （過去の “Producer with transactionalId 'ksql_service_1' … fenced” を踏まえ、**同一IDの多重起動**を確実に排除）
- **State/Volume の掃除ショートカット**：環境が怪しくなったら迷わず実行  
  ```bash
  docker compose down -v
  docker volume prune -f
  docker compose up -d
  ```

## 1) スモーク（15分で整合性を確認）
1. **起動＆ヘルス**
   ```bash
   docker compose ps
   docker logs ksqldb --tail=200
   ```
2. **ksqlDB API 疎通**（PowerShell例・司令の既存ワンライナーに準拠）
   ```powershell
   $h=@{ "Content-Type"="application/vnd.ksql.v1+json; charset=utf-8" }
   (Invoke-RestMethod -Method POST -Uri "http://localhost:8088/ksql" -Headers $h -Body '{"ksql":"SHOW TABLES;","streamsProperties":{}}').tables
   (Invoke-RestMethod -Method POST -Uri "http://localhost:8088/ksql" -Headers $h -Body '{"ksql":"SHOW STREAMS;","streamsProperties":{}}').streams
   ```
3. **存在確認クエリ**（作成済みの対象を1つ選ぶ）
   ```powershell
   $q='{"ksql":"DESCRIBE EXTENDED bar_1m_live;","streamsProperties":{}}'
   Invoke-RestMethod -Method POST -Uri "http://localhost:8088/ksql" -Headers $h -Body $q
   ```
4. **短時間のライブ読み出し**
   ```powershell
   $q='{"ksql":"SELECT * FROM bar_1m_live EMIT CHANGES LIMIT 5;","streamsProperties":{}}'
   Invoke-RestMethod -Method POST -Uri "http://localhost:8088/query" -Headers $h -Body $q
   ```

## 2) “足” 物理テストのショートコース（30–45分）
- **テスト粒度**：Raw→1s_final→上位Live（or Final）を **1系統だけ** 先に通す  
  （全系統を一気にやらず、**1本を確実に合格**させてから拡張）
- **投入データの固定**：乱数は禁止。**固定CSV/JSON**の最少セットを投入して期待値を“固定化”。
- **期待値の検証**：  
  - 1s_final：遅延取り込み後の確定値が1つに収束すること  
  - 上位Live：`WINDOWSTART`（= BucketStart）で1s_finalから正しくロールアップされること  
  - OHLC が **同じ入力**に対して常に同値（flaky防止）

（例）最小データ投入（Kafka CLI）
```bash
# テスト用トピックは毎回消して作る
kafka-topics --bootstrap-server localhost:9092 --delete --topic bars_raw || true
kafka-topics --bootstrap-server localhost:9092 --create --topic bars_raw --replication-factor 1 --partitions 1

# 固定メッセージを投入（キーは Broker+Symbol、時間は固定刻み）
kafka-console-producer --bootstrap-server localhost:9092 --topic bars_raw <<'EOF'
{"broker":"X","symbol":"USDJPY","ts":[[REDACTED_PHONE]],"bid":150.10}
{"broker":"X","symbol":"USDJPY","ts":[[REDACTED_PHONE]],"bid":150.12}
{"broker":"X","symbol":"USDJPY","ts":[[REDACTED_PHONE]],"bid":150.08}
EOF
```

## 3) よくある詰まりを**先に**潰す
- **フェンシング**：  
  - 原因：同一 `transactional.id` を複数プロセスで使用。  
  - 対策：**単一ksqlDB**、`KSQL_KSQL_SERVICE_ID` 固定、古いコンテナ停止、**State/Transaction の掃除→再起動**。
- **キー列の解釈違い**：  
  - `GROUP BY O.KEY` ではなく **`GROUP BY BROKER, SYMBOL`**（key structでない場合）。  
- **1分足の親問題**：  
  - “上位Liveの親を常に `_1m_live` に固定”する設計は、**1mを常に用意**してから上げる（最初は1mと5mだけでOK）。

## 4) Codex CLI への依頼テンプレ（物理テスト用）
> **目的**  
> 物理テストのショートコースを安定実行できるように、環境リセット→固定データ投入→検証→後始末までをスクリプト化してください。  
> 
> **要件**  
> - Docker Compose の `down -v` → `up -d` を含む **再現可能なリセット**  
> - ksqlDB APIで `SHOW TABLES/STREAMS` と `DESCRIBE EXTENDED` を叩く PowerShell スクリプト  
> - Kafka CLI で固定サンプルを投入（Raw → 1s_final → 1m_live まで検証）  
> - `SELECT ... EMIT CHANGES LIMIT 5` で目視しやすい出力  
> - 後始末（テスト用トピック削除）  
> - 1コマンド（例：`.\scripts\physical_smoke.ps1`）で通せること  
> 
> **制約/注意**  
> - 複数インスタンスを立てない。`KSQL_KSQL_SERVICE_ID` を固定。  
> - transactional/fencing が出たら自動で “再試行前に down -v” を走らせてからリトライ。  
> - ランダムデータは使わない。**期待値が固定**される投入のみ。  
> 
> **成果物**  
> - `scripts/physical_smoke.ps1`  
> - `scripts/seed/bars_raw.jsonl`（固定データ）  
> - `docs/physical_test_minimum.md`（実行手順と期待値）

## 5) 短期運用ルール
- **毎回同じデータで比較**（回帰検出が容易）  
- **1PR＝1削除/1修正テーマ**（差分を細く）  
- **結果ログを保存**：`artifacts/physical/<timestamp>/` にAPI応答とクエリ結果を保存

---

必要なら `physical_smoke.ps1` の雛形も書きます。まずはショートコース1本を**必ず緑**にしてから、5m/15m…へ拡張しましょう。進めながらPRリンクを投げてもらえれば、レビュー観点（特にフェンシングとキー扱い）を付けます。

—  
送信日時（JST）: [[REDACTED_PHONE]]:46:47

### assistant — 2025-09-10T23:46:51.178785+00:00

_(empty)_
