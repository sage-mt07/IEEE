---
conversation_id: "68d3e543-1718-8323-b60c-0eab884894c2"
title: "ソース不具合検出提案"
create_time: 1758717282.960357
update_time: 1758717547.448028
language_guess: "en"
num_messages: 17
part_index: 1
part_count: 1
---

### system — 2025-09-24T12:34:42.960357+00:00

_(empty)_

### user — 2025-09-24T12:34:42.960357+00:00

_(empty)_

### system — 2025-09-24T12:34:42.960357+00:00

_(empty)_

### assistant — 2025-09-24T12:34:43.771352+00:00

ほんとにそうですね — 昔なら数時間〜数日掛かって掘り下げていた不具合が、今はツールとAIの組合せで一瞬で発見できる。隔世の感があります。  

簡単に使える“実利”的な武器をざっと挙げます（あなたの現場向けにカスタム提案もできます）:

- 静的解析／コンパイラ拡張: Roslyn アナライザやStyleCopで設計違反やヌル参照を自動検出。  
- 型と契約: 厳密な型（nullable 有効化）＋明示的契約（Guard/Code Contracts）でクラス境界の誤用を減らす。  
- テスト自動化: 単体テスト＋統合テストを CI に組み込み、テスト生成（AI補助）でカバレッジを素早く広げる。  
- 変異テスト / ファジング: Stryker.NET やファジングでテストの盲点を露呈させる。  
- CI ガードレール: PR 毎にビルド／テスト／静的解析を必須化。ブレークする前に止める。  
- スキーマ検証: Kafka/Avro の Schema Registry チェックを pre-commit/CI に入れて、フィールド名・キー形式の不整合を即発見。  
- AIでのコードレビュー自動化: Codex／天城スタイルのレビュープロンプトで「変なパターン」「null周り」「例外の取り扱い」を指摘させる。  
- ランタイム監視とテレメトリ: 例外・遅延・不正データの検出アラートで本番の早期発見を支援。

あなたの最近の話題（ksqlDB / Streamiz / Avro / tombstone）を踏まえると、まずは「Schema-Registry 検証 + CI の PR ガード（テスト・静的解析）」を導入するのが費用対効果高めです。必要なら、あなたのリポジトリ向けに以下のどれかをサッと作ります：

1. PR チェック用の GitHub Actions ワークフロー（ビルド・テスト・Roslyn・SchemaCheck）  
2. pre-commit フック（format + schemaチェック + simple static lint）  
3. AIレビュープロンプトのテンプレート（鳴瀬／鏡花スタイルで出すやつ）

どれを先に作るか指定してくれたら、すぐに草案を用意します〜。  

送信日時（日本時間）: [[REDACTED_PHONE]]:00 JST

### user — 2025-09-24T12:34:44.048000+00:00

人のソースの不具合を簡単に検出できるようになったのは隔世の感がある

### system — 2025-09-24T12:34:44.789267+00:00

_(empty)_

### system — 2025-09-24T12:34:44.793188+00:00

_(empty)_

### assistant — 2025-09-24T12:34:44.807998+00:00

_(empty)_

### assistant — 2025-09-24T12:34:44.925943+00:00

_(empty)_

### assistant — 2025-09-24T12:34:57.126380+00:00

_(empty)_

### assistant — 2025-09-24T12:36:45.683635+00:00

やったね、核心まで特定できた👏  
「TUMBLING を使う ksqlDB の *windowed-key* トピックを Streamiz で読むと壊れる」—これを **Streamiz 側の不具合**として切り分け完了、という理解で合っています。

約束どおり、英語で GitHub Issue のドラフト置いておきます（そのまま貼れます）。  
必要なら `Ritu` 名義で出す前提のトーンにしてあります。

---

# 📄 GitHub Issue Draft (English)

**Title**  
`TimeWindowedSerDes with Avro inner serde fails on ksqlDB tumbling-window table topics (windowed keys)`

**Versions**
- `Streamiz.Kafka.Net` **1.7.1**  
- `Streamiz.Kafka.Net.SchemaRegistry.SerDes.Avro` **1.7.1**  
- ksqlDB **7.9.x** (also observed on 7.4.x)  
- Kafka single broker, Schema Registry enabled  
- Default timestamp extractor: `Streamiz.Kafka.Net.Processors.Internal.FailOnInvalidTimestamp`

**Summary**  
When consuming a **tumbling-window** ksqlDB **TABLE** topic produced by `CTAS ... WINDOW TUMBLING (...)` with `KEY_FORMAT='AVRO'`, Streamiz fails to materialize/read records using `TimeWindowedSerDes<GenericRecord>` (Avro inner serde). We frequently see `Windowed key instance is null` and/or deserialization problems around the windowed key bytes. This blocks state-store/rocksdb projection and downstream processing.

**Why this looks like a Streamiz bug**  
- The same topics are consumable from ksqlDB/Kafka Streams Java apps without errors.  
- Our producer side is ksqlDB (CTAS), so the wire format for **Avro windowed keys** should match Kafka Streams’ TimeWindowedSerde with Avro inner serde.  
- Symptoms point to how Streamiz extracts/decodes the **windowed key bytes** and timestamps for state-store keys.

**Likely code path**  
We traced issues to the helper used for store keys:  
`core/State/Helper/WindowKeyHelper.cs` — methods such as:  
- `ExtractStoreKeyBytes(...)` (around lines ~89)  
- `ExtractStoreTimestamp(...)` (around lines ~117)  
- `ExtractStoreKey(...)` / related (around lines ~142)

It appears the logic doesn’t fully align with the bytes layout produced by **ksqlDB’s Avro windowed keys** (original composite key + window start/end). As a result, the inner Avro key is not reconstructed and the `TimeWindowedSerDes` path ends up with a null/invalid key instance.

**Minimal Repro (conceptual)**

1) Define a simple source stream and **tumbling table** in ksqlDB:

```sql
CREATE OR REPLACE STREAM ticks_tbimp (
  Broker VARCHAR KEY,
  Symbol VARCHAR KEY,
  TimestampUtc TIMESTAMP,
  Bid DECIMAL(18,2)
) WITH (
  KAFKA_TOPIC='ticks_tbimp',
  KEY_FORMAT='AVRO',
  VALUE_FORMAT='AVRO',
  TIMESTAMP='TimestampUtc',
  PARTITIONS=1,
  REPLICAS=1
);

CREATE TABLE bar_tbimp_1m_live WITH (
  KAFKA_TOPIC='bar_tbimp_1m_live',
  KEY_FORMAT='AVRO',
  VALUE_FORMAT='AVRO'
) AS
SELECT
  o.BROKER AS Broker,
  o.SYMBOL AS Symbol,
  WINDOWSTART AS BucketStart,
  EARLIEST_BY_OFFSET(o.BID) AS Open,
  MAX(o.BID) AS High,
  MIN(o.BID) AS Low,
  LATEST_BY_OFFSET(o.BID) AS Close
FROM ticks_tbimp o
WINDOW TUMBLING (SIZE 1 MINUTES, GRACE PERIOD 2 SECONDS)
GROUP BY o.BROKER, o.SYMBOL
EMIT CHANGES;
```

2) In a Streamiz app, consume `bar_tbimp_1m_live` with **windowed key** using Avro inner serde:

```csharp
var builder = new StreamBuilder();

var keyInner = new SchemaAvroSerDes<GenericRecord>(); // inner Avro serde
var keySerde = new TimeWindowedSerDes<GenericRecord>(keyInner, /*windowSizeMs*/ 60_000);

var valueSerde = new SchemaAvroSerDes<GenericRecord>();

builder.Stream<Windowed<GenericRecord>, GenericRecord>("bar_tbimp_1m_live", keySerde, valueSerde)
       .Peek((k,v) => Console.WriteLine("got one"));
```

**Actual behavior**  
- Intermittent/null keys: `InvalidOperationException: Windowed key instance is null.`  
- Downstream mapping/materialization fails; local RocksDB store not populated.

**Expected behavior**  
- Keys should deserialize into `Windowed<GenericRecord>` where `GenericRecord` contains `Broker`, `Symbol` (matching the Avro key schema), and window bounds should be properly available from the wrapper/window.  
- No null keys for non-tombstone records. Tombstones should be handled gracefully.

**Notes on tombstones**  
- We do see tombstones from ksqlDB during topology churn; we set deserialization exception handling to log-and-continue. Even after filtering, the core failure persists on non-tombstone records, so tombstones are **not** the root cause.

**Hypotheses / Where to look**  
- The **windowed-key byte layout** for Avro (as emitted by ksqlDB/Kafka Streams) may not match what `WindowKeyHelper` assumes when extracting store keys and timestamps.  
- The helper may be tailored to a different inner-serde or expects KAFKA/STRING inner keys rather than **Avro record** keys.  
- Any **uppercase/lowercase** field-name normalization or schema-fullname handling differences between `Schema Registry` key schema and Streamiz’ `GenericRecord` might contribute (ksqlDB often uppercases field names in physical schema).

**Proposed directions / Help wanted**  
1. Verify `WindowKeyHelper` against Kafka Streams’ `TimeWindowedDeserializer` with **Avro** inner serde (ksqlDB format). Ensure the bytes split into: inner-key payload + window start/end (or start only for tumbling), in the correct order and endianness.  
2. Add dedicated tests for *Avro* windowed keys (tumbling), consuming a topic produced by ksqlDB CTAS, asserting `Windowed<GenericRecord>` keys are non-null and match the Schema Registry key record.  
3. Consider exposing a pluggable windowed-key extractor for Avro to avoid tight coupling to one layout.  
4. Ensure null-handling for tombstones short-circuits *before* trying to project windowed keys.

**Workarounds we use today**  
- Avoid assigning the problematic tumbling **TABLE** topics to Streamiz; read upstream non-windowed streams instead.  
- Keep deserialization exception handler to log-and-continue to survive tombstones.  
- When possible, prefer non-Avro keys (STRING/KAFKA) for windowed topics—this is not ideal as we want Avro keys for schema-governed interop.

**We can help**  
Happy to provide a small docker-compose (Kafka + Schema Registry + ksqlDB) and a minimal C# Streamiz repro project if needed, plus example topics and Schema Registry subjects (including `*-key` schemas) that reproduce the null windowed key.

Thanks a lot for Streamiz—fixing this would unlock a clean interop path with ksqlDB tumbling tables using Avro keys.

---

## 次の一手（提案）
- このドラフトで **Issue を起票** → 返信での追加質問に備え、再現用の minimal repo（docker-compose + .csproj）を用意しておきます。  
- 併走策として：テスト系は **“非 windowed (stream)” → “ksqlDB 側で集計”** に寄せ、Streamiz は当面 “non-windowed / changelog 以外” を読み込む構成に限定すると安定します。

必要なら、最小再現用の **docker-compose & Program.cs** もすぐ書き出します。Issue 文面の微調整（担当者名・社名出し・トーン）も言ってください。

---

送信日時（日本時間）: [[REDACTED_PHONE]]:12 JST

### user — 2025-09-24T12:36:46.013000+00:00

今回はTumblingを使用するトピックのstreamiz連携が問題だった
githubからソースをダウンロードし、解析、streamizの問題であることが判明

### system — 2025-09-24T12:36:46.640384+00:00

_(empty)_

### system — 2025-09-24T12:36:46.645426+00:00

_(empty)_

### assistant — 2025-09-24T12:36:47.076906+00:00

_(empty)_

### assistant — 2025-09-24T12:37:27.306217+00:00

_(empty)_
