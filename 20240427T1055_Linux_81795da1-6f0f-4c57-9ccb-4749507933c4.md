---
conversation_id: "81795da1-6f0f-4c57-9ccb-4749507933c4"
title: "Linuxスレッド設定の比較"
create_time: 1714215326.559952
update_time: 1714215769.84578
language_guess: "en"
num_messages: 17
part_index: 1
part_count: 1
---

### system — 2024-04-27T10:55:26.559952+00:00

_(empty)_

### user — 2024-04-27T10:55:26.562015+00:00

.netcoreをlinux上で動作させるときのスレッド数設定についてwindowsと比較して説明

### assistant — 2024-04-27T10:56:15.344061+00:00

_(empty)_

### assistant — 2024-04-27T10:56:15.344353+00:00

.NET Core（現在は.NET 5以降として知られています）をLinuxとWindowsで動作させる際のスレッド数の設定には、いくつかの違いがあります。これらの違いを理解することは、アプリケーションのパフォーマンスを最適化するために重要です。

### 1. デフォルトのスレッドプールの挙動
.NET Coreのスレッドプールは、動作するOSによって異なる挙動を示す場合があります。基本的に、.NET Coreは動的にスレッドプールのスレッド数を調整しますが、OSのスレッド管理方式によって、その調整が異なることがあります。

- **Windows**: Windowsでは、.NET CoreはCLR（Common Language Runtime）を使用し、プロセッサの数に基づいて初期スレッド数を設定します。また、負荷に応じてスレッド数を増やすか減らすことが可能です。
- **Linux**: Linuxでは、スレッドの管理は主にカーネルに依存しています。Linuxの場合、環境変数や特定のAPIを通じてスレッドプールの最大スレッド数を制御することが多く、デフォルトの挙動も異なる場合があります。特に、IO待機やタスクのスケジューリングがLinuxとWindowsで異なるため、スレッドの使用効率に差が出ることがあります。

### 2. 環境変数の活用
Linuxでは、環境変数`COMPlus_ThreadPool_ForceMinWorkerThreads`や`COMPlus_ThreadPool_ForceMaxWorkerThreads`を設定することで、スレッドプールの最小および最大スレッド数を調整できます。これにより、アプリケーションの要求に応じてスレッドプールのサイズをより細かく制御することが可能です。

### 3. スケーリングの違い
LinuxとWindowsの間でスレッドプールのスケーリングの仕方には違いがあり、これは主にOSがスレッドをどのように扱うかに依存します。LinuxはCFS（Completely Fair Scheduler）などのスケジューラを利用しており、多数のスレッドが存在する場合でも公平にCPU時間を割り当てようとします。一方、Windowsは異なるスケジューリングアルゴリズムを使用しており、アプリケーションの応答性やスケーラビリティが異なることがあります。

### 結論
Linux上で.NET Coreを運用する際には、OSのスレッド管理の特性を理解し、適切にスレッドプールの設定を調整することが重要です。特に高負荷なアプリケーションやIOが多いアプリケーションでは、スレッドの管理と最適化がパフォーマンスに直結します。そのため、開発環境と本番環境のOSが異なる場合は、それぞれの環境での挙動をしっかりと検証することが推奨されます。

### user — 2024-04-27T10:57:50.963197+00:00

linux上で動作する.net coreのスレッド数設定方法に関するURL

### assistant — 2024-04-27T10:58:17.815809+00:00

search("Linux .NET Core thread pool settings site:microsoft.com")

### tool — 2024-04-27T10:58:17.820213+00:00

_(empty)_

### assistant — 2024-04-27T10:58:17.824220+00:00

mclick([0, 1, 13])

### tool — 2024-04-27T10:58:17.831528+00:00

* This setting is enabled by default on Windows 11 and later versions, and disabled by default on Windows 10 and earlier versions. For this setting to take effect when enabled, the GC must also be configured to use all CPU groups; for more information, see 【6†GC CPU groups】.

Setting name Values  
runtimeconfig.json N/A N/A  
Environment variable `COMPlus_Thread_UseAllCpuGroups` or `DOTNET_Thread_UseAllCpuGroups` `0` - disabled   
`1` - enabled  

## Assign threads to CPU groups on Windows

  * On machines that have multiple CPU groups and 【7†all CPU groups are being used】, this setting configures whether threads are automatically distributed across CPU groups.
  * When this setting is enabled, new threads are assigned to a CPU group in a way that tries to fully populate a CPU group that is already in use before utilizing a new CPU group.
  * This setting is enabled by default.

Setting name Values  
runtimeconfig.json N/A N/A  
Environment variable `COMPlus_Thread_AssignCpuGroups` or `DOTNET_Thread_AssignCpuGroups` `0` - disabled   
`1` - enabled  

## Minimum threads

  * Specifies the minimum number of threads for the worker thread pool.
  * Corresponds to the 【8†ThreadPool.SetMinThreads】 method.

Setting name Values  
runtimeconfig.json `System.Threading.ThreadPool.MinThreads` An integer that represents the minimum number of threads  
MSBuild property `ThreadPoolMinThreads` An integer that represents the minimum number of threads  
Environment variable N/A N/A  

### Examples

runtimeconfig.json file:

    {
       "runtimeOptions": {
          "configProperties": {
             "System.Threading.ThreadPool.MinThreads": 4
          }
       }
    }

runtimeconfig.template.json file:

    {
       "configProperties": {
          "System.Threading.ThreadPool.MinThreads": 4
       }
    }

Project file:

    <Project Sdk="Microsoft.NET.Sdk">

      <PropertyGroup>
        <ThreadPoolMinThreads>4</ThreadPoolMinThreads>
      </PropertyGroup>

    </Project>

## Maximum threads

  * Specifies the maximum number of threads for the worker thread pool.
  * Corresponds to the 【9†ThreadPool.SetMaxThreads】 method.

Setting name Values  
runtimeconfig.json `System.Threading.ThreadPool.MaxThreads` An integer that represents the maximum number of threads  
MSBuild property `ThreadPoolMaxThreads` An integer that represents the maximum number of threads  
Environment variable N/A N/A  

### Examples

runtimeconfig.json file:

    {
       "runtimeOptions": {
          "configProperties": {
             "System.Threading.ThreadPool.MaxThreads": 20
          }
       }
    }

runtimeconfig.template.json file:

    {
       "configProperties": {
          "System.Threading.ThreadPool.MaxThreads": 20
       }
    }

Project file:

    <Project Sdk="Microsoft.NET.Sdk">

      <PropertyGroup>
        <ThreadPoolMaxThreads>20</ThreadPoolMaxThreads>
      </PropertyGroup>

    </Project>

## Windows thread pool

  * For projects on Windows, configures whether thread pool thread management is delegated to the Windows thread pool.
  * If you omit this setting or the platform is not Windows, the .NET thread pool is used instead.
  * Only applications published with Native AOT on Windows use the Windows thread pool by default, for which you can opt to use the .NET thread pool instead by disabling the config setting.
  * The Windows thread pool may perform better in some cases, such as in cases where the minimum number of threads is configured to a high value, or when the Windows thread pool is already being heavily used by the app. There may also be cases where the .NET thread pool performs better, such as in heavy I/O handling on larger machines. It's advisable to check performance metrics when changing this config setting.
  * Some APIs are not supported when using the Windows thread pool, such as 【8†ThreadPool.SetMinThreads】, 【9†ThreadPool.SetMaxThreads】, and 【10†ThreadPool.BindHandle(SafeHandle)】. Thread pool config settings for minimum and maximum threads are also not effective. An alternative to 【10†ThreadPool.BindHandle(SafeHandle)】 is the 【11†ThreadPoolBoundHandle】 class.

Setting name Values Version introduced  
runtimeconfig.json `System.Threading.ThreadPool.UseWindowsThreadPool` `true` - enabled   
`false` - disabled .NET 8  
MSBuild property `UseWindowsThreadPool` `true` - enabled   
`false` - disabled .NET 8  
Environment variable `DOTNET_ThreadPool_UseWindowsThreadPool` `1` - enabled   
`0` - disabled .NET 8  

### Examples

runtimeconfig.json file:

    {
       "runtimeOptions": {
          "configProperties": {
             "System.Threading.ThreadPool.UseWindowsThreadPool": true
          }
       }
    }

runtimeconfig.template.json file:

    {
       "configProperties": {
          "System.Threading.ThreadPool.UseWindowsThreadPool": true
       }
    }

Project file:

    <Project Sdk="Microsoft.NET.Sdk">

      <PropertyGroup>
        <UseWindowsThreadPool>true</UseWindowsThreadPool>
      </PropertyGroup>

    </Project>

## Thread injection in response to blocking work items

In some cases, the thread pool detects work items that block its threads. To compensate, it injects more threads. In .NET 6+, you can use the following 【12†runtime configuration†github.com】 settings to configure thread injection in response to blocking work items. Currently, these settings take effect only for work items that wait for another task to complete, such as in typical 【13†sync-over-async†devblogs.microsoft.com】 cases.

runtimeconfig.json setting name Description Version introduced  
`System.Threading.ThreadPool.Blocking.ThreadsToAddWithoutDelay_ProcCountFactor` After the thread count based on `MinThreads` is reached, this value (after it is multiplied by the processor count) specifies how many additional threads may be created without a delay. .NET 6  
`System.Threading.ThreadPool.Blocking.ThreadsPerDelayStep_ProcCountFactor` After the thread count based on `ThreadsToAddWithoutDelay` is reached, this value (after it is multiplied by the processor count) specifies after how many threads an additional `DelayStepMs` would be added to the delay before each new thread is created. .NET 6  
`System.Threading.ThreadPool.Blocking.DelayStepMs` After the thread count based on `ThreadsToAddWithoutDelay` is reached, this value specifies how much additional delay to add per `ThreadsPerDelayStep` threads, which would be applied before each new thread is created. .NET 6  
`System.Threading.ThreadPool.Blocking.MaxDelayMs` After the thread count based on `ThreadsToAddWithoutDelay` is reached, this value specifies the max delay to use before each new thread is created. .NET 6  
`System.Threading.ThreadPool.Blocking.IgnoreMemoryUsage` By default, the rate of thread injection in response to blocking is limited by heuristics that determine whether there is sufficient physical memory available. In some situations, it may be preferable to inject threads more quickly even in low-memory situations. You can disable the memory usage heuristics by turning off this switch. .NET 7  

### How the configuration settings take effect

  * After the thread count based on `MinThreads` is reached, up to `ThreadsToAddWithoutDelay` additional threads may be created without a delay.
  * After that, before each additional thread is created, a delay is induced, starting with `DelayStepMs`.
  * For every `ThreadsPerDelayStep` threads that are added with a delay, an additional `DelayStepMs` is added to the delay.
  * The delay may not exceed `MaxDelayMs`.
  * Delays are only induced before creating threads. If threads are already available, they would be released without delay to compensate for blocking work items.
  * Physical memory usage and limits are also used and, beyond a threshold, the system switches to slower thread injection.

### Examples

runtimeconfig.json file:

    {
       "runtimeOptions": {
          "configProperties": {
             "System.Threading.ThreadPool.Blocking.ThreadsToAddWithoutDelay_ProcCountFactor": 5
          }
       }
    }

runtimeconfig.template.json file:

    {
       "configProperties": {
          "System.Threading.ThreadPool.Blocking.ThreadsToAddWithoutDelay_ProcCountFactor": 5
       }
    }

## `AutoreleasePool` for managed threads

This option configures whether each managed thread receives an implicit 【14†NSAutoreleasePool†developer.apple.com】 when running on a supported macOS platform.

Setting name Values Version introduced  
runtimeconfig.json `System.Threading.Thread.EnableAutoreleasePool` `true` or `false` .NET 6  
MSBuild property `AutoreleasePoolSupport` `true` or `false` .NET 6  
Environment variable N/A N/A N/A  

### Examples

runtimeconfig.json file:

    {
       "runtimeOptions": {
          "configProperties": {
             "System.Threading.Thread.EnableAutoreleasePool": true
          }
       }
    }

runtimeconfig.template.json file:

    {
       "configProperties": {
          "System.Threading.Thread.EnableAutoreleasePool": true
       }
    }

Project file:

    <Project Sdk="Microsoft.NET.Sdk">

      <PropertyGroup>
        <AutoreleasePoolSupport>true</AutoreleasePoolSupport>
      </PropertyGroup>

    </Project>

Collaborate with us on GitHub 

The source for this content can be found on GitHub, where you can also create and review issues and pull requests. For more information, see 【15†our contributor guide】. 

[Image 0] [Image 1] 

.NET

Open a documentation issue 【16† Provide product fe

### tool — 2024-04-27T10:58:17.831801+00:00

URL: https://learn.microsoft.com/en-us/dotnet/standard/threading/the-managed-thread-pool
【0†Skip to main content】 

This browser is no longer supported.

Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

【1† Download Microsoft Edge †go.microsoft.com】 【2† More info about Internet Explorer and Microsoft Edge 】 

Table of contents  Exit focus mode

   Read in English Save 【3† †github.com】  

Table of contents   Read in English Save Add to Plan 【3† Edit †github.com】  Print

Twitter LinkedIn Facebook Email

Table of contents

# The managed thread pool

  * Article 
  * 09/15/2021
  * 11 contributors 

   Feedback

## In this article

The 【4†System.Threading.ThreadPool】 class provides your application with a pool of worker threads that are managed by the system, allowing you to concentrate on application tasks rather than thread management. If you have short tasks that require background processing, the managed thread pool is an easy way to take advantage of multiple threads. Use of the thread pool is significantly easier in Framework 4 and later, since you can create 【5†Task】 and 【6†Task<TResult>】 objects that perform asynchronous tasks on thread pool threads.

.NET uses thread pool threads for many purposes, including 【7†Task Parallel Library (TPL)】 operations, asynchronous I/O completion, 【8†timer】 callbacks, registered wait operations, asynchronous method calls using delegates, and 【9†System.Net】 socket connections.

## Thread pool characteristics

Thread pool threads are 【10†background】 threads. Each thread uses the default stack size, runs at the default priority, and is in the multithreaded apartment. Once a thread in the thread pool completes its task, it's returned to a queue of waiting threads. From this moment it can be reused. This reuse enables applications to avoid the cost of creating a new thread for each task.

There is only one thread pool per process.

### Exceptions in thread pool threads

Unhandled exceptions in thread pool threads terminate the process. There are three exceptions to this rule:

  * A 【11†System.Threading.ThreadAbortException】 is thrown in a thread pool thread because 【12†Thread.Abort】 was called.
  * A 【13†System.AppDomainUnloadedException】 is thrown in a thread pool thread because the application domain is being unloaded.
  * The common language runtime or a host process terminates the thread.

For more information, see 【14†Exceptions in Managed Threads】.

### Maximum number of thread pool threads

The number of operations that can be queued to the thread pool is limited only by available memory. However, the thread pool limits the number of threads that can be active in the process simultaneously. If all thread pool threads are busy, additional work items are queued until threads to execute them become available. The default size of the thread pool for a process depends on several factors, such as the size of the virtual address space. A process can call the 【15†ThreadPool.GetMaxThreads】 method to determine the number of threads.

You can control the maximum number of threads by using the 【15†ThreadPool.GetMaxThreads】 and 【16†ThreadPool.SetMaxThreads】 methods.

Note

Code that hosts the common language runtime can set the size using the 【17†ICorThreadpool::CorSetMaxThreads】 method.

### Thread pool minimums

The thread pool provides new worker threads or I/O completion threads on demand until it reaches a specified minimum for each category. You can use the 【18†ThreadPool.GetMinThreads】 method to obtain these minimum values.

Note

When demand is low, the actual number of thread pool threads can fall below the minimum values.

When a minimum is reached, the thread pool can create additional threads or wait until some tasks complete. The thread pool creates and destroys worker threads in order to optimize throughput, which is defined as the number of tasks that complete per unit of time. Too few threads might not make optimal use of available resources, whereas too many threads could increase resource contention.

Caution

You can use the 【19†ThreadPool.SetMinThreads】 method to increase the minimum number of idle threads. However, unnecessarily increasing these values can cause performance problems. If too many tasks start at the same time, all of them might appear to be slow. In most cases the thread pool will perform better with its own algorithm for allocating threads.

## Using the thread pool

The easiest way to use the thread pool is to use the 【7†Task Parallel Library (TPL)】. By default, TPL types like 【5†Task】 and 【6†Task<TResult>】 use thread pool threads to run tasks.

You can also use the thread pool by calling 【20†ThreadPool.QueueUserWorkItem】 from managed code (or 【21†ICorThreadpool::CorQueueUserWorkItem】 from unmanaged code) and passing a 【22†System.Threading.WaitCallback】 delegate representing the method that performs the task.

Another way to use the thread pool is to queue work items that are related to a wait operation by using the 【23†ThreadPool.RegisterWaitForSingleObject】 method and passing a 【24†System.Threading.WaitHandle】 that, when signaled or when timed out, calls the method represented by the 【25†System.Threading.WaitOrTimerCallback】 delegate. Thread pool threads are used to invoke callback methods.

For the examples, check the referenced API pages.

## Skipping security checks

The thread pool also provides the 【26†ThreadPool.UnsafeQueueUserWorkItem】 and 【27†ThreadPool.UnsafeRegisterWaitForSingleObject】 methods. Use these methods only when you are certain that the caller's stack is irrelevant to any security checks performed during the execution of the queued task. 【20†ThreadPool.QueueUserWorkItem】 and 【23†ThreadPool.RegisterWaitForSingleObject】 both capture the caller's stack, which is merged into the stack of the thread pool thread when the thread begins to execute a task. If a security check is required, the entire stack must be checked. Although the check provides safety, it also has a performance cost.

## When not to use thread pool threads

There are several scenarios in which it's appropriate to create and manage your own threads instead of using thread pool threads:

  * You require a foreground thread.
  * You require a thread to have a particular priority.
  * You have tasks that cause the thread to block for long periods of time. The thread pool has a maximum number of threads, so a large number of blocked thread pool threads might prevent tasks from starting.
  * You need to place threads into a single-threaded apartment. All 【4†ThreadPool】 threads are in the multithreaded apartment.
  * You need to have a stable identity associated with the thread, or to dedicate a thread to a task.

## See also

  * 【4†System.Threading.ThreadPool】
  * 【5†System.Threading.Tasks.Task】
  * 【6†System.Threading.Tasks.Task<TResult>】
  * 【7†Task Parallel Library (TPL)】
  * 【28†How to: Return a Value from a Task】
  * 【29†Threading Objects and Features】
  * 【30†Threads and Threading】
  * 【31†Asynchronous File I/O】
  * 【8†Timers】

Collaborate with us on GitHub 

The source for this content can be found on GitHub, where you can also create and review issues and pull requests. For more information, see 【32†our contributor guide】. 

[Image 0] [Image 1] 

.NET

Open a documentation issue 【33† Provide product feedback †aka.ms】 

## Feedback

  Coming soon: Throughout 2024 we will be phasing out GitHub Issues as the feedback mechanism for content and replacing it with a new feedback system. For more information see: 【34†https://aka.ms/ContentUserFeedback†aka.ms】. 

Submit and view feedback for

【33† This product †aka.ms】  This page

【35† View all page feedback †github.com】 

* * *

## Additional resources

【36† California Consumer Privacy Act (CCPA) Opt-Out Icon Your Privacy Choices †aka.ms】 

Theme

  * Light 
  * Dark 
  * High contrast 

  *   * 【37†Previous Versions】
  * 【38†Blog†techcommunity.microsoft.com】
  * 【39†Contribute】
  * 【40†Privacy†go.microsoft.com】
  * 【41†Terms of Use】
  * 【42†Trademarks†www.microsoft.com】
  * © Microsoft 2024

## Additional resources

### In this article

【36† California Consumer Privacy Act (CCPA) Opt-Out Icon Your Privacy Choices †aka.ms】 

Theme

  * Light 
  * Dark 
  * High contrast 

  *   * 【37†Previous Versions】
  * 【38†Blog†techcommunity.microsoft.com】
  * 【39†Contribute】
  * 【40†Privacy†go.microsoft.com】
  * 【41†Terms of Use】
  * 【42†Trademarks†www.microsoft.com】
  * © Microsoft 2024
Visible: 0% - 100%

### tool — 2024-04-27T10:58:17.832042+00:00

}
    }
    // The example displays output like the following:
    //       Main thread does some work, then sleeps.
    //       Hello from the thread pool.
    //       Main thread exits.

    Imports System.Threading

    Public Module Example
        Public Sub Main()
            ' Queue the work for execution.
            ThreadPool.QueueUserWorkItem(AddressOf ThreadProc)

            Console.WriteLine("Main thread does some work, then sleeps.")

            Thread.Sleep(1000)

            Console.WriteLine("Main thread exits.")
        End Sub

        ' This thread procedure performs the task.
        Sub ThreadProc(stateInfo As Object)
            ' No state object was passed to QueueUserWorkItem, so stateInfo is null.
            Console.WriteLine("Hello from the thread pool.")
        End Sub
    End Module
    ' The example displays output like the following:
    '       Main thread does some work, then sleeps.
    '       Hello from the thread pool.
    '       Main thread exits.

If you comment out the call to the 【9†Thread.Sleep】 method, the main thread exits before method runs on the thread pool thread. The thread pool uses background threads, which do not keep the application running if all foreground threads have terminated. (This is a simple example of a race condition.)

## Remarks

Many applications create threads that spend a great deal of time in the sleeping state, waiting for an event to occur. Other threads might enter a sleeping state only to be awakened periodically to poll for a change or update status information. The thread pool enables you to use threads more efficiently by providing your application with a pool of worker threads that are managed by the system. Examples of operations that use thread pool threads include the following:

  * When you create a 【10†Task】 or 【11†Task<TResult>】 object to perform some task asynchronously, by default the task is scheduled to run on a thread pool thread.

  * Asynchronous timers use the thread pool. Thread pool threads execute callbacks from the 【12†System.Threading.Timer】 class and raise events from the 【13†System.Timers.Timer】 class.

  * When you use registered wait handles, a system thread monitors the status of the wait handles. When a wait operation completes, a worker thread from the thread pool executes the corresponding callback function.

  * When you call the 【14†QueueUserWorkItem】 method to queue a method for execution on a thread pool thread. You do this by passing the method a 【15†WaitCallback】 delegate. The delegate has the signature

        void WaitCallback(Object state)

        Sub WaitCallback(state As Object)

where `state` is an object that contains data to be used by the delegate. The actual data can be passed to the delegate by calling the 【16†QueueUserWorkItem(WaitCallback, Object)】 method.

Note

The threads in the managed thread pool are background threads. That is, their 【17†IsBackground】 properties are `true`. This means that a 【18†ThreadPool】 thread will not keep an application running after all foreground threads have exited.

Important

When the thread pool reuses a thread, it does not clear the data in thread local storage or in fields that are marked with the 【19†ThreadStaticAttribute】 attribute. Therefore, when a method examines thread local storage or fields that are marked with the 【19†ThreadStaticAttribute】 attribute, the values it finds might be left over from an earlier use of the thread pool thread.

You can also queue work items that are not related to a wait operation to the thread pool. To request that a work item be handled by a thread in the thread pool, call the 【14†QueueUserWorkItem】 method. This method takes as a parameter a reference to the method or delegate that will be called by the thread selected from the thread pool. There is no way to cancel a work item after it has been queued.

Timer-queue timers and registered wait operations also use the thread pool. Their callback functions are queued to the thread pool.

There is one thread pool per process. Beginning with the .NET Framework 4, the default size of the thread pool for a process depends on several factors, such as the size of the virtual address space. A process can call the 【20†GetMaxThreads】 method to determine the number of threads. The number of threads in the thread pool can be changed by using the 【21†SetMaxThreads】 method. Each thread uses the default stack size and runs at the default priority.

Note

Unmanaged code that hosts the .NET Framework can change the size of the thread pool by using the `CorSetMaxThreads` function, defined in the mscoree.h file.

The thread pool provides new worker threads or I/O completion threads on demand until it reaches the maximum for each category. When a maximum is reached, the thread pool can create additional threads in that category or wait until some tasks complete. Beginning with the .NET Framework 4, the thread pool creates and destroys worker threads in order to optimize throughput, which is defined as the number of tasks that complete per unit of time. Too few threads might not make optimal use of available resources, whereas too many threads could increase resource contention.

Note

When demand is low, the actual number of thread pool threads can fall below the minimum values.

You can use the 【22†GetMinThreads】 method to obtain these minimum values.

Caution

You can use the 【23†SetMinThreads】 method to increase the minimum number of threads. However, unnecessarily increasing these values can cause performance problems. If too many tasks start at the same time, all of them might appear to be slow. In most cases the thread pool will perform better with its own algorithm for allocating threads.

##  Properties 

【24†CompletedWorkItemCount】 

Gets the number of work items that have been processed so far.  

【25†PendingWorkItemCount】 

Gets the number of work items that are currently queued to be processed.  

【26†ThreadCount】 

Gets the number of thread pool threads that currently exist.  

##  Methods 

【27†BindHandle(IntPtr)】 

Obsolete.

Obsolete.

Binds an operating system handle to the 【18†ThreadPool】.  

【28†BindHandle(SafeHandle)】 

Binds an operating system handle to the 【18†ThreadPool】.  

【29†GetAvailableThreads(Int32, Int32)】 

Retrieves the difference between the maximum number of thread pool threads returned by the 【30†GetMaxThreads(Int32, Int32)】 method, and the number currently active.  

【30†GetMaxThreads(Int32, Int32)】 

Retrieves the number of requests to the thread pool that can be active concurrently. All requests above that number remain queued until thread pool threads become available.  

【31†GetMinThreads(Int32, Int32)】 

Retrieves the minimum number of threads the thread pool creates on demand, as new requests are made, before switching to an algorithm for managing thread creation and destruction.  

【32†QueueUserWorkItem(WaitCallback)】 

Queues a method for execution. The method executes when a thread pool thread becomes available.  

【16†QueueUserWorkItem(WaitCallback, Object)】 

Queues a method for execution, and specifies an object containing data to be used by the method. The method executes when a thread pool thread becomes available.  

【33†QueueUserWorkItem<TState>(Action<TState>, TState, Boolean)】 

Queues a method specified by an 【34†Action<T>】 delegate for execution, and provides data to be used by the method. The method executes when a thread pool thread becomes available.  

【35†RegisterWaitForSingleObject(WaitHandle, WaitOrTimerCallback, Object, Int32, Boolean)】 

Registers a delegate to wait for a 【36†WaitHandle】, specifying a 32-bit signed integer for the time-out in milliseconds.  

【37†RegisterWaitForSingleObject(WaitHandle, WaitOrTimerCallback, Object, Int64, Boolean)】 

Registers a delegate to wait for a 【36†WaitHandle】, specifying a 64-bit signed integer for the time-out in milliseconds.  

【38†RegisterWaitForSingleObject(WaitHandle, WaitOrTimerCallback, Object, TimeSpan, Boolean)】 

Registers a delegate to wait for a 【36†WaitHandle】, specifying a 【39†TimeSpan】 value for the time-out.  

【40†RegisterWaitForSingleObject(WaitHandle, WaitOrTimerCallback, Object, UInt32, Boolean)】 

Registers a delegate to wait for a 【36†WaitHandle】, specifying a 32-bit unsigned integer for the time-out in milliseconds.  

【41†SetMaxThreads(Int32, Int32)】 

Sets the number of requests to the thread pool that can be active concurrently. All requests above that number remain queued until thread pool threads become available.  

【42†SetMinThreads(Int32, Int32)】 

Sets the minimum number of threads the thread pool creates on demand, as new requests are made, before switching to an algorithm for managing thread creation and destruction.  

【43†UnsafeQueueNativeOverlapped(NativeOverlapped*)】 

Queues an overlapped I/O operation for execution.  

【44†UnsafeQueueUserWorkItem(IThreadPoolWorkItem, Boolean)】 

Queues the specified work item object to the thread pool.  

【45†UnsafeQueueUserWorkItem(WaitCallback, Object)】 

Queues the specified delegate to the thread pool, but does not propagate the calling stack to the worker thread.  

【46†UnsafeQueueUserWorkItem<TState>(Action<TState>, TState, Boolean)】 

Queues a method specified by an 【34†Action<T>】 delegate for execution, and specifies an object containing data to be used by the me

### assistant — 2024-04-27T10:58:17.832289+00:00

To configure the number of threads in a .NET Core application running on Linux, you can utilize several settings related to the managed thread pool provided by .NET. Here are some key configurations:

1. **Minimum and Maximum Thread Settings**: You can specify the minimum and maximum number of threads for the worker thread pool directly in your `runtimeconfig.json` file. For example, you can set the minimum number of threads to 4 and the maximum to 20 using the `System.Threading.ThreadPool.MinThreads` and `System.Threading.ThreadPool.MaxThreads` settings respectively.

2. **Setting Thread Limits Using Methods**: Alternatively, you can programmatically set these limits using `ThreadPool.SetMinThreads` and `ThreadPool.SetMaxThreads` methods within your application code. This allows dynamic adjustments based on the application's runtime needs.

3. **Environment Variables**: For broader system-level configurations that influence thread behavior across applications, Linux systems also support various environment variables like `COMPlus_ThreadPool_ForceMinWorkerThreads` and `COMPlus_ThreadPool_ForceMaxWorkerThreads`, which can be set to manage thread allocation beyond the scope of a single application.

For more detailed information on configuring the thread pool in .NET applications, you can refer to Microsoft's official documentation here: [Managing the Thread Pool](https://learn.microsoft.com/en-us/dotnet/standard/threading/the-managed-thread-pool).

This guide provides comprehensive details on how to effectively manage thread settings to optimize the performance of your .NET applications on different operating systems, including Linux.

### user — 2024-04-27T11:00:36.074390+00:00

linuxで高頻度の処理を行うマルチスレッドアプリケーションでスレッド数を1000以上に設定するのは適切なのか

### assistant — 2024-04-27T11:01:32.433404+00:00

Linux環境でスレッド数を1000以上に設定することは、一部の非常に特殊なシナリオを除いて、通常は推奨されません。多くのスレッドを生成することは、システムリソースに対する圧力を大幅に増加させ、パフォーマンスの低下や他の問題を引き起こす可能性があります。

### スレッド数の増加による影響
- **リソース消費**: 各スレッドはスタックメモリを消費します。Linuxでは通常、スレッドごとにデフォルトで8MBのスタックスペースが割り当てられます。したがって、1000スレッドを生成すると、約8GBのRAMが必要になります。
- **コンテキストスイッチング**: スレッドが多いほど、OSが各スレッド間でCPUの時間を分割するためのコンテキストスイッチが頻繁に発生します。これにより、システムのオーバーヘッドが増加し、実際の処理時間が減少する可能性があります。
- **スケーラビリティの問題**: 物理的なCPUコアの数がスレッドの数よりも少ない場合、スレッドは効果的に並列実行されません。これは、多くのスレッドが実際にはシリアルに実行されることを意味し、期待されるパフォーマンス向上が得られない可能性があります。

### 適切なスレッド数の設定
- **ハードウェアの能力に合わせる**: システムのCPUコアの数に基づいてスレッド数を決定するのが一般的です。例えば、8コアのCPUでは、各コアに数スレッドを割り当てるのが適切かもしれません。
- **プールメカニズムの利用**: スレッドプールを使用してスレッドの生成と破棄を管理することで、システムリソースをより効率的に使用することができます。スレッドプールは必要に応じてスレッドを再利用し、不要なスレッドを削減します。

### 代替手段
- **非同期プログラミング**: 非同期I/Oやタスクベースの非同期パターンを利用することで、スレッドを減らしつつ効率的にリソースを使用することができます。これにより、I/O操作やネットワークリクエストの待ち時間を有効に活用することが可能です。

スレッドの数を増やす前に、アプリケーションの実際のニーズとシステムのリソースを慎重に評価し、適切なスレッド管理戦略を選択することが重要です。また、プロファイリングツールを使用して、アプリケーションのパフォーマンスを定期的に監視し、必要に応じて調整を行うことをお勧めします。

### user — 2024-04-27T11:01:59.861089+00:00

スループットを向上させる目的でスレッド数を多くしたアプリケーションを配置する方法と、同じアプリケーションを多く配置する方法はいずれがいいのか

### assistant — 2024-04-27T11:02:49.328334+00:00

スループットを向上させるためのアプローチとして、スレッド数を多くする方法と、同じアプリケーションを複数配置する方法がありますが、どちらが適切かはアプリケーションの性質と要件によります。以下はそれぞれの方法の利点と欠点を考慮した概要です。

### スレッド数を多くする方法
スレッド数を増やすことで、マルチタスク処理が可能になり、理論的にはCPUの使用効率が向上します。しかし、以下の点を検討する必要があります。

**利点:**
- 単一のアプリケーションインスタンスでリソースを最大限に活用。
- コンテキストスイッチのコストが、適切なスレッド数で管理された場合、比較的低く抑えられる。

**欠点:**
- スレッド数が多すぎると、スレッド間の競合やコンテキストスイッチングのオーバーヘッドによって性能が逆に低下する可能性がある。
- 物理的なCPUコアの数に限界があるため、スレッドの過多はリソースの浪費につながることがある。

### 同じアプリケーションを複数配置する方法
アプリケーションのインスタンスを複数デプロイすることで、負荷を分散させ、システム全体の耐障害性やスケーラビリティが向上します。

**利点:**
- フェイルオーバーや負荷分散が容易に実装でき、システム全体の可用性が向上する。
- 各インスタンスが独立して動作するため、一部の障害が他のインスタンスに影響を及ぼすことが少ない。

**欠点:**
- リソース（CPU、メモリ、ストレージ）の総需要が増加する。
- インフラストラクチャの複雑さが増すため、管理が難しくなる可能性がある。

### 結論
選択はアプリケーションの性質に依存します。I/O待ちやネットワーク待ちが多いアプリケーションでは、スレッド数を増やすことが有効な場合があります。一方で、アプリケーションがCPU集約型で、並列処理が可能な場合は、複数のインスタンスをデプロイすることで、より高いスループットと耐障害性を得られるかもしれません。

実際には、両方のアプローチを組み合わせることが一般的で、スケーラビリティと効率のバランスを取るために、適切なスレッド管理とインスタンスの数の調整が推奨されます。プロファイリングとパフォーマンステストを行い、アプリケーションの要件に最適な設定を見つけることが重要です。
